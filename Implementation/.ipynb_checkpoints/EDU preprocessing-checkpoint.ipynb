{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'error_indices' is the list of rejected document due to the HTTP error from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "path = r'../../data/edu/train/'\n",
    "edu_files = glob.glob(path+\"*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13802"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edu_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(path, X):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "\n",
    "def open_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "y_train = open_pickle(\"../../data/imdb/imdb_original_preprocessed_ytrain.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:len(edu_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13802"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'../../data/edu/error_indices.txt'\n",
    "error_indices = []\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "        for l in f:\n",
    "            error_indices.append(int(l.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1207"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anneke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y_train_sliced = np.delete(y_train, error_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12686"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6229\n",
      "6457\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_train_sliced==1))\n",
    "print(np.sum(y_train_sliced==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_first = y_train_sliced[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_train_first==1))\n",
    "print(np.sum(y_train_first==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "names = [int(os.path.basename(x).split('.')[0].split('_')[1]) for x in glob.glob(path+\"*.txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.asarray(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475221"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13802,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'../../data/data/human-terms/imdb-unigrams.txt'\n",
    "human_terms = []\n",
    "with open(filename, 'r') as f:\n",
    "        for l in f:\n",
    "            human_terms.append(l.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load EDU\n",
    "\n",
    "path = r'../../data/edu/train/'\n",
    "edu_files = glob.glob(path+\"*.txt\")\n",
    "\n",
    "all_edu = []\n",
    "for files in edu_files[151:]:\n",
    "    with open(files, 'r') as f:\n",
    "        for l in f:\n",
    "            all_edu.append(l.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edu = np.asarray(all_edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_edu = []\n",
    "for edu in all_edu:\n",
    "    for terms in human_terms:\n",
    "        if terms in edu:\n",
    "            selected_edu.append(edu)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50463"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awful !',\n",
       " 'awful !',\n",
       " '( insert your favorite zombie',\n",
       " 'to appreciate the subtle similarity between these two movie .',\n",
       " 'pecker is actually a funny film',\n",
       " 'judgment day ) was surprisingly good as pecker .',\n",
       " \"comes in with another great performance as pecker 's girlfriend .\",\n",
       " 'it enjoyable.there are many funny scene ,',\n",
       " 'the best was when a crown gather screaming ,',\n",
       " '10/10 hidden frontier crew.make',\n",
       " 'and some of it was so bad',\n",
       " 'it was funny .',\n",
       " 'is neither fun',\n",
       " 'and they must have used the cheapest camera',\n",
       " 'the acting was worse than me reading straight from a script .',\n",
       " 'the script was horrible ,',\n",
       " 'here were some horrible highlight of the movie .',\n",
       " \"the great `` computer hacker '' was able to get this kid 's address\",\n",
       " 'if you like really bad acting',\n",
       " 'bad camera work and an obvious plot ,',\n",
       " \"`` inspector gadget '' was one of my favorite cartoon\",\n",
       " 'i was severely disappointed ,',\n",
       " 'that made him such a fun character in the original cartoon',\n",
       " 'the movie was terrible at editing .',\n",
       " 'the direction was not bad ,',\n",
       " 'karisma kapoor has given her best role to date ,',\n",
       " 'what is most ironic is this is probably her weakest written role to date .',\n",
       " 'nana patekar was excellent as her father-in-law .',\n",
       " 'deepti naval as the mother-in-law was excellent especially in her final scene .',\n",
       " 'sanjay kapoor was all right ,',\n",
       " 'shahrukh khan was wasted in his bad boyish type role .',\n",
       " 'the song picturization and dancing is perfect for the crude lyric of the song .',\n",
       " 'only because it came at the worst moment ever .',\n",
       " 'damroo bhaje was boring and nothing to rave about .',\n",
       " 'dil ne pukara is too boring of a song',\n",
       " 'despite the poor editing ,',\n",
       " 'there are some great shot .',\n",
       " 'close-up by candle light suggest the beautiful work of the classical painter and it is fascinating to watch the painter and their student',\n",
       " 'are quite superbly authentic',\n",
       " 'the beautiful artemisia is urged by her father',\n",
       " 'to study under the great florentine artist',\n",
       " 'billowing their voluminous clothing add wonderful effects.artemisia',\n",
       " 'unfortunately',\n",
       " '( voiced by diedrich bader ) ,',\n",
       " 'as their food supply.the gags in this movie are very funny .',\n",
       " 'it was great ! !',\n",
       " 'and this was right up there as one of my favorite .',\n",
       " 'dennis quaid was great .',\n",
       " 'it is a great movie .',\n",
       " \"dr. terrible 's house of horrible ; garth marenghi 's darkplace ; the mighty boosh ; snuff box .\",\n",
       " 'where the unemployed are abused and insulted at the job center ;',\n",
       " 'but it is also great acting :',\n",
       " 'but this is the worst movie ever probably ,',\n",
       " 'the story had the most awful plot ,',\n",
       " 'i only watched it to laugh at how bad it was ,',\n",
       " 'awful simply awful .',\n",
       " 'the engagement of the dishwasher ?',\n",
       " 'the choreography is fantastic throughout ,',\n",
       " 'particularly the sympathetic monk work perfectly for the material .',\n",
       " 'with a subtle yet warming tale of a useless guy',\n",
       " 'i wanted to become a specialist in bad movie from all decade ,',\n",
       " 'to find some lost gem and uncomprehended masterpiece ,',\n",
       " 'but i did not see anything of the sort in this pastel-coloured mess .',\n",
       " 'i have not really watched many bad film before ,',\n",
       " 'this is what is called `` so bad',\n",
       " 'probably because it is so unintentionally damn funny !',\n",
       " 'there is not exactly bad acting from everyone',\n",
       " 'involved in that hot mess of a movie',\n",
       " 'geoffrey lewis looks completely pathetic as frank ,',\n",
       " 'which is an utterly stupid character .',\n",
       " 'but the movie was mostly very bad and the sad part is',\n",
       " 'beautiful actress joey wang/wong is the ghost',\n",
       " 'who collects human soul for herself/itself with the help of her beautiful ghost .',\n",
       " 'which all have incredible visual and kinetic power in their action scene .',\n",
       " 'which is lightened by the strong presence of the beautiful and good willing ghost .',\n",
       " 'and would work at their greatest power in the big screen .',\n",
       " 'they are and look gratuitous or stupid',\n",
       " 'leslie and joey should have been written with greater care',\n",
       " 'deep and genuine in order to give the story a greater power',\n",
       " 'the message about love and power of it is underlined little too much at one point',\n",
       " 'that is very irritating and sadly shows the flaw many scriptwriter tend to do',\n",
       " 'the writer should have in order to write greater scripts.otherwise ,',\n",
       " 'chinese ghost story is very beautiful and visually eath taking piece of eastern cinema ,',\n",
       " 'is very beautiful and hopefully earned some award in the hong kong film award back then .',\n",
       " 'i give chinese ghost story 7/10',\n",
       " 'this would without a doubt be almost perfect masterpiece of the fantasy genre .',\n",
       " 'annoying',\n",
       " 'the plot lacks sophistication or credibility ,',\n",
       " 'the screenplay is very good with great dialogue and character ,',\n",
       " 'the performance particularly by caine are amazing .',\n",
       " 'it certainly is a throwback to those wonderfully politically-incorrect time .',\n",
       " 'the excellent giallo `` whatever happened to solange ?',\n",
       " 'which looks great both as a glowing milieu for the nubile student and as a shadowy backdrop for one of the murder scene .',\n",
       " 'unfortunately',\n",
       " 'phantasm iii ... ..erm ... ..terrible.even',\n",
       " 'first bad sign come',\n",
       " 'also too many pointless character',\n",
       " 'funny initially',\n",
       " 'very disappointing .',\n",
       " 'the whole concept of the movie is ridiculous and absolutely implausible .']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_edu[1000:1100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "150 has been labelled.  \n",
    "397 - <br>\n",
    "228 + <br>\n",
    "595 neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
