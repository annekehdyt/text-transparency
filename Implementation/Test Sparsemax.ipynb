{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Layer\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02038496 -0.5463682  -0.7210144   0.31411332  1.3295283   0.44473293\n",
      "   0.0554226   0.7371137   0.9403496  -0.88727677]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#define a variable to hold normal random values \n",
    "normal_rv = tf.Variable( tf.truncated_normal([1,10],stddev = 1))\n",
    "\n",
    "#initialize the variable\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "#run the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op) #execute init_op\n",
    "    #print the random values that we sample\n",
    "    print (sess.run(normal_rv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseMax(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(SparseMax, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        return K.dot(x, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_input = Input(shape=(10,), dtype='float32')\n",
    "last_output = Dense(3, activation='softmax')(first_input)\n",
    "\n",
    "model = Model(first_input, last_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = np.random.rand(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=-1):\n",
    "    \"\"\"Softmax activation function.\n",
    "    # Arguments\n",
    "        x: Input tensor.\n",
    "        axis: Integer, axis along which the softmax normalization is applied.\n",
    "    # Returns\n",
    "        Tensor, output of softmax transformation.\n",
    "    # Raises\n",
    "        ValueError: In case `dim(x) == 1`.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D. '\n",
    "                         'Received input: %s' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "get = sparsemax(normal_rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2181993   0.7580004  -1.0405164  -0.9009907   0.45127302 -1.116122\n",
      "  -1.4705615   1.6638165  -0.4929908   0.31552693]]\n",
      "[[0.2771914 0.        0.        0.        0.        0.        0.\n",
      "  0.7228086 0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op) #execute init_op\n",
    "    #print the random values that we sample\n",
    "#     sess.run(get)\n",
    "    print(sess.run(normal_rv))\n",
    "    print (sess.run(get))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsemax(logits, name=None):\n",
    "    with ops.name_scope(name, \"sparsemax\", [logits]) as name:\n",
    "        logits = ops.convert_to_tensor(logits, name=\"logits\")\n",
    "        obs = array_ops.shape(logits)[0]\n",
    "        dims = array_ops.shape(logits)[1]\n",
    "\n",
    "        z = logits - math_ops.reduce_mean(logits, axis=1)[:, array_ops.newaxis]\n",
    "\n",
    "        # sort z\n",
    "        z_sorted, _ = nn.top_k(z, k=dims)\n",
    "\n",
    "        # calculate k(z)\n",
    "        z_cumsum = math_ops.cumsum(z_sorted, axis=1)\n",
    "        k = math_ops.range(\n",
    "            1, math_ops.cast(dims, logits.dtype) + 1, dtype=logits.dtype)\n",
    "        z_check = 1 + k * z_sorted > z_cumsum\n",
    "        # because the z_check vector is always [1,1,...1,0,0,...0] finding the\n",
    "        # (index + 1) of the last `1` is the same as just summing the number of 1.\n",
    "        k_z = math_ops.reduce_sum(math_ops.cast(z_check, dtypes.int32), axis=1)\n",
    "\n",
    "        # calculate tau(z)\n",
    "        indices = array_ops.stack([math_ops.range(0, obs), k_z - 1], axis=1)\n",
    "        tau_sum = array_ops.gather_nd(z_cumsum, indices)\n",
    "        tau_z = (tau_sum - 1) / math_ops.cast(k_z, logits.dtype)\n",
    "\n",
    "        # calculate p\n",
    "        return math_ops.maximum(\n",
    "            math_ops.cast(0, logits.dtype), z - tau_z[:, array_ops.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
