{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "# Merge\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "# from keras import initializations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import constraints\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(path, X):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "\n",
    "def open_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "# Preprocess\n",
    "# path = r\"C:\\Users\\Anneke\\Documents\\GitHub\\data\\imdb-sentence\"\n",
    "path = r\"C:\\Users\\Anneke Hidayat\\Documents\\GitHub\\data\\imdb-sentence\"\n",
    "X_train_sent = open_pickle(path + r\"\\imdb_sentence_xtrain.pickle\")\n",
    "X_test_sent = open_pickle(path + r\"\\imdb_sentence_xtest.pickle\")\n",
    "y_train_sent = open_pickle(path + r\"\\imdb_sentence_ytrain.pickle\")\n",
    "y_test_sent = open_pickle(path + r\"\\imdb_sentence_ytest.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anneke Hidayat\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\text.py:174: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 1000\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(X_train_sent)\n",
    "\n",
    "data = np.zeros((len(X_train_sent), MAX_SEQUENCE), dtype='int32')\n",
    "test_data = np.zeros((len(X_test_sent), MAX_SEQUENCE), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(X_train_sent):\n",
    "    wordTokens = text_to_word_sequence(doc)\n",
    "    for j, word in enumerate(wordTokens):\n",
    "        try:\n",
    "            if j<MAX_SEQUENCE and tokenizer.word_index[word]<MAX_NB_WORDS:\n",
    "                data[i,j] = tokenizer.word_index[word]\n",
    "        except KeyError as error:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.zeros((len(X_test_sent), MAX_SEQUENCE), dtype='int32')\n",
    "for i, doc in enumerate(X_test_sent):\n",
    "    wordTokens = text_to_word_sequence(doc)\n",
    "    for j, word in enumerate(wordTokens):\n",
    "        try:\n",
    "            if j<MAX_SEQUENCE and tokenizer.word_index[word]<MAX_NB_WORDS:\n",
    "                test_data[i,j] = tokenizer.word_index[word]\n",
    "        except KeyError as error:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1333 samples, validate on 667 samples\n",
      "Epoch 1/5\n",
      "1333/1333 [==============================] - 3s 3ms/step - loss: 0.6942 - acc: 0.5079 - val_loss: 0.6932 - val_acc: 0.4783\n",
      "[array([[-0.01619206, -0.011444  ,  0.01943986, ...,  0.02972713,\n",
      "         0.0262487 , -0.0285209 ],\n",
      "       [-0.03585785,  0.03127167,  0.03126559, ..., -0.00561228,\n",
      "        -0.0042346 , -0.0380744 ],\n",
      "       [-0.03778478, -0.02851261, -0.02452684, ..., -0.02501042,\n",
      "         0.04171848,  0.03500111],\n",
      "       ...,\n",
      "       [-0.02566451, -0.02490049,  0.03947111, ...,  0.05370446,\n",
      "        -0.03833213, -0.03140172],\n",
      "       [ 0.05154862, -0.00823694, -0.03150044, ..., -0.04924107,\n",
      "        -0.03610131, -0.00983203],\n",
      "       [ 0.00985876,  0.02452417,  0.01987306, ...,  0.04193798,\n",
      "         0.04032152,  0.02287592]], dtype=float32)]\n",
      "Epoch 2/5\n",
      "1333/1333 [==============================] - 2s 2ms/step - loss: 0.6914 - acc: 0.5536 - val_loss: 0.7010 - val_acc: 0.4723\n",
      "[array([[-0.00784647, -0.00788475,  0.02581005, ...,  0.02640807,\n",
      "         0.02041104, -0.03184671],\n",
      "       [-0.04306588,  0.02963333,  0.02603502, ..., -0.00113426,\n",
      "         0.0005447 , -0.03815574],\n",
      "       [-0.03144028, -0.02948077, -0.02220646, ..., -0.0223138 ,\n",
      "         0.03278462,  0.03361719],\n",
      "       ...,\n",
      "       [-0.02061657, -0.02027398,  0.04304312, ...,  0.05693802,\n",
      "        -0.0380739 , -0.02477176],\n",
      "       [ 0.05238174, -0.00865595, -0.03111481, ..., -0.04856972,\n",
      "        -0.04008432, -0.00266246],\n",
      "       [ 0.0064809 ,  0.02024006,  0.01873562, ...,  0.0373021 ,\n",
      "         0.04385125,  0.01964883]], dtype=float32)]\n",
      "Epoch 3/5\n",
      "1333/1333 [==============================] - 2s 2ms/step - loss: 0.6203 - acc: 0.6849 - val_loss: 0.5797 - val_acc: 0.6882\n",
      "[array([[-0.00233399, -0.01245174,  0.02175048, ...,  0.03606971,\n",
      "         0.01512759, -0.01763854],\n",
      "       [-0.05214366,  0.01181947,  0.01212407, ...,  0.00135063,\n",
      "         0.005525  , -0.04484727],\n",
      "       [-0.05368639, -0.0303978 , -0.04639654, ..., -0.04028406,\n",
      "         0.05366793,  0.01741955],\n",
      "       ...,\n",
      "       [-0.01057897, -0.00957504,  0.05439525, ...,  0.06729995,\n",
      "        -0.044771  , -0.01307637],\n",
      "       [ 0.06173957,  0.00109305, -0.0204926 , ..., -0.03600277,\n",
      "        -0.05044729,  0.00805869],\n",
      "       [ 0.00860635,  0.03457104,  0.0097135 , ...,  0.04693647,\n",
      "         0.03948869,  0.02111472]], dtype=float32)]\n",
      "Epoch 4/5\n",
      "1333/1333 [==============================] - 2s 2ms/step - loss: 0.4454 - acc: 0.8282 - val_loss: 0.5031 - val_acc: 0.7736\n",
      "[array([[ 0.00330606, -0.01374743,  0.02192558, ...,  0.03606461,\n",
      "         0.01457288, -0.01284256],\n",
      "       [-0.04726917,  0.00511908,  0.01586416, ...,  0.00200173,\n",
      "         0.00403445, -0.03845993],\n",
      "       [-0.04414729, -0.0262355 , -0.03797945, ..., -0.0319203 ,\n",
      "         0.04785409,  0.02105707],\n",
      "       ...,\n",
      "       [ 0.00639401, -0.01456359,  0.05846634, ...,  0.07401579,\n",
      "        -0.06193524, -0.00290955],\n",
      "       [ 0.06391864, -0.00673125, -0.00928537, ..., -0.02388219,\n",
      "        -0.06179829,  0.01934757],\n",
      "       [ 0.00811366,  0.03131602,  0.00855279, ...,  0.04955835,\n",
      "         0.04835189,  0.0263014 ]], dtype=float32)]\n",
      "Epoch 5/5\n",
      "1333/1333 [==============================] - 2s 2ms/step - loss: 0.3179 - acc: 0.8867 - val_loss: 0.6205 - val_acc: 0.7436\n",
      "[array([[ 0.00348856, -0.01807653,  0.02789423, ...,  0.02310583,\n",
      "         0.0103933 , -0.01179303],\n",
      "       [-0.04892924,  0.00265884,  0.02297566, ..., -0.00496989,\n",
      "         0.0081661 , -0.03986548],\n",
      "       [-0.04090006, -0.01898977, -0.02918246, ..., -0.02747239,\n",
      "         0.04005621,  0.02645087],\n",
      "       ...,\n",
      "       [ 0.01476137, -0.01865641,  0.06150306, ...,  0.07956489,\n",
      "        -0.06906298,  0.00379002],\n",
      "       [ 0.06557968, -0.00785183, -0.0074236 , ..., -0.02203731,\n",
      "        -0.06367368,  0.02095277],\n",
      "       [ 0.00819281,  0.01993278,  0.0068599 , ...,  0.04965481,\n",
      "         0.05866076,  0.02728082]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22d4366d160>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "max_features = 1000\n",
    "batch_size = 32\n",
    "MAX_SEQUENCE = 30\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))  \n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(model.layers[0].get_weights()))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(data, \n",
    "          y_train_sent, \n",
    "          batch_size=batch_size, \n",
    "          epochs=5,validation_data=(test_data, y_test_sent), \n",
    "          callbacks = [print_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
