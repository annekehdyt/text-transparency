{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "#### 1. use kernel_initializer = 'ones' instead of 'zeros' -> the gradients do not flow through the ReLu layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy files\n",
    "np.random.seed(42)\n",
    "EMBEDDING_SIZE = 15\n",
    "X = np.random.randint(2, size=(1000,100))\n",
    "X_val = np.random.randint(2, size=(1000,100))\n",
    "y = np.random.randint(2, size=1000)\n",
    "y_val = np.random.randint(2, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anneke\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, TimeDistributed, Embedding\n",
    "from keras.layers import Concatenate, Reshape, Lambda, Multiply, multiply, concatenate\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tanh = []\n",
    "y_tanh_val = []\n",
    "\n",
    "for i in y:\n",
    "    if i==0:\n",
    "        y_tanh.append(-1)\n",
    "    else:\n",
    "        y_tanh.append(1)\n",
    "\n",
    "\n",
    "for i in y_val:\n",
    "    if i==0:\n",
    "        y_tanh_val.append(-1)\n",
    "    else:\n",
    "        y_tanh_val.append(1)\n",
    "        \n",
    "y_tanh = np.asarray(y_tanh)  \n",
    "y_tanh_val = np.asarray(y_tanh_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# make first model\n",
    "\n",
    "def build_base_model(input_shape):\n",
    "    input_layer = Input(shape=(input_shape,))\n",
    "    tanh_output = Dense(1, activation='tanh', name='tanh_output')(input_layer)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=tanh_output)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "base_model = build_base_model(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            101         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 1)            0           input_3[0][0]                    \n",
      "                                                                 model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 1)            0           input_4[0][0]                    \n",
      "                                                                 model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            2           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            3           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 108\n",
      "Trainable params: 108\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Combined model\n",
    "\n",
    "combined_input_layer = Input(shape=(X.shape[1],))\n",
    "\n",
    "ht_1 = Input(shape=(1,))\n",
    "ht_2 = Input(shape=(1,))\n",
    "\n",
    "label_layer = base_model(combined_input_layer)\n",
    "\n",
    "dense_1 = Dense(1, activation='relu')(Multiply()([ht_1, label_layer]))\n",
    "dense_2 = Dense(1, activation='relu')(Multiply()([ht_2, label_layer]))\n",
    "\n",
    "concat = Concatenate()([dense_1, dense_2])\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "combined_model = Model(inputs=[combined_input_layer, ht_1, ht_2], outputs=output_layer)\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(loss='mse',\n",
    "            optimizer='adam',\n",
    "            metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.compile(loss='mse',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make second model\n",
    "# first, make the vector to see if it is appears \n",
    "\n",
    "# we have two terms (human-terms) for now. c1 == pos word, c2 == neg word\n",
    "# 1st column gives the feature index where that particular human_terms located\n",
    "# 2nd column gives whether it is positive/negative word\n",
    "term = [[1,1],[2,-1]]\n",
    "term = np.asarray(term)\n",
    "\n",
    "#assume X is a document vector [1,n] where n is the number of terms\n",
    "\n",
    "def np_present_by_term(X, term):\n",
    "    np_vector = np.zeros([term.shape[0],1])\n",
    "    \n",
    "    for i,(feature_index,np_term) in enumerate(term):\n",
    "        if X[feature_index] == 1:\n",
    "            np_vector[i] = np_term\n",
    "    \n",
    "    return np_vector\n",
    "\n",
    "# Assuming 'term' is a [1X2] vector\n",
    "def np_present_by_doc(X, term):\n",
    "    np_vector = np.zeros([X.shape[0],1])\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        if x[term[0]] == 1:\n",
    "            np_vector[i] = term[1]\n",
    "    \n",
    "    return np_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_1_input = np_present_by_doc(X, term[0])\n",
    "ht_2_input = np_present_by_doc(X, term[1])\n",
    "\n",
    "ht_1_input_val = np_present_by_doc(X_val, term[0])\n",
    "ht_2_input_val = np_present_by_doc(X_val, term[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 1.2658 - acc: 0.2460 - val_loss: 1.2741 - val_acc: 0.2300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 233us/step - loss: 1.2297 - acc: 0.2530 - val_loss: 1.2626 - val_acc: 0.2260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 201us/step - loss: 1.2123 - acc: 0.2490 - val_loss: 1.2414 - val_acc: 0.2110\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 234us/step - loss: 1.1941 - acc: 0.2370 - val_loss: 1.2583 - val_acc: 0.2170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 214us/step - loss: 1.1793 - acc: 0.2440 - val_loss: 1.2443 - val_acc: 0.2110\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 204us/step - loss: 1.1619 - acc: 0.2400 - val_loss: 1.2324 - val_acc: 0.1990\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 232us/step - loss: 1.1469 - acc: 0.2280 - val_loss: 1.2268 - val_acc: 0.1970\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 216us/step - loss: 1.1354 - acc: 0.2240 - val_loss: 1.2338 - val_acc: 0.1910\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 234us/step - loss: 1.1181 - acc: 0.2250 - val_loss: 1.2176 - val_acc: 0.1870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 215us/step - loss: 1.1047 - acc: 0.2220 - val_loss: 1.2072 - val_acc: 0.1780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c7f7f2f98>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(X, y_tanh, validation_data=(X_val, y_tanh_val), epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 667us/step - loss: 0.2499 - acc: 0.5070 - val_loss: 0.2500 - val_acc: 0.4830\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 334us/step - loss: 0.2496 - acc: 0.5420 - val_loss: 0.2502 - val_acc: 0.4800\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 318us/step - loss: 0.2493 - acc: 0.5380 - val_loss: 0.2505 - val_acc: 0.4710\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 334us/step - loss: 0.2491 - acc: 0.5380 - val_loss: 0.2508 - val_acc: 0.4710\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 318us/step - loss: 0.2488 - acc: 0.5340 - val_loss: 0.2510 - val_acc: 0.4700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 332us/step - loss: 0.2485 - acc: 0.5400 - val_loss: 0.2511 - val_acc: 0.4740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 327us/step - loss: 0.2482 - acc: 0.5440 - val_loss: 0.2513 - val_acc: 0.4700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 322us/step - loss: 0.2479 - acc: 0.5510 - val_loss: 0.2512 - val_acc: 0.4770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 318us/step - loss: 0.2473 - acc: 0.5480 - val_loss: 0.2516 - val_acc: 0.4710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 316us/step - loss: 0.2468 - acc: 0.5680 - val_loss: 0.2516 - val_acc: 0.4760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c11dbd9e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit([X, ht_1_input, ht_2_input], y, \n",
    "                   validation_data=([X_val, ht_1_input_val, ht_2_input_val], y_val), \n",
    "                   epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Domain Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate 16 documents\n",
    "# n1 = negative word with importance 1\n",
    "# p2 = positive word with importance 2\n",
    "# p3 = positive word with importance 3\n",
    "# n4 = negative word with importance 4\n",
    "# movie = neutral word with importance 0\n",
    "\n",
    "word_list = ['movie', 'bad', 'good', 'amazing', 'awful']\n",
    "word_weight = np.asarray([0, -1, 2, 3, -4], dtype='int32')\n",
    "word_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "num = 16\n",
    "data = np.zeros([num, len(word_list)])\n",
    "index=0\n",
    "label = []\n",
    "\n",
    "for i in range(5):\n",
    "    # get the combination\n",
    "    perm = combinations([1,2,3,4], i)\n",
    "    \n",
    "    for j in list(perm):\n",
    "        # always put neutral word\n",
    "        data[index, 0] = 1\n",
    "        \n",
    "        # if its only 1 terms\n",
    "        if i==1:\n",
    "            data[index,j] = 1\n",
    "        else:\n",
    "            for k in j:\n",
    "                data[index, k] = 1\n",
    "        \n",
    "        # calculate weights\n",
    "        \n",
    "        weights = data[index,:] * word_weight\n",
    "        label.append(np.sign(np.sum(weights)))\n",
    "        \n",
    "        index+=1\n",
    "        \n",
    "label = np.asarray(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_label = (label == 1).astype('int32')\n",
    "np_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1.,  0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, 1)            6           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 1)            0           input_13[0][0]                   \n",
      "                                                                 model_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 1)            0           input_14[0][0]                   \n",
      "                                                                 model_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 1)            0           input_15[0][0]                   \n",
      "                                                                 model_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 1)            0           input_16[0][0]                   \n",
      "                                                                 model_5[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            1           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            5           concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the network\n",
    "\n",
    "base_model = build_base_model(data.shape[1])\n",
    "\n",
    "# build second model\n",
    "\n",
    "# Combined model\n",
    "\n",
    "combined_input_layer = Input(shape=(data.shape[1],))\n",
    "\n",
    "# build the hard coded weight for human terms\n",
    "ht_1 = Input(shape=(1,))\n",
    "ht_2 = Input(shape=(1,))\n",
    "ht_3 = Input(shape=(1,))\n",
    "ht_4 = Input(shape=(1,))\n",
    "\n",
    "label_layer = base_model(combined_input_layer)\n",
    "\n",
    "# multiply and pass it into relu\n",
    "dense_1 = Dense(1, activation='relu', name='dense_1', use_bias=False, kernel_initializer='ones')(Multiply(name='multiply_1')([ht_1, label_layer]))\n",
    "dense_2 = Dense(1, activation='relu', name='dense_2', use_bias=False, kernel_initializer='ones')(Multiply(name='multiply_2')([ht_2, label_layer]))\n",
    "dense_3 = Dense(1, activation='relu', name='dense_3', use_bias=False, kernel_initializer='ones')(Multiply(name='multiply_3')([ht_3, label_layer]))\n",
    "dense_4 = Dense(1, activation='relu', name='dense_4', use_bias=False, kernel_initializer='ones')(Multiply(name='multiply_4')([ht_4, label_layer]))\n",
    "\n",
    "# concat all the result\n",
    "concat = Concatenate(name='concatenate')([dense_1, dense_2, dense_3, dense_4])\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "\n",
    "combined_model = Model(inputs=[combined_input_layer, ht_1, ht_2, ht_3, ht_4], outputs=output_layer)\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(loss='mse',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "combined_model.compile(loss='mse',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_present_by_doc(X, index, weight):\n",
    "    np_vector = np.zeros([X.shape[0],1])\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        if x[index] == 1:\n",
    "            np_vector[i] = np.sign(weight)\n",
    "    \n",
    "    return np_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to generate the ht's\n",
    "\n",
    "ht_1_input = np_present_by_doc(data, 1, word_weight[1])\n",
    "ht_2_input = np_present_by_doc(data, 2, word_weight[2])\n",
    "ht_3_input = np_present_by_doc(data, 3, word_weight[3])\n",
    "ht_4_input = np_present_by_doc(data, 4, word_weight[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_1_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_input = np.hstack([ht_1_input, ht_2_input, ht_3_input, ht_4_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.],\n",
       "       [-1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., -1.],\n",
       "       [-1.,  1.,  0.,  0.],\n",
       "       [-1.,  0.,  1.,  0.],\n",
       "       [-1.,  0.,  0., -1.],\n",
       "       [ 0.,  1.,  1.,  0.],\n",
       "       [ 0.,  1.,  0., -1.],\n",
       "       [ 0.,  0.,  1., -1.],\n",
       "       [-1.,  1.,  1.,  0.],\n",
       "       [-1.,  1.,  0., -1.],\n",
       "       [-1.,  0.,  1., -1.],\n",
       "       [ 0.,  1.,  1., -1.],\n",
       "       [-1.,  1.,  1., -1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0.] [0.]\n",
      "[1. 1. 0. 0. 0.] [0.]\n",
      "[1. 0. 1. 0. 0.] [0.]\n",
      "[1. 0. 0. 1. 0.] [0.]\n",
      "[1. 0. 0. 0. 1.] [-1.]\n",
      "[1. 1. 1. 0. 0.] [0.]\n",
      "[1. 1. 0. 1. 0.] [0.]\n",
      "[1. 1. 0. 0. 1.] [-1.]\n",
      "[1. 0. 1. 1. 0.] [0.]\n",
      "[1. 0. 1. 0. 1.] [-1.]\n",
      "[1. 0. 0. 1. 1.] [-1.]\n",
      "[1. 1. 1. 1. 0.] [0.]\n",
      "[1. 1. 1. 0. 1.] [-1.]\n",
      "[1. 1. 0. 1. 1.] [-1.]\n",
      "[1. 0. 1. 1. 1.] [-1.]\n",
      "[1. 1. 1. 1. 1.] [-1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ht_1_input)):\n",
    "    print(data[i], ht_4_input[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adjust y to -> [-1, 1]\n",
    "# label_tanh = []\n",
    "# for i in label:\n",
    "#     if i==0:\n",
    "#         label_tanh.append(-1)\n",
    "#     else:\n",
    "#         label_tanh.append(1)\n",
    "# label_tanh = np.asarray(label_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 0s - loss: 1.6720 - acc: 0.2857\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1.6626 - acc: 0.2857\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 1.6542 - acc: 0.2857\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 1.6506 - acc: 0.2857\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 1.6373 - acc: 0.2857\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 1.6292 - acc: 0.2857\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 1.6209 - acc: 0.2857\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 1.6115 - acc: 0.2143\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 1.6051 - acc: 0.2143\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 1.5915 - acc: 0.2143\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 1.5823 - acc: 0.2143\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 1.5725 - acc: 0.2143\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 1.5630 - acc: 0.2143\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 1.5550 - acc: 0.2143\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 1.5402 - acc: 0.2143\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 1.5340 - acc: 0.2143\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 1.5209 - acc: 0.2143\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 1.5072 - acc: 0.2143\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 1.4968 - acc: 0.2143\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 1.4855 - acc: 0.2143\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 1.4728 - acc: 0.2143\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 1.4615 - acc: 0.2143\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 1.4500 - acc: 0.2143\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 1.4375 - acc: 0.2143\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 1.4271 - acc: 0.2143\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 1.4130 - acc: 0.2143\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 1.3980 - acc: 0.2143\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 1.3872 - acc: 0.2143\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 1.3744 - acc: 0.2143\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 1.3630 - acc: 0.2143\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 1.3491 - acc: 0.2143\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 1.3375 - acc: 0.2143\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 1.3234 - acc: 0.2143\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 1.3155 - acc: 0.2143\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 1.2970 - acc: 0.2143\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 1.2849 - acc: 0.1429\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 1.2733 - acc: 0.1429\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 1.2616 - acc: 0.1429\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 1.2480 - acc: 0.1429\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 1.2350 - acc: 0.1429\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 1.2228 - acc: 0.1429\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 1.2129 - acc: 0.1429\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 1.1988 - acc: 0.1429\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 1.1870 - acc: 0.1429\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 1.1737 - acc: 0.1429\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 1.1639 - acc: 0.1429\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 1.1523 - acc: 0.1429\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 1.1413 - acc: 0.1429\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 1.1286 - acc: 0.1429\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 1.1181 - acc: 0.1429\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 1.1075 - acc: 0.1429\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 1.0995 - acc: 0.1429\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 1.0865 - acc: 0.1429\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 1.0762 - acc: 0.0714\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 1.0656 - acc: 0.0714\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 1.0545 - acc: 0.0714\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 1.0453 - acc: 0.0714\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 1.0388 - acc: 0.0714\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 1.0299 - acc: 0.0714\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 1.0153 - acc: 0.0714\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 1.0074 - acc: 0.0714\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 0.9973 - acc: 0.0714\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 0.9892 - acc: 0.0714\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.9795 - acc: 0.0714\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.9711 - acc: 0.0714\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.9630 - acc: 0.0714\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.9537 - acc: 0.0714\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 0.9457 - acc: 0.0714\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 0.9377 - acc: 0.0714\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 0.9304 - acc: 0.0714\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 0.9212 - acc: 0.0714\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 0.9126 - acc: 0.0714\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 0.9064 - acc: 0.0714\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 0.8967 - acc: 0.0714\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.8896 - acc: 0.0714\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.8822 - acc: 0.0714\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.8767 - acc: 0.0714\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.8670 - acc: 0.0714\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 0.8597 - acc: 0.0714\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.8533 - acc: 0.0714\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 0.8461 - acc: 0.0714\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.8391 - acc: 0.0714\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.8326 - acc: 0.0714\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.8253 - acc: 0.0714\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 0.8197 - acc: 0.0714\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 0.8117 - acc: 0.0714\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 0.8075 - acc: 0.0714\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 0.8000 - acc: 0.0714\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 0.7933 - acc: 0.0714\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 0.7873 - acc: 0.0714\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 0.7806 - acc: 0.0714\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 0.7752 - acc: 0.0714\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 0.7674 - acc: 0.0714\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 0.7611 - acc: 0.0714\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 0.7575 - acc: 0.0714\n",
      "Epoch 96/1000\n",
      " - 0s - loss: 0.7493 - acc: 0.0714\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 0.7453 - acc: 0.0714\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.7376 - acc: 0.0714\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 0.7323 - acc: 0.0714\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 0.7268 - acc: 0.0714\n",
      "Epoch 101/1000\n",
      " - 0s - loss: 0.7211 - acc: 0.0714\n",
      "Epoch 102/1000\n",
      " - 0s - loss: 0.7157 - acc: 0.0714\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 0.7104 - acc: 0.0714\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 0.7051 - acc: 0.1429\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 0.6986 - acc: 0.1429\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 0.6942 - acc: 0.1429\n",
      "Epoch 107/1000\n",
      " - 0s - loss: 0.6884 - acc: 0.1429\n",
      "Epoch 108/1000\n",
      " - 0s - loss: 0.6832 - acc: 0.1429\n",
      "Epoch 109/1000\n",
      " - 0s - loss: 0.6783 - acc: 0.1429\n",
      "Epoch 110/1000\n",
      " - 0s - loss: 0.6736 - acc: 0.2143\n",
      "Epoch 111/1000\n",
      " - 0s - loss: 0.6678 - acc: 0.2143\n",
      "Epoch 112/1000\n",
      " - 0s - loss: 0.6632 - acc: 0.2143\n",
      "Epoch 113/1000\n",
      " - 0s - loss: 0.6582 - acc: 0.2143\n",
      "Epoch 114/1000\n",
      " - 0s - loss: 0.6528 - acc: 0.2143\n",
      "Epoch 115/1000\n",
      " - 0s - loss: 0.6477 - acc: 0.2143\n",
      "Epoch 116/1000\n",
      " - 0s - loss: 0.6431 - acc: 0.2143\n",
      "Epoch 117/1000\n",
      " - 0s - loss: 0.6374 - acc: 0.2143\n",
      "Epoch 118/1000\n",
      " - 0s - loss: 0.6330 - acc: 0.2143\n",
      "Epoch 119/1000\n",
      " - 0s - loss: 0.6290 - acc: 0.2143\n",
      "Epoch 120/1000\n",
      " - 0s - loss: 0.6239 - acc: 0.2857\n",
      "Epoch 121/1000\n",
      " - 0s - loss: 0.6197 - acc: 0.2857\n",
      "Epoch 122/1000\n",
      " - 0s - loss: 0.6146 - acc: 0.2857\n",
      "Epoch 123/1000\n",
      " - 0s - loss: 0.6112 - acc: 0.2857\n",
      "Epoch 124/1000\n",
      " - 0s - loss: 0.6061 - acc: 0.2857\n",
      "Epoch 125/1000\n",
      " - 0s - loss: 0.6023 - acc: 0.2857\n",
      "Epoch 126/1000\n",
      " - 0s - loss: 0.5968 - acc: 0.2857\n",
      "Epoch 127/1000\n",
      " - 0s - loss: 0.5931 - acc: 0.2857\n",
      "Epoch 128/1000\n",
      " - 0s - loss: 0.5886 - acc: 0.2857\n",
      "Epoch 129/1000\n",
      " - 0s - loss: 0.5857 - acc: 0.2857\n",
      "Epoch 130/1000\n",
      " - 0s - loss: 0.5801 - acc: 0.2857\n",
      "Epoch 131/1000\n",
      " - 0s - loss: 0.5762 - acc: 0.2857\n",
      "Epoch 132/1000\n",
      " - 0s - loss: 0.5714 - acc: 0.2857\n",
      "Epoch 133/1000\n",
      " - 0s - loss: 0.5675 - acc: 0.2857\n",
      "Epoch 134/1000\n",
      " - 0s - loss: 0.5635 - acc: 0.2857\n",
      "Epoch 135/1000\n",
      " - 0s - loss: 0.5603 - acc: 0.2857\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.5563 - acc: 0.2857\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.5526 - acc: 0.2857\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.5478 - acc: 0.2857\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.5449 - acc: 0.2857\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.5404 - acc: 0.2857\n",
      "Epoch 141/1000\n",
      " - 0s - loss: 0.5377 - acc: 0.2857\n",
      "Epoch 142/1000\n",
      " - 0s - loss: 0.5342 - acc: 0.2857\n",
      "Epoch 143/1000\n",
      " - 0s - loss: 0.5292 - acc: 0.2857\n",
      "Epoch 144/1000\n",
      " - 0s - loss: 0.5262 - acc: 0.2857\n",
      "Epoch 145/1000\n",
      " - 0s - loss: 0.5223 - acc: 0.2857\n",
      "Epoch 146/1000\n",
      " - 0s - loss: 0.5187 - acc: 0.2857\n",
      "Epoch 147/1000\n",
      " - 0s - loss: 0.5147 - acc: 0.2857\n",
      "Epoch 148/1000\n",
      " - 0s - loss: 0.5115 - acc: 0.2857\n",
      "Epoch 149/1000\n",
      " - 0s - loss: 0.5087 - acc: 0.2857\n",
      "Epoch 150/1000\n",
      " - 0s - loss: 0.5055 - acc: 0.2857\n",
      "Epoch 151/1000\n",
      " - 0s - loss: 0.5016 - acc: 0.2857\n",
      "Epoch 152/1000\n",
      " - 0s - loss: 0.4982 - acc: 0.2857\n",
      "Epoch 153/1000\n",
      " - 0s - loss: 0.4946 - acc: 0.2857\n",
      "Epoch 154/1000\n",
      " - 0s - loss: 0.4924 - acc: 0.2857\n",
      "Epoch 155/1000\n",
      " - 0s - loss: 0.4878 - acc: 0.2857\n",
      "Epoch 156/1000\n",
      " - 0s - loss: 0.4854 - acc: 0.2857\n",
      "Epoch 157/1000\n",
      " - 0s - loss: 0.4827 - acc: 0.3571\n",
      "Epoch 158/1000\n",
      " - 0s - loss: 0.4791 - acc: 0.4286\n",
      "Epoch 159/1000\n",
      " - 0s - loss: 0.4770 - acc: 0.4286\n",
      "Epoch 160/1000\n",
      " - 0s - loss: 0.4725 - acc: 0.4286\n",
      "Epoch 161/1000\n",
      " - 0s - loss: 0.4696 - acc: 0.4286\n",
      "Epoch 162/1000\n",
      " - 0s - loss: 0.4669 - acc: 0.4286\n",
      "Epoch 163/1000\n",
      " - 0s - loss: 0.4643 - acc: 0.4286\n",
      "Epoch 164/1000\n",
      " - 0s - loss: 0.4610 - acc: 0.4286\n",
      "Epoch 165/1000\n",
      " - 0s - loss: 0.4579 - acc: 0.4286\n",
      "Epoch 166/1000\n",
      " - 0s - loss: 0.4549 - acc: 0.4286\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.4524 - acc: 0.4286\n",
      "Epoch 168/1000\n",
      " - 0s - loss: 0.4489 - acc: 0.4286\n",
      "Epoch 169/1000\n",
      " - 0s - loss: 0.4465 - acc: 0.4286\n",
      "Epoch 170/1000\n",
      " - 0s - loss: 0.4436 - acc: 0.4286\n",
      "Epoch 171/1000\n",
      " - 0s - loss: 0.4408 - acc: 0.4286\n",
      "Epoch 172/1000\n",
      " - 0s - loss: 0.4390 - acc: 0.4286\n",
      "Epoch 173/1000\n",
      " - 0s - loss: 0.4362 - acc: 0.4286\n",
      "Epoch 174/1000\n",
      " - 0s - loss: 0.4325 - acc: 0.4286\n",
      "Epoch 175/1000\n",
      " - 0s - loss: 0.4303 - acc: 0.4286\n",
      "Epoch 176/1000\n",
      " - 0s - loss: 0.4276 - acc: 0.4286\n",
      "Epoch 177/1000\n",
      " - 0s - loss: 0.4249 - acc: 0.4286\n",
      "Epoch 178/1000\n",
      " - 0s - loss: 0.4223 - acc: 0.4286\n",
      "Epoch 179/1000\n",
      " - 0s - loss: 0.4202 - acc: 0.4286\n",
      "Epoch 180/1000\n",
      " - 0s - loss: 0.4177 - acc: 0.4286\n",
      "Epoch 181/1000\n",
      " - 0s - loss: 0.4151 - acc: 0.4286\n",
      "Epoch 182/1000\n",
      " - 0s - loss: 0.4130 - acc: 0.4286\n",
      "Epoch 183/1000\n",
      " - 0s - loss: 0.4101 - acc: 0.4286\n",
      "Epoch 184/1000\n",
      " - 0s - loss: 0.4076 - acc: 0.4286\n",
      "Epoch 185/1000\n",
      " - 0s - loss: 0.4054 - acc: 0.4286\n",
      "Epoch 186/1000\n",
      " - 0s - loss: 0.4031 - acc: 0.4286\n",
      "Epoch 187/1000\n",
      " - 0s - loss: 0.4007 - acc: 0.4286\n",
      "Epoch 188/1000\n",
      " - 0s - loss: 0.3989 - acc: 0.4286\n",
      "Epoch 189/1000\n",
      " - 0s - loss: 0.3963 - acc: 0.4286\n",
      "Epoch 190/1000\n",
      " - 0s - loss: 0.3940 - acc: 0.4286\n",
      "Epoch 191/1000\n",
      " - 0s - loss: 0.3917 - acc: 0.4286\n",
      "Epoch 192/1000\n",
      " - 0s - loss: 0.3898 - acc: 0.4286\n",
      "Epoch 193/1000\n",
      " - 0s - loss: 0.3879 - acc: 0.4286\n",
      "Epoch 194/1000\n",
      " - 0s - loss: 0.3857 - acc: 0.4286\n",
      "Epoch 195/1000\n",
      " - 0s - loss: 0.3837 - acc: 0.4286\n",
      "Epoch 196/1000\n",
      " - 0s - loss: 0.3812 - acc: 0.4286\n",
      "Epoch 197/1000\n",
      " - 0s - loss: 0.3790 - acc: 0.4286\n",
      "Epoch 198/1000\n",
      " - 0s - loss: 0.3767 - acc: 0.4286\n",
      "Epoch 199/1000\n",
      " - 0s - loss: 0.3750 - acc: 0.4286\n",
      "Epoch 200/1000\n",
      " - 0s - loss: 0.3727 - acc: 0.4286\n",
      "Epoch 201/1000\n",
      " - 0s - loss: 0.3710 - acc: 0.4286\n",
      "Epoch 202/1000\n",
      " - 0s - loss: 0.3692 - acc: 0.4286\n",
      "Epoch 203/1000\n",
      " - 0s - loss: 0.3669 - acc: 0.4286\n",
      "Epoch 204/1000\n",
      " - 0s - loss: 0.3660 - acc: 0.4286\n",
      "Epoch 205/1000\n",
      " - 0s - loss: 0.3630 - acc: 0.4286\n",
      "Epoch 206/1000\n",
      " - 0s - loss: 0.3618 - acc: 0.4286\n",
      "Epoch 207/1000\n",
      " - 0s - loss: 0.3592 - acc: 0.4286\n",
      "Epoch 208/1000\n",
      " - 0s - loss: 0.3574 - acc: 0.4286\n",
      "Epoch 209/1000\n",
      " - 0s - loss: 0.3554 - acc: 0.4286\n",
      "Epoch 210/1000\n",
      " - 0s - loss: 0.3547 - acc: 0.4286\n",
      "Epoch 211/1000\n",
      " - 0s - loss: 0.3532 - acc: 0.4286\n",
      "Epoch 212/1000\n",
      " - 0s - loss: 0.3500 - acc: 0.4286\n",
      "Epoch 213/1000\n",
      " - 0s - loss: 0.3485 - acc: 0.4286\n",
      "Epoch 214/1000\n",
      " - 0s - loss: 0.3465 - acc: 0.4286\n",
      "Epoch 215/1000\n",
      " - 0s - loss: 0.3444 - acc: 0.4286\n",
      "Epoch 216/1000\n",
      " - 0s - loss: 0.3431 - acc: 0.4286\n",
      "Epoch 217/1000\n",
      " - 0s - loss: 0.3412 - acc: 0.4286\n",
      "Epoch 218/1000\n",
      " - 0s - loss: 0.3396 - acc: 0.4286\n",
      "Epoch 219/1000\n",
      " - 0s - loss: 0.3375 - acc: 0.4286\n",
      "Epoch 220/1000\n",
      " - 0s - loss: 0.3360 - acc: 0.4286\n",
      "Epoch 221/1000\n",
      " - 0s - loss: 0.3345 - acc: 0.4286\n",
      "Epoch 222/1000\n",
      " - 0s - loss: 0.3325 - acc: 0.4286\n",
      "Epoch 223/1000\n",
      " - 0s - loss: 0.3312 - acc: 0.4286\n",
      "Epoch 224/1000\n",
      " - 0s - loss: 0.3293 - acc: 0.4286\n",
      "Epoch 225/1000\n",
      " - 0s - loss: 0.3277 - acc: 0.4286\n",
      "Epoch 226/1000\n",
      " - 0s - loss: 0.3265 - acc: 0.4286\n",
      "Epoch 227/1000\n",
      " - 0s - loss: 0.3246 - acc: 0.4286\n",
      "Epoch 228/1000\n",
      " - 0s - loss: 0.3234 - acc: 0.4286\n",
      "Epoch 229/1000\n",
      " - 0s - loss: 0.3215 - acc: 0.4286\n",
      "Epoch 230/1000\n",
      " - 0s - loss: 0.3200 - acc: 0.4286\n",
      "Epoch 231/1000\n",
      " - 0s - loss: 0.3184 - acc: 0.4286\n",
      "Epoch 232/1000\n",
      " - 0s - loss: 0.3172 - acc: 0.4286\n",
      "Epoch 233/1000\n",
      " - 0s - loss: 0.3159 - acc: 0.4286\n",
      "Epoch 234/1000\n",
      " - 0s - loss: 0.3140 - acc: 0.4286\n",
      "Epoch 235/1000\n",
      " - 0s - loss: 0.3128 - acc: 0.4286\n",
      "Epoch 236/1000\n",
      " - 0s - loss: 0.3109 - acc: 0.4286\n",
      "Epoch 237/1000\n",
      " - 0s - loss: 0.3108 - acc: 0.4286\n",
      "Epoch 238/1000\n",
      " - 0s - loss: 0.3080 - acc: 0.4286\n",
      "Epoch 239/1000\n",
      " - 0s - loss: 0.3078 - acc: 0.4286\n",
      "Epoch 240/1000\n",
      " - 0s - loss: 0.3054 - acc: 0.4286\n",
      "Epoch 241/1000\n",
      " - 0s - loss: 0.3042 - acc: 0.4286\n",
      "Epoch 242/1000\n",
      " - 0s - loss: 0.3033 - acc: 0.4286\n",
      "Epoch 243/1000\n",
      " - 0s - loss: 0.3020 - acc: 0.4286\n",
      "Epoch 244/1000\n",
      " - 0s - loss: 0.3009 - acc: 0.4286\n",
      "Epoch 245/1000\n",
      " - 0s - loss: 0.2988 - acc: 0.4286\n",
      "Epoch 246/1000\n",
      " - 0s - loss: 0.2975 - acc: 0.4286\n",
      "Epoch 247/1000\n",
      " - 0s - loss: 0.2961 - acc: 0.4286\n",
      "Epoch 248/1000\n",
      " - 0s - loss: 0.2949 - acc: 0.4286\n",
      "Epoch 249/1000\n",
      " - 0s - loss: 0.2938 - acc: 0.4286\n",
      "Epoch 250/1000\n",
      " - 0s - loss: 0.2922 - acc: 0.4286\n",
      "Epoch 251/1000\n",
      " - 0s - loss: 0.2909 - acc: 0.4286\n",
      "Epoch 252/1000\n",
      " - 0s - loss: 0.2896 - acc: 0.4286\n",
      "Epoch 253/1000\n",
      " - 0s - loss: 0.2883 - acc: 0.4286\n",
      "Epoch 254/1000\n",
      " - 0s - loss: 0.2870 - acc: 0.4286\n",
      "Epoch 255/1000\n",
      " - 0s - loss: 0.2858 - acc: 0.4286\n",
      "Epoch 256/1000\n",
      " - 0s - loss: 0.2845 - acc: 0.4286\n",
      "Epoch 257/1000\n",
      " - 0s - loss: 0.2839 - acc: 0.4286\n",
      "Epoch 258/1000\n",
      " - 0s - loss: 0.2819 - acc: 0.4286\n",
      "Epoch 259/1000\n",
      " - 0s - loss: 0.2811 - acc: 0.4286\n",
      "Epoch 260/1000\n",
      " - 0s - loss: 0.2802 - acc: 0.4286\n",
      "Epoch 261/1000\n",
      " - 0s - loss: 0.2795 - acc: 0.4286\n",
      "Epoch 262/1000\n",
      " - 0s - loss: 0.2774 - acc: 0.4286\n",
      "Epoch 263/1000\n",
      " - 0s - loss: 0.2761 - acc: 0.4286\n",
      "Epoch 264/1000\n",
      " - 0s - loss: 0.2750 - acc: 0.4286\n",
      "Epoch 265/1000\n",
      " - 0s - loss: 0.2746 - acc: 0.4286\n",
      "Epoch 266/1000\n",
      " - 0s - loss: 0.2728 - acc: 0.4286\n",
      "Epoch 267/1000\n",
      " - 0s - loss: 0.2714 - acc: 0.4286\n",
      "Epoch 268/1000\n",
      " - 0s - loss: 0.2703 - acc: 0.4286\n",
      "Epoch 269/1000\n",
      " - 0s - loss: 0.2699 - acc: 0.4286\n",
      "Epoch 270/1000\n",
      " - 0s - loss: 0.2681 - acc: 0.5000\n",
      "Epoch 271/1000\n",
      " - 0s - loss: 0.2677 - acc: 0.5000\n",
      "Epoch 272/1000\n",
      " - 0s - loss: 0.2663 - acc: 0.5000\n",
      "Epoch 273/1000\n",
      " - 0s - loss: 0.2651 - acc: 0.5000\n",
      "Epoch 274/1000\n",
      " - 0s - loss: 0.2638 - acc: 0.5000\n",
      "Epoch 275/1000\n",
      " - 0s - loss: 0.2625 - acc: 0.5714\n",
      "Epoch 276/1000\n",
      " - 0s - loss: 0.2616 - acc: 0.5714\n",
      "Epoch 277/1000\n",
      " - 0s - loss: 0.2608 - acc: 0.5714\n",
      "Epoch 278/1000\n",
      " - 0s - loss: 0.2595 - acc: 0.5714\n",
      "Epoch 279/1000\n",
      " - 0s - loss: 0.2586 - acc: 0.5714\n",
      "Epoch 280/1000\n",
      " - 0s - loss: 0.2584 - acc: 0.5714\n",
      "Epoch 281/1000\n",
      " - 0s - loss: 0.2564 - acc: 0.5714\n",
      "Epoch 282/1000\n",
      " - 0s - loss: 0.2554 - acc: 0.5714\n",
      "Epoch 283/1000\n",
      " - 0s - loss: 0.2543 - acc: 0.5714\n",
      "Epoch 284/1000\n",
      " - 0s - loss: 0.2534 - acc: 0.5714\n",
      "Epoch 285/1000\n",
      " - 0s - loss: 0.2523 - acc: 0.5714\n",
      "Epoch 286/1000\n",
      " - 0s - loss: 0.2514 - acc: 0.5714\n",
      "Epoch 287/1000\n",
      " - 0s - loss: 0.2504 - acc: 0.5714\n",
      "Epoch 288/1000\n",
      " - 0s - loss: 0.2496 - acc: 0.5714\n",
      "Epoch 289/1000\n",
      " - 0s - loss: 0.2484 - acc: 0.5714\n",
      "Epoch 290/1000\n",
      " - 0s - loss: 0.2475 - acc: 0.5714\n",
      "Epoch 291/1000\n",
      " - 0s - loss: 0.2465 - acc: 0.5714\n",
      "Epoch 292/1000\n",
      " - 0s - loss: 0.2457 - acc: 0.5714\n",
      "Epoch 293/1000\n",
      " - 0s - loss: 0.2448 - acc: 0.5714\n",
      "Epoch 294/1000\n",
      " - 0s - loss: 0.2440 - acc: 0.5714\n",
      "Epoch 295/1000\n",
      " - 0s - loss: 0.2429 - acc: 0.5714\n",
      "Epoch 296/1000\n",
      " - 0s - loss: 0.2423 - acc: 0.5714\n",
      "Epoch 297/1000\n",
      " - 0s - loss: 0.2410 - acc: 0.5714\n",
      "Epoch 298/1000\n",
      " - 0s - loss: 0.2405 - acc: 0.5714\n",
      "Epoch 299/1000\n",
      " - 0s - loss: 0.2392 - acc: 0.5714\n",
      "Epoch 300/1000\n",
      " - 0s - loss: 0.2384 - acc: 0.5714\n",
      "Epoch 301/1000\n",
      " - 0s - loss: 0.2373 - acc: 0.5714\n",
      "Epoch 302/1000\n",
      " - 0s - loss: 0.2362 - acc: 0.5714\n",
      "Epoch 303/1000\n",
      " - 0s - loss: 0.2354 - acc: 0.5714\n",
      "Epoch 304/1000\n",
      " - 0s - loss: 0.2344 - acc: 0.5714\n",
      "Epoch 305/1000\n",
      " - 0s - loss: 0.2338 - acc: 0.5714\n",
      "Epoch 306/1000\n",
      " - 0s - loss: 0.2333 - acc: 0.5714\n",
      "Epoch 307/1000\n",
      " - 0s - loss: 0.2320 - acc: 0.5714\n",
      "Epoch 308/1000\n",
      " - 0s - loss: 0.2311 - acc: 0.5714\n",
      "Epoch 309/1000\n",
      " - 0s - loss: 0.2307 - acc: 0.5714\n",
      "Epoch 310/1000\n",
      " - 0s - loss: 0.2295 - acc: 0.5714\n",
      "Epoch 311/1000\n",
      " - 0s - loss: 0.2289 - acc: 0.5714\n",
      "Epoch 312/1000\n",
      " - 0s - loss: 0.2277 - acc: 0.5714\n",
      "Epoch 313/1000\n",
      " - 0s - loss: 0.2273 - acc: 0.5714\n",
      "Epoch 314/1000\n",
      " - 0s - loss: 0.2260 - acc: 0.5714\n",
      "Epoch 315/1000\n",
      " - 0s - loss: 0.2264 - acc: 0.5714\n",
      "Epoch 316/1000\n",
      " - 0s - loss: 0.2249 - acc: 0.5714\n",
      "Epoch 317/1000\n",
      " - 0s - loss: 0.2238 - acc: 0.5714\n",
      "Epoch 318/1000\n",
      " - 0s - loss: 0.2229 - acc: 0.5714\n",
      "Epoch 319/1000\n",
      " - 0s - loss: 0.2220 - acc: 0.5714\n",
      "Epoch 320/1000\n",
      " - 0s - loss: 0.2215 - acc: 0.5714\n",
      "Epoch 321/1000\n",
      " - 0s - loss: 0.2209 - acc: 0.5714\n",
      "Epoch 322/1000\n",
      " - 0s - loss: 0.2193 - acc: 0.5714\n",
      "Epoch 323/1000\n",
      " - 0s - loss: 0.2193 - acc: 0.5714\n",
      "Epoch 324/1000\n",
      " - 0s - loss: 0.2181 - acc: 0.5714\n",
      "Epoch 325/1000\n",
      " - 0s - loss: 0.2172 - acc: 0.5714\n",
      "Epoch 326/1000\n",
      " - 0s - loss: 0.2168 - acc: 0.5714\n",
      "Epoch 327/1000\n",
      " - 0s - loss: 0.2164 - acc: 0.5714\n",
      "Epoch 328/1000\n",
      " - 0s - loss: 0.2147 - acc: 0.5714\n",
      "Epoch 329/1000\n",
      " - 0s - loss: 0.2143 - acc: 0.5714\n",
      "Epoch 330/1000\n",
      " - 0s - loss: 0.2131 - acc: 0.5714\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2123 - acc: 0.5714\n",
      "Epoch 332/1000\n",
      " - 0s - loss: 0.2118 - acc: 0.5714\n",
      "Epoch 333/1000\n",
      " - 0s - loss: 0.2112 - acc: 0.5714\n",
      "Epoch 334/1000\n",
      " - 0s - loss: 0.2103 - acc: 0.5714\n",
      "Epoch 335/1000\n",
      " - 0s - loss: 0.2095 - acc: 0.5714\n",
      "Epoch 336/1000\n",
      " - 0s - loss: 0.2087 - acc: 0.5714\n",
      "Epoch 337/1000\n",
      " - 0s - loss: 0.2084 - acc: 0.5714\n",
      "Epoch 338/1000\n",
      " - 0s - loss: 0.2072 - acc: 0.5714\n",
      "Epoch 339/1000\n",
      " - 0s - loss: 0.2064 - acc: 0.5714\n",
      "Epoch 340/1000\n",
      " - 0s - loss: 0.2062 - acc: 0.5714\n",
      "Epoch 341/1000\n",
      " - 0s - loss: 0.2052 - acc: 0.5714\n",
      "Epoch 342/1000\n",
      " - 0s - loss: 0.2046 - acc: 0.5714\n",
      "Epoch 343/1000\n",
      " - 0s - loss: 0.2036 - acc: 0.5714\n",
      "Epoch 344/1000\n",
      " - 0s - loss: 0.2029 - acc: 0.5714\n",
      "Epoch 345/1000\n",
      " - 0s - loss: 0.2024 - acc: 0.5714\n",
      "Epoch 346/1000\n",
      " - 0s - loss: 0.2016 - acc: 0.5714\n",
      "Epoch 347/1000\n",
      " - 0s - loss: 0.2012 - acc: 0.5714\n",
      "Epoch 348/1000\n",
      " - 0s - loss: 0.2000 - acc: 0.5714\n",
      "Epoch 349/1000\n",
      " - 0s - loss: 0.1995 - acc: 0.5714\n",
      "Epoch 350/1000\n",
      " - 0s - loss: 0.1993 - acc: 0.5714\n",
      "Epoch 351/1000\n",
      " - 0s - loss: 0.1981 - acc: 0.5714\n",
      "Epoch 352/1000\n",
      " - 0s - loss: 0.1975 - acc: 0.5714\n",
      "Epoch 353/1000\n",
      " - 0s - loss: 0.1968 - acc: 0.5714\n",
      "Epoch 354/1000\n",
      " - 0s - loss: 0.1960 - acc: 0.5714\n",
      "Epoch 355/1000\n",
      " - 0s - loss: 0.1954 - acc: 0.5714\n",
      "Epoch 356/1000\n",
      " - 0s - loss: 0.1950 - acc: 0.5714\n",
      "Epoch 357/1000\n",
      " - 0s - loss: 0.1945 - acc: 0.5714\n",
      "Epoch 358/1000\n",
      " - 0s - loss: 0.1932 - acc: 0.5714\n",
      "Epoch 359/1000\n",
      " - 0s - loss: 0.1927 - acc: 0.5714\n",
      "Epoch 360/1000\n",
      " - 0s - loss: 0.1921 - acc: 0.5714\n",
      "Epoch 361/1000\n",
      " - 0s - loss: 0.1917 - acc: 0.5714\n",
      "Epoch 362/1000\n",
      " - 0s - loss: 0.1908 - acc: 0.5714\n",
      "Epoch 363/1000\n",
      " - 0s - loss: 0.1903 - acc: 0.5714\n",
      "Epoch 364/1000\n",
      " - 0s - loss: 0.1895 - acc: 0.5714\n",
      "Epoch 365/1000\n",
      " - 0s - loss: 0.1893 - acc: 0.5714\n",
      "Epoch 366/1000\n",
      " - 0s - loss: 0.1883 - acc: 0.5714\n",
      "Epoch 367/1000\n",
      " - 0s - loss: 0.1876 - acc: 0.5714\n",
      "Epoch 368/1000\n",
      " - 0s - loss: 0.1869 - acc: 0.5714\n",
      "Epoch 369/1000\n",
      " - 0s - loss: 0.1866 - acc: 0.5714\n",
      "Epoch 370/1000\n",
      " - 0s - loss: 0.1858 - acc: 0.5714\n",
      "Epoch 371/1000\n",
      " - 0s - loss: 0.1850 - acc: 0.5714\n",
      "Epoch 372/1000\n",
      " - 0s - loss: 0.1844 - acc: 0.5714\n",
      "Epoch 373/1000\n",
      " - 0s - loss: 0.1843 - acc: 0.5714\n",
      "Epoch 374/1000\n",
      " - 0s - loss: 0.1837 - acc: 0.5714\n",
      "Epoch 375/1000\n",
      " - 0s - loss: 0.1824 - acc: 0.5714\n",
      "Epoch 376/1000\n",
      " - 0s - loss: 0.1819 - acc: 0.5714\n",
      "Epoch 377/1000\n",
      " - 0s - loss: 0.1816 - acc: 0.5714\n",
      "Epoch 378/1000\n",
      " - 0s - loss: 0.1808 - acc: 0.5714\n",
      "Epoch 379/1000\n",
      " - 0s - loss: 0.1799 - acc: 0.5714\n",
      "Epoch 380/1000\n",
      " - 0s - loss: 0.1797 - acc: 0.5714\n",
      "Epoch 381/1000\n",
      " - 0s - loss: 0.1789 - acc: 0.5714\n",
      "Epoch 382/1000\n",
      " - 0s - loss: 0.1784 - acc: 0.5714\n",
      "Epoch 383/1000\n",
      " - 0s - loss: 0.1780 - acc: 0.5714\n",
      "Epoch 384/1000\n",
      " - 0s - loss: 0.1772 - acc: 0.5714\n",
      "Epoch 385/1000\n",
      " - 0s - loss: 0.1772 - acc: 0.5714\n",
      "Epoch 386/1000\n",
      " - 0s - loss: 0.1765 - acc: 0.5714\n",
      "Epoch 387/1000\n",
      " - 0s - loss: 0.1753 - acc: 0.5714\n",
      "Epoch 388/1000\n",
      " - 0s - loss: 0.1747 - acc: 0.5714\n",
      "Epoch 389/1000\n",
      " - 0s - loss: 0.1745 - acc: 0.5714\n",
      "Epoch 390/1000\n",
      " - 0s - loss: 0.1736 - acc: 0.5714\n",
      "Epoch 391/1000\n",
      " - 0s - loss: 0.1737 - acc: 0.5714\n",
      "Epoch 392/1000\n",
      " - 0s - loss: 0.1728 - acc: 0.5714\n",
      "Epoch 393/1000\n",
      " - 0s - loss: 0.1718 - acc: 0.5714\n",
      "Epoch 394/1000\n",
      " - 0s - loss: 0.1714 - acc: 0.5714\n",
      "Epoch 395/1000\n",
      " - 0s - loss: 0.1707 - acc: 0.5714\n",
      "Epoch 396/1000\n",
      " - 0s - loss: 0.1701 - acc: 0.5714\n",
      "Epoch 397/1000\n",
      " - 0s - loss: 0.1705 - acc: 0.5714\n",
      "Epoch 398/1000\n",
      " - 0s - loss: 0.1692 - acc: 0.5714\n",
      "Epoch 399/1000\n",
      " - 0s - loss: 0.1686 - acc: 0.5714\n",
      "Epoch 400/1000\n",
      " - 0s - loss: 0.1681 - acc: 0.5714\n",
      "Epoch 401/1000\n",
      " - 0s - loss: 0.1677 - acc: 0.5714\n",
      "Epoch 402/1000\n",
      " - 0s - loss: 0.1670 - acc: 0.5714\n",
      "Epoch 403/1000\n",
      " - 0s - loss: 0.1668 - acc: 0.6429\n",
      "Epoch 404/1000\n",
      " - 0s - loss: 0.1661 - acc: 0.6429\n",
      "Epoch 405/1000\n",
      " - 0s - loss: 0.1655 - acc: 0.6429\n",
      "Epoch 406/1000\n",
      " - 0s - loss: 0.1647 - acc: 0.5714\n",
      "Epoch 407/1000\n",
      " - 0s - loss: 0.1644 - acc: 0.6429\n",
      "Epoch 408/1000\n",
      " - 0s - loss: 0.1641 - acc: 0.6429\n",
      "Epoch 409/1000\n",
      " - 0s - loss: 0.1634 - acc: 0.6429\n",
      "Epoch 410/1000\n",
      " - 0s - loss: 0.1625 - acc: 0.6429\n",
      "Epoch 411/1000\n",
      " - 0s - loss: 0.1621 - acc: 0.6429\n",
      "Epoch 412/1000\n",
      " - 0s - loss: 0.1616 - acc: 0.6429\n",
      "Epoch 413/1000\n",
      " - 0s - loss: 0.1610 - acc: 0.6429\n",
      "Epoch 414/1000\n",
      " - 0s - loss: 0.1606 - acc: 0.6429\n",
      "Epoch 415/1000\n",
      " - 0s - loss: 0.1605 - acc: 0.6429\n",
      "Epoch 416/1000\n",
      " - 0s - loss: 0.1594 - acc: 0.6429\n",
      "Epoch 417/1000\n",
      " - 0s - loss: 0.1588 - acc: 0.6429\n",
      "Epoch 418/1000\n",
      " - 0s - loss: 0.1585 - acc: 0.6429\n",
      "Epoch 419/1000\n",
      " - 0s - loss: 0.1579 - acc: 0.6429\n",
      "Epoch 420/1000\n",
      " - 0s - loss: 0.1577 - acc: 0.6429\n",
      "Epoch 421/1000\n",
      " - 0s - loss: 0.1574 - acc: 0.6429\n",
      "Epoch 422/1000\n",
      " - 0s - loss: 0.1563 - acc: 0.6429\n",
      "Epoch 423/1000\n",
      " - 0s - loss: 0.1562 - acc: 0.6429\n",
      "Epoch 424/1000\n",
      " - 0s - loss: 0.1552 - acc: 0.6429\n",
      "Epoch 425/1000\n",
      " - 0s - loss: 0.1550 - acc: 0.6429\n",
      "Epoch 426/1000\n",
      " - 0s - loss: 0.1544 - acc: 0.7143\n",
      "Epoch 427/1000\n",
      " - 0s - loss: 0.1537 - acc: 0.7143\n",
      "Epoch 428/1000\n",
      " - 0s - loss: 0.1540 - acc: 0.6429\n",
      "Epoch 429/1000\n",
      " - 0s - loss: 0.1534 - acc: 0.6429\n",
      "Epoch 430/1000\n",
      " - 0s - loss: 0.1524 - acc: 0.6429\n",
      "Epoch 431/1000\n",
      " - 0s - loss: 0.1521 - acc: 0.6429\n",
      "Epoch 432/1000\n",
      " - 0s - loss: 0.1514 - acc: 0.7143\n",
      "Epoch 433/1000\n",
      " - 0s - loss: 0.1508 - acc: 0.7143\n",
      "Epoch 434/1000\n",
      " - 0s - loss: 0.1506 - acc: 0.7143\n",
      "Epoch 435/1000\n",
      " - 0s - loss: 0.1500 - acc: 0.7857\n",
      "Epoch 436/1000\n",
      " - 0s - loss: 0.1493 - acc: 0.7857\n",
      "Epoch 437/1000\n",
      " - 0s - loss: 0.1489 - acc: 0.7857\n",
      "Epoch 438/1000\n",
      " - 0s - loss: 0.1487 - acc: 0.7857\n",
      "Epoch 439/1000\n",
      " - 0s - loss: 0.1482 - acc: 0.7857\n",
      "Epoch 440/1000\n",
      " - 0s - loss: 0.1475 - acc: 0.7857\n",
      "Epoch 441/1000\n",
      " - 0s - loss: 0.1470 - acc: 0.7857\n",
      "Epoch 442/1000\n",
      " - 0s - loss: 0.1465 - acc: 0.7857\n",
      "Epoch 443/1000\n",
      " - 0s - loss: 0.1461 - acc: 0.7857\n",
      "Epoch 444/1000\n",
      " - 0s - loss: 0.1456 - acc: 0.7857\n",
      "Epoch 445/1000\n",
      " - 0s - loss: 0.1455 - acc: 0.7857\n",
      "Epoch 446/1000\n",
      " - 0s - loss: 0.1448 - acc: 0.7857\n",
      "Epoch 447/1000\n",
      " - 0s - loss: 0.1444 - acc: 0.7857\n",
      "Epoch 448/1000\n",
      " - 0s - loss: 0.1440 - acc: 0.7857\n",
      "Epoch 449/1000\n",
      " - 0s - loss: 0.1434 - acc: 0.7857\n",
      "Epoch 450/1000\n",
      " - 0s - loss: 0.1427 - acc: 0.7857\n",
      "Epoch 451/1000\n",
      " - 0s - loss: 0.1425 - acc: 0.7857\n",
      "Epoch 452/1000\n",
      " - 0s - loss: 0.1424 - acc: 0.7857\n",
      "Epoch 453/1000\n",
      " - 0s - loss: 0.1416 - acc: 0.7857\n",
      "Epoch 454/1000\n",
      " - 0s - loss: 0.1410 - acc: 0.7857\n",
      "Epoch 455/1000\n",
      " - 0s - loss: 0.1413 - acc: 0.7857\n",
      "Epoch 456/1000\n",
      " - 0s - loss: 0.1401 - acc: 0.7857\n",
      "Epoch 457/1000\n",
      " - 0s - loss: 0.1397 - acc: 0.8571\n",
      "Epoch 458/1000\n",
      " - 0s - loss: 0.1393 - acc: 0.8571\n",
      "Epoch 459/1000\n",
      " - 0s - loss: 0.1390 - acc: 0.8571\n",
      "Epoch 460/1000\n",
      " - 0s - loss: 0.1384 - acc: 0.8571\n",
      "Epoch 461/1000\n",
      " - 0s - loss: 0.1379 - acc: 0.8571\n",
      "Epoch 462/1000\n",
      " - 0s - loss: 0.1374 - acc: 0.8571\n",
      "Epoch 463/1000\n",
      " - 0s - loss: 0.1370 - acc: 0.8571\n",
      "Epoch 464/1000\n",
      " - 0s - loss: 0.1367 - acc: 0.8571\n",
      "Epoch 465/1000\n",
      " - 0s - loss: 0.1362 - acc: 0.8571\n",
      "Epoch 466/1000\n",
      " - 0s - loss: 0.1360 - acc: 0.8571\n",
      "Epoch 467/1000\n",
      " - 0s - loss: 0.1357 - acc: 0.8571\n",
      "Epoch 468/1000\n",
      " - 0s - loss: 0.1349 - acc: 0.8571\n",
      "Epoch 469/1000\n",
      " - 0s - loss: 0.1345 - acc: 0.8571\n",
      "Epoch 470/1000\n",
      " - 0s - loss: 0.1340 - acc: 0.8571\n",
      "Epoch 471/1000\n",
      " - 0s - loss: 0.1336 - acc: 0.8571\n",
      "Epoch 472/1000\n",
      " - 0s - loss: 0.1332 - acc: 0.8571\n",
      "Epoch 473/1000\n",
      " - 0s - loss: 0.1330 - acc: 0.8571\n",
      "Epoch 474/1000\n",
      " - 0s - loss: 0.1323 - acc: 0.8571\n",
      "Epoch 475/1000\n",
      " - 0s - loss: 0.1320 - acc: 0.8571\n",
      "Epoch 476/1000\n",
      " - 0s - loss: 0.1315 - acc: 0.8571\n",
      "Epoch 477/1000\n",
      " - 0s - loss: 0.1315 - acc: 0.8571\n",
      "Epoch 478/1000\n",
      " - 0s - loss: 0.1308 - acc: 0.8571\n",
      "Epoch 479/1000\n",
      " - 0s - loss: 0.1305 - acc: 0.8571\n",
      "Epoch 480/1000\n",
      " - 0s - loss: 0.1298 - acc: 0.8571\n",
      "Epoch 481/1000\n",
      " - 0s - loss: 0.1297 - acc: 0.8571\n",
      "Epoch 482/1000\n",
      " - 0s - loss: 0.1291 - acc: 0.8571\n",
      "Epoch 483/1000\n",
      " - 0s - loss: 0.1294 - acc: 0.8571\n",
      "Epoch 484/1000\n",
      " - 0s - loss: 0.1282 - acc: 0.8571\n",
      "Epoch 485/1000\n",
      " - 0s - loss: 0.1280 - acc: 0.8571\n",
      "Epoch 486/1000\n",
      " - 0s - loss: 0.1275 - acc: 0.8571\n",
      "Epoch 487/1000\n",
      " - 0s - loss: 0.1270 - acc: 0.8571\n",
      "Epoch 488/1000\n",
      " - 0s - loss: 0.1268 - acc: 0.8571\n",
      "Epoch 489/1000\n",
      " - 0s - loss: 0.1263 - acc: 0.8571\n",
      "Epoch 490/1000\n",
      " - 0s - loss: 0.1262 - acc: 0.8571\n",
      "Epoch 491/1000\n",
      " - 0s - loss: 0.1257 - acc: 0.8571\n",
      "Epoch 492/1000\n",
      " - 0s - loss: 0.1253 - acc: 0.8571\n",
      "Epoch 493/1000\n",
      " - 0s - loss: 0.1247 - acc: 0.8571\n",
      "Epoch 494/1000\n",
      " - 0s - loss: 0.1244 - acc: 0.8571\n",
      "Epoch 495/1000\n",
      " - 0s - loss: 0.1240 - acc: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/1000\n",
      " - 0s - loss: 0.1235 - acc: 0.8571\n",
      "Epoch 497/1000\n",
      " - 0s - loss: 0.1232 - acc: 0.8571\n",
      "Epoch 498/1000\n",
      " - 0s - loss: 0.1228 - acc: 0.8571\n",
      "Epoch 499/1000\n",
      " - 0s - loss: 0.1225 - acc: 0.8571\n",
      "Epoch 500/1000\n",
      " - 0s - loss: 0.1220 - acc: 0.8571\n",
      "Epoch 501/1000\n",
      " - 0s - loss: 0.1216 - acc: 0.8571\n",
      "Epoch 502/1000\n",
      " - 0s - loss: 0.1211 - acc: 0.8571\n",
      "Epoch 503/1000\n",
      " - 0s - loss: 0.1208 - acc: 0.8571\n",
      "Epoch 504/1000\n",
      " - 0s - loss: 0.1205 - acc: 0.8571\n",
      "Epoch 505/1000\n",
      " - 0s - loss: 0.1202 - acc: 0.8571\n",
      "Epoch 506/1000\n",
      " - 0s - loss: 0.1197 - acc: 0.8571\n",
      "Epoch 507/1000\n",
      " - 0s - loss: 0.1194 - acc: 0.8571\n",
      "Epoch 508/1000\n",
      " - 0s - loss: 0.1193 - acc: 0.8571\n",
      "Epoch 509/1000\n",
      " - 0s - loss: 0.1188 - acc: 0.8571\n",
      "Epoch 510/1000\n",
      " - 0s - loss: 0.1182 - acc: 0.8571\n",
      "Epoch 511/1000\n",
      " - 0s - loss: 0.1178 - acc: 0.8571\n",
      "Epoch 512/1000\n",
      " - 0s - loss: 0.1175 - acc: 0.8571\n",
      "Epoch 513/1000\n",
      " - 0s - loss: 0.1171 - acc: 0.8571\n",
      "Epoch 514/1000\n",
      " - 0s - loss: 0.1169 - acc: 0.8571\n",
      "Epoch 515/1000\n",
      " - 0s - loss: 0.1167 - acc: 0.8571\n",
      "Epoch 516/1000\n",
      " - 0s - loss: 0.1164 - acc: 0.8571\n",
      "Epoch 517/1000\n",
      " - 0s - loss: 0.1156 - acc: 0.8571\n",
      "Epoch 518/1000\n",
      " - 0s - loss: 0.1152 - acc: 0.8571\n",
      "Epoch 519/1000\n",
      " - 0s - loss: 0.1150 - acc: 0.8571\n",
      "Epoch 520/1000\n",
      " - 0s - loss: 0.1152 - acc: 0.8571\n",
      "Epoch 521/1000\n",
      " - 0s - loss: 0.1142 - acc: 0.8571\n",
      "Epoch 522/1000\n",
      " - 0s - loss: 0.1140 - acc: 0.8571\n",
      "Epoch 523/1000\n",
      " - 0s - loss: 0.1137 - acc: 0.8571\n",
      "Epoch 524/1000\n",
      " - 0s - loss: 0.1131 - acc: 0.8571\n",
      "Epoch 525/1000\n",
      " - 0s - loss: 0.1127 - acc: 0.8571\n",
      "Epoch 526/1000\n",
      " - 0s - loss: 0.1126 - acc: 0.8571\n",
      "Epoch 527/1000\n",
      " - 0s - loss: 0.1121 - acc: 0.8571\n",
      "Epoch 528/1000\n",
      " - 0s - loss: 0.1117 - acc: 0.8571\n",
      "Epoch 529/1000\n",
      " - 0s - loss: 0.1114 - acc: 0.8571\n",
      "Epoch 530/1000\n",
      " - 0s - loss: 0.1113 - acc: 0.8571\n",
      "Epoch 531/1000\n",
      " - 0s - loss: 0.1108 - acc: 0.8571\n",
      "Epoch 532/1000\n",
      " - 0s - loss: 0.1105 - acc: 0.8571\n",
      "Epoch 533/1000\n",
      " - 0s - loss: 0.1102 - acc: 0.8571\n",
      "Epoch 534/1000\n",
      " - 0s - loss: 0.1096 - acc: 0.8571\n",
      "Epoch 535/1000\n",
      " - 0s - loss: 0.1095 - acc: 0.8571\n",
      "Epoch 536/1000\n",
      " - 0s - loss: 0.1090 - acc: 0.8571\n",
      "Epoch 537/1000\n",
      " - 0s - loss: 0.1093 - acc: 0.8571\n",
      "Epoch 538/1000\n",
      " - 0s - loss: 0.1084 - acc: 0.8571\n",
      "Epoch 539/1000\n",
      " - 0s - loss: 0.1080 - acc: 0.8571\n",
      "Epoch 540/1000\n",
      " - 0s - loss: 0.1076 - acc: 0.8571\n",
      "Epoch 541/1000\n",
      " - 0s - loss: 0.1072 - acc: 0.8571\n",
      "Epoch 542/1000\n",
      " - 0s - loss: 0.1071 - acc: 0.8571\n",
      "Epoch 543/1000\n",
      " - 0s - loss: 0.1067 - acc: 0.8571\n",
      "Epoch 544/1000\n",
      " - 0s - loss: 0.1066 - acc: 0.8571\n",
      "Epoch 545/1000\n",
      " - 0s - loss: 0.1060 - acc: 0.8571\n",
      "Epoch 546/1000\n",
      " - 0s - loss: 0.1057 - acc: 0.8571\n",
      "Epoch 547/1000\n",
      " - 0s - loss: 0.1055 - acc: 0.8571\n",
      "Epoch 548/1000\n",
      " - 0s - loss: 0.1053 - acc: 0.8571\n",
      "Epoch 549/1000\n",
      " - 0s - loss: 0.1050 - acc: 0.8571\n",
      "Epoch 550/1000\n",
      " - 0s - loss: 0.1051 - acc: 0.8571\n",
      "Epoch 551/1000\n",
      " - 0s - loss: 0.1042 - acc: 0.9286\n",
      "Epoch 552/1000\n",
      " - 0s - loss: 0.1037 - acc: 0.9286\n",
      "Epoch 553/1000\n",
      " - 0s - loss: 0.1035 - acc: 0.8571\n",
      "Epoch 554/1000\n",
      " - 0s - loss: 0.1037 - acc: 0.8571\n",
      "Epoch 555/1000\n",
      " - 0s - loss: 0.1030 - acc: 0.9286\n",
      "Epoch 556/1000\n",
      " - 0s - loss: 0.1025 - acc: 0.8571\n",
      "Epoch 557/1000\n",
      " - 0s - loss: 0.1022 - acc: 0.8571\n",
      "Epoch 558/1000\n",
      " - 0s - loss: 0.1017 - acc: 0.9286\n",
      "Epoch 559/1000\n",
      " - 0s - loss: 0.1016 - acc: 0.9286\n",
      "Epoch 560/1000\n",
      " - 0s - loss: 0.1016 - acc: 0.9286\n",
      "Epoch 561/1000\n",
      " - 0s - loss: 0.1009 - acc: 0.9286\n",
      "Epoch 562/1000\n",
      " - 0s - loss: 0.1006 - acc: 0.9286\n",
      "Epoch 563/1000\n",
      " - 0s - loss: 0.1002 - acc: 0.9286\n",
      "Epoch 564/1000\n",
      " - 0s - loss: 0.0999 - acc: 0.9286\n",
      "Epoch 565/1000\n",
      " - 0s - loss: 0.0997 - acc: 0.9286\n",
      "Epoch 566/1000\n",
      " - 0s - loss: 0.0993 - acc: 0.9286\n",
      "Epoch 567/1000\n",
      " - 0s - loss: 0.0991 - acc: 0.9286\n",
      "Epoch 568/1000\n",
      " - 0s - loss: 0.0989 - acc: 0.9286\n",
      "Epoch 569/1000\n",
      " - 0s - loss: 0.0984 - acc: 0.9286\n",
      "Epoch 570/1000\n",
      " - 0s - loss: 0.0981 - acc: 0.9286\n",
      "Epoch 571/1000\n",
      " - 0s - loss: 0.0977 - acc: 0.9286\n",
      "Epoch 572/1000\n",
      " - 0s - loss: 0.0974 - acc: 0.9286\n",
      "Epoch 573/1000\n",
      " - 0s - loss: 0.0972 - acc: 0.9286\n",
      "Epoch 574/1000\n",
      " - 0s - loss: 0.0973 - acc: 0.9286\n",
      "Epoch 575/1000\n",
      " - 0s - loss: 0.0965 - acc: 0.9286\n",
      "Epoch 576/1000\n",
      " - 0s - loss: 0.0962 - acc: 0.9286\n",
      "Epoch 577/1000\n",
      " - 0s - loss: 0.0960 - acc: 0.9286\n",
      "Epoch 578/1000\n",
      " - 0s - loss: 0.0956 - acc: 0.9286\n",
      "Epoch 579/1000\n",
      " - 0s - loss: 0.0953 - acc: 0.9286\n",
      "Epoch 580/1000\n",
      " - 0s - loss: 0.0951 - acc: 0.9286\n",
      "Epoch 581/1000\n",
      " - 0s - loss: 0.0949 - acc: 0.9286\n",
      "Epoch 582/1000\n",
      " - 0s - loss: 0.0945 - acc: 0.9286\n",
      "Epoch 583/1000\n",
      " - 0s - loss: 0.0942 - acc: 0.9286\n",
      "Epoch 584/1000\n",
      " - 0s - loss: 0.0941 - acc: 0.9286\n",
      "Epoch 585/1000\n",
      " - 0s - loss: 0.0936 - acc: 1.0000\n",
      "Epoch 586/1000\n",
      " - 0s - loss: 0.0934 - acc: 1.0000\n",
      "Epoch 587/1000\n",
      " - 0s - loss: 0.0934 - acc: 1.0000\n",
      "Epoch 588/1000\n",
      " - 0s - loss: 0.0927 - acc: 1.0000\n",
      "Epoch 589/1000\n",
      " - 0s - loss: 0.0925 - acc: 1.0000\n",
      "Epoch 590/1000\n",
      " - 0s - loss: 0.0921 - acc: 1.0000\n",
      "Epoch 591/1000\n",
      " - 0s - loss: 0.0920 - acc: 1.0000\n",
      "Epoch 592/1000\n",
      " - 0s - loss: 0.0915 - acc: 1.0000\n",
      "Epoch 593/1000\n",
      " - 0s - loss: 0.0913 - acc: 1.0000\n",
      "Epoch 594/1000\n",
      " - 0s - loss: 0.0911 - acc: 1.0000\n",
      "Epoch 595/1000\n",
      " - 0s - loss: 0.0908 - acc: 1.0000\n",
      "Epoch 596/1000\n",
      " - 0s - loss: 0.0905 - acc: 1.0000\n",
      "Epoch 597/1000\n",
      " - 0s - loss: 0.0904 - acc: 1.0000\n",
      "Epoch 598/1000\n",
      " - 0s - loss: 0.0902 - acc: 1.0000\n",
      "Epoch 599/1000\n",
      " - 0s - loss: 0.0897 - acc: 1.0000\n",
      "Epoch 600/1000\n",
      " - 0s - loss: 0.0894 - acc: 1.0000\n",
      "Epoch 601/1000\n",
      " - 0s - loss: 0.0893 - acc: 1.0000\n",
      "Epoch 602/1000\n",
      " - 0s - loss: 0.0888 - acc: 1.0000\n",
      "Epoch 603/1000\n",
      " - 0s - loss: 0.0886 - acc: 1.0000\n",
      "Epoch 604/1000\n",
      " - 0s - loss: 0.0882 - acc: 1.0000\n",
      "Epoch 605/1000\n",
      " - 0s - loss: 0.0880 - acc: 1.0000\n",
      "Epoch 606/1000\n",
      " - 0s - loss: 0.0877 - acc: 1.0000\n",
      "Epoch 607/1000\n",
      " - 0s - loss: 0.0875 - acc: 1.0000\n",
      "Epoch 608/1000\n",
      " - 0s - loss: 0.0871 - acc: 1.0000\n",
      "Epoch 609/1000\n",
      " - 0s - loss: 0.0868 - acc: 1.0000\n",
      "Epoch 610/1000\n",
      " - 0s - loss: 0.0869 - acc: 1.0000\n",
      "Epoch 611/1000\n",
      " - 0s - loss: 0.0863 - acc: 1.0000\n",
      "Epoch 612/1000\n",
      " - 0s - loss: 0.0863 - acc: 1.0000\n",
      "Epoch 613/1000\n",
      " - 0s - loss: 0.0859 - acc: 1.0000\n",
      "Epoch 614/1000\n",
      " - 0s - loss: 0.0857 - acc: 1.0000\n",
      "Epoch 615/1000\n",
      " - 0s - loss: 0.0859 - acc: 1.0000\n",
      "Epoch 616/1000\n",
      " - 0s - loss: 0.0853 - acc: 1.0000\n",
      "Epoch 617/1000\n",
      " - 0s - loss: 0.0849 - acc: 1.0000\n",
      "Epoch 618/1000\n",
      " - 0s - loss: 0.0846 - acc: 1.0000\n",
      "Epoch 619/1000\n",
      " - 0s - loss: 0.0844 - acc: 1.0000\n",
      "Epoch 620/1000\n",
      " - 0s - loss: 0.0840 - acc: 1.0000\n",
      "Epoch 621/1000\n",
      " - 0s - loss: 0.0838 - acc: 1.0000\n",
      "Epoch 622/1000\n",
      " - 0s - loss: 0.0836 - acc: 1.0000\n",
      "Epoch 623/1000\n",
      " - 0s - loss: 0.0831 - acc: 1.0000\n",
      "Epoch 624/1000\n",
      " - 0s - loss: 0.0833 - acc: 1.0000\n",
      "Epoch 625/1000\n",
      " - 0s - loss: 0.0827 - acc: 1.0000\n",
      "Epoch 626/1000\n",
      " - 0s - loss: 0.0825 - acc: 1.0000\n",
      "Epoch 627/1000\n",
      " - 0s - loss: 0.0826 - acc: 1.0000\n",
      "Epoch 628/1000\n",
      " - 0s - loss: 0.0819 - acc: 1.0000\n",
      "Epoch 629/1000\n",
      " - 0s - loss: 0.0817 - acc: 1.0000\n",
      "Epoch 630/1000\n",
      " - 0s - loss: 0.0815 - acc: 1.0000\n",
      "Epoch 631/1000\n",
      " - 0s - loss: 0.0813 - acc: 1.0000\n",
      "Epoch 632/1000\n",
      " - 0s - loss: 0.0809 - acc: 1.0000\n",
      "Epoch 633/1000\n",
      " - 0s - loss: 0.0808 - acc: 1.0000\n",
      "Epoch 634/1000\n",
      " - 0s - loss: 0.0806 - acc: 1.0000\n",
      "Epoch 635/1000\n",
      " - 0s - loss: 0.0803 - acc: 1.0000\n",
      "Epoch 636/1000\n",
      " - 0s - loss: 0.0799 - acc: 1.0000\n",
      "Epoch 637/1000\n",
      " - 0s - loss: 0.0798 - acc: 1.0000\n",
      "Epoch 638/1000\n",
      " - 0s - loss: 0.0796 - acc: 1.0000\n",
      "Epoch 639/1000\n",
      " - 0s - loss: 0.0792 - acc: 1.0000\n",
      "Epoch 640/1000\n",
      " - 0s - loss: 0.0789 - acc: 1.0000\n",
      "Epoch 641/1000\n",
      " - 0s - loss: 0.0788 - acc: 1.0000\n",
      "Epoch 642/1000\n",
      " - 0s - loss: 0.0785 - acc: 1.0000\n",
      "Epoch 643/1000\n",
      " - 0s - loss: 0.0782 - acc: 1.0000\n",
      "Epoch 644/1000\n",
      " - 0s - loss: 0.0781 - acc: 1.0000\n",
      "Epoch 645/1000\n",
      " - 0s - loss: 0.0778 - acc: 1.0000\n",
      "Epoch 646/1000\n",
      " - 0s - loss: 0.0778 - acc: 1.0000\n",
      "Epoch 647/1000\n",
      " - 0s - loss: 0.0772 - acc: 1.0000\n",
      "Epoch 648/1000\n",
      " - 0s - loss: 0.0771 - acc: 1.0000\n",
      "Epoch 649/1000\n",
      " - 0s - loss: 0.0768 - acc: 1.0000\n",
      "Epoch 650/1000\n",
      " - 0s - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 651/1000\n",
      " - 0s - loss: 0.0765 - acc: 1.0000\n",
      "Epoch 652/1000\n",
      " - 0s - loss: 0.0762 - acc: 1.0000\n",
      "Epoch 653/1000\n",
      " - 0s - loss: 0.0759 - acc: 1.0000\n",
      "Epoch 654/1000\n",
      " - 0s - loss: 0.0758 - acc: 1.0000\n",
      "Epoch 655/1000\n",
      " - 0s - loss: 0.0755 - acc: 1.0000\n",
      "Epoch 656/1000\n",
      " - 0s - loss: 0.0752 - acc: 1.0000\n",
      "Epoch 657/1000\n",
      " - 0s - loss: 0.0750 - acc: 1.0000\n",
      "Epoch 658/1000\n",
      " - 0s - loss: 0.0746 - acc: 1.0000\n",
      "Epoch 659/1000\n",
      " - 0s - loss: 0.0746 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/1000\n",
      " - 0s - loss: 0.0743 - acc: 1.0000\n",
      "Epoch 661/1000\n",
      " - 0s - loss: 0.0745 - acc: 1.0000\n",
      "Epoch 662/1000\n",
      " - 0s - loss: 0.0738 - acc: 1.0000\n",
      "Epoch 663/1000\n",
      " - 0s - loss: 0.0737 - acc: 1.0000\n",
      "Epoch 664/1000\n",
      " - 0s - loss: 0.0736 - acc: 1.0000\n",
      "Epoch 665/1000\n",
      " - 0s - loss: 0.0735 - acc: 1.0000\n",
      "Epoch 666/1000\n",
      " - 0s - loss: 0.0728 - acc: 1.0000\n",
      "Epoch 667/1000\n",
      " - 0s - loss: 0.0729 - acc: 1.0000\n",
      "Epoch 668/1000\n",
      " - 0s - loss: 0.0726 - acc: 1.0000\n",
      "Epoch 669/1000\n",
      " - 0s - loss: 0.0722 - acc: 1.0000\n",
      "Epoch 670/1000\n",
      " - 0s - loss: 0.0720 - acc: 1.0000\n",
      "Epoch 671/1000\n",
      " - 0s - loss: 0.0718 - acc: 1.0000\n",
      "Epoch 672/1000\n",
      " - 0s - loss: 0.0718 - acc: 1.0000\n",
      "Epoch 673/1000\n",
      " - 0s - loss: 0.0715 - acc: 1.0000\n",
      "Epoch 674/1000\n",
      " - 0s - loss: 0.0712 - acc: 1.0000\n",
      "Epoch 675/1000\n",
      " - 0s - loss: 0.0709 - acc: 1.0000\n",
      "Epoch 676/1000\n",
      " - 0s - loss: 0.0708 - acc: 1.0000\n",
      "Epoch 677/1000\n",
      " - 0s - loss: 0.0707 - acc: 1.0000\n",
      "Epoch 678/1000\n",
      " - 0s - loss: 0.0701 - acc: 1.0000\n",
      "Epoch 679/1000\n",
      " - 0s - loss: 0.0700 - acc: 1.0000\n",
      "Epoch 680/1000\n",
      " - 0s - loss: 0.0698 - acc: 1.0000\n",
      "Epoch 681/1000\n",
      " - 0s - loss: 0.0696 - acc: 1.0000\n",
      "Epoch 682/1000\n",
      " - 0s - loss: 0.0694 - acc: 1.0000\n",
      "Epoch 683/1000\n",
      " - 0s - loss: 0.0691 - acc: 1.0000\n",
      "Epoch 684/1000\n",
      " - 0s - loss: 0.0689 - acc: 1.0000\n",
      "Epoch 685/1000\n",
      " - 0s - loss: 0.0692 - acc: 1.0000\n",
      "Epoch 686/1000\n",
      " - 0s - loss: 0.0685 - acc: 1.0000\n",
      "Epoch 687/1000\n",
      " - 0s - loss: 0.0683 - acc: 1.0000\n",
      "Epoch 688/1000\n",
      " - 0s - loss: 0.0680 - acc: 1.0000\n",
      "Epoch 689/1000\n",
      " - 0s - loss: 0.0680 - acc: 1.0000\n",
      "Epoch 690/1000\n",
      " - 0s - loss: 0.0677 - acc: 1.0000\n",
      "Epoch 691/1000\n",
      " - 0s - loss: 0.0675 - acc: 1.0000\n",
      "Epoch 692/1000\n",
      " - 0s - loss: 0.0674 - acc: 1.0000\n",
      "Epoch 693/1000\n",
      " - 0s - loss: 0.0673 - acc: 1.0000\n",
      "Epoch 694/1000\n",
      " - 0s - loss: 0.0670 - acc: 1.0000\n",
      "Epoch 695/1000\n",
      " - 0s - loss: 0.0667 - acc: 1.0000\n",
      "Epoch 696/1000\n",
      " - 0s - loss: 0.0664 - acc: 1.0000\n",
      "Epoch 697/1000\n",
      " - 0s - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 698/1000\n",
      " - 0s - loss: 0.0661 - acc: 1.0000\n",
      "Epoch 699/1000\n",
      " - 0s - loss: 0.0658 - acc: 1.0000\n",
      "Epoch 700/1000\n",
      " - 0s - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 701/1000\n",
      " - 0s - loss: 0.0655 - acc: 1.0000\n",
      "Epoch 702/1000\n",
      " - 0s - loss: 0.0652 - acc: 1.0000\n",
      "Epoch 703/1000\n",
      " - 0s - loss: 0.0650 - acc: 1.0000\n",
      "Epoch 704/1000\n",
      " - 0s - loss: 0.0650 - acc: 1.0000\n",
      "Epoch 705/1000\n",
      " - 0s - loss: 0.0646 - acc: 1.0000\n",
      "Epoch 706/1000\n",
      " - 0s - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 707/1000\n",
      " - 0s - loss: 0.0642 - acc: 1.0000\n",
      "Epoch 708/1000\n",
      " - 0s - loss: 0.0640 - acc: 1.0000\n",
      "Epoch 709/1000\n",
      " - 0s - loss: 0.0638 - acc: 1.0000\n",
      "Epoch 710/1000\n",
      " - 0s - loss: 0.0636 - acc: 1.0000\n",
      "Epoch 711/1000\n",
      " - 0s - loss: 0.0635 - acc: 1.0000\n",
      "Epoch 712/1000\n",
      " - 0s - loss: 0.0632 - acc: 1.0000\n",
      "Epoch 713/1000\n",
      " - 0s - loss: 0.0632 - acc: 1.0000\n",
      "Epoch 714/1000\n",
      " - 0s - loss: 0.0628 - acc: 1.0000\n",
      "Epoch 715/1000\n",
      " - 0s - loss: 0.0626 - acc: 1.0000\n",
      "Epoch 716/1000\n",
      " - 0s - loss: 0.0625 - acc: 1.0000\n",
      "Epoch 717/1000\n",
      " - 0s - loss: 0.0623 - acc: 1.0000\n",
      "Epoch 718/1000\n",
      " - 0s - loss: 0.0622 - acc: 1.0000\n",
      "Epoch 719/1000\n",
      " - 0s - loss: 0.0619 - acc: 1.0000\n",
      "Epoch 720/1000\n",
      " - 0s - loss: 0.0617 - acc: 1.0000\n",
      "Epoch 721/1000\n",
      " - 0s - loss: 0.0614 - acc: 1.0000\n",
      "Epoch 722/1000\n",
      " - 0s - loss: 0.0616 - acc: 1.0000\n",
      "Epoch 723/1000\n",
      " - 0s - loss: 0.0611 - acc: 1.0000\n",
      "Epoch 724/1000\n",
      " - 0s - loss: 0.0609 - acc: 1.0000\n",
      "Epoch 725/1000\n",
      " - 0s - loss: 0.0607 - acc: 1.0000\n",
      "Epoch 726/1000\n",
      " - 0s - loss: 0.0607 - acc: 1.0000\n",
      "Epoch 727/1000\n",
      " - 0s - loss: 0.0605 - acc: 1.0000\n",
      "Epoch 728/1000\n",
      " - 0s - loss: 0.0602 - acc: 1.0000\n",
      "Epoch 729/1000\n",
      " - 0s - loss: 0.0601 - acc: 1.0000\n",
      "Epoch 730/1000\n",
      " - 0s - loss: 0.0600 - acc: 1.0000\n",
      "Epoch 731/1000\n",
      " - 0s - loss: 0.0596 - acc: 1.0000\n",
      "Epoch 732/1000\n",
      " - 0s - loss: 0.0595 - acc: 1.0000\n",
      "Epoch 733/1000\n",
      " - 0s - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 734/1000\n",
      " - 0s - loss: 0.0591 - acc: 1.0000\n",
      "Epoch 735/1000\n",
      " - 0s - loss: 0.0590 - acc: 1.0000\n",
      "Epoch 736/1000\n",
      " - 0s - loss: 0.0588 - acc: 1.0000\n",
      "Epoch 737/1000\n",
      " - 0s - loss: 0.0586 - acc: 1.0000\n",
      "Epoch 738/1000\n",
      " - 0s - loss: 0.0584 - acc: 1.0000\n",
      "Epoch 739/1000\n",
      " - 0s - loss: 0.0582 - acc: 1.0000\n",
      "Epoch 740/1000\n",
      " - 0s - loss: 0.0580 - acc: 1.0000\n",
      "Epoch 741/1000\n",
      " - 0s - loss: 0.0578 - acc: 1.0000\n",
      "Epoch 742/1000\n",
      " - 0s - loss: 0.0576 - acc: 1.0000\n",
      "Epoch 743/1000\n",
      " - 0s - loss: 0.0575 - acc: 1.0000\n",
      "Epoch 744/1000\n",
      " - 0s - loss: 0.0575 - acc: 1.0000\n",
      "Epoch 745/1000\n",
      " - 0s - loss: 0.0573 - acc: 1.0000\n",
      "Epoch 746/1000\n",
      " - 0s - loss: 0.0571 - acc: 1.0000\n",
      "Epoch 747/1000\n",
      " - 0s - loss: 0.0569 - acc: 1.0000\n",
      "Epoch 748/1000\n",
      " - 0s - loss: 0.0565 - acc: 1.0000\n",
      "Epoch 749/1000\n",
      " - 0s - loss: 0.0565 - acc: 1.0000\n",
      "Epoch 750/1000\n",
      " - 0s - loss: 0.0566 - acc: 1.0000\n",
      "Epoch 751/1000\n",
      " - 0s - loss: 0.0561 - acc: 1.0000\n",
      "Epoch 752/1000\n",
      " - 0s - loss: 0.0560 - acc: 1.0000\n",
      "Epoch 753/1000\n",
      " - 0s - loss: 0.0557 - acc: 1.0000\n",
      "Epoch 754/1000\n",
      " - 0s - loss: 0.0558 - acc: 1.0000\n",
      "Epoch 755/1000\n",
      " - 0s - loss: 0.0554 - acc: 1.0000\n",
      "Epoch 756/1000\n",
      " - 0s - loss: 0.0552 - acc: 1.0000\n",
      "Epoch 757/1000\n",
      " - 0s - loss: 0.0552 - acc: 1.0000\n",
      "Epoch 758/1000\n",
      " - 0s - loss: 0.0548 - acc: 1.0000\n",
      "Epoch 759/1000\n",
      " - 0s - loss: 0.0550 - acc: 1.0000\n",
      "Epoch 760/1000\n",
      " - 0s - loss: 0.0545 - acc: 1.0000\n",
      "Epoch 761/1000\n",
      " - 0s - loss: 0.0544 - acc: 1.0000\n",
      "Epoch 762/1000\n",
      " - 0s - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 763/1000\n",
      " - 0s - loss: 0.0540 - acc: 1.0000\n",
      "Epoch 764/1000\n",
      " - 0s - loss: 0.0538 - acc: 1.0000\n",
      "Epoch 765/1000\n",
      " - 0s - loss: 0.0537 - acc: 1.0000\n",
      "Epoch 766/1000\n",
      " - 0s - loss: 0.0535 - acc: 1.0000\n",
      "Epoch 767/1000\n",
      " - 0s - loss: 0.0534 - acc: 1.0000\n",
      "Epoch 768/1000\n",
      " - 0s - loss: 0.0533 - acc: 1.0000\n",
      "Epoch 769/1000\n",
      " - 0s - loss: 0.0530 - acc: 1.0000\n",
      "Epoch 770/1000\n",
      " - 0s - loss: 0.0529 - acc: 1.0000\n",
      "Epoch 771/1000\n",
      " - 0s - loss: 0.0527 - acc: 1.0000\n",
      "Epoch 772/1000\n",
      " - 0s - loss: 0.0525 - acc: 1.0000\n",
      "Epoch 773/1000\n",
      " - 0s - loss: 0.0523 - acc: 1.0000\n",
      "Epoch 774/1000\n",
      " - 0s - loss: 0.0524 - acc: 1.0000\n",
      "Epoch 775/1000\n",
      " - 0s - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 776/1000\n",
      " - 0s - loss: 0.0518 - acc: 1.0000\n",
      "Epoch 777/1000\n",
      " - 0s - loss: 0.0517 - acc: 1.0000\n",
      "Epoch 778/1000\n",
      " - 0s - loss: 0.0516 - acc: 1.0000\n",
      "Epoch 779/1000\n",
      " - 0s - loss: 0.0514 - acc: 1.0000\n",
      "Epoch 780/1000\n",
      " - 0s - loss: 0.0513 - acc: 1.0000\n",
      "Epoch 781/1000\n",
      " - 0s - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 782/1000\n",
      " - 0s - loss: 0.0509 - acc: 1.0000\n",
      "Epoch 783/1000\n",
      " - 0s - loss: 0.0508 - acc: 1.0000\n",
      "Epoch 784/1000\n",
      " - 0s - loss: 0.0507 - acc: 1.0000\n",
      "Epoch 785/1000\n",
      " - 0s - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 786/1000\n",
      " - 0s - loss: 0.0504 - acc: 1.0000\n",
      "Epoch 787/1000\n",
      " - 0s - loss: 0.0502 - acc: 1.0000\n",
      "Epoch 788/1000\n",
      " - 0s - loss: 0.0500 - acc: 1.0000\n",
      "Epoch 789/1000\n",
      " - 0s - loss: 0.0498 - acc: 1.0000\n",
      "Epoch 790/1000\n",
      " - 0s - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 791/1000\n",
      " - 0s - loss: 0.0496 - acc: 1.0000\n",
      "Epoch 792/1000\n",
      " - 0s - loss: 0.0493 - acc: 1.0000\n",
      "Epoch 793/1000\n",
      " - 0s - loss: 0.0493 - acc: 1.0000\n",
      "Epoch 794/1000\n",
      " - 0s - loss: 0.0490 - acc: 1.0000\n",
      "Epoch 795/1000\n",
      " - 0s - loss: 0.0489 - acc: 1.0000\n",
      "Epoch 796/1000\n",
      " - 0s - loss: 0.0488 - acc: 1.0000\n",
      "Epoch 797/1000\n",
      " - 0s - loss: 0.0486 - acc: 1.0000\n",
      "Epoch 798/1000\n",
      " - 0s - loss: 0.0484 - acc: 1.0000\n",
      "Epoch 799/1000\n",
      " - 0s - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 800/1000\n",
      " - 0s - loss: 0.0484 - acc: 1.0000\n",
      "Epoch 801/1000\n",
      " - 0s - loss: 0.0480 - acc: 1.0000\n",
      "Epoch 802/1000\n",
      " - 0s - loss: 0.0478 - acc: 1.0000\n",
      "Epoch 803/1000\n",
      " - 0s - loss: 0.0477 - acc: 1.0000\n",
      "Epoch 804/1000\n",
      " - 0s - loss: 0.0476 - acc: 1.0000\n",
      "Epoch 805/1000\n",
      " - 0s - loss: 0.0474 - acc: 1.0000\n",
      "Epoch 806/1000\n",
      " - 0s - loss: 0.0472 - acc: 1.0000\n",
      "Epoch 807/1000\n",
      " - 0s - loss: 0.0471 - acc: 1.0000\n",
      "Epoch 808/1000\n",
      " - 0s - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 809/1000\n",
      " - 0s - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 810/1000\n",
      " - 0s - loss: 0.0467 - acc: 1.0000\n",
      "Epoch 811/1000\n",
      " - 0s - loss: 0.0466 - acc: 1.0000\n",
      "Epoch 812/1000\n",
      " - 0s - loss: 0.0464 - acc: 1.0000\n",
      "Epoch 813/1000\n",
      " - 0s - loss: 0.0462 - acc: 1.0000\n",
      "Epoch 814/1000\n",
      " - 0s - loss: 0.0461 - acc: 1.0000\n",
      "Epoch 815/1000\n",
      " - 0s - loss: 0.0461 - acc: 1.0000\n",
      "Epoch 816/1000\n",
      " - 0s - loss: 0.0458 - acc: 1.0000\n",
      "Epoch 817/1000\n",
      " - 0s - loss: 0.0457 - acc: 1.0000\n",
      "Epoch 818/1000\n",
      " - 0s - loss: 0.0455 - acc: 1.0000\n",
      "Epoch 819/1000\n",
      " - 0s - loss: 0.0458 - acc: 1.0000\n",
      "Epoch 820/1000\n",
      " - 0s - loss: 0.0452 - acc: 1.0000\n",
      "Epoch 821/1000\n",
      " - 0s - loss: 0.0451 - acc: 1.0000\n",
      "Epoch 822/1000\n",
      " - 0s - loss: 0.0450 - acc: 1.0000\n",
      "Epoch 823/1000\n",
      " - 0s - loss: 0.0448 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 824/1000\n",
      " - 0s - loss: 0.0447 - acc: 1.0000\n",
      "Epoch 825/1000\n",
      " - 0s - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 826/1000\n",
      " - 0s - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 827/1000\n",
      " - 0s - loss: 0.0443 - acc: 1.0000\n",
      "Epoch 828/1000\n",
      " - 0s - loss: 0.0442 - acc: 1.0000\n",
      "Epoch 829/1000\n",
      " - 0s - loss: 0.0440 - acc: 1.0000\n",
      "Epoch 830/1000\n",
      " - 0s - loss: 0.0440 - acc: 1.0000\n",
      "Epoch 831/1000\n",
      " - 0s - loss: 0.0438 - acc: 1.0000\n",
      "Epoch 832/1000\n",
      " - 0s - loss: 0.0436 - acc: 1.0000\n",
      "Epoch 833/1000\n",
      " - 0s - loss: 0.0435 - acc: 1.0000\n",
      "Epoch 834/1000\n",
      " - 0s - loss: 0.0433 - acc: 1.0000\n",
      "Epoch 835/1000\n",
      " - 0s - loss: 0.0432 - acc: 1.0000\n",
      "Epoch 836/1000\n",
      " - 0s - loss: 0.0431 - acc: 1.0000\n",
      "Epoch 837/1000\n",
      " - 0s - loss: 0.0430 - acc: 1.0000\n",
      "Epoch 838/1000\n",
      " - 0s - loss: 0.0429 - acc: 1.0000\n",
      "Epoch 839/1000\n",
      " - 0s - loss: 0.0427 - acc: 1.0000\n",
      "Epoch 840/1000\n",
      " - 0s - loss: 0.0425 - acc: 1.0000\n",
      "Epoch 841/1000\n",
      " - 0s - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 842/1000\n",
      " - 0s - loss: 0.0423 - acc: 1.0000\n",
      "Epoch 843/1000\n",
      " - 0s - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 844/1000\n",
      " - 0s - loss: 0.0420 - acc: 1.0000\n",
      "Epoch 845/1000\n",
      " - 0s - loss: 0.0419 - acc: 1.0000\n",
      "Epoch 846/1000\n",
      " - 0s - loss: 0.0418 - acc: 1.0000\n",
      "Epoch 847/1000\n",
      " - 0s - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 848/1000\n",
      " - 0s - loss: 0.0415 - acc: 1.0000\n",
      "Epoch 849/1000\n",
      " - 0s - loss: 0.0414 - acc: 1.0000\n",
      "Epoch 850/1000\n",
      " - 0s - loss: 0.0414 - acc: 1.0000\n",
      "Epoch 851/1000\n",
      " - 0s - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 852/1000\n",
      " - 0s - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 853/1000\n",
      " - 0s - loss: 0.0409 - acc: 1.0000\n",
      "Epoch 854/1000\n",
      " - 0s - loss: 0.0408 - acc: 1.0000\n",
      "Epoch 855/1000\n",
      " - 0s - loss: 0.0406 - acc: 1.0000\n",
      "Epoch 856/1000\n",
      " - 0s - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 857/1000\n",
      " - 0s - loss: 0.0403 - acc: 1.0000\n",
      "Epoch 858/1000\n",
      " - 0s - loss: 0.0402 - acc: 1.0000\n",
      "Epoch 859/1000\n",
      " - 0s - loss: 0.0401 - acc: 1.0000\n",
      "Epoch 860/1000\n",
      " - 0s - loss: 0.0400 - acc: 1.0000\n",
      "Epoch 861/1000\n",
      " - 0s - loss: 0.0401 - acc: 1.0000\n",
      "Epoch 862/1000\n",
      " - 0s - loss: 0.0402 - acc: 1.0000\n",
      "Epoch 863/1000\n",
      " - 0s - loss: 0.0396 - acc: 1.0000\n",
      "Epoch 864/1000\n",
      " - 0s - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 865/1000\n",
      " - 0s - loss: 0.0394 - acc: 1.0000\n",
      "Epoch 866/1000\n",
      " - 0s - loss: 0.0393 - acc: 1.0000\n",
      "Epoch 867/1000\n",
      " - 0s - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 868/1000\n",
      " - 0s - loss: 0.0389 - acc: 1.0000\n",
      "Epoch 869/1000\n",
      " - 0s - loss: 0.0390 - acc: 1.0000\n",
      "Epoch 870/1000\n",
      " - 0s - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 871/1000\n",
      " - 0s - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 872/1000\n",
      " - 0s - loss: 0.0385 - acc: 1.0000\n",
      "Epoch 873/1000\n",
      " - 0s - loss: 0.0385 - acc: 1.0000\n",
      "Epoch 874/1000\n",
      " - 0s - loss: 0.0383 - acc: 1.0000\n",
      "Epoch 875/1000\n",
      " - 0s - loss: 0.0382 - acc: 1.0000\n",
      "Epoch 876/1000\n",
      " - 0s - loss: 0.0381 - acc: 1.0000\n",
      "Epoch 877/1000\n",
      " - 0s - loss: 0.0380 - acc: 1.0000\n",
      "Epoch 878/1000\n",
      " - 0s - loss: 0.0378 - acc: 1.0000\n",
      "Epoch 879/1000\n",
      " - 0s - loss: 0.0377 - acc: 1.0000\n",
      "Epoch 880/1000\n",
      " - 0s - loss: 0.0376 - acc: 1.0000\n",
      "Epoch 881/1000\n",
      " - 0s - loss: 0.0375 - acc: 1.0000\n",
      "Epoch 882/1000\n",
      " - 0s - loss: 0.0373 - acc: 1.0000\n",
      "Epoch 883/1000\n",
      " - 0s - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 884/1000\n",
      " - 0s - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 885/1000\n",
      " - 0s - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 886/1000\n",
      " - 0s - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 887/1000\n",
      " - 0s - loss: 0.0367 - acc: 1.0000\n",
      "Epoch 888/1000\n",
      " - 0s - loss: 0.0367 - acc: 1.0000\n",
      "Epoch 889/1000\n",
      " - 0s - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 890/1000\n",
      " - 0s - loss: 0.0365 - acc: 1.0000\n",
      "Epoch 891/1000\n",
      " - 0s - loss: 0.0363 - acc: 1.0000\n",
      "Epoch 892/1000\n",
      " - 0s - loss: 0.0362 - acc: 1.0000\n",
      "Epoch 893/1000\n",
      " - 0s - loss: 0.0361 - acc: 1.0000\n",
      "Epoch 894/1000\n",
      " - 0s - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 895/1000\n",
      " - 0s - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 896/1000\n",
      " - 0s - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 897/1000\n",
      " - 0s - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 898/1000\n",
      " - 0s - loss: 0.0355 - acc: 1.0000\n",
      "Epoch 899/1000\n",
      " - 0s - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 900/1000\n",
      " - 0s - loss: 0.0353 - acc: 1.0000\n",
      "Epoch 901/1000\n",
      " - 0s - loss: 0.0352 - acc: 1.0000\n",
      "Epoch 902/1000\n",
      " - 0s - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 903/1000\n",
      " - 0s - loss: 0.0350 - acc: 1.0000\n",
      "Epoch 904/1000\n",
      " - 0s - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 905/1000\n",
      " - 0s - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 906/1000\n",
      " - 0s - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 907/1000\n",
      " - 0s - loss: 0.0345 - acc: 1.0000\n",
      "Epoch 908/1000\n",
      " - 0s - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 909/1000\n",
      " - 0s - loss: 0.0343 - acc: 1.0000\n",
      "Epoch 910/1000\n",
      " - 0s - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 911/1000\n",
      " - 0s - loss: 0.0343 - acc: 1.0000\n",
      "Epoch 912/1000\n",
      " - 0s - loss: 0.0340 - acc: 1.0000\n",
      "Epoch 913/1000\n",
      " - 0s - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 914/1000\n",
      " - 0s - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 915/1000\n",
      " - 0s - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 916/1000\n",
      " - 0s - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 917/1000\n",
      " - 0s - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 918/1000\n",
      " - 0s - loss: 0.0333 - acc: 1.0000\n",
      "Epoch 919/1000\n",
      " - 0s - loss: 0.0333 - acc: 1.0000\n",
      "Epoch 920/1000\n",
      " - 0s - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 921/1000\n",
      " - 0s - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 922/1000\n",
      " - 0s - loss: 0.0330 - acc: 1.0000\n",
      "Epoch 923/1000\n",
      " - 0s - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 924/1000\n",
      " - 0s - loss: 0.0328 - acc: 1.0000\n",
      "Epoch 925/1000\n",
      " - 0s - loss: 0.0327 - acc: 1.0000\n",
      "Epoch 926/1000\n",
      " - 0s - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 927/1000\n",
      " - 0s - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 928/1000\n",
      " - 0s - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 929/1000\n",
      " - 0s - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 930/1000\n",
      " - 0s - loss: 0.0321 - acc: 1.0000\n",
      "Epoch 931/1000\n",
      " - 0s - loss: 0.0321 - acc: 1.0000\n",
      "Epoch 932/1000\n",
      " - 0s - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 933/1000\n",
      " - 0s - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 934/1000\n",
      " - 0s - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 935/1000\n",
      " - 0s - loss: 0.0317 - acc: 1.0000\n",
      "Epoch 936/1000\n",
      " - 0s - loss: 0.0315 - acc: 1.0000\n",
      "Epoch 937/1000\n",
      " - 0s - loss: 0.0315 - acc: 1.0000\n",
      "Epoch 938/1000\n",
      " - 0s - loss: 0.0314 - acc: 1.0000\n",
      "Epoch 939/1000\n",
      " - 0s - loss: 0.0313 - acc: 1.0000\n",
      "Epoch 940/1000\n",
      " - 0s - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 941/1000\n",
      " - 0s - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 942/1000\n",
      " - 0s - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 943/1000\n",
      " - 0s - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 944/1000\n",
      " - 0s - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 945/1000\n",
      " - 0s - loss: 0.0307 - acc: 1.0000\n",
      "Epoch 946/1000\n",
      " - 0s - loss: 0.0306 - acc: 1.0000\n",
      "Epoch 947/1000\n",
      " - 0s - loss: 0.0305 - acc: 1.0000\n",
      "Epoch 948/1000\n",
      " - 0s - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 949/1000\n",
      " - 0s - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 950/1000\n",
      " - 0s - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 951/1000\n",
      " - 0s - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 952/1000\n",
      " - 0s - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 953/1000\n",
      " - 0s - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 954/1000\n",
      " - 0s - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 955/1000\n",
      " - 0s - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 956/1000\n",
      " - 0s - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 957/1000\n",
      " - 0s - loss: 0.0295 - acc: 1.0000\n",
      "Epoch 958/1000\n",
      " - 0s - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 959/1000\n",
      " - 0s - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 960/1000\n",
      " - 0s - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 961/1000\n",
      " - 0s - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 962/1000\n",
      " - 0s - loss: 0.0291 - acc: 1.0000\n",
      "Epoch 963/1000\n",
      " - 0s - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 964/1000\n",
      " - 0s - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 965/1000\n",
      " - 0s - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 966/1000\n",
      " - 0s - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 967/1000\n",
      " - 0s - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 968/1000\n",
      " - 0s - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 969/1000\n",
      " - 0s - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 970/1000\n",
      " - 0s - loss: 0.0283 - acc: 1.0000\n",
      "Epoch 971/1000\n",
      " - 0s - loss: 0.0283 - acc: 1.0000\n",
      "Epoch 972/1000\n",
      " - 0s - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 973/1000\n",
      " - 0s - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 974/1000\n",
      " - 0s - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 975/1000\n",
      " - 0s - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 976/1000\n",
      " - 0s - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 977/1000\n",
      " - 0s - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 978/1000\n",
      " - 0s - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 979/1000\n",
      " - 0s - loss: 0.0276 - acc: 1.0000\n",
      "Epoch 980/1000\n",
      " - 0s - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 981/1000\n",
      " - 0s - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 982/1000\n",
      " - 0s - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 983/1000\n",
      " - 0s - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 984/1000\n",
      " - 0s - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 985/1000\n",
      " - 0s - loss: 0.0271 - acc: 1.0000\n",
      "Epoch 986/1000\n",
      " - 0s - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 987/1000\n",
      " - 0s - loss: 0.0271 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/1000\n",
      " - 0s - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 989/1000\n",
      " - 0s - loss: 0.0268 - acc: 1.0000\n",
      "Epoch 990/1000\n",
      " - 0s - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 991/1000\n",
      " - 0s - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 992/1000\n",
      " - 0s - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 993/1000\n",
      " - 0s - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 994/1000\n",
      " - 0s - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 995/1000\n",
      " - 0s - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 996/1000\n",
      " - 0s - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 997/1000\n",
      " - 0s - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 998/1000\n",
      " - 0s - loss: 0.0260 - acc: 1.0000\n",
      "Epoch 999/1000\n",
      " - 0s - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 1000/1000\n",
      " - 0s - loss: 0.0258 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22dd284c518>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(data[1:15], label[1:15], epochs=1000, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 0.] -1.0 [-0.73418593]\n",
      "[1. 0. 1. 0. 0.] 1.0 [0.90499914]\n",
      "[1. 0. 0. 1. 0.] 1.0 [0.9051766]\n",
      "[1. 0. 0. 0. 1.] -1.0 [-0.9955049]\n",
      "[1. 1. 1. 0. 0.] 1.0 [0.78906035]\n",
      "[1. 1. 0. 1. 0.] 1.0 [0.7894305]\n",
      "[1. 1. 0. 0. 1.] -1.0 [-0.9980963]\n",
      "[1. 0. 1. 1. 0.] 1.0 [0.9982026]\n",
      "[1. 0. 1. 0. 1.] -1.0 [-0.77834153]\n",
      "[1. 0. 0. 1. 1.] -1.0 [-0.77795434]\n",
      "[1. 1. 1. 1. 0.] 1.0 [0.99575573]\n",
      "[1. 1. 1. 0. 1.] -1.0 [-0.89984185]\n",
      "[1. 1. 0. 1. 1.] -1.0 [-0.8996549]\n",
      "[1. 0. 1. 1. 1.] 1.0 [0.74716973]\n"
     ]
    }
   ],
   "source": [
    "y = base_model.predict(data[1:15])\n",
    "for i in range(len(y)):\n",
    "    print(data[i+1], label[i+1], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 1s - loss: 0.4670 - acc: 0.0714\n",
      "Epoch 2/500\n",
      " - 0s - loss: 0.4613 - acc: 0.0714\n",
      "Epoch 3/500\n",
      " - 0s - loss: 0.4559 - acc: 0.0714\n",
      "Epoch 4/500\n",
      " - 0s - loss: 0.4505 - acc: 0.0714\n",
      "Epoch 5/500\n",
      " - 0s - loss: 0.4450 - acc: 0.0714\n",
      "Epoch 6/500\n",
      " - 0s - loss: 0.4394 - acc: 0.0714\n",
      "Epoch 7/500\n",
      " - 0s - loss: 0.4342 - acc: 0.0714\n",
      "Epoch 8/500\n",
      " - 0s - loss: 0.4289 - acc: 0.0714\n",
      "Epoch 9/500\n",
      " - 0s - loss: 0.4236 - acc: 0.0714\n",
      "Epoch 10/500\n",
      " - 0s - loss: 0.4179 - acc: 0.0714\n",
      "Epoch 11/500\n",
      " - 0s - loss: 0.4127 - acc: 0.0714\n",
      "Epoch 12/500\n",
      " - 0s - loss: 0.4075 - acc: 0.0714\n",
      "Epoch 13/500\n",
      " - 0s - loss: 0.4023 - acc: 0.0714\n",
      "Epoch 14/500\n",
      " - 0s - loss: 0.3972 - acc: 0.0714\n",
      "Epoch 15/500\n",
      " - 0s - loss: 0.3918 - acc: 0.0714\n",
      "Epoch 16/500\n",
      " - 0s - loss: 0.3868 - acc: 0.0714\n",
      "Epoch 17/500\n",
      " - 0s - loss: 0.3817 - acc: 0.0714\n",
      "Epoch 18/500\n",
      " - 0s - loss: 0.3769 - acc: 0.0714\n",
      "Epoch 19/500\n",
      " - 0s - loss: 0.3716 - acc: 0.2857\n",
      "Epoch 20/500\n",
      " - 0s - loss: 0.3668 - acc: 0.2857\n",
      "Epoch 21/500\n",
      " - 0s - loss: 0.3620 - acc: 0.2857\n",
      "Epoch 22/500\n",
      " - 0s - loss: 0.3573 - acc: 0.2857\n",
      "Epoch 23/500\n",
      " - 0s - loss: 0.3525 - acc: 0.2857\n",
      "Epoch 24/500\n",
      " - 0s - loss: 0.3478 - acc: 0.2857\n",
      "Epoch 25/500\n",
      " - 0s - loss: 0.3432 - acc: 0.2857\n",
      "Epoch 26/500\n",
      " - 0s - loss: 0.3387 - acc: 0.2857\n",
      "Epoch 27/500\n",
      " - 0s - loss: 0.3345 - acc: 0.2857\n",
      "Epoch 28/500\n",
      " - 0s - loss: 0.3299 - acc: 0.2857\n",
      "Epoch 29/500\n",
      " - 0s - loss: 0.3257 - acc: 0.2857\n",
      "Epoch 30/500\n",
      " - 0s - loss: 0.3214 - acc: 0.2857\n",
      "Epoch 31/500\n",
      " - 0s - loss: 0.3174 - acc: 0.2857\n",
      "Epoch 32/500\n",
      " - 0s - loss: 0.3132 - acc: 0.2857\n",
      "Epoch 33/500\n",
      " - 0s - loss: 0.3096 - acc: 0.2857\n",
      "Epoch 34/500\n",
      " - 0s - loss: 0.3053 - acc: 0.2857\n",
      "Epoch 35/500\n",
      " - 0s - loss: 0.3016 - acc: 0.2857\n",
      "Epoch 36/500\n",
      " - 0s - loss: 0.2980 - acc: 0.2857\n",
      "Epoch 37/500\n",
      " - 0s - loss: 0.2942 - acc: 0.2857\n",
      "Epoch 38/500\n",
      " - 0s - loss: 0.2909 - acc: 0.2857\n",
      "Epoch 39/500\n",
      " - 0s - loss: 0.2876 - acc: 0.2857\n",
      "Epoch 40/500\n",
      " - 0s - loss: 0.2841 - acc: 0.2857\n",
      "Epoch 41/500\n",
      " - 0s - loss: 0.2808 - acc: 0.2857\n",
      "Epoch 42/500\n",
      " - 0s - loss: 0.2776 - acc: 0.2857\n",
      "Epoch 43/500\n",
      " - 0s - loss: 0.2746 - acc: 0.3571\n",
      "Epoch 44/500\n",
      " - 0s - loss: 0.2715 - acc: 0.3571\n",
      "Epoch 45/500\n",
      " - 0s - loss: 0.2687 - acc: 0.4286\n",
      "Epoch 46/500\n",
      " - 0s - loss: 0.2662 - acc: 0.4286\n",
      "Epoch 47/500\n",
      " - 0s - loss: 0.2636 - acc: 0.5000\n",
      "Epoch 48/500\n",
      " - 0s - loss: 0.2613 - acc: 0.5000\n",
      "Epoch 49/500\n",
      " - 0s - loss: 0.2588 - acc: 0.5000\n",
      "Epoch 50/500\n",
      " - 0s - loss: 0.2568 - acc: 0.5000\n",
      "Epoch 51/500\n",
      " - 0s - loss: 0.2551 - acc: 0.5000\n",
      "Epoch 52/500\n",
      " - 0s - loss: 0.2531 - acc: 0.5000\n",
      "Epoch 53/500\n",
      " - 0s - loss: 0.2513 - acc: 0.5000\n",
      "Epoch 54/500\n",
      " - 0s - loss: 0.2498 - acc: 0.5000\n",
      "Epoch 55/500\n",
      " - 0s - loss: 0.2480 - acc: 0.5000\n",
      "Epoch 56/500\n",
      " - 0s - loss: 0.2464 - acc: 0.5000\n",
      "Epoch 57/500\n",
      " - 0s - loss: 0.2446 - acc: 0.5000\n",
      "Epoch 58/500\n",
      " - 0s - loss: 0.2433 - acc: 0.5000\n",
      "Epoch 59/500\n",
      " - 0s - loss: 0.2414 - acc: 0.5000\n",
      "Epoch 60/500\n",
      " - 0s - loss: 0.2399 - acc: 0.5000\n",
      "Epoch 61/500\n",
      " - 0s - loss: 0.2385 - acc: 0.5000\n",
      "Epoch 62/500\n",
      " - 0s - loss: 0.2369 - acc: 0.5000\n",
      "Epoch 63/500\n",
      " - 0s - loss: 0.2354 - acc: 0.5000\n",
      "Epoch 64/500\n",
      " - 0s - loss: 0.2342 - acc: 0.5000\n",
      "Epoch 65/500\n",
      " - 0s - loss: 0.2325 - acc: 0.5714\n",
      "Epoch 66/500\n",
      " - 0s - loss: 0.2313 - acc: 0.5714\n",
      "Epoch 67/500\n",
      " - 0s - loss: 0.2300 - acc: 0.5714\n",
      "Epoch 68/500\n",
      " - 0s - loss: 0.2285 - acc: 0.5714\n",
      "Epoch 69/500\n",
      " - 0s - loss: 0.2272 - acc: 0.5714\n",
      "Epoch 70/500\n",
      " - 0s - loss: 0.2260 - acc: 0.5714\n",
      "Epoch 71/500\n",
      " - 0s - loss: 0.2247 - acc: 0.5714\n",
      "Epoch 72/500\n",
      " - 0s - loss: 0.2236 - acc: 0.5714\n",
      "Epoch 73/500\n",
      " - 0s - loss: 0.2223 - acc: 0.5714\n",
      "Epoch 74/500\n",
      " - 0s - loss: 0.2210 - acc: 0.5714\n",
      "Epoch 75/500\n",
      " - 0s - loss: 0.2201 - acc: 0.5714\n",
      "Epoch 76/500\n",
      " - 0s - loss: 0.2188 - acc: 0.5714\n",
      "Epoch 77/500\n",
      " - 0s - loss: 0.2175 - acc: 0.5714\n",
      "Epoch 78/500\n",
      " - 0s - loss: 0.2168 - acc: 0.5714\n",
      "Epoch 79/500\n",
      " - 0s - loss: 0.2155 - acc: 0.5714\n",
      "Epoch 80/500\n",
      " - 0s - loss: 0.2145 - acc: 0.5714\n",
      "Epoch 81/500\n",
      " - 0s - loss: 0.2134 - acc: 0.5714\n",
      "Epoch 82/500\n",
      " - 0s - loss: 0.2124 - acc: 0.5714\n",
      "Epoch 83/500\n",
      " - 0s - loss: 0.2113 - acc: 0.5714\n",
      "Epoch 84/500\n",
      " - 0s - loss: 0.2102 - acc: 0.5714\n",
      "Epoch 85/500\n",
      " - 0s - loss: 0.2097 - acc: 0.5714\n",
      "Epoch 86/500\n",
      " - 0s - loss: 0.2085 - acc: 0.5714\n",
      "Epoch 87/500\n",
      " - 0s - loss: 0.2075 - acc: 0.5714\n",
      "Epoch 88/500\n",
      " - 0s - loss: 0.2064 - acc: 0.5714\n",
      "Epoch 89/500\n",
      " - 0s - loss: 0.2055 - acc: 0.5714\n",
      "Epoch 90/500\n",
      " - 0s - loss: 0.2046 - acc: 0.5714\n",
      "Epoch 91/500\n",
      " - 0s - loss: 0.2037 - acc: 0.5714\n",
      "Epoch 92/500\n",
      " - 0s - loss: 0.2031 - acc: 0.5714\n",
      "Epoch 93/500\n",
      " - 0s - loss: 0.2022 - acc: 0.5714\n",
      "Epoch 94/500\n",
      " - 0s - loss: 0.2013 - acc: 0.5714\n",
      "Epoch 95/500\n",
      " - 0s - loss: 0.2003 - acc: 0.5714\n",
      "Epoch 96/500\n",
      " - 0s - loss: 0.1994 - acc: 0.6429\n",
      "Epoch 97/500\n",
      " - 0s - loss: 0.1987 - acc: 0.6429\n",
      "Epoch 98/500\n",
      " - 0s - loss: 0.1980 - acc: 0.6429\n",
      "Epoch 99/500\n",
      " - 0s - loss: 0.1970 - acc: 0.6429\n",
      "Epoch 100/500\n",
      " - 0s - loss: 0.1962 - acc: 0.6429\n",
      "Epoch 101/500\n",
      " - 0s - loss: 0.1955 - acc: 0.6429\n",
      "Epoch 102/500\n",
      " - 0s - loss: 0.1947 - acc: 0.6429\n",
      "Epoch 103/500\n",
      " - 0s - loss: 0.1940 - acc: 0.6429\n",
      "Epoch 104/500\n",
      " - 0s - loss: 0.1934 - acc: 0.6429\n",
      "Epoch 105/500\n",
      " - 0s - loss: 0.1927 - acc: 0.6429\n",
      "Epoch 106/500\n",
      " - 0s - loss: 0.1920 - acc: 0.6429\n",
      "Epoch 107/500\n",
      " - 0s - loss: 0.1912 - acc: 0.6429\n",
      "Epoch 108/500\n",
      " - 0s - loss: 0.1904 - acc: 0.6429\n",
      "Epoch 109/500\n",
      " - 0s - loss: 0.1897 - acc: 0.6429\n",
      "Epoch 110/500\n",
      " - 0s - loss: 0.1890 - acc: 0.7143\n",
      "Epoch 111/500\n",
      " - 0s - loss: 0.1884 - acc: 0.7143\n",
      "Epoch 112/500\n",
      " - 0s - loss: 0.1877 - acc: 0.7857\n",
      "Epoch 113/500\n",
      " - 0s - loss: 0.1870 - acc: 0.7857\n",
      "Epoch 114/500\n",
      " - 0s - loss: 0.1864 - acc: 0.7857\n",
      "Epoch 115/500\n",
      " - 0s - loss: 0.1857 - acc: 0.7857\n",
      "Epoch 116/500\n",
      " - 0s - loss: 0.1851 - acc: 0.7857\n",
      "Epoch 117/500\n",
      " - 0s - loss: 0.1845 - acc: 0.7857\n",
      "Epoch 118/500\n",
      " - 0s - loss: 0.1839 - acc: 0.7857\n",
      "Epoch 119/500\n",
      " - 0s - loss: 0.1833 - acc: 0.7857\n",
      "Epoch 120/500\n",
      " - 0s - loss: 0.1827 - acc: 0.7857\n",
      "Epoch 121/500\n",
      " - 0s - loss: 0.1820 - acc: 0.7857\n",
      "Epoch 122/500\n",
      " - 0s - loss: 0.1816 - acc: 0.7857\n",
      "Epoch 123/500\n",
      " - 0s - loss: 0.1809 - acc: 0.7857\n",
      "Epoch 124/500\n",
      " - 0s - loss: 0.1804 - acc: 0.7857\n",
      "Epoch 125/500\n",
      " - 0s - loss: 0.1798 - acc: 0.7857\n",
      "Epoch 126/500\n",
      " - 0s - loss: 0.1792 - acc: 0.7857\n",
      "Epoch 127/500\n",
      " - 0s - loss: 0.1787 - acc: 0.7857\n",
      "Epoch 128/500\n",
      " - 0s - loss: 0.1781 - acc: 0.7857\n",
      "Epoch 129/500\n",
      " - 0s - loss: 0.1776 - acc: 0.7857\n",
      "Epoch 130/500\n",
      " - 0s - loss: 0.1771 - acc: 0.7857\n",
      "Epoch 131/500\n",
      " - 0s - loss: 0.1766 - acc: 0.7857\n",
      "Epoch 132/500\n",
      " - 0s - loss: 0.1760 - acc: 0.7857\n",
      "Epoch 133/500\n",
      " - 0s - loss: 0.1755 - acc: 0.7857\n",
      "Epoch 134/500\n",
      " - 0s - loss: 0.1749 - acc: 0.7857\n",
      "Epoch 135/500\n",
      " - 0s - loss: 0.1744 - acc: 0.7857\n",
      "Epoch 136/500\n",
      " - 0s - loss: 0.1739 - acc: 0.7857\n",
      "Epoch 137/500\n",
      " - 0s - loss: 0.1734 - acc: 0.7857\n",
      "Epoch 138/500\n",
      " - 0s - loss: 0.1729 - acc: 0.7857\n",
      "Epoch 139/500\n",
      " - 0s - loss: 0.1724 - acc: 0.7857\n",
      "Epoch 140/500\n",
      " - 0s - loss: 0.1720 - acc: 0.7857\n",
      "Epoch 141/500\n",
      " - 0s - loss: 0.1716 - acc: 0.7857\n",
      "Epoch 142/500\n",
      " - 0s - loss: 0.1710 - acc: 0.7857\n",
      "Epoch 143/500\n",
      " - 0s - loss: 0.1705 - acc: 0.7857\n",
      "Epoch 144/500\n",
      " - 0s - loss: 0.1700 - acc: 0.7857\n",
      "Epoch 145/500\n",
      " - 0s - loss: 0.1696 - acc: 0.7857\n",
      "Epoch 146/500\n",
      " - 0s - loss: 0.1690 - acc: 0.7857\n",
      "Epoch 147/500\n",
      " - 0s - loss: 0.1686 - acc: 0.7857\n",
      "Epoch 148/500\n",
      " - 0s - loss: 0.1681 - acc: 0.7857\n",
      "Epoch 149/500\n",
      " - 0s - loss: 0.1676 - acc: 0.7857\n",
      "Epoch 150/500\n",
      " - 0s - loss: 0.1672 - acc: 0.7857\n",
      "Epoch 151/500\n",
      " - 0s - loss: 0.1667 - acc: 0.7857\n",
      "Epoch 152/500\n",
      " - 0s - loss: 0.1662 - acc: 0.7857\n",
      "Epoch 153/500\n",
      " - 0s - loss: 0.1658 - acc: 0.7857\n",
      "Epoch 154/500\n",
      " - 0s - loss: 0.1653 - acc: 0.7857\n",
      "Epoch 155/500\n",
      " - 0s - loss: 0.1649 - acc: 0.7857\n",
      "Epoch 156/500\n",
      " - 0s - loss: 0.1644 - acc: 0.7857\n",
      "Epoch 157/500\n",
      " - 0s - loss: 0.1639 - acc: 0.7857\n",
      "Epoch 158/500\n",
      " - 0s - loss: 0.1635 - acc: 0.7857\n",
      "Epoch 159/500\n",
      " - 0s - loss: 0.1630 - acc: 0.7857\n",
      "Epoch 160/500\n",
      " - 0s - loss: 0.1627 - acc: 0.7857\n",
      "Epoch 161/500\n",
      " - 0s - loss: 0.1622 - acc: 0.7857\n",
      "Epoch 162/500\n",
      " - 0s - loss: 0.1617 - acc: 0.7857\n",
      "Epoch 163/500\n",
      " - 0s - loss: 0.1613 - acc: 0.7857\n",
      "Epoch 164/500\n",
      " - 0s - loss: 0.1608 - acc: 0.7857\n",
      "Epoch 165/500\n",
      " - 0s - loss: 0.1603 - acc: 0.7857\n",
      "Epoch 166/500\n",
      " - 0s - loss: 0.1599 - acc: 0.7857\n",
      "Epoch 167/500\n",
      " - 0s - loss: 0.1594 - acc: 0.7857\n",
      "Epoch 168/500\n",
      " - 0s - loss: 0.1590 - acc: 0.7857\n",
      "Epoch 169/500\n",
      " - 0s - loss: 0.1586 - acc: 0.7857\n",
      "Epoch 170/500\n",
      " - 0s - loss: 0.1581 - acc: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/500\n",
      " - 0s - loss: 0.1577 - acc: 0.7857\n",
      "Epoch 172/500\n",
      " - 0s - loss: 0.1572 - acc: 0.7857\n",
      "Epoch 173/500\n",
      " - 0s - loss: 0.1567 - acc: 0.7857\n",
      "Epoch 174/500\n",
      " - 0s - loss: 0.1562 - acc: 0.7857\n",
      "Epoch 175/500\n",
      " - 0s - loss: 0.1558 - acc: 0.7857\n",
      "Epoch 176/500\n",
      " - 0s - loss: 0.1553 - acc: 0.7857\n",
      "Epoch 177/500\n",
      " - 0s - loss: 0.1549 - acc: 0.7857\n",
      "Epoch 178/500\n",
      " - 0s - loss: 0.1544 - acc: 0.7857\n",
      "Epoch 179/500\n",
      " - 0s - loss: 0.1539 - acc: 0.7857\n",
      "Epoch 180/500\n",
      " - 0s - loss: 0.1535 - acc: 0.7857\n",
      "Epoch 181/500\n",
      " - 0s - loss: 0.1530 - acc: 0.7857\n",
      "Epoch 182/500\n",
      " - 0s - loss: 0.1524 - acc: 0.7857\n",
      "Epoch 183/500\n",
      " - 0s - loss: 0.1521 - acc: 0.7857\n",
      "Epoch 184/500\n",
      " - 0s - loss: 0.1515 - acc: 0.7857\n",
      "Epoch 185/500\n",
      " - 0s - loss: 0.1510 - acc: 0.7857\n",
      "Epoch 186/500\n",
      " - 0s - loss: 0.1505 - acc: 0.7857\n",
      "Epoch 187/500\n",
      " - 0s - loss: 0.1501 - acc: 0.7857\n",
      "Epoch 188/500\n",
      " - 0s - loss: 0.1496 - acc: 0.7857\n",
      "Epoch 189/500\n",
      " - 0s - loss: 0.1491 - acc: 0.7857\n",
      "Epoch 190/500\n",
      " - 0s - loss: 0.1486 - acc: 0.7857\n",
      "Epoch 191/500\n",
      " - 0s - loss: 0.1480 - acc: 0.7857\n",
      "Epoch 192/500\n",
      " - 0s - loss: 0.1475 - acc: 0.7857\n",
      "Epoch 193/500\n",
      " - 0s - loss: 0.1471 - acc: 0.7857\n",
      "Epoch 194/500\n",
      " - 0s - loss: 0.1466 - acc: 0.7857\n",
      "Epoch 195/500\n",
      " - 0s - loss: 0.1460 - acc: 0.7857\n",
      "Epoch 196/500\n",
      " - 0s - loss: 0.1455 - acc: 0.7857\n",
      "Epoch 197/500\n",
      " - 0s - loss: 0.1450 - acc: 0.7857\n",
      "Epoch 198/500\n",
      " - 0s - loss: 0.1445 - acc: 0.7857\n",
      "Epoch 199/500\n",
      " - 0s - loss: 0.1440 - acc: 0.7857\n",
      "Epoch 200/500\n",
      " - 0s - loss: 0.1435 - acc: 0.7857\n",
      "Epoch 201/500\n",
      " - 0s - loss: 0.1430 - acc: 0.7857\n",
      "Epoch 202/500\n",
      " - 0s - loss: 0.1425 - acc: 0.7857\n",
      "Epoch 203/500\n",
      " - 0s - loss: 0.1419 - acc: 0.7857\n",
      "Epoch 204/500\n",
      " - 0s - loss: 0.1414 - acc: 0.7857\n",
      "Epoch 205/500\n",
      " - 0s - loss: 0.1409 - acc: 0.7857\n",
      "Epoch 206/500\n",
      " - 0s - loss: 0.1404 - acc: 0.7857\n",
      "Epoch 207/500\n",
      " - 0s - loss: 0.1399 - acc: 0.7857\n",
      "Epoch 208/500\n",
      " - 0s - loss: 0.1394 - acc: 0.7857\n",
      "Epoch 209/500\n",
      " - 0s - loss: 0.1389 - acc: 0.7857\n",
      "Epoch 210/500\n",
      " - 0s - loss: 0.1382 - acc: 0.7857\n",
      "Epoch 211/500\n",
      " - 0s - loss: 0.1374 - acc: 0.7857\n",
      "Epoch 212/500\n",
      " - 0s - loss: 0.1367 - acc: 0.7857\n",
      "Epoch 213/500\n",
      " - 0s - loss: 0.1358 - acc: 0.7857\n",
      "Epoch 214/500\n",
      " - 0s - loss: 0.1348 - acc: 0.7857\n",
      "Epoch 215/500\n",
      " - 0s - loss: 0.1341 - acc: 0.7857\n",
      "Epoch 216/500\n",
      " - 0s - loss: 0.1332 - acc: 0.7857\n",
      "Epoch 217/500\n",
      " - 0s - loss: 0.1324 - acc: 0.7857\n",
      "Epoch 218/500\n",
      " - 0s - loss: 0.1316 - acc: 0.7857\n",
      "Epoch 219/500\n",
      " - 0s - loss: 0.1308 - acc: 0.7857\n",
      "Epoch 220/500\n",
      " - 0s - loss: 0.1299 - acc: 0.7857\n",
      "Epoch 221/500\n",
      " - 0s - loss: 0.1291 - acc: 0.7857\n",
      "Epoch 222/500\n",
      " - 0s - loss: 0.1283 - acc: 0.7857\n",
      "Epoch 223/500\n",
      " - 0s - loss: 0.1275 - acc: 0.7857\n",
      "Epoch 224/500\n",
      " - 0s - loss: 0.1269 - acc: 0.7857\n",
      "Epoch 225/500\n",
      " - 0s - loss: 0.1259 - acc: 0.7857\n",
      "Epoch 226/500\n",
      " - 0s - loss: 0.1251 - acc: 0.7857\n",
      "Epoch 227/500\n",
      " - 0s - loss: 0.1245 - acc: 0.7857\n",
      "Epoch 228/500\n",
      " - 0s - loss: 0.1238 - acc: 0.7857\n",
      "Epoch 229/500\n",
      " - 0s - loss: 0.1230 - acc: 0.7857\n",
      "Epoch 230/500\n",
      " - 0s - loss: 0.1223 - acc: 0.7857\n",
      "Epoch 231/500\n",
      " - 0s - loss: 0.1217 - acc: 0.7857\n",
      "Epoch 232/500\n",
      " - 0s - loss: 0.1209 - acc: 0.7857\n",
      "Epoch 233/500\n",
      " - 0s - loss: 0.1203 - acc: 0.7857\n",
      "Epoch 234/500\n",
      " - 0s - loss: 0.1196 - acc: 0.7857\n",
      "Epoch 235/500\n",
      " - 0s - loss: 0.1190 - acc: 0.7857\n",
      "Epoch 236/500\n",
      " - 0s - loss: 0.1185 - acc: 0.7857\n",
      "Epoch 237/500\n",
      " - 0s - loss: 0.1178 - acc: 0.7857\n",
      "Epoch 238/500\n",
      " - 0s - loss: 0.1172 - acc: 0.7857\n",
      "Epoch 239/500\n",
      " - 0s - loss: 0.1166 - acc: 0.7857\n",
      "Epoch 240/500\n",
      " - 0s - loss: 0.1160 - acc: 0.7857\n",
      "Epoch 241/500\n",
      " - 0s - loss: 0.1154 - acc: 0.7857\n",
      "Epoch 242/500\n",
      " - 0s - loss: 0.1149 - acc: 0.7857\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.1143 - acc: 0.7857\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.1138 - acc: 0.7857\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.1132 - acc: 0.7857\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.1127 - acc: 0.7857\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.1122 - acc: 0.7857\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.1117 - acc: 0.7857\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.1111 - acc: 0.7857\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.1107 - acc: 0.7857\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.1102 - acc: 0.7857\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.1097 - acc: 0.7857\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.1093 - acc: 0.7857\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.1088 - acc: 0.7857\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.1083 - acc: 0.7857\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.1078 - acc: 0.7857\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.1074 - acc: 0.7857\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.1070 - acc: 0.7857\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.1065 - acc: 0.7857\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.1060 - acc: 0.7857\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.1056 - acc: 0.7857\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.1051 - acc: 0.7857\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.1047 - acc: 0.7857\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.1042 - acc: 0.7857\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.1037 - acc: 0.7857\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.1033 - acc: 0.7857\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.1028 - acc: 0.7857\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.1024 - acc: 0.7857\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.1019 - acc: 0.7857\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.1014 - acc: 0.7857\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.1010 - acc: 0.7857\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.1004 - acc: 0.7857\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.1000 - acc: 0.7857\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.0995 - acc: 0.7857\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.0989 - acc: 0.7857\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.0985 - acc: 0.7857\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.0980 - acc: 0.7857\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.0975 - acc: 0.7857\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.0969 - acc: 0.7857\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.0964 - acc: 0.7857\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.0959 - acc: 0.7857\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.0954 - acc: 0.7857\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.0948 - acc: 0.7857\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.0944 - acc: 0.7857\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.0937 - acc: 0.7857\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.0931 - acc: 0.7857\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.0926 - acc: 0.7857\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.0921 - acc: 0.7857\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.0914 - acc: 0.7857\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.0908 - acc: 0.7857\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.0903 - acc: 0.7857\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.0895 - acc: 0.7857\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.0890 - acc: 0.7857\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.0883 - acc: 0.7857\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.0878 - acc: 0.7857\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.0871 - acc: 0.7857\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.0864 - acc: 0.8571\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.0858 - acc: 0.9286\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.0852 - acc: 0.9286\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.0845 - acc: 0.9286\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.0838 - acc: 0.9286\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.0831 - acc: 0.9286\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.0824 - acc: 0.9286\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.0817 - acc: 0.9286\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.0811 - acc: 0.9286\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.0804 - acc: 1.0000\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.0798 - acc: 1.0000\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.0790 - acc: 1.0000\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.0775 - acc: 1.0000\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.0769 - acc: 1.0000\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.0763 - acc: 1.0000\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.0754 - acc: 1.0000\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.0748 - acc: 1.0000\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.0740 - acc: 1.0000\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.0734 - acc: 1.0000\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.0726 - acc: 1.0000\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.0721 - acc: 1.0000\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.0712 - acc: 1.0000\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.0705 - acc: 1.0000\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.0698 - acc: 1.0000\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.0693 - acc: 1.0000\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.0684 - acc: 1.0000\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.0678 - acc: 1.0000\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.0671 - acc: 1.0000\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.0666 - acc: 1.0000\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.0651 - acc: 1.0000\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.0638 - acc: 1.0000\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.0632 - acc: 1.0000\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.0626 - acc: 1.0000\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.0620 - acc: 1.0000\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.0606 - acc: 1.0000\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.0601 - acc: 1.0000\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.0594 - acc: 1.0000\n",
      "Epoch 338/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0588 - acc: 1.0000\n",
      "Epoch 339/500\n",
      " - 0s - loss: 0.0583 - acc: 1.0000\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.0577 - acc: 1.0000\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.0572 - acc: 1.0000\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.0566 - acc: 1.0000\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.0560 - acc: 1.0000\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.0556 - acc: 1.0000\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.0549 - acc: 1.0000\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.0544 - acc: 1.0000\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.0539 - acc: 1.0000\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.0534 - acc: 1.0000\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.0530 - acc: 1.0000\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.0524 - acc: 1.0000\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.0519 - acc: 1.0000\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.0515 - acc: 1.0000\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.0509 - acc: 1.0000\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.0504 - acc: 1.0000\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.0500 - acc: 1.0000\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.0491 - acc: 1.0000\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.0486 - acc: 1.0000\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.0478 - acc: 1.0000\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.0474 - acc: 1.0000\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.0466 - acc: 1.0000\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.0462 - acc: 1.0000\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.0458 - acc: 1.0000\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.0455 - acc: 1.0000\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.0450 - acc: 1.0000\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.0447 - acc: 1.0000\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.0443 - acc: 1.0000\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.0440 - acc: 1.0000\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.0436 - acc: 1.0000\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.0433 - acc: 1.0000\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.0429 - acc: 1.0000\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.0426 - acc: 1.0000\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.0423 - acc: 1.0000\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.0420 - acc: 1.0000\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.0407 - acc: 1.0000\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.0404 - acc: 1.0000\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.0401 - acc: 1.0000\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.0398 - acc: 1.0000\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.0396 - acc: 1.0000\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.0390 - acc: 1.0000\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.0387 - acc: 1.0000\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.0384 - acc: 1.0000\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.0381 - acc: 1.0000\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.0376 - acc: 1.0000\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.0374 - acc: 1.0000\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.0369 - acc: 1.0000\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.0362 - acc: 1.0000\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.0355 - acc: 1.0000\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.0353 - acc: 1.0000\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.0340 - acc: 1.0000\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.0336 - acc: 1.0000\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.0334 - acc: 1.0000\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.0332 - acc: 1.0000\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.0330 - acc: 1.0000\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.0327 - acc: 1.0000\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.0326 - acc: 1.0000\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.0322 - acc: 1.0000\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.0317 - acc: 1.0000\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.0315 - acc: 1.0000\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.0313 - acc: 1.0000\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.0307 - acc: 1.0000\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.0306 - acc: 1.0000\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.0291 - acc: 1.0000\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.0288 - acc: 1.0000\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.0283 - acc: 1.0000\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.0276 - acc: 1.0000\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.0271 - acc: 1.0000\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.0268 - acc: 1.0000\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.0260 - acc: 1.0000\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.0254 - acc: 1.0000\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.0247 - acc: 1.0000\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.0246 - acc: 1.0000\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.0242 - acc: 1.0000\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.0239 - acc: 1.0000\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.0236 - acc: 1.0000\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.0231 - acc: 1.0000\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.0223 - acc: 1.0000\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.0216 - acc: 1.0000\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.0207 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22dd2827ba8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit([data[1:15], ht_1_input[1:15], ht_2_input[1:15], ht_3_input[1:15], ht_4_input[1:15]], \n",
    "                   np_label[1:15], \n",
    "                   epochs=500,\n",
    "                   batch_size=1,\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.22956319],\n",
       "        [-0.4299929 ],\n",
       "        [ 2.0729353 ],\n",
       "        [ 2.3534873 ],\n",
       "        [-2.8235989 ]], dtype=float32),\n",
       " array([-0.70369315], dtype=float32),\n",
       " array([[2.435016]], dtype=float32),\n",
       " array([[-0.42480403]], dtype=float32),\n",
       " array([[2.3615427]], dtype=float32),\n",
       " array([[1.7641373]], dtype=float32),\n",
       " array([[-1.7631199 ],\n",
       "        [-0.57229006],\n",
       "        [ 1.5718032 ],\n",
       "        [-1.6381247 ]], dtype=float32),\n",
       " array([0.60496473], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_weight = combined_model.get_weights()\n",
    "net_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report():\n",
    "    for i in range(1,15):\n",
    "        bm = base_model.predict(np.reshape(data[i], (1,5)))\n",
    "        \n",
    "        cm = combined_model.predict([np.reshape(data[i], (1,5)), \n",
    "                                np.reshape(ht_input[i], (1,4))])\n",
    "        \n",
    "#         document_output = 'multiply'\n",
    "#         document_predict = Model(inputs=combined_model.input,\n",
    "#                                      outputs=combined_model.get_layer(document_output).output)\n",
    "#         doc_output = document_predict.predict([np.reshape(data[i], (1,5)), \n",
    "#                                       ht_1_input[i], \n",
    "#                                       ht_2_input[i], \n",
    "#                                       ht_3_input[i], \n",
    "#                                       ht_4_input[i]])\n",
    "        \n",
    "        layer_name = 'concatenate'\n",
    "        concat_after_relu = Model(inputs=combined_model.input,\n",
    "                                     outputs=combined_model.get_layer(layer_name).output)\n",
    "        concat_output = concat_after_relu.predict([np.reshape(data[i], (1,5)), \n",
    "                                     np.reshape(ht_input[i], (1,4))])\n",
    "        \n",
    "        print(data[i], '\\t', np_label[i], '\\t', bm.flatten(), '\\t', cm.flatten(), '\\t',concat_output.flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 5 array(s), but instead got the following list of 2 arrays: [array([[1., 1., 0., 0., 0.]]), array([[-1.,  0.,  0.,  0.]])]...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-e9c8e97115c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-16739adf6f01>\u001b[0m in \u001b[0;36mreport\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         cm = combined_model.predict([np.reshape(data[i], (1,5)), \n\u001b[1;32m----> 6\u001b[1;33m                                 np.reshape(ht_input[i], (1,4))])\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#         document_output = 'multiply'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                              'argument.')\n\u001b[0;32m   1151\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;34m'Expected to see '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' array(s), '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[1;34m'but instead got the following list of '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 5 array(s), but instead got the following list of 2 arrays: [array([[1., 1., 0., 0., 0.]]), array([[-1.,  0.,  0.,  0.]])]..."
     ]
    }
   ],
   "source": [
    "# report()\n",
    "# need to modify the ht_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# base_model.save('overfit_base_model.h5')\n",
    "# combined_model.save('overfit_combined_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm = base_model.predict(np.reshape(data[test_idx], (1,5)))\n",
    "# print(bm)\n",
    "\n",
    "# before jointly trained.\n",
    "# 0.7995629"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB network Model\n",
    "#### concat and split layer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               [(None, 1), (None, 1 0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_7 (Model)                 (None, 1)            6           input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 1)            0           lambda_1[0][0]                   \n",
      "                                                                 model_7[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 1)            0           lambda_1[0][1]                   \n",
      "                                                                 model_7[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 1)            0           lambda_1[0][2]                   \n",
      "                                                                 model_7[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 1)            0           lambda_1[0][3]                   \n",
      "                                                                 model_7[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_layer (Dense)              (None, 1)            1           multiply_3[0][0]                 \n",
      "                                                                 multiply_4[0][0]                 \n",
      "                                                                 multiply_5[0][0]                 \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Lambda)            (None, 4)            0           relu_layer[0][0]                 \n",
      "                                                                 relu_layer[1][0]                 \n",
      "                                                                 relu_layer[2][0]                 \n",
      "                                                                 relu_layer[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            5           concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the combined model\n",
    "# Combined model\n",
    "human_terms_len = 4\n",
    "\n",
    "base_model = build_base_model(data.shape[1])\n",
    "\n",
    "combined_input_layer = Input(shape=(data.shape[1],))\n",
    "\n",
    "# build the hard coded weight for human terms\n",
    "ht_input_layer = Input(shape=(human_terms_len,))\n",
    "\n",
    "split = Lambda( lambda x: tf.split(x,num_or_size_splits=human_terms_len,axis=1))(ht_input_layer)\n",
    "\n",
    "# get the document prediction\n",
    "label_layer = base_model(combined_input_layer)\n",
    "\n",
    "# multiply and pass it into relu\n",
    "# initialize relu layer\n",
    "\n",
    "relu_layer = Dense(1, activation='relu', name='relu_layer', use_bias=False, kernel_initializer='ones')\n",
    "\n",
    "# stack the multiply layer\n",
    "dense_layer = []\n",
    "for i in range(human_terms_len):\n",
    "    dense_layer.append(relu_layer(Multiply()([split[i], label_layer])))\n",
    "\n",
    "# concat all the result   \n",
    "concat = Lambda( lambda x: tf.concat(x, axis=1), name='concatenate')(dense_layer)\n",
    "\n",
    "# pass it to sigmoid layer\n",
    "output_layer = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "combined_model = Model(inputs=[combined_input_layer, ht_input_layer], outputs=output_layer)\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(loss='mse',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "combined_model.compile(loss='mse',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 0s - loss: 0.9015 - acc: 0.2857\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 0.8843 - acc: 0.2857\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 0.8724 - acc: 0.2857\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 0.8577 - acc: 0.2857\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 0.8435 - acc: 0.2857\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 0.8345 - acc: 0.2857\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 0.8206 - acc: 0.3571\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 0.8093 - acc: 0.3571\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 0.7982 - acc: 0.3571\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 0.7874 - acc: 0.3571\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 0.7782 - acc: 0.3571\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 0.7710 - acc: 0.2857\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 0.7588 - acc: 0.2857\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 0.7487 - acc: 0.2857\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 0.7415 - acc: 0.2857\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 0.7330 - acc: 0.2857\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 0.7243 - acc: 0.2857\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 0.7209 - acc: 0.2857\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 0.7093 - acc: 0.2857\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 0.7018 - acc: 0.2857\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 0.6967 - acc: 0.2857\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 0.6889 - acc: 0.2857\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 0.6836 - acc: 0.2857\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 0.6778 - acc: 0.2143\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 0.6695 - acc: 0.2143\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 0.6646 - acc: 0.2143\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 0.6586 - acc: 0.2143\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 0.6537 - acc: 0.2143\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 0.6480 - acc: 0.2143\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 0.6426 - acc: 0.2143\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 0.6376 - acc: 0.2143\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 0.6321 - acc: 0.2143\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 0.6280 - acc: 0.2143\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 0.6216 - acc: 0.2143\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 0.6182 - acc: 0.2143\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 0.6131 - acc: 0.2143\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 0.6085 - acc: 0.2143\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 0.6037 - acc: 0.2143\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 0.5995 - acc: 0.2143\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 0.5961 - acc: 0.2857\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 0.5907 - acc: 0.2857\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 0.5864 - acc: 0.2857\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 0.5838 - acc: 0.2857\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 0.5778 - acc: 0.2857\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 0.5745 - acc: 0.2857\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 0.5704 - acc: 0.2857\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 0.5658 - acc: 0.2857\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 0.5631 - acc: 0.2857\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 0.5581 - acc: 0.2857\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 0.5548 - acc: 0.2857\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 0.5506 - acc: 0.2857\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 0.5500 - acc: 0.2857\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 0.5441 - acc: 0.2857\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 0.5394 - acc: 0.2857\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 0.5357 - acc: 0.2857\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 0.5317 - acc: 0.2857\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 0.5288 - acc: 0.2857\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 0.5261 - acc: 0.2857\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 0.5226 - acc: 0.2857\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 0.5179 - acc: 0.2857\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 0.5151 - acc: 0.2857\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 0.5111 - acc: 0.2857\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 0.5088 - acc: 0.2857\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.5039 - acc: 0.2857\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.5007 - acc: 0.2857\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.4991 - acc: 0.2857\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.4947 - acc: 0.2857\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 0.4910 - acc: 0.2857\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 0.4879 - acc: 0.2857\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 0.4848 - acc: 0.2857\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 0.4816 - acc: 0.2857\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 0.4791 - acc: 0.2857\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 0.4755 - acc: 0.2857\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 0.4722 - acc: 0.2857\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.4695 - acc: 0.2857\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.4672 - acc: 0.2857\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.4639 - acc: 0.2857\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.4604 - acc: 0.2857\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 0.4576 - acc: 0.2857\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.4549 - acc: 0.2857\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 0.4513 - acc: 0.2857\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.4489 - acc: 0.2857\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.4455 - acc: 0.2857\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.4430 - acc: 0.2857\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 0.4408 - acc: 0.2857\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 0.4371 - acc: 0.2857\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 0.4373 - acc: 0.2857\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 0.4322 - acc: 0.2857\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 0.4294 - acc: 0.2857\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 0.4263 - acc: 0.2857\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 0.4236 - acc: 0.2857\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 0.4221 - acc: 0.2857\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 0.4184 - acc: 0.2857\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 0.4167 - acc: 0.2857\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 0.4134 - acc: 0.2857\n",
      "Epoch 96/1000\n",
      " - 0s - loss: 0.4121 - acc: 0.2857\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 0.4084 - acc: 0.2857\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.4056 - acc: 0.2857\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 0.4029 - acc: 0.2857\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 0.4012 - acc: 0.2857\n",
      "Epoch 101/1000\n",
      " - 0s - loss: 0.3983 - acc: 0.2857\n",
      "Epoch 102/1000\n",
      " - 0s - loss: 0.3959 - acc: 0.2857\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 0.3947 - acc: 0.2857\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 0.3907 - acc: 0.2857\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 0.3888 - acc: 0.2857\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 0.3867 - acc: 0.2857\n",
      "Epoch 107/1000\n",
      " - 0s - loss: 0.3855 - acc: 0.2857\n",
      "Epoch 108/1000\n",
      " - 0s - loss: 0.3815 - acc: 0.2857\n",
      "Epoch 109/1000\n",
      " - 0s - loss: 0.3797 - acc: 0.2857\n",
      "Epoch 110/1000\n",
      " - 0s - loss: 0.3772 - acc: 0.2857\n",
      "Epoch 111/1000\n",
      " - 0s - loss: 0.3758 - acc: 0.2857\n",
      "Epoch 112/1000\n",
      " - 0s - loss: 0.3724 - acc: 0.2857\n",
      "Epoch 113/1000\n",
      " - 0s - loss: 0.3703 - acc: 0.2857\n",
      "Epoch 114/1000\n",
      " - 0s - loss: 0.3682 - acc: 0.2857\n",
      "Epoch 115/1000\n",
      " - 0s - loss: 0.3656 - acc: 0.2857\n",
      "Epoch 116/1000\n",
      " - 0s - loss: 0.3640 - acc: 0.2857\n",
      "Epoch 117/1000\n",
      " - 0s - loss: 0.3618 - acc: 0.2857\n",
      "Epoch 118/1000\n",
      " - 0s - loss: 0.3595 - acc: 0.2857\n",
      "Epoch 119/1000\n",
      " - 0s - loss: 0.3572 - acc: 0.2857\n",
      "Epoch 120/1000\n",
      " - 0s - loss: 0.3555 - acc: 0.2857\n",
      "Epoch 121/1000\n",
      " - 0s - loss: 0.3531 - acc: 0.2857\n",
      "Epoch 122/1000\n",
      " - 0s - loss: 0.3523 - acc: 0.2857\n",
      "Epoch 123/1000\n",
      " - 0s - loss: 0.3503 - acc: 0.2857\n",
      "Epoch 124/1000\n",
      " - 0s - loss: 0.3473 - acc: 0.2857\n",
      "Epoch 125/1000\n",
      " - 0s - loss: 0.3453 - acc: 0.2857\n",
      "Epoch 126/1000\n",
      " - 0s - loss: 0.3434 - acc: 0.2857\n",
      "Epoch 127/1000\n",
      " - 0s - loss: 0.3414 - acc: 0.2857\n",
      "Epoch 128/1000\n",
      " - 0s - loss: 0.3396 - acc: 0.2857\n",
      "Epoch 129/1000\n",
      " - 0s - loss: 0.3372 - acc: 0.2857\n",
      "Epoch 130/1000\n",
      " - 0s - loss: 0.3353 - acc: 0.2857\n",
      "Epoch 131/1000\n",
      " - 0s - loss: 0.3339 - acc: 0.2857\n",
      "Epoch 132/1000\n",
      " - 0s - loss: 0.3327 - acc: 0.2857\n",
      "Epoch 133/1000\n",
      " - 0s - loss: 0.3297 - acc: 0.2857\n",
      "Epoch 134/1000\n",
      " - 0s - loss: 0.3284 - acc: 0.2857\n",
      "Epoch 135/1000\n",
      " - 0s - loss: 0.3259 - acc: 0.2857\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.3253 - acc: 0.2857\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.3228 - acc: 0.2857\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.3204 - acc: 0.2857\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.3201 - acc: 0.2857\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.3172 - acc: 0.2857\n",
      "Epoch 141/1000\n",
      " - 0s - loss: 0.3156 - acc: 0.2857\n",
      "Epoch 142/1000\n",
      " - 0s - loss: 0.3133 - acc: 0.2857\n",
      "Epoch 143/1000\n",
      " - 0s - loss: 0.3119 - acc: 0.2857\n",
      "Epoch 144/1000\n",
      " - 0s - loss: 0.3103 - acc: 0.2857\n",
      "Epoch 145/1000\n",
      " - 0s - loss: 0.3085 - acc: 0.2857\n",
      "Epoch 146/1000\n",
      " - 0s - loss: 0.3068 - acc: 0.2857\n",
      "Epoch 147/1000\n",
      " - 0s - loss: 0.3052 - acc: 0.2857\n",
      "Epoch 148/1000\n",
      " - 0s - loss: 0.3038 - acc: 0.2857\n",
      "Epoch 149/1000\n",
      " - 0s - loss: 0.3021 - acc: 0.2857\n",
      "Epoch 150/1000\n",
      " - 0s - loss: 0.3002 - acc: 0.2857\n",
      "Epoch 151/1000\n",
      " - 0s - loss: 0.2991 - acc: 0.2857\n",
      "Epoch 152/1000\n",
      " - 0s - loss: 0.2975 - acc: 0.2857\n",
      "Epoch 153/1000\n",
      " - 0s - loss: 0.2958 - acc: 0.2857\n",
      "Epoch 154/1000\n",
      " - 0s - loss: 0.2938 - acc: 0.2857\n",
      "Epoch 155/1000\n",
      " - 0s - loss: 0.2922 - acc: 0.2857\n",
      "Epoch 156/1000\n",
      " - 0s - loss: 0.2908 - acc: 0.2857\n",
      "Epoch 157/1000\n",
      " - 0s - loss: 0.2893 - acc: 0.2857\n",
      "Epoch 158/1000\n",
      " - 0s - loss: 0.2875 - acc: 0.2857\n",
      "Epoch 159/1000\n",
      " - 0s - loss: 0.2862 - acc: 0.2857\n",
      "Epoch 160/1000\n",
      " - 0s - loss: 0.2846 - acc: 0.2857\n",
      "Epoch 161/1000\n",
      " - 0s - loss: 0.2832 - acc: 0.2857\n",
      "Epoch 162/1000\n",
      " - 0s - loss: 0.2814 - acc: 0.2857\n",
      "Epoch 163/1000\n",
      " - 0s - loss: 0.2804 - acc: 0.2857\n",
      "Epoch 164/1000\n",
      " - 0s - loss: 0.2791 - acc: 0.2857\n",
      "Epoch 165/1000\n",
      " - 0s - loss: 0.2775 - acc: 0.2857\n",
      "Epoch 166/1000\n",
      " - 0s - loss: 0.2766 - acc: 0.2857\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2747 - acc: 0.2857\n",
      "Epoch 168/1000\n",
      " - 0s - loss: 0.2733 - acc: 0.2857\n",
      "Epoch 169/1000\n",
      " - 0s - loss: 0.2714 - acc: 0.2857\n",
      "Epoch 170/1000\n",
      " - 0s - loss: 0.2703 - acc: 0.2857\n",
      "Epoch 171/1000\n",
      " - 0s - loss: 0.2691 - acc: 0.2857\n",
      "Epoch 172/1000\n",
      " - 0s - loss: 0.2680 - acc: 0.2857\n",
      "Epoch 173/1000\n",
      " - 0s - loss: 0.2661 - acc: 0.2857\n",
      "Epoch 174/1000\n",
      " - 0s - loss: 0.2649 - acc: 0.2857\n",
      "Epoch 175/1000\n",
      " - 0s - loss: 0.2636 - acc: 0.2857\n",
      "Epoch 176/1000\n",
      " - 0s - loss: 0.2620 - acc: 0.2857\n",
      "Epoch 177/1000\n",
      " - 0s - loss: 0.2608 - acc: 0.2857\n",
      "Epoch 178/1000\n",
      " - 0s - loss: 0.2594 - acc: 0.2857\n",
      "Epoch 179/1000\n",
      " - 0s - loss: 0.2579 - acc: 0.2857\n",
      "Epoch 180/1000\n",
      " - 0s - loss: 0.2571 - acc: 0.2857\n",
      "Epoch 181/1000\n",
      " - 0s - loss: 0.2555 - acc: 0.2857\n",
      "Epoch 182/1000\n",
      " - 0s - loss: 0.2543 - acc: 0.2857\n",
      "Epoch 183/1000\n",
      " - 0s - loss: 0.2529 - acc: 0.2857\n",
      "Epoch 184/1000\n",
      " - 0s - loss: 0.2519 - acc: 0.2857\n",
      "Epoch 185/1000\n",
      " - 0s - loss: 0.2504 - acc: 0.2857\n",
      "Epoch 186/1000\n",
      " - 0s - loss: 0.2495 - acc: 0.2857\n",
      "Epoch 187/1000\n",
      " - 0s - loss: 0.2482 - acc: 0.2857\n",
      "Epoch 188/1000\n",
      " - 0s - loss: 0.2466 - acc: 0.2857\n",
      "Epoch 189/1000\n",
      " - 0s - loss: 0.2456 - acc: 0.2857\n",
      "Epoch 190/1000\n",
      " - 0s - loss: 0.2443 - acc: 0.2857\n",
      "Epoch 191/1000\n",
      " - 0s - loss: 0.2434 - acc: 0.2857\n",
      "Epoch 192/1000\n",
      " - 0s - loss: 0.2421 - acc: 0.2857\n",
      "Epoch 193/1000\n",
      " - 0s - loss: 0.2408 - acc: 0.2857\n",
      "Epoch 194/1000\n",
      " - 0s - loss: 0.2399 - acc: 0.2857\n",
      "Epoch 195/1000\n",
      " - 0s - loss: 0.2386 - acc: 0.2857\n",
      "Epoch 196/1000\n",
      " - 0s - loss: 0.2376 - acc: 0.3571\n",
      "Epoch 197/1000\n",
      " - 0s - loss: 0.2362 - acc: 0.2857\n",
      "Epoch 198/1000\n",
      " - 0s - loss: 0.2350 - acc: 0.2857\n",
      "Epoch 199/1000\n",
      " - 0s - loss: 0.2342 - acc: 0.2857\n",
      "Epoch 200/1000\n",
      " - 0s - loss: 0.2331 - acc: 0.3571\n",
      "Epoch 201/1000\n",
      " - 0s - loss: 0.2317 - acc: 0.3571\n",
      "Epoch 202/1000\n",
      " - 0s - loss: 0.2317 - acc: 0.2857\n",
      "Epoch 203/1000\n",
      " - 0s - loss: 0.2304 - acc: 0.3571\n",
      "Epoch 204/1000\n",
      " - 0s - loss: 0.2286 - acc: 0.3571\n",
      "Epoch 205/1000\n",
      " - 0s - loss: 0.2274 - acc: 0.3571\n",
      "Epoch 206/1000\n",
      " - 0s - loss: 0.2263 - acc: 0.3571\n",
      "Epoch 207/1000\n",
      " - 0s - loss: 0.2256 - acc: 0.3571\n",
      "Epoch 208/1000\n",
      " - 0s - loss: 0.2241 - acc: 0.3571\n",
      "Epoch 209/1000\n",
      " - 0s - loss: 0.2233 - acc: 0.3571\n",
      "Epoch 210/1000\n",
      " - 0s - loss: 0.2224 - acc: 0.3571\n",
      "Epoch 211/1000\n",
      " - 0s - loss: 0.2212 - acc: 0.3571\n",
      "Epoch 212/1000\n",
      " - 0s - loss: 0.2200 - acc: 0.3571\n",
      "Epoch 213/1000\n",
      " - 0s - loss: 0.2194 - acc: 0.3571\n",
      "Epoch 214/1000\n",
      " - 0s - loss: 0.2181 - acc: 0.3571\n",
      "Epoch 215/1000\n",
      " - 0s - loss: 0.2170 - acc: 0.3571\n",
      "Epoch 216/1000\n",
      " - 0s - loss: 0.2160 - acc: 0.3571\n",
      "Epoch 217/1000\n",
      " - 0s - loss: 0.2152 - acc: 0.3571\n",
      "Epoch 218/1000\n",
      " - 0s - loss: 0.2140 - acc: 0.3571\n",
      "Epoch 219/1000\n",
      " - 0s - loss: 0.2129 - acc: 0.3571\n",
      "Epoch 220/1000\n",
      " - 0s - loss: 0.2122 - acc: 0.3571\n",
      "Epoch 221/1000\n",
      " - 0s - loss: 0.2110 - acc: 0.3571\n",
      "Epoch 222/1000\n",
      " - 0s - loss: 0.2101 - acc: 0.3571\n",
      "Epoch 223/1000\n",
      " - 0s - loss: 0.2092 - acc: 0.4286\n",
      "Epoch 224/1000\n",
      " - 0s - loss: 0.2087 - acc: 0.3571\n",
      "Epoch 225/1000\n",
      " - 0s - loss: 0.2075 - acc: 0.4286\n",
      "Epoch 226/1000\n",
      " - 0s - loss: 0.2063 - acc: 0.4286\n",
      "Epoch 227/1000\n",
      " - 0s - loss: 0.2054 - acc: 0.4286\n",
      "Epoch 228/1000\n",
      " - 0s - loss: 0.2046 - acc: 0.4286\n",
      "Epoch 229/1000\n",
      " - 0s - loss: 0.2036 - acc: 0.4286\n",
      "Epoch 230/1000\n",
      " - 0s - loss: 0.2026 - acc: 0.4286\n",
      "Epoch 231/1000\n",
      " - 0s - loss: 0.2022 - acc: 0.4286\n",
      "Epoch 232/1000\n",
      " - 0s - loss: 0.2013 - acc: 0.4286\n",
      "Epoch 233/1000\n",
      " - 0s - loss: 0.1999 - acc: 0.4286\n",
      "Epoch 234/1000\n",
      " - 0s - loss: 0.1992 - acc: 0.4286\n",
      "Epoch 235/1000\n",
      " - 0s - loss: 0.1982 - acc: 0.4286\n",
      "Epoch 236/1000\n",
      " - 0s - loss: 0.1974 - acc: 0.4286\n",
      "Epoch 237/1000\n",
      " - 0s - loss: 0.1966 - acc: 0.4286\n",
      "Epoch 238/1000\n",
      " - 0s - loss: 0.1957 - acc: 0.4286\n",
      "Epoch 239/1000\n",
      " - 0s - loss: 0.1947 - acc: 0.4286\n",
      "Epoch 240/1000\n",
      " - 0s - loss: 0.1939 - acc: 0.5000\n",
      "Epoch 241/1000\n",
      " - 0s - loss: 0.1933 - acc: 0.5000\n",
      "Epoch 242/1000\n",
      " - 0s - loss: 0.1924 - acc: 0.5714\n",
      "Epoch 243/1000\n",
      " - 0s - loss: 0.1914 - acc: 0.5714\n",
      "Epoch 244/1000\n",
      " - 0s - loss: 0.1905 - acc: 0.5714\n",
      "Epoch 245/1000\n",
      " - 0s - loss: 0.1897 - acc: 0.5714\n",
      "Epoch 246/1000\n",
      " - 0s - loss: 0.1894 - acc: 0.5714\n",
      "Epoch 247/1000\n",
      " - 0s - loss: 0.1879 - acc: 0.5714\n",
      "Epoch 248/1000\n",
      " - 0s - loss: 0.1873 - acc: 0.6429\n",
      "Epoch 249/1000\n",
      " - 0s - loss: 0.1864 - acc: 0.6429\n",
      "Epoch 250/1000\n",
      " - 0s - loss: 0.1856 - acc: 0.6429\n",
      "Epoch 251/1000\n",
      " - 0s - loss: 0.1850 - acc: 0.6429\n",
      "Epoch 252/1000\n",
      " - 0s - loss: 0.1840 - acc: 0.6429\n",
      "Epoch 253/1000\n",
      " - 0s - loss: 0.1832 - acc: 0.6429\n",
      "Epoch 254/1000\n",
      " - 0s - loss: 0.1825 - acc: 0.7143\n",
      "Epoch 255/1000\n",
      " - 0s - loss: 0.1816 - acc: 0.7143\n",
      "Epoch 256/1000\n",
      " - 0s - loss: 0.1810 - acc: 0.7857\n",
      "Epoch 257/1000\n",
      " - 0s - loss: 0.1803 - acc: 0.7143\n",
      "Epoch 258/1000\n",
      " - 0s - loss: 0.1794 - acc: 0.7857\n",
      "Epoch 259/1000\n",
      " - 0s - loss: 0.1787 - acc: 0.7857\n",
      "Epoch 260/1000\n",
      " - 0s - loss: 0.1778 - acc: 0.7857\n",
      "Epoch 261/1000\n",
      " - 0s - loss: 0.1775 - acc: 0.7857\n",
      "Epoch 262/1000\n",
      " - 0s - loss: 0.1763 - acc: 0.7857\n",
      "Epoch 263/1000\n",
      " - 0s - loss: 0.1756 - acc: 0.7857\n",
      "Epoch 264/1000\n",
      " - 0s - loss: 0.1747 - acc: 0.7857\n",
      "Epoch 265/1000\n",
      " - 0s - loss: 0.1743 - acc: 0.7857\n",
      "Epoch 266/1000\n",
      " - 0s - loss: 0.1735 - acc: 0.7857\n",
      "Epoch 267/1000\n",
      " - 0s - loss: 0.1725 - acc: 0.7857\n",
      "Epoch 268/1000\n",
      " - 0s - loss: 0.1720 - acc: 0.7857\n",
      "Epoch 269/1000\n",
      " - 0s - loss: 0.1715 - acc: 0.7857\n",
      "Epoch 270/1000\n",
      " - 0s - loss: 0.1705 - acc: 0.7857\n",
      "Epoch 271/1000\n",
      " - 0s - loss: 0.1700 - acc: 0.7857\n",
      "Epoch 272/1000\n",
      " - 0s - loss: 0.1694 - acc: 0.7857\n",
      "Epoch 273/1000\n",
      " - 0s - loss: 0.1683 - acc: 0.7857\n",
      "Epoch 274/1000\n",
      " - 0s - loss: 0.1676 - acc: 0.7857\n",
      "Epoch 275/1000\n",
      " - 0s - loss: 0.1674 - acc: 0.7857\n",
      "Epoch 276/1000\n",
      " - 0s - loss: 0.1665 - acc: 0.7857\n",
      "Epoch 277/1000\n",
      " - 0s - loss: 0.1656 - acc: 0.8571\n",
      "Epoch 278/1000\n",
      " - 0s - loss: 0.1650 - acc: 0.8571\n",
      "Epoch 279/1000\n",
      " - 0s - loss: 0.1643 - acc: 0.8571\n",
      "Epoch 280/1000\n",
      " - 0s - loss: 0.1639 - acc: 0.8571\n",
      "Epoch 281/1000\n",
      " - 0s - loss: 0.1632 - acc: 0.8571\n",
      "Epoch 282/1000\n",
      " - 0s - loss: 0.1624 - acc: 0.8571\n",
      "Epoch 283/1000\n",
      " - 0s - loss: 0.1618 - acc: 0.8571\n",
      "Epoch 284/1000\n",
      " - 0s - loss: 0.1610 - acc: 0.8571\n",
      "Epoch 285/1000\n",
      " - 0s - loss: 0.1604 - acc: 0.8571\n",
      "Epoch 286/1000\n",
      " - 0s - loss: 0.1599 - acc: 0.8571\n",
      "Epoch 287/1000\n",
      " - 0s - loss: 0.1593 - acc: 0.8571\n",
      "Epoch 288/1000\n",
      " - 0s - loss: 0.1584 - acc: 0.8571\n",
      "Epoch 289/1000\n",
      " - 0s - loss: 0.1577 - acc: 0.8571\n",
      "Epoch 290/1000\n",
      " - 0s - loss: 0.1573 - acc: 0.8571\n",
      "Epoch 291/1000\n",
      " - 0s - loss: 0.1566 - acc: 0.8571\n",
      "Epoch 292/1000\n",
      " - 0s - loss: 0.1559 - acc: 0.8571\n",
      "Epoch 293/1000\n",
      " - 0s - loss: 0.1558 - acc: 0.8571\n",
      "Epoch 294/1000\n",
      " - 0s - loss: 0.1545 - acc: 0.8571\n",
      "Epoch 295/1000\n",
      " - 0s - loss: 0.1541 - acc: 0.8571\n",
      "Epoch 296/1000\n",
      " - 0s - loss: 0.1533 - acc: 0.8571\n",
      "Epoch 297/1000\n",
      " - 0s - loss: 0.1529 - acc: 0.8571\n",
      "Epoch 298/1000\n",
      " - 0s - loss: 0.1521 - acc: 0.8571\n",
      "Epoch 299/1000\n",
      " - 0s - loss: 0.1519 - acc: 0.8571\n",
      "Epoch 300/1000\n",
      " - 0s - loss: 0.1513 - acc: 0.8571\n",
      "Epoch 301/1000\n",
      " - 0s - loss: 0.1504 - acc: 0.8571\n",
      "Epoch 302/1000\n",
      " - 0s - loss: 0.1499 - acc: 0.8571\n",
      "Epoch 303/1000\n",
      " - 0s - loss: 0.1491 - acc: 0.8571\n",
      "Epoch 304/1000\n",
      " - 0s - loss: 0.1486 - acc: 0.8571\n",
      "Epoch 305/1000\n",
      " - 0s - loss: 0.1484 - acc: 0.8571\n",
      "Epoch 306/1000\n",
      " - 0s - loss: 0.1473 - acc: 0.8571\n",
      "Epoch 307/1000\n",
      " - 0s - loss: 0.1469 - acc: 0.8571\n",
      "Epoch 308/1000\n",
      " - 0s - loss: 0.1464 - acc: 0.8571\n",
      "Epoch 309/1000\n",
      " - 0s - loss: 0.1457 - acc: 0.8571\n",
      "Epoch 310/1000\n",
      " - 0s - loss: 0.1455 - acc: 0.8571\n",
      "Epoch 311/1000\n",
      " - 0s - loss: 0.1448 - acc: 0.8571\n",
      "Epoch 312/1000\n",
      " - 0s - loss: 0.1441 - acc: 0.8571\n",
      "Epoch 313/1000\n",
      " - 0s - loss: 0.1436 - acc: 0.8571\n",
      "Epoch 314/1000\n",
      " - 0s - loss: 0.1428 - acc: 0.8571\n",
      "Epoch 315/1000\n",
      " - 0s - loss: 0.1423 - acc: 0.8571\n",
      "Epoch 316/1000\n",
      " - 0s - loss: 0.1421 - acc: 0.8571\n",
      "Epoch 317/1000\n",
      " - 0s - loss: 0.1413 - acc: 0.8571\n",
      "Epoch 318/1000\n",
      " - 0s - loss: 0.1408 - acc: 0.8571\n",
      "Epoch 319/1000\n",
      " - 0s - loss: 0.1403 - acc: 0.8571\n",
      "Epoch 320/1000\n",
      " - 0s - loss: 0.1395 - acc: 0.8571\n",
      "Epoch 321/1000\n",
      " - 0s - loss: 0.1392 - acc: 0.8571\n",
      "Epoch 322/1000\n",
      " - 0s - loss: 0.1386 - acc: 0.8571\n",
      "Epoch 323/1000\n",
      " - 0s - loss: 0.1386 - acc: 0.8571\n",
      "Epoch 324/1000\n",
      " - 0s - loss: 0.1378 - acc: 0.8571\n",
      "Epoch 325/1000\n",
      " - 0s - loss: 0.1369 - acc: 0.8571\n",
      "Epoch 326/1000\n",
      " - 0s - loss: 0.1368 - acc: 0.8571\n",
      "Epoch 327/1000\n",
      " - 0s - loss: 0.1360 - acc: 0.8571\n",
      "Epoch 328/1000\n",
      " - 0s - loss: 0.1354 - acc: 0.8571\n",
      "Epoch 329/1000\n",
      " - 0s - loss: 0.1348 - acc: 0.8571\n",
      "Epoch 330/1000\n",
      " - 0s - loss: 0.1345 - acc: 0.8571\n",
      "Epoch 331/1000\n",
      " - 0s - loss: 0.1339 - acc: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/1000\n",
      " - 0s - loss: 0.1336 - acc: 0.8571\n",
      "Epoch 333/1000\n",
      " - 0s - loss: 0.1328 - acc: 0.8571\n",
      "Epoch 334/1000\n",
      " - 0s - loss: 0.1324 - acc: 0.8571\n",
      "Epoch 335/1000\n",
      " - 0s - loss: 0.1319 - acc: 0.8571\n",
      "Epoch 336/1000\n",
      " - 0s - loss: 0.1315 - acc: 0.8571\n",
      "Epoch 337/1000\n",
      " - 0s - loss: 0.1308 - acc: 0.8571\n",
      "Epoch 338/1000\n",
      " - 0s - loss: 0.1307 - acc: 0.8571\n",
      "Epoch 339/1000\n",
      " - 0s - loss: 0.1297 - acc: 0.8571\n",
      "Epoch 340/1000\n",
      " - 0s - loss: 0.1296 - acc: 0.8571\n",
      "Epoch 341/1000\n",
      " - 0s - loss: 0.1288 - acc: 0.8571\n",
      "Epoch 342/1000\n",
      " - 0s - loss: 0.1285 - acc: 0.8571\n",
      "Epoch 343/1000\n",
      " - 0s - loss: 0.1279 - acc: 0.8571\n",
      "Epoch 344/1000\n",
      " - 0s - loss: 0.1273 - acc: 0.8571\n",
      "Epoch 345/1000\n",
      " - 0s - loss: 0.1269 - acc: 0.9286\n",
      "Epoch 346/1000\n",
      " - 0s - loss: 0.1265 - acc: 0.8571\n",
      "Epoch 347/1000\n",
      " - 0s - loss: 0.1259 - acc: 1.0000\n",
      "Epoch 348/1000\n",
      " - 0s - loss: 0.1257 - acc: 0.9286\n",
      "Epoch 349/1000\n",
      " - 0s - loss: 0.1249 - acc: 0.9286\n",
      "Epoch 350/1000\n",
      " - 0s - loss: 0.1248 - acc: 0.9286\n",
      "Epoch 351/1000\n",
      " - 0s - loss: 0.1241 - acc: 0.9286\n",
      "Epoch 352/1000\n",
      " - 0s - loss: 0.1237 - acc: 0.9286\n",
      "Epoch 353/1000\n",
      " - 0s - loss: 0.1233 - acc: 0.9286\n",
      "Epoch 354/1000\n",
      " - 0s - loss: 0.1226 - acc: 0.9286\n",
      "Epoch 355/1000\n",
      " - 0s - loss: 0.1224 - acc: 1.0000\n",
      "Epoch 356/1000\n",
      " - 0s - loss: 0.1219 - acc: 1.0000\n",
      "Epoch 357/1000\n",
      " - 0s - loss: 0.1214 - acc: 1.0000\n",
      "Epoch 358/1000\n",
      " - 0s - loss: 0.1208 - acc: 1.0000\n",
      "Epoch 359/1000\n",
      " - 0s - loss: 0.1209 - acc: 1.0000\n",
      "Epoch 360/1000\n",
      " - 0s - loss: 0.1200 - acc: 1.0000\n",
      "Epoch 361/1000\n",
      " - 0s - loss: 0.1196 - acc: 1.0000\n",
      "Epoch 362/1000\n",
      " - 0s - loss: 0.1192 - acc: 1.0000\n",
      "Epoch 363/1000\n",
      " - 0s - loss: 0.1186 - acc: 1.0000\n",
      "Epoch 364/1000\n",
      " - 0s - loss: 0.1182 - acc: 1.0000\n",
      "Epoch 365/1000\n",
      " - 0s - loss: 0.1178 - acc: 1.0000\n",
      "Epoch 366/1000\n",
      " - 0s - loss: 0.1174 - acc: 1.0000\n",
      "Epoch 367/1000\n",
      " - 0s - loss: 0.1169 - acc: 1.0000\n",
      "Epoch 368/1000\n",
      " - 0s - loss: 0.1165 - acc: 1.0000\n",
      "Epoch 369/1000\n",
      " - 0s - loss: 0.1162 - acc: 1.0000\n",
      "Epoch 370/1000\n",
      " - 0s - loss: 0.1157 - acc: 1.0000\n",
      "Epoch 371/1000\n",
      " - 0s - loss: 0.1152 - acc: 1.0000\n",
      "Epoch 372/1000\n",
      " - 0s - loss: 0.1150 - acc: 1.0000\n",
      "Epoch 373/1000\n",
      " - 0s - loss: 0.1145 - acc: 1.0000\n",
      "Epoch 374/1000\n",
      " - 0s - loss: 0.1141 - acc: 1.0000\n",
      "Epoch 375/1000\n",
      " - 0s - loss: 0.1136 - acc: 1.0000\n",
      "Epoch 376/1000\n",
      " - 0s - loss: 0.1132 - acc: 1.0000\n",
      "Epoch 377/1000\n",
      " - 0s - loss: 0.1126 - acc: 1.0000\n",
      "Epoch 378/1000\n",
      " - 0s - loss: 0.1124 - acc: 1.0000\n",
      "Epoch 379/1000\n",
      " - 0s - loss: 0.1120 - acc: 1.0000\n",
      "Epoch 380/1000\n",
      " - 0s - loss: 0.1116 - acc: 1.0000\n",
      "Epoch 381/1000\n",
      " - 0s - loss: 0.1111 - acc: 1.0000\n",
      "Epoch 382/1000\n",
      " - 0s - loss: 0.1108 - acc: 1.0000\n",
      "Epoch 383/1000\n",
      " - 0s - loss: 0.1105 - acc: 1.0000\n",
      "Epoch 384/1000\n",
      " - 0s - loss: 0.1099 - acc: 1.0000\n",
      "Epoch 385/1000\n",
      " - 0s - loss: 0.1096 - acc: 1.0000\n",
      "Epoch 386/1000\n",
      " - 0s - loss: 0.1093 - acc: 1.0000\n",
      "Epoch 387/1000\n",
      " - 0s - loss: 0.1089 - acc: 1.0000\n",
      "Epoch 388/1000\n",
      " - 0s - loss: 0.1085 - acc: 1.0000\n",
      "Epoch 389/1000\n",
      " - 0s - loss: 0.1081 - acc: 1.0000\n",
      "Epoch 390/1000\n",
      " - 0s - loss: 0.1076 - acc: 1.0000\n",
      "Epoch 391/1000\n",
      " - 0s - loss: 0.1075 - acc: 1.0000\n",
      "Epoch 392/1000\n",
      " - 0s - loss: 0.1068 - acc: 1.0000\n",
      "Epoch 393/1000\n",
      " - 0s - loss: 0.1068 - acc: 1.0000\n",
      "Epoch 394/1000\n",
      " - 0s - loss: 0.1060 - acc: 1.0000\n",
      "Epoch 395/1000\n",
      " - 0s - loss: 0.1057 - acc: 1.0000\n",
      "Epoch 396/1000\n",
      " - 0s - loss: 0.1052 - acc: 1.0000\n",
      "Epoch 397/1000\n",
      " - 0s - loss: 0.1049 - acc: 1.0000\n",
      "Epoch 398/1000\n",
      " - 0s - loss: 0.1045 - acc: 1.0000\n",
      "Epoch 399/1000\n",
      " - 0s - loss: 0.1042 - acc: 1.0000\n",
      "Epoch 400/1000\n",
      " - 0s - loss: 0.1037 - acc: 1.0000\n",
      "Epoch 401/1000\n",
      " - 0s - loss: 0.1036 - acc: 1.0000\n",
      "Epoch 402/1000\n",
      " - 0s - loss: 0.1030 - acc: 1.0000\n",
      "Epoch 403/1000\n",
      " - 0s - loss: 0.1027 - acc: 1.0000\n",
      "Epoch 404/1000\n",
      " - 0s - loss: 0.1023 - acc: 1.0000\n",
      "Epoch 405/1000\n",
      " - 0s - loss: 0.1020 - acc: 1.0000\n",
      "Epoch 406/1000\n",
      " - 0s - loss: 0.1016 - acc: 1.0000\n",
      "Epoch 407/1000\n",
      " - 0s - loss: 0.1012 - acc: 1.0000\n",
      "Epoch 408/1000\n",
      " - 0s - loss: 0.1010 - acc: 1.0000\n",
      "Epoch 409/1000\n",
      " - 0s - loss: 0.1004 - acc: 1.0000\n",
      "Epoch 410/1000\n",
      " - 0s - loss: 0.1001 - acc: 1.0000\n",
      "Epoch 411/1000\n",
      " - 0s - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 412/1000\n",
      " - 0s - loss: 0.0993 - acc: 1.0000\n",
      "Epoch 413/1000\n",
      " - 0s - loss: 0.0994 - acc: 1.0000\n",
      "Epoch 414/1000\n",
      " - 0s - loss: 0.0993 - acc: 1.0000\n",
      "Epoch 415/1000\n",
      " - 0s - loss: 0.0986 - acc: 1.0000\n",
      "Epoch 416/1000\n",
      " - 0s - loss: 0.0984 - acc: 1.0000\n",
      "Epoch 417/1000\n",
      " - 0s - loss: 0.0978 - acc: 1.0000\n",
      "Epoch 418/1000\n",
      " - 0s - loss: 0.0974 - acc: 1.0000\n",
      "Epoch 419/1000\n",
      " - 0s - loss: 0.0972 - acc: 1.0000\n",
      "Epoch 420/1000\n",
      " - 0s - loss: 0.0968 - acc: 1.0000\n",
      "Epoch 421/1000\n",
      " - 0s - loss: 0.0965 - acc: 1.0000\n",
      "Epoch 422/1000\n",
      " - 0s - loss: 0.0960 - acc: 1.0000\n",
      "Epoch 423/1000\n",
      " - 0s - loss: 0.0957 - acc: 1.0000\n",
      "Epoch 424/1000\n",
      " - 0s - loss: 0.0954 - acc: 1.0000\n",
      "Epoch 425/1000\n",
      " - 0s - loss: 0.0949 - acc: 1.0000\n",
      "Epoch 426/1000\n",
      " - 0s - loss: 0.0947 - acc: 1.0000\n",
      "Epoch 427/1000\n",
      " - 0s - loss: 0.0942 - acc: 1.0000\n",
      "Epoch 428/1000\n",
      " - 0s - loss: 0.0939 - acc: 1.0000\n",
      "Epoch 429/1000\n",
      " - 0s - loss: 0.0939 - acc: 1.0000\n",
      "Epoch 430/1000\n",
      " - 0s - loss: 0.0934 - acc: 1.0000\n",
      "Epoch 431/1000\n",
      " - 0s - loss: 0.0931 - acc: 1.0000\n",
      "Epoch 432/1000\n",
      " - 0s - loss: 0.0926 - acc: 1.0000\n",
      "Epoch 433/1000\n",
      " - 0s - loss: 0.0923 - acc: 1.0000\n",
      "Epoch 434/1000\n",
      " - 0s - loss: 0.0920 - acc: 1.0000\n",
      "Epoch 435/1000\n",
      " - 0s - loss: 0.0917 - acc: 1.0000\n",
      "Epoch 436/1000\n",
      " - 0s - loss: 0.0914 - acc: 1.0000\n",
      "Epoch 437/1000\n",
      " - 0s - loss: 0.0911 - acc: 1.0000\n",
      "Epoch 438/1000\n",
      " - 0s - loss: 0.0908 - acc: 1.0000\n",
      "Epoch 439/1000\n",
      " - 0s - loss: 0.0905 - acc: 1.0000\n",
      "Epoch 440/1000\n",
      " - 0s - loss: 0.0902 - acc: 1.0000\n",
      "Epoch 441/1000\n",
      " - 0s - loss: 0.0897 - acc: 1.0000\n",
      "Epoch 442/1000\n",
      " - 0s - loss: 0.0896 - acc: 1.0000\n",
      "Epoch 443/1000\n",
      " - 0s - loss: 0.0897 - acc: 1.0000\n",
      "Epoch 444/1000\n",
      " - 0s - loss: 0.0889 - acc: 1.0000\n",
      "Epoch 445/1000\n",
      " - 0s - loss: 0.0886 - acc: 1.0000\n",
      "Epoch 446/1000\n",
      " - 0s - loss: 0.0884 - acc: 1.0000\n",
      "Epoch 447/1000\n",
      " - 0s - loss: 0.0880 - acc: 1.0000\n",
      "Epoch 448/1000\n",
      " - 0s - loss: 0.0876 - acc: 1.0000\n",
      "Epoch 449/1000\n",
      " - 0s - loss: 0.0873 - acc: 1.0000\n",
      "Epoch 450/1000\n",
      " - 0s - loss: 0.0872 - acc: 1.0000\n",
      "Epoch 451/1000\n",
      " - 0s - loss: 0.0867 - acc: 1.0000\n",
      "Epoch 452/1000\n",
      " - 0s - loss: 0.0864 - acc: 1.0000\n",
      "Epoch 453/1000\n",
      " - 0s - loss: 0.0861 - acc: 1.0000\n",
      "Epoch 454/1000\n",
      " - 0s - loss: 0.0859 - acc: 1.0000\n",
      "Epoch 455/1000\n",
      " - 0s - loss: 0.0855 - acc: 1.0000\n",
      "Epoch 456/1000\n",
      " - 0s - loss: 0.0853 - acc: 1.0000\n",
      "Epoch 457/1000\n",
      " - 0s - loss: 0.0851 - acc: 1.0000\n",
      "Epoch 458/1000\n",
      " - 0s - loss: 0.0848 - acc: 1.0000\n",
      "Epoch 459/1000\n",
      " - 0s - loss: 0.0843 - acc: 1.0000\n",
      "Epoch 460/1000\n",
      " - 0s - loss: 0.0841 - acc: 1.0000\n",
      "Epoch 461/1000\n",
      " - 0s - loss: 0.0839 - acc: 1.0000\n",
      "Epoch 462/1000\n",
      " - 0s - loss: 0.0834 - acc: 1.0000\n",
      "Epoch 463/1000\n",
      " - 0s - loss: 0.0833 - acc: 1.0000\n",
      "Epoch 464/1000\n",
      " - 0s - loss: 0.0829 - acc: 1.0000\n",
      "Epoch 465/1000\n",
      " - 0s - loss: 0.0827 - acc: 1.0000\n",
      "Epoch 466/1000\n",
      " - 0s - loss: 0.0824 - acc: 1.0000\n",
      "Epoch 467/1000\n",
      " - 0s - loss: 0.0822 - acc: 1.0000\n",
      "Epoch 468/1000\n",
      " - 0s - loss: 0.0819 - acc: 1.0000\n",
      "Epoch 469/1000\n",
      " - 0s - loss: 0.0815 - acc: 1.0000\n",
      "Epoch 470/1000\n",
      " - 0s - loss: 0.0813 - acc: 1.0000\n",
      "Epoch 471/1000\n",
      " - 0s - loss: 0.0810 - acc: 1.0000\n",
      "Epoch 472/1000\n",
      " - 0s - loss: 0.0807 - acc: 1.0000\n",
      "Epoch 473/1000\n",
      " - 0s - loss: 0.0805 - acc: 1.0000\n",
      "Epoch 474/1000\n",
      " - 0s - loss: 0.0801 - acc: 1.0000\n",
      "Epoch 475/1000\n",
      " - 0s - loss: 0.0801 - acc: 1.0000\n",
      "Epoch 476/1000\n",
      " - 0s - loss: 0.0797 - acc: 1.0000\n",
      "Epoch 477/1000\n",
      " - 0s - loss: 0.0794 - acc: 1.0000\n",
      "Epoch 478/1000\n",
      " - 0s - loss: 0.0791 - acc: 1.0000\n",
      "Epoch 479/1000\n",
      " - 0s - loss: 0.0787 - acc: 1.0000\n",
      "Epoch 480/1000\n",
      " - 0s - loss: 0.0786 - acc: 1.0000\n",
      "Epoch 481/1000\n",
      " - 0s - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 482/1000\n",
      " - 0s - loss: 0.0779 - acc: 1.0000\n",
      "Epoch 483/1000\n",
      " - 0s - loss: 0.0777 - acc: 1.0000\n",
      "Epoch 484/1000\n",
      " - 0s - loss: 0.0774 - acc: 1.0000\n",
      "Epoch 485/1000\n",
      " - 0s - loss: 0.0772 - acc: 1.0000\n",
      "Epoch 486/1000\n",
      " - 0s - loss: 0.0769 - acc: 1.0000\n",
      "Epoch 487/1000\n",
      " - 0s - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 488/1000\n",
      " - 0s - loss: 0.0764 - acc: 1.0000\n",
      "Epoch 489/1000\n",
      " - 0s - loss: 0.0764 - acc: 1.0000\n",
      "Epoch 490/1000\n",
      " - 0s - loss: 0.0758 - acc: 1.0000\n",
      "Epoch 491/1000\n",
      " - 0s - loss: 0.0756 - acc: 1.0000\n",
      "Epoch 492/1000\n",
      " - 0s - loss: 0.0755 - acc: 1.0000\n",
      "Epoch 493/1000\n",
      " - 0s - loss: 0.0751 - acc: 1.0000\n",
      "Epoch 494/1000\n",
      " - 0s - loss: 0.0749 - acc: 1.0000\n",
      "Epoch 495/1000\n",
      " - 0s - loss: 0.0747 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/1000\n",
      " - 0s - loss: 0.0746 - acc: 1.0000\n",
      "Epoch 497/1000\n",
      " - 0s - loss: 0.0741 - acc: 1.0000\n",
      "Epoch 498/1000\n",
      " - 0s - loss: 0.0740 - acc: 1.0000\n",
      "Epoch 499/1000\n",
      " - 0s - loss: 0.0736 - acc: 1.0000\n",
      "Epoch 500/1000\n",
      " - 0s - loss: 0.0736 - acc: 1.0000\n",
      "Epoch 501/1000\n",
      " - 0s - loss: 0.0731 - acc: 1.0000\n",
      "Epoch 502/1000\n",
      " - 0s - loss: 0.0729 - acc: 1.0000\n",
      "Epoch 503/1000\n",
      " - 0s - loss: 0.0726 - acc: 1.0000\n",
      "Epoch 504/1000\n",
      " - 0s - loss: 0.0724 - acc: 1.0000\n",
      "Epoch 505/1000\n",
      " - 0s - loss: 0.0721 - acc: 1.0000\n",
      "Epoch 506/1000\n",
      " - 0s - loss: 0.0719 - acc: 1.0000\n",
      "Epoch 507/1000\n",
      " - 0s - loss: 0.0716 - acc: 1.0000\n",
      "Epoch 508/1000\n",
      " - 0s - loss: 0.0714 - acc: 1.0000\n",
      "Epoch 509/1000\n",
      " - 0s - loss: 0.0712 - acc: 1.0000\n",
      "Epoch 510/1000\n",
      " - 0s - loss: 0.0712 - acc: 1.0000\n",
      "Epoch 511/1000\n",
      " - 0s - loss: 0.0707 - acc: 1.0000\n",
      "Epoch 512/1000\n",
      " - 0s - loss: 0.0704 - acc: 1.0000\n",
      "Epoch 513/1000\n",
      " - 0s - loss: 0.0702 - acc: 1.0000\n",
      "Epoch 514/1000\n",
      " - 0s - loss: 0.0700 - acc: 1.0000\n",
      "Epoch 515/1000\n",
      " - 0s - loss: 0.0698 - acc: 1.0000\n",
      "Epoch 516/1000\n",
      " - 0s - loss: 0.0695 - acc: 1.0000\n",
      "Epoch 517/1000\n",
      " - 0s - loss: 0.0695 - acc: 1.0000\n",
      "Epoch 518/1000\n",
      " - 0s - loss: 0.0690 - acc: 1.0000\n",
      "Epoch 519/1000\n",
      " - 0s - loss: 0.0690 - acc: 1.0000\n",
      "Epoch 520/1000\n",
      " - 0s - loss: 0.0687 - acc: 1.0000\n",
      "Epoch 521/1000\n",
      " - 0s - loss: 0.0684 - acc: 1.0000\n",
      "Epoch 522/1000\n",
      " - 0s - loss: 0.0681 - acc: 1.0000\n",
      "Epoch 523/1000\n",
      " - 0s - loss: 0.0678 - acc: 1.0000\n",
      "Epoch 524/1000\n",
      " - 0s - loss: 0.0677 - acc: 1.0000\n",
      "Epoch 525/1000\n",
      " - 0s - loss: 0.0676 - acc: 1.0000\n",
      "Epoch 526/1000\n",
      " - 0s - loss: 0.0673 - acc: 1.0000\n",
      "Epoch 527/1000\n",
      " - 0s - loss: 0.0671 - acc: 1.0000\n",
      "Epoch 528/1000\n",
      " - 0s - loss: 0.0667 - acc: 1.0000\n",
      "Epoch 529/1000\n",
      " - 0s - loss: 0.0665 - acc: 1.0000\n",
      "Epoch 530/1000\n",
      " - 0s - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 531/1000\n",
      " - 0s - loss: 0.0662 - acc: 1.0000\n",
      "Epoch 532/1000\n",
      " - 0s - loss: 0.0659 - acc: 1.0000\n",
      "Epoch 533/1000\n",
      " - 0s - loss: 0.0657 - acc: 1.0000\n",
      "Epoch 534/1000\n",
      " - 0s - loss: 0.0655 - acc: 1.0000\n",
      "Epoch 535/1000\n",
      " - 0s - loss: 0.0652 - acc: 1.0000\n",
      "Epoch 536/1000\n",
      " - 0s - loss: 0.0650 - acc: 1.0000\n",
      "Epoch 537/1000\n",
      " - 0s - loss: 0.0648 - acc: 1.0000\n",
      "Epoch 538/1000\n",
      " - 0s - loss: 0.0646 - acc: 1.0000\n",
      "Epoch 539/1000\n",
      " - 0s - loss: 0.0643 - acc: 1.0000\n",
      "Epoch 540/1000\n",
      " - 0s - loss: 0.0644 - acc: 1.0000\n",
      "Epoch 541/1000\n",
      " - 0s - loss: 0.0642 - acc: 1.0000\n",
      "Epoch 542/1000\n",
      " - 0s - loss: 0.0636 - acc: 1.0000\n",
      "Epoch 543/1000\n",
      " - 0s - loss: 0.0634 - acc: 1.0000\n",
      "Epoch 544/1000\n",
      " - 0s - loss: 0.0633 - acc: 1.0000\n",
      "Epoch 545/1000\n",
      " - 0s - loss: 0.0632 - acc: 1.0000\n",
      "Epoch 546/1000\n",
      " - 0s - loss: 0.0628 - acc: 1.0000\n",
      "Epoch 547/1000\n",
      " - 0s - loss: 0.0626 - acc: 1.0000\n",
      "Epoch 548/1000\n",
      " - 0s - loss: 0.0624 - acc: 1.0000\n",
      "Epoch 549/1000\n",
      " - 0s - loss: 0.0622 - acc: 1.0000\n",
      "Epoch 550/1000\n",
      " - 0s - loss: 0.0621 - acc: 1.0000\n",
      "Epoch 551/1000\n",
      " - 0s - loss: 0.0618 - acc: 1.0000\n",
      "Epoch 552/1000\n",
      " - 0s - loss: 0.0616 - acc: 1.0000\n",
      "Epoch 553/1000\n",
      " - 0s - loss: 0.0614 - acc: 1.0000\n",
      "Epoch 554/1000\n",
      " - 0s - loss: 0.0612 - acc: 1.0000\n",
      "Epoch 555/1000\n",
      " - 0s - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 556/1000\n",
      " - 0s - loss: 0.0608 - acc: 1.0000\n",
      "Epoch 557/1000\n",
      " - 0s - loss: 0.0607 - acc: 1.0000\n",
      "Epoch 558/1000\n",
      " - 0s - loss: 0.0603 - acc: 1.0000\n",
      "Epoch 559/1000\n",
      " - 0s - loss: 0.0602 - acc: 1.0000\n",
      "Epoch 560/1000\n",
      " - 0s - loss: 0.0601 - acc: 1.0000\n",
      "Epoch 561/1000\n",
      " - 0s - loss: 0.0600 - acc: 1.0000\n",
      "Epoch 562/1000\n",
      " - 0s - loss: 0.0598 - acc: 1.0000\n",
      "Epoch 563/1000\n",
      " - 0s - loss: 0.0593 - acc: 1.0000\n",
      "Epoch 564/1000\n",
      " - 0s - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 565/1000\n",
      " - 0s - loss: 0.0589 - acc: 1.0000\n",
      "Epoch 566/1000\n",
      " - 0s - loss: 0.0588 - acc: 1.0000\n",
      "Epoch 567/1000\n",
      " - 0s - loss: 0.0587 - acc: 1.0000\n",
      "Epoch 568/1000\n",
      " - 0s - loss: 0.0584 - acc: 1.0000\n",
      "Epoch 569/1000\n",
      " - 0s - loss: 0.0582 - acc: 1.0000\n",
      "Epoch 570/1000\n",
      " - 0s - loss: 0.0581 - acc: 1.0000\n",
      "Epoch 571/1000\n",
      " - 0s - loss: 0.0578 - acc: 1.0000\n",
      "Epoch 572/1000\n",
      " - 0s - loss: 0.0577 - acc: 1.0000\n",
      "Epoch 573/1000\n",
      " - 0s - loss: 0.0575 - acc: 1.0000\n",
      "Epoch 574/1000\n",
      " - 0s - loss: 0.0573 - acc: 1.0000\n",
      "Epoch 575/1000\n",
      " - 0s - loss: 0.0572 - acc: 1.0000\n",
      "Epoch 576/1000\n",
      " - 0s - loss: 0.0570 - acc: 1.0000\n",
      "Epoch 577/1000\n",
      " - 0s - loss: 0.0567 - acc: 1.0000\n",
      "Epoch 578/1000\n",
      " - 0s - loss: 0.0565 - acc: 1.0000\n",
      "Epoch 579/1000\n",
      " - 0s - loss: 0.0563 - acc: 1.0000\n",
      "Epoch 580/1000\n",
      " - 0s - loss: 0.0561 - acc: 1.0000\n",
      "Epoch 581/1000\n",
      " - 0s - loss: 0.0559 - acc: 1.0000\n",
      "Epoch 582/1000\n",
      " - 0s - loss: 0.0558 - acc: 1.0000\n",
      "Epoch 583/1000\n",
      " - 0s - loss: 0.0555 - acc: 1.0000\n",
      "Epoch 584/1000\n",
      " - 0s - loss: 0.0556 - acc: 1.0000\n",
      "Epoch 585/1000\n",
      " - 0s - loss: 0.0552 - acc: 1.0000\n",
      "Epoch 586/1000\n",
      " - 0s - loss: 0.0550 - acc: 1.0000\n",
      "Epoch 587/1000\n",
      " - 0s - loss: 0.0548 - acc: 1.0000\n",
      "Epoch 588/1000\n",
      " - 0s - loss: 0.0546 - acc: 1.0000\n",
      "Epoch 589/1000\n",
      " - 0s - loss: 0.0545 - acc: 1.0000\n",
      "Epoch 590/1000\n",
      " - 0s - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 591/1000\n",
      " - 0s - loss: 0.0542 - acc: 1.0000\n",
      "Epoch 592/1000\n",
      " - 0s - loss: 0.0539 - acc: 1.0000\n",
      "Epoch 593/1000\n",
      " - 0s - loss: 0.0537 - acc: 1.0000\n",
      "Epoch 594/1000\n",
      " - 0s - loss: 0.0535 - acc: 1.0000\n",
      "Epoch 595/1000\n",
      " - 0s - loss: 0.0535 - acc: 1.0000\n",
      "Epoch 596/1000\n",
      " - 0s - loss: 0.0532 - acc: 1.0000\n",
      "Epoch 597/1000\n",
      " - 0s - loss: 0.0530 - acc: 1.0000\n",
      "Epoch 598/1000\n",
      " - 0s - loss: 0.0529 - acc: 1.0000\n",
      "Epoch 599/1000\n",
      " - 0s - loss: 0.0527 - acc: 1.0000\n",
      "Epoch 600/1000\n",
      " - 0s - loss: 0.0525 - acc: 1.0000\n",
      "Epoch 601/1000\n",
      " - 0s - loss: 0.0524 - acc: 1.0000\n",
      "Epoch 602/1000\n",
      " - 0s - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 603/1000\n",
      " - 0s - loss: 0.0520 - acc: 1.0000\n",
      "Epoch 604/1000\n",
      " - 0s - loss: 0.0519 - acc: 1.0000\n",
      "Epoch 605/1000\n",
      " - 0s - loss: 0.0517 - acc: 1.0000\n",
      "Epoch 606/1000\n",
      " - 0s - loss: 0.0515 - acc: 1.0000\n",
      "Epoch 607/1000\n",
      " - 0s - loss: 0.0515 - acc: 1.0000\n",
      "Epoch 608/1000\n",
      " - 0s - loss: 0.0512 - acc: 1.0000\n",
      "Epoch 609/1000\n",
      " - 0s - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 610/1000\n",
      " - 0s - loss: 0.0509 - acc: 1.0000\n",
      "Epoch 611/1000\n",
      " - 0s - loss: 0.0507 - acc: 1.0000\n",
      "Epoch 612/1000\n",
      " - 0s - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 613/1000\n",
      " - 0s - loss: 0.0506 - acc: 1.0000\n",
      "Epoch 614/1000\n",
      " - 0s - loss: 0.0504 - acc: 1.0000\n",
      "Epoch 615/1000\n",
      " - 0s - loss: 0.0502 - acc: 1.0000\n",
      "Epoch 616/1000\n",
      " - 0s - loss: 0.0500 - acc: 1.0000\n",
      "Epoch 617/1000\n",
      " - 0s - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 618/1000\n",
      " - 0s - loss: 0.0496 - acc: 1.0000\n",
      "Epoch 619/1000\n",
      " - 0s - loss: 0.0493 - acc: 1.0000\n",
      "Epoch 620/1000\n",
      " - 0s - loss: 0.0492 - acc: 1.0000\n",
      "Epoch 621/1000\n",
      " - 0s - loss: 0.0490 - acc: 1.0000\n",
      "Epoch 622/1000\n",
      " - 0s - loss: 0.0488 - acc: 1.0000\n",
      "Epoch 623/1000\n",
      " - 0s - loss: 0.0488 - acc: 1.0000\n",
      "Epoch 624/1000\n",
      " - 0s - loss: 0.0486 - acc: 1.0000\n",
      "Epoch 625/1000\n",
      " - 0s - loss: 0.0484 - acc: 1.0000\n",
      "Epoch 626/1000\n",
      " - 0s - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 627/1000\n",
      " - 0s - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 628/1000\n",
      " - 0s - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 629/1000\n",
      " - 0s - loss: 0.0478 - acc: 1.0000\n",
      "Epoch 630/1000\n",
      " - 0s - loss: 0.0476 - acc: 1.0000\n",
      "Epoch 631/1000\n",
      " - 0s - loss: 0.0474 - acc: 1.0000\n",
      "Epoch 632/1000\n",
      " - 0s - loss: 0.0473 - acc: 1.0000\n",
      "Epoch 633/1000\n",
      " - 0s - loss: 0.0471 - acc: 1.0000\n",
      "Epoch 634/1000\n",
      " - 0s - loss: 0.0469 - acc: 1.0000\n",
      "Epoch 635/1000\n",
      " - 0s - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 636/1000\n",
      " - 0s - loss: 0.0467 - acc: 1.0000\n",
      "Epoch 637/1000\n",
      " - 0s - loss: 0.0465 - acc: 1.0000\n",
      "Epoch 638/1000\n",
      " - 0s - loss: 0.0465 - acc: 1.0000\n",
      "Epoch 639/1000\n",
      " - 0s - loss: 0.0462 - acc: 1.0000\n",
      "Epoch 640/1000\n",
      " - 0s - loss: 0.0461 - acc: 1.0000\n",
      "Epoch 641/1000\n",
      " - 0s - loss: 0.0460 - acc: 1.0000\n",
      "Epoch 642/1000\n",
      " - 0s - loss: 0.0460 - acc: 1.0000\n",
      "Epoch 643/1000\n",
      " - 0s - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 644/1000\n",
      " - 0s - loss: 0.0454 - acc: 1.0000\n",
      "Epoch 645/1000\n",
      " - 0s - loss: 0.0454 - acc: 1.0000\n",
      "Epoch 646/1000\n",
      " - 0s - loss: 0.0452 - acc: 1.0000\n",
      "Epoch 647/1000\n",
      " - 0s - loss: 0.0450 - acc: 1.0000\n",
      "Epoch 648/1000\n",
      " - 0s - loss: 0.0449 - acc: 1.0000\n",
      "Epoch 649/1000\n",
      " - 0s - loss: 0.0447 - acc: 1.0000\n",
      "Epoch 650/1000\n",
      " - 0s - loss: 0.0447 - acc: 1.0000\n",
      "Epoch 651/1000\n",
      " - 0s - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 652/1000\n",
      " - 0s - loss: 0.0443 - acc: 1.0000\n",
      "Epoch 653/1000\n",
      " - 0s - loss: 0.0441 - acc: 1.0000\n",
      "Epoch 654/1000\n",
      " - 0s - loss: 0.0440 - acc: 1.0000\n",
      "Epoch 655/1000\n",
      " - 0s - loss: 0.0440 - acc: 1.0000\n",
      "Epoch 656/1000\n",
      " - 0s - loss: 0.0439 - acc: 1.0000\n",
      "Epoch 657/1000\n",
      " - 0s - loss: 0.0437 - acc: 1.0000\n",
      "Epoch 658/1000\n",
      " - 0s - loss: 0.0435 - acc: 1.0000\n",
      "Epoch 659/1000\n",
      " - 0s - loss: 0.0433 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/1000\n",
      " - 0s - loss: 0.0431 - acc: 1.0000\n",
      "Epoch 661/1000\n",
      " - 0s - loss: 0.0430 - acc: 1.0000\n",
      "Epoch 662/1000\n",
      " - 0s - loss: 0.0429 - acc: 1.0000\n",
      "Epoch 663/1000\n",
      " - 0s - loss: 0.0427 - acc: 1.0000\n",
      "Epoch 664/1000\n",
      " - 0s - loss: 0.0425 - acc: 1.0000\n",
      "Epoch 665/1000\n",
      " - 0s - loss: 0.0425 - acc: 1.0000\n",
      "Epoch 666/1000\n",
      " - 0s - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 667/1000\n",
      " - 0s - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 668/1000\n",
      " - 0s - loss: 0.0420 - acc: 1.0000\n",
      "Epoch 669/1000\n",
      " - 0s - loss: 0.0419 - acc: 1.0000\n",
      "Epoch 670/1000\n",
      " - 0s - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 671/1000\n",
      " - 0s - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 672/1000\n",
      " - 0s - loss: 0.0414 - acc: 1.0000\n",
      "Epoch 673/1000\n",
      " - 0s - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 674/1000\n",
      " - 0s - loss: 0.0412 - acc: 1.0000\n",
      "Epoch 675/1000\n",
      " - 0s - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 676/1000\n",
      " - 0s - loss: 0.0410 - acc: 1.0000\n",
      "Epoch 677/1000\n",
      " - 0s - loss: 0.0408 - acc: 1.0000\n",
      "Epoch 678/1000\n",
      " - 0s - loss: 0.0408 - acc: 1.0000\n",
      "Epoch 679/1000\n",
      " - 0s - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 680/1000\n",
      " - 0s - loss: 0.0404 - acc: 1.0000\n",
      "Epoch 681/1000\n",
      " - 0s - loss: 0.0403 - acc: 1.0000\n",
      "Epoch 682/1000\n",
      " - 0s - loss: 0.0401 - acc: 1.0000\n",
      "Epoch 683/1000\n",
      " - 0s - loss: 0.0400 - acc: 1.0000\n",
      "Epoch 684/1000\n",
      " - 0s - loss: 0.0399 - acc: 1.0000\n",
      "Epoch 685/1000\n",
      " - 0s - loss: 0.0397 - acc: 1.0000\n",
      "Epoch 686/1000\n",
      " - 0s - loss: 0.0396 - acc: 1.0000\n",
      "Epoch 687/1000\n",
      " - 0s - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 688/1000\n",
      " - 0s - loss: 0.0394 - acc: 1.0000\n",
      "Epoch 689/1000\n",
      " - 0s - loss: 0.0393 - acc: 1.0000\n",
      "Epoch 690/1000\n",
      " - 0s - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 691/1000\n",
      " - 0s - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 692/1000\n",
      " - 0s - loss: 0.0389 - acc: 1.0000\n",
      "Epoch 693/1000\n",
      " - 0s - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 694/1000\n",
      " - 0s - loss: 0.0386 - acc: 1.0000\n",
      "Epoch 695/1000\n",
      " - 0s - loss: 0.0384 - acc: 1.0000\n",
      "Epoch 696/1000\n",
      " - 0s - loss: 0.0383 - acc: 1.0000\n",
      "Epoch 697/1000\n",
      " - 0s - loss: 0.0383 - acc: 1.0000\n",
      "Epoch 698/1000\n",
      " - 0s - loss: 0.0381 - acc: 1.0000\n",
      "Epoch 699/1000\n",
      " - 0s - loss: 0.0381 - acc: 1.0000\n",
      "Epoch 700/1000\n",
      " - 0s - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 701/1000\n",
      " - 0s - loss: 0.0378 - acc: 1.0000\n",
      "Epoch 702/1000\n",
      " - 0s - loss: 0.0376 - acc: 1.0000\n",
      "Epoch 703/1000\n",
      " - 0s - loss: 0.0375 - acc: 1.0000\n",
      "Epoch 704/1000\n",
      " - 0s - loss: 0.0374 - acc: 1.0000\n",
      "Epoch 705/1000\n",
      " - 0s - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 706/1000\n",
      " - 0s - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 707/1000\n",
      " - 0s - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 708/1000\n",
      " - 0s - loss: 0.0369 - acc: 1.0000\n",
      "Epoch 709/1000\n",
      " - 0s - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 710/1000\n",
      " - 0s - loss: 0.0367 - acc: 1.0000\n",
      "Epoch 711/1000\n",
      " - 0s - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 712/1000\n",
      " - 0s - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 713/1000\n",
      " - 0s - loss: 0.0363 - acc: 1.0000\n",
      "Epoch 714/1000\n",
      " - 0s - loss: 0.0361 - acc: 1.0000\n",
      "Epoch 715/1000\n",
      " - 0s - loss: 0.0361 - acc: 1.0000\n",
      "Epoch 716/1000\n",
      " - 0s - loss: 0.0360 - acc: 1.0000\n",
      "Epoch 717/1000\n",
      " - 0s - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 718/1000\n",
      " - 0s - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 719/1000\n",
      " - 0s - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 720/1000\n",
      " - 0s - loss: 0.0355 - acc: 1.0000\n",
      "Epoch 721/1000\n",
      " - 0s - loss: 0.0353 - acc: 1.0000\n",
      "Epoch 722/1000\n",
      " - 0s - loss: 0.0352 - acc: 1.0000\n",
      "Epoch 723/1000\n",
      " - 0s - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 724/1000\n",
      " - 0s - loss: 0.0350 - acc: 1.0000\n",
      "Epoch 725/1000\n",
      " - 0s - loss: 0.0350 - acc: 1.0000\n",
      "Epoch 726/1000\n",
      " - 0s - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 727/1000\n",
      " - 0s - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 728/1000\n",
      " - 0s - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 729/1000\n",
      " - 0s - loss: 0.0345 - acc: 1.0000\n",
      "Epoch 730/1000\n",
      " - 0s - loss: 0.0343 - acc: 1.0000\n",
      "Epoch 731/1000\n",
      " - 0s - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 732/1000\n",
      " - 0s - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 733/1000\n",
      " - 0s - loss: 0.0340 - acc: 1.0000\n",
      "Epoch 734/1000\n",
      " - 0s - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 735/1000\n",
      " - 0s - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 736/1000\n",
      " - 0s - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 737/1000\n",
      " - 0s - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 738/1000\n",
      " - 0s - loss: 0.0334 - acc: 1.0000\n",
      "Epoch 739/1000\n",
      " - 0s - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 740/1000\n",
      " - 0s - loss: 0.0332 - acc: 1.0000\n",
      "Epoch 741/1000\n",
      " - 0s - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 742/1000\n",
      " - 0s - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 743/1000\n",
      " - 0s - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 744/1000\n",
      " - 0s - loss: 0.0328 - acc: 1.0000\n",
      "Epoch 745/1000\n",
      " - 0s - loss: 0.0327 - acc: 1.0000\n",
      "Epoch 746/1000\n",
      " - 0s - loss: 0.0327 - acc: 1.0000\n",
      "Epoch 747/1000\n",
      " - 0s - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 748/1000\n",
      " - 0s - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 749/1000\n",
      " - 0s - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 750/1000\n",
      " - 0s - loss: 0.0322 - acc: 1.0000\n",
      "Epoch 751/1000\n",
      " - 0s - loss: 0.0321 - acc: 1.0000\n",
      "Epoch 752/1000\n",
      " - 0s - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 753/1000\n",
      " - 0s - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 754/1000\n",
      " - 0s - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 755/1000\n",
      " - 0s - loss: 0.0316 - acc: 1.0000\n",
      "Epoch 756/1000\n",
      " - 0s - loss: 0.0315 - acc: 1.0000\n",
      "Epoch 757/1000\n",
      " - 0s - loss: 0.0314 - acc: 1.0000\n",
      "Epoch 758/1000\n",
      " - 0s - loss: 0.0314 - acc: 1.0000\n",
      "Epoch 759/1000\n",
      " - 0s - loss: 0.0313 - acc: 1.0000\n",
      "Epoch 760/1000\n",
      " - 0s - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 761/1000\n",
      " - 0s - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 762/1000\n",
      " - 0s - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 763/1000\n",
      " - 0s - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 764/1000\n",
      " - 0s - loss: 0.0307 - acc: 1.0000\n",
      "Epoch 765/1000\n",
      " - 0s - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 766/1000\n",
      " - 0s - loss: 0.0306 - acc: 1.0000\n",
      "Epoch 767/1000\n",
      " - 0s - loss: 0.0305 - acc: 1.0000\n",
      "Epoch 768/1000\n",
      " - 0s - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 769/1000\n",
      " - 0s - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 770/1000\n",
      " - 0s - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 771/1000\n",
      " - 0s - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 772/1000\n",
      " - 0s - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 773/1000\n",
      " - 0s - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 774/1000\n",
      " - 0s - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 775/1000\n",
      " - 0s - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 776/1000\n",
      " - 0s - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 777/1000\n",
      " - 0s - loss: 0.0295 - acc: 1.0000\n",
      "Epoch 778/1000\n",
      " - 0s - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 779/1000\n",
      " - 0s - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 780/1000\n",
      " - 0s - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 781/1000\n",
      " - 0s - loss: 0.0291 - acc: 1.0000\n",
      "Epoch 782/1000\n",
      " - 0s - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 783/1000\n",
      " - 0s - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 784/1000\n",
      " - 0s - loss: 0.0288 - acc: 1.0000\n",
      "Epoch 785/1000\n",
      " - 0s - loss: 0.0288 - acc: 1.0000\n",
      "Epoch 786/1000\n",
      " - 0s - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 787/1000\n",
      " - 0s - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 788/1000\n",
      " - 0s - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 789/1000\n",
      " - 0s - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 790/1000\n",
      " - 0s - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 791/1000\n",
      " - 0s - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 792/1000\n",
      " - 0s - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 793/1000\n",
      " - 0s - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 794/1000\n",
      " - 0s - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 795/1000\n",
      " - 0s - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 796/1000\n",
      " - 0s - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 797/1000\n",
      " - 0s - loss: 0.0276 - acc: 1.0000\n",
      "Epoch 798/1000\n",
      " - 0s - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 799/1000\n",
      " - 0s - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 800/1000\n",
      " - 0s - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 801/1000\n",
      " - 0s - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 802/1000\n",
      " - 0s - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 803/1000\n",
      " - 0s - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 804/1000\n",
      " - 0s - loss: 0.0271 - acc: 1.0000\n",
      "Epoch 805/1000\n",
      " - 0s - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 806/1000\n",
      " - 0s - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 807/1000\n",
      " - 0s - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 808/1000\n",
      " - 0s - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 809/1000\n",
      " - 0s - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 810/1000\n",
      " - 0s - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 811/1000\n",
      " - 0s - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 812/1000\n",
      " - 0s - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 813/1000\n",
      " - 0s - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 814/1000\n",
      " - 0s - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 815/1000\n",
      " - 0s - loss: 0.0260 - acc: 1.0000\n",
      "Epoch 816/1000\n",
      " - 0s - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 817/1000\n",
      " - 0s - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 818/1000\n",
      " - 0s - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 819/1000\n",
      " - 0s - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 820/1000\n",
      " - 0s - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 821/1000\n",
      " - 0s - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 822/1000\n",
      " - 0s - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 823/1000\n",
      " - 0s - loss: 0.0254 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 824/1000\n",
      " - 0s - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 825/1000\n",
      " - 0s - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 826/1000\n",
      " - 0s - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 827/1000\n",
      " - 0s - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 828/1000\n",
      " - 0s - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 829/1000\n",
      " - 0s - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 830/1000\n",
      " - 0s - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 831/1000\n",
      " - 0s - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 832/1000\n",
      " - 0s - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 833/1000\n",
      " - 0s - loss: 0.0246 - acc: 1.0000\n",
      "Epoch 834/1000\n",
      " - 0s - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 835/1000\n",
      " - 0s - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 836/1000\n",
      " - 0s - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 837/1000\n",
      " - 0s - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 838/1000\n",
      " - 0s - loss: 0.0242 - acc: 1.0000\n",
      "Epoch 839/1000\n",
      " - 0s - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 840/1000\n",
      " - 0s - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 841/1000\n",
      " - 0s - loss: 0.0240 - acc: 1.0000\n",
      "Epoch 842/1000\n",
      " - 0s - loss: 0.0239 - acc: 1.0000\n",
      "Epoch 843/1000\n",
      " - 0s - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 844/1000\n",
      " - 0s - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 845/1000\n",
      " - 0s - loss: 0.0236 - acc: 1.0000\n",
      "Epoch 846/1000\n",
      " - 0s - loss: 0.0236 - acc: 1.0000\n",
      "Epoch 847/1000\n",
      " - 0s - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 848/1000\n",
      " - 0s - loss: 0.0234 - acc: 1.0000\n",
      "Epoch 849/1000\n",
      " - 0s - loss: 0.0234 - acc: 1.0000\n",
      "Epoch 850/1000\n",
      " - 0s - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 851/1000\n",
      " - 0s - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 852/1000\n",
      " - 0s - loss: 0.0231 - acc: 1.0000\n",
      "Epoch 853/1000\n",
      " - 0s - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 854/1000\n",
      " - 0s - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 855/1000\n",
      " - 0s - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 856/1000\n",
      " - 0s - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 857/1000\n",
      " - 0s - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 858/1000\n",
      " - 0s - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 859/1000\n",
      " - 0s - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 860/1000\n",
      " - 0s - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 861/1000\n",
      " - 0s - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 862/1000\n",
      " - 0s - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 863/1000\n",
      " - 0s - loss: 0.0223 - acc: 1.0000\n",
      "Epoch 864/1000\n",
      " - 0s - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 865/1000\n",
      " - 0s - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 866/1000\n",
      " - 0s - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 867/1000\n",
      " - 0s - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 868/1000\n",
      " - 0s - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 869/1000\n",
      " - 0s - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 870/1000\n",
      " - 0s - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 871/1000\n",
      " - 0s - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 872/1000\n",
      " - 0s - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 873/1000\n",
      " - 0s - loss: 0.0216 - acc: 1.0000\n",
      "Epoch 874/1000\n",
      " - 0s - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 875/1000\n",
      " - 0s - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 876/1000\n",
      " - 0s - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 877/1000\n",
      " - 0s - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 878/1000\n",
      " - 0s - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 879/1000\n",
      " - 0s - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 880/1000\n",
      " - 0s - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 881/1000\n",
      " - 0s - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 882/1000\n",
      " - 0s - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 883/1000\n",
      " - 0s - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 884/1000\n",
      " - 0s - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 885/1000\n",
      " - 0s - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 886/1000\n",
      " - 0s - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 887/1000\n",
      " - 0s - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 888/1000\n",
      " - 0s - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 889/1000\n",
      " - 0s - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 890/1000\n",
      " - 0s - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 891/1000\n",
      " - 0s - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 892/1000\n",
      " - 0s - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 893/1000\n",
      " - 0s - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 894/1000\n",
      " - 0s - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 895/1000\n",
      " - 0s - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 896/1000\n",
      " - 0s - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 897/1000\n",
      " - 0s - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 898/1000\n",
      " - 0s - loss: 0.0199 - acc: 1.0000\n",
      "Epoch 899/1000\n",
      " - 0s - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 900/1000\n",
      " - 0s - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 901/1000\n",
      " - 0s - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 902/1000\n",
      " - 0s - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 903/1000\n",
      " - 0s - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 904/1000\n",
      " - 0s - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 905/1000\n",
      " - 0s - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 906/1000\n",
      " - 0s - loss: 0.0194 - acc: 1.0000\n",
      "Epoch 907/1000\n",
      " - 0s - loss: 0.0194 - acc: 1.0000\n",
      "Epoch 908/1000\n",
      " - 0s - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 909/1000\n",
      " - 0s - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 910/1000\n",
      " - 0s - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 911/1000\n",
      " - 0s - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 912/1000\n",
      " - 0s - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 913/1000\n",
      " - 0s - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 914/1000\n",
      " - 0s - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 915/1000\n",
      " - 0s - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 916/1000\n",
      " - 0s - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 917/1000\n",
      " - 0s - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 918/1000\n",
      " - 0s - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 919/1000\n",
      " - 0s - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 920/1000\n",
      " - 0s - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 921/1000\n",
      " - 0s - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 922/1000\n",
      " - 0s - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 923/1000\n",
      " - 0s - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 924/1000\n",
      " - 0s - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 925/1000\n",
      " - 0s - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 926/1000\n",
      " - 0s - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 927/1000\n",
      " - 0s - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 928/1000\n",
      " - 0s - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 929/1000\n",
      " - 0s - loss: 0.0180 - acc: 1.0000\n",
      "Epoch 930/1000\n",
      " - 0s - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 931/1000\n",
      " - 0s - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 932/1000\n",
      " - 0s - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 933/1000\n",
      " - 0s - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 934/1000\n",
      " - 0s - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 935/1000\n",
      " - 0s - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 936/1000\n",
      " - 0s - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 937/1000\n",
      " - 0s - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 938/1000\n",
      " - 0s - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 939/1000\n",
      " - 0s - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 940/1000\n",
      " - 0s - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 941/1000\n",
      " - 0s - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 942/1000\n",
      " - 0s - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 943/1000\n",
      " - 0s - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 944/1000\n",
      " - 0s - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 945/1000\n",
      " - 0s - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 946/1000\n",
      " - 0s - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 947/1000\n",
      " - 0s - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 948/1000\n",
      " - 0s - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 949/1000\n",
      " - 0s - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 950/1000\n",
      " - 0s - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 951/1000\n",
      " - 0s - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 952/1000\n",
      " - 0s - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 953/1000\n",
      " - 0s - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 954/1000\n",
      " - 0s - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 955/1000\n",
      " - 0s - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 956/1000\n",
      " - 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 957/1000\n",
      " - 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 958/1000\n",
      " - 0s - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 959/1000\n",
      " - 0s - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 960/1000\n",
      " - 0s - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 961/1000\n",
      " - 0s - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 962/1000\n",
      " - 0s - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 963/1000\n",
      " - 0s - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 964/1000\n",
      " - 0s - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 965/1000\n",
      " - 0s - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 966/1000\n",
      " - 0s - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 967/1000\n",
      " - 0s - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 968/1000\n",
      " - 0s - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 969/1000\n",
      " - 0s - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 970/1000\n",
      " - 0s - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 971/1000\n",
      " - 0s - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 972/1000\n",
      " - 0s - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 973/1000\n",
      " - 0s - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 974/1000\n",
      " - 0s - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 975/1000\n",
      " - 0s - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 976/1000\n",
      " - 0s - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 977/1000\n",
      " - 0s - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 978/1000\n",
      " - 0s - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 979/1000\n",
      " - 0s - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 980/1000\n",
      " - 0s - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 981/1000\n",
      " - 0s - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 982/1000\n",
      " - 0s - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 983/1000\n",
      " - 0s - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 984/1000\n",
      " - 0s - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 985/1000\n",
      " - 0s - loss: 0.0150 - acc: 1.0000\n",
      "Epoch 986/1000\n",
      " - 0s - loss: 0.0150 - acc: 1.0000\n",
      "Epoch 987/1000\n",
      " - 0s - loss: 0.0150 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/1000\n",
      " - 0s - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 989/1000\n",
      " - 0s - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 990/1000\n",
      " - 0s - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 991/1000\n",
      " - 0s - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 992/1000\n",
      " - 0s - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 993/1000\n",
      " - 0s - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 994/1000\n",
      " - 0s - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 995/1000\n",
      " - 0s - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 996/1000\n",
      " - 0s - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 997/1000\n",
      " - 0s - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 998/1000\n",
      " - 0s - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 999/1000\n",
      " - 0s - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 1000/1000\n",
      " - 0s - loss: 0.0143 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22dd957bcf8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(data[1:15], label[1:15], epochs=1000, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 1s - loss: 0.4586 - acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      " - 0s - loss: 0.4527 - acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      " - 0s - loss: 0.4473 - acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      " - 0s - loss: 0.4413 - acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      " - 0s - loss: 0.4361 - acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      " - 0s - loss: 0.4307 - acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      " - 0s - loss: 0.4250 - acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      " - 0s - loss: 0.4200 - acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      " - 0s - loss: 0.4147 - acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      " - 0s - loss: 0.4098 - acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      " - 0s - loss: 0.4051 - acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      " - 0s - loss: 0.3998 - acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      " - 0s - loss: 0.3952 - acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      " - 0s - loss: 0.3907 - acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      " - 0s - loss: 0.3863 - acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      " - 0s - loss: 0.3815 - acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      " - 0s - loss: 0.3777 - acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      " - 0s - loss: 0.3731 - acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      " - 0s - loss: 0.3690 - acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      " - 0s - loss: 0.3653 - acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      " - 0s - loss: 0.3611 - acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      " - 0s - loss: 0.3574 - acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      " - 0s - loss: 0.3537 - acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      " - 0s - loss: 0.3501 - acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      " - 0s - loss: 0.3466 - acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      " - 0s - loss: 0.3435 - acc: 0.2143\n",
      "Epoch 27/500\n",
      " - 0s - loss: 0.3397 - acc: 0.2143\n",
      "Epoch 28/500\n",
      " - 0s - loss: 0.3368 - acc: 0.2143\n",
      "Epoch 29/500\n",
      " - 0s - loss: 0.3337 - acc: 0.2143\n",
      "Epoch 30/500\n",
      " - 0s - loss: 0.3305 - acc: 0.2143\n",
      "Epoch 31/500\n",
      " - 0s - loss: 0.3276 - acc: 0.2143\n",
      "Epoch 32/500\n",
      " - 0s - loss: 0.3247 - acc: 0.2143\n",
      "Epoch 33/500\n",
      " - 0s - loss: 0.3220 - acc: 0.2143\n",
      "Epoch 34/500\n",
      " - 0s - loss: 0.3193 - acc: 0.2143\n",
      "Epoch 35/500\n",
      " - 0s - loss: 0.3167 - acc: 0.2143\n",
      "Epoch 36/500\n",
      " - 0s - loss: 0.3142 - acc: 0.2143\n",
      "Epoch 37/500\n",
      " - 0s - loss: 0.3117 - acc: 0.2143\n",
      "Epoch 38/500\n",
      " - 0s - loss: 0.3092 - acc: 0.2143\n",
      "Epoch 39/500\n",
      " - 0s - loss: 0.3071 - acc: 0.2143\n",
      "Epoch 40/500\n",
      " - 0s - loss: 0.3048 - acc: 0.2143\n",
      "Epoch 41/500\n",
      " - 0s - loss: 0.3025 - acc: 0.2143\n",
      "Epoch 42/500\n",
      " - 0s - loss: 0.3006 - acc: 0.2143\n",
      "Epoch 43/500\n",
      " - 0s - loss: 0.2984 - acc: 0.2143\n",
      "Epoch 44/500\n",
      " - 0s - loss: 0.2965 - acc: 0.2143\n",
      "Epoch 45/500\n",
      " - 0s - loss: 0.2947 - acc: 0.2143\n",
      "Epoch 46/500\n",
      " - 0s - loss: 0.2928 - acc: 0.2143\n",
      "Epoch 47/500\n",
      " - 0s - loss: 0.2911 - acc: 0.2143\n",
      "Epoch 48/500\n",
      " - 0s - loss: 0.2893 - acc: 0.2143\n",
      "Epoch 49/500\n",
      " - 0s - loss: 0.2876 - acc: 0.2143\n",
      "Epoch 50/500\n",
      " - 0s - loss: 0.2860 - acc: 0.2143\n",
      "Epoch 51/500\n",
      " - 0s - loss: 0.2844 - acc: 0.2143\n",
      "Epoch 52/500\n",
      " - 0s - loss: 0.2830 - acc: 0.2143\n",
      "Epoch 53/500\n",
      " - 0s - loss: 0.2814 - acc: 0.2143\n",
      "Epoch 54/500\n",
      " - 0s - loss: 0.2802 - acc: 0.2143\n",
      "Epoch 55/500\n",
      " - 0s - loss: 0.2787 - acc: 0.2143\n",
      "Epoch 56/500\n",
      " - 0s - loss: 0.2775 - acc: 0.2143\n",
      "Epoch 57/500\n",
      " - 0s - loss: 0.2762 - acc: 0.2143\n",
      "Epoch 58/500\n",
      " - 0s - loss: 0.2749 - acc: 0.2143\n",
      "Epoch 59/500\n",
      " - 0s - loss: 0.2737 - acc: 0.2143\n",
      "Epoch 60/500\n",
      " - 0s - loss: 0.2725 - acc: 0.2143\n",
      "Epoch 61/500\n",
      " - 0s - loss: 0.2714 - acc: 0.2143\n",
      "Epoch 62/500\n",
      " - 0s - loss: 0.2703 - acc: 0.2143\n",
      "Epoch 63/500\n",
      " - 0s - loss: 0.2694 - acc: 0.2143\n",
      "Epoch 64/500\n",
      " - 0s - loss: 0.2682 - acc: 0.2143\n",
      "Epoch 65/500\n",
      " - 0s - loss: 0.2673 - acc: 0.2143\n",
      "Epoch 66/500\n",
      " - 0s - loss: 0.2663 - acc: 0.2143\n",
      "Epoch 67/500\n",
      " - 0s - loss: 0.2654 - acc: 0.2857\n",
      "Epoch 68/500\n",
      " - 0s - loss: 0.2645 - acc: 0.2857\n",
      "Epoch 69/500\n",
      " - 0s - loss: 0.2637 - acc: 0.2857\n",
      "Epoch 70/500\n",
      " - 0s - loss: 0.2628 - acc: 0.2857\n",
      "Epoch 71/500\n",
      " - 0s - loss: 0.2620 - acc: 0.2857\n",
      "Epoch 72/500\n",
      " - 0s - loss: 0.2613 - acc: 0.2857\n",
      "Epoch 73/500\n",
      " - 0s - loss: 0.2606 - acc: 0.2857\n",
      "Epoch 74/500\n",
      " - 0s - loss: 0.2600 - acc: 0.2857\n",
      "Epoch 75/500\n",
      " - 0s - loss: 0.2593 - acc: 0.2857\n",
      "Epoch 76/500\n",
      " - 0s - loss: 0.2586 - acc: 0.2857\n",
      "Epoch 77/500\n",
      " - 0s - loss: 0.2580 - acc: 0.2857\n",
      "Epoch 78/500\n",
      " - 0s - loss: 0.2573 - acc: 0.3571\n",
      "Epoch 79/500\n",
      " - 0s - loss: 0.2568 - acc: 0.3571\n",
      "Epoch 80/500\n",
      " - 0s - loss: 0.2561 - acc: 0.3571\n",
      "Epoch 81/500\n",
      " - 0s - loss: 0.2556 - acc: 0.3571\n",
      "Epoch 82/500\n",
      " - 0s - loss: 0.2550 - acc: 0.3571\n",
      "Epoch 83/500\n",
      " - 0s - loss: 0.2544 - acc: 0.3571\n",
      "Epoch 84/500\n",
      " - 0s - loss: 0.2538 - acc: 0.3571\n",
      "Epoch 85/500\n",
      " - 0s - loss: 0.2532 - acc: 0.3571\n",
      "Epoch 86/500\n",
      " - 0s - loss: 0.2527 - acc: 0.4286\n",
      "Epoch 87/500\n",
      " - 0s - loss: 0.2521 - acc: 0.4286\n",
      "Epoch 88/500\n",
      " - 0s - loss: 0.2517 - acc: 0.4286\n",
      "Epoch 89/500\n",
      " - 0s - loss: 0.2510 - acc: 0.4286\n",
      "Epoch 90/500\n",
      " - 0s - loss: 0.2504 - acc: 0.4286\n",
      "Epoch 91/500\n",
      " - 0s - loss: 0.2499 - acc: 0.4286\n",
      "Epoch 92/500\n",
      " - 0s - loss: 0.2494 - acc: 0.4286\n",
      "Epoch 93/500\n",
      " - 0s - loss: 0.2488 - acc: 0.6429\n",
      "Epoch 94/500\n",
      " - 0s - loss: 0.2483 - acc: 0.6429\n",
      "Epoch 95/500\n",
      " - 0s - loss: 0.2477 - acc: 0.6429\n",
      "Epoch 96/500\n",
      " - 0s - loss: 0.2471 - acc: 0.6429\n",
      "Epoch 97/500\n",
      " - 0s - loss: 0.2465 - acc: 0.6429\n",
      "Epoch 98/500\n",
      " - 0s - loss: 0.2460 - acc: 0.6429\n",
      "Epoch 99/500\n",
      " - 0s - loss: 0.2454 - acc: 0.6429\n",
      "Epoch 100/500\n",
      " - 0s - loss: 0.2448 - acc: 0.6429\n",
      "Epoch 101/500\n",
      " - 0s - loss: 0.2443 - acc: 0.6429\n",
      "Epoch 102/500\n",
      " - 0s - loss: 0.2437 - acc: 0.6429\n",
      "Epoch 103/500\n",
      " - 0s - loss: 0.2430 - acc: 0.6429\n",
      "Epoch 104/500\n",
      " - 0s - loss: 0.2424 - acc: 0.6429\n",
      "Epoch 105/500\n",
      " - 0s - loss: 0.2418 - acc: 0.6429\n",
      "Epoch 106/500\n",
      " - 0s - loss: 0.2411 - acc: 0.6429\n",
      "Epoch 107/500\n",
      " - 0s - loss: 0.2405 - acc: 0.6429\n",
      "Epoch 108/500\n",
      " - 0s - loss: 0.2398 - acc: 0.6429\n",
      "Epoch 109/500\n",
      " - 0s - loss: 0.2391 - acc: 0.6429\n",
      "Epoch 110/500\n",
      " - 0s - loss: 0.2384 - acc: 0.6429\n",
      "Epoch 111/500\n",
      " - 0s - loss: 0.2377 - acc: 0.7143\n",
      "Epoch 112/500\n",
      " - 0s - loss: 0.2370 - acc: 0.7143\n",
      "Epoch 113/500\n",
      " - 0s - loss: 0.2361 - acc: 0.7143\n",
      "Epoch 114/500\n",
      " - 0s - loss: 0.2353 - acc: 0.7143\n",
      "Epoch 115/500\n",
      " - 0s - loss: 0.2344 - acc: 0.7143\n",
      "Epoch 116/500\n",
      " - 0s - loss: 0.2337 - acc: 0.7143\n",
      "Epoch 117/500\n",
      " - 0s - loss: 0.2328 - acc: 0.7143\n",
      "Epoch 118/500\n",
      " - 0s - loss: 0.2319 - acc: 0.7143\n",
      "Epoch 119/500\n",
      " - 0s - loss: 0.2309 - acc: 0.8571\n",
      "Epoch 120/500\n",
      " - 0s - loss: 0.2299 - acc: 0.8571\n",
      "Epoch 121/500\n",
      " - 0s - loss: 0.2289 - acc: 0.8571\n",
      "Epoch 122/500\n",
      " - 0s - loss: 0.2279 - acc: 0.8571\n",
      "Epoch 123/500\n",
      " - 0s - loss: 0.2269 - acc: 0.8571\n",
      "Epoch 124/500\n",
      " - 0s - loss: 0.2258 - acc: 0.8571\n",
      "Epoch 125/500\n",
      " - 0s - loss: 0.2246 - acc: 0.8571\n",
      "Epoch 126/500\n",
      " - 0s - loss: 0.2234 - acc: 0.9286\n",
      "Epoch 127/500\n",
      " - 0s - loss: 0.2221 - acc: 0.9286\n",
      "Epoch 128/500\n",
      " - 0s - loss: 0.2210 - acc: 0.9286\n",
      "Epoch 129/500\n",
      " - 0s - loss: 0.2196 - acc: 0.9286\n",
      "Epoch 130/500\n",
      " - 0s - loss: 0.2182 - acc: 0.9286\n",
      "Epoch 131/500\n",
      " - 0s - loss: 0.2169 - acc: 0.9286\n",
      "Epoch 132/500\n",
      " - 0s - loss: 0.2154 - acc: 0.9286\n",
      "Epoch 133/500\n",
      " - 0s - loss: 0.2139 - acc: 0.9286\n",
      "Epoch 134/500\n",
      " - 0s - loss: 0.2124 - acc: 0.9286\n",
      "Epoch 135/500\n",
      " - 0s - loss: 0.2108 - acc: 0.9286\n",
      "Epoch 136/500\n",
      " - 0s - loss: 0.2092 - acc: 0.9286\n",
      "Epoch 137/500\n",
      " - 0s - loss: 0.2075 - acc: 0.9286\n",
      "Epoch 138/500\n",
      " - 0s - loss: 0.2058 - acc: 0.9286\n",
      "Epoch 139/500\n",
      " - 0s - loss: 0.2040 - acc: 0.9286\n",
      "Epoch 140/500\n",
      " - 0s - loss: 0.2022 - acc: 0.9286\n",
      "Epoch 141/500\n",
      " - 0s - loss: 0.2002 - acc: 0.9286\n",
      "Epoch 142/500\n",
      " - 0s - loss: 0.1983 - acc: 0.9286\n",
      "Epoch 143/500\n",
      " - 0s - loss: 0.1963 - acc: 0.9286\n",
      "Epoch 144/500\n",
      " - 0s - loss: 0.1941 - acc: 0.9286\n",
      "Epoch 145/500\n",
      " - 0s - loss: 0.1923 - acc: 0.9286\n",
      "Epoch 146/500\n",
      " - 0s - loss: 0.1898 - acc: 0.9286\n",
      "Epoch 147/500\n",
      " - 0s - loss: 0.1877 - acc: 0.9286\n",
      "Epoch 148/500\n",
      " - 0s - loss: 0.1853 - acc: 0.9286\n",
      "Epoch 149/500\n",
      " - 0s - loss: 0.1829 - acc: 0.9286\n",
      "Epoch 150/500\n",
      " - 0s - loss: 0.1805 - acc: 0.9286\n",
      "Epoch 151/500\n",
      " - 0s - loss: 0.1779 - acc: 0.9286\n",
      "Epoch 152/500\n",
      " - 0s - loss: 0.1754 - acc: 0.9286\n",
      "Epoch 153/500\n",
      " - 0s - loss: 0.1728 - acc: 0.9286\n",
      "Epoch 154/500\n",
      " - 0s - loss: 0.1701 - acc: 0.9286\n",
      "Epoch 155/500\n",
      " - 0s - loss: 0.1674 - acc: 0.9286\n",
      "Epoch 156/500\n",
      " - 0s - loss: 0.1645 - acc: 0.9286\n",
      "Epoch 157/500\n",
      " - 0s - loss: 0.1619 - acc: 0.9286\n",
      "Epoch 158/500\n",
      " - 0s - loss: 0.1588 - acc: 0.9286\n",
      "Epoch 159/500\n",
      " - 0s - loss: 0.1560 - acc: 0.9286\n",
      "Epoch 160/500\n",
      " - 0s - loss: 0.1530 - acc: 0.9286\n",
      "Epoch 161/500\n",
      " - 0s - loss: 0.1501 - acc: 0.9286\n",
      "Epoch 162/500\n",
      " - 0s - loss: 0.1471 - acc: 0.9286\n",
      "Epoch 163/500\n",
      " - 0s - loss: 0.1441 - acc: 0.9286\n",
      "Epoch 164/500\n",
      " - 0s - loss: 0.1411 - acc: 0.9286\n",
      "Epoch 165/500\n",
      " - 0s - loss: 0.1382 - acc: 0.9286\n",
      "Epoch 166/500\n",
      " - 0s - loss: 0.1352 - acc: 0.9286\n",
      "Epoch 167/500\n",
      " - 0s - loss: 0.1322 - acc: 1.0000\n",
      "Epoch 168/500\n",
      " - 0s - loss: 0.1293 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      " - 0s - loss: 0.1264 - acc: 1.0000\n",
      "Epoch 170/500\n",
      " - 0s - loss: 0.1235 - acc: 1.0000\n",
      "Epoch 171/500\n",
      " - 0s - loss: 0.1206 - acc: 1.0000\n",
      "Epoch 172/500\n",
      " - 0s - loss: 0.1178 - acc: 1.0000\n",
      "Epoch 173/500\n",
      " - 0s - loss: 0.1151 - acc: 1.0000\n",
      "Epoch 174/500\n",
      " - 0s - loss: 0.1123 - acc: 1.0000\n",
      "Epoch 175/500\n",
      " - 0s - loss: 0.1096 - acc: 1.0000\n",
      "Epoch 176/500\n",
      " - 0s - loss: 0.1070 - acc: 1.0000\n",
      "Epoch 177/500\n",
      " - 0s - loss: 0.1044 - acc: 1.0000\n",
      "Epoch 178/500\n",
      " - 0s - loss: 0.1019 - acc: 1.0000\n",
      "Epoch 179/500\n",
      " - 0s - loss: 0.0994 - acc: 1.0000\n",
      "Epoch 180/500\n",
      " - 0s - loss: 0.0970 - acc: 1.0000\n",
      "Epoch 181/500\n",
      " - 0s - loss: 0.0946 - acc: 1.0000\n",
      "Epoch 182/500\n",
      " - 0s - loss: 0.0924 - acc: 1.0000\n",
      "Epoch 183/500\n",
      " - 0s - loss: 0.0901 - acc: 1.0000\n",
      "Epoch 184/500\n",
      " - 0s - loss: 0.0879 - acc: 1.0000\n",
      "Epoch 185/500\n",
      " - 0s - loss: 0.0858 - acc: 1.0000\n",
      "Epoch 186/500\n",
      " - 0s - loss: 0.0837 - acc: 1.0000\n",
      "Epoch 187/500\n",
      " - 0s - loss: 0.0817 - acc: 1.0000\n",
      "Epoch 188/500\n",
      " - 0s - loss: 0.0798 - acc: 1.0000\n",
      "Epoch 189/500\n",
      " - 0s - loss: 0.0779 - acc: 1.0000\n",
      "Epoch 190/500\n",
      " - 0s - loss: 0.0760 - acc: 1.0000\n",
      "Epoch 191/500\n",
      " - 0s - loss: 0.0743 - acc: 1.0000\n",
      "Epoch 192/500\n",
      " - 0s - loss: 0.0725 - acc: 1.0000\n",
      "Epoch 193/500\n",
      " - 0s - loss: 0.0709 - acc: 1.0000\n",
      "Epoch 194/500\n",
      " - 0s - loss: 0.0692 - acc: 1.0000\n",
      "Epoch 195/500\n",
      " - 0s - loss: 0.0676 - acc: 1.0000\n",
      "Epoch 196/500\n",
      " - 0s - loss: 0.0661 - acc: 1.0000\n",
      "Epoch 197/500\n",
      " - 0s - loss: 0.0646 - acc: 1.0000\n",
      "Epoch 198/500\n",
      " - 0s - loss: 0.0632 - acc: 1.0000\n",
      "Epoch 199/500\n",
      " - 0s - loss: 0.0618 - acc: 1.0000\n",
      "Epoch 200/500\n",
      " - 0s - loss: 0.0604 - acc: 1.0000\n",
      "Epoch 201/500\n",
      " - 0s - loss: 0.0591 - acc: 1.0000\n",
      "Epoch 202/500\n",
      " - 0s - loss: 0.0578 - acc: 1.0000\n",
      "Epoch 203/500\n",
      " - 0s - loss: 0.0566 - acc: 1.0000\n",
      "Epoch 204/500\n",
      " - 0s - loss: 0.0554 - acc: 1.0000\n",
      "Epoch 205/500\n",
      " - 0s - loss: 0.0542 - acc: 1.0000\n",
      "Epoch 206/500\n",
      " - 0s - loss: 0.0531 - acc: 1.0000\n",
      "Epoch 207/500\n",
      " - 0s - loss: 0.0520 - acc: 1.0000\n",
      "Epoch 208/500\n",
      " - 0s - loss: 0.0509 - acc: 1.0000\n",
      "Epoch 209/500\n",
      " - 0s - loss: 0.0499 - acc: 1.0000\n",
      "Epoch 210/500\n",
      " - 0s - loss: 0.0489 - acc: 1.0000\n",
      "Epoch 211/500\n",
      " - 0s - loss: 0.0479 - acc: 1.0000\n",
      "Epoch 212/500\n",
      " - 0s - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 213/500\n",
      " - 0s - loss: 0.0460 - acc: 1.0000\n",
      "Epoch 214/500\n",
      " - 0s - loss: 0.0451 - acc: 1.0000\n",
      "Epoch 215/500\n",
      " - 0s - loss: 0.0442 - acc: 1.0000\n",
      "Epoch 216/500\n",
      " - 0s - loss: 0.0434 - acc: 1.0000\n",
      "Epoch 217/500\n",
      " - 0s - loss: 0.0426 - acc: 1.0000\n",
      "Epoch 218/500\n",
      " - 0s - loss: 0.0418 - acc: 1.0000\n",
      "Epoch 219/500\n",
      " - 0s - loss: 0.0410 - acc: 1.0000\n",
      "Epoch 220/500\n",
      " - 0s - loss: 0.0402 - acc: 1.0000\n",
      "Epoch 221/500\n",
      " - 0s - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 222/500\n",
      " - 0s - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 223/500\n",
      " - 0s - loss: 0.0381 - acc: 1.0000\n",
      "Epoch 224/500\n",
      " - 0s - loss: 0.0374 - acc: 1.0000\n",
      "Epoch 225/500\n",
      " - 0s - loss: 0.0367 - acc: 1.0000\n",
      "Epoch 226/500\n",
      " - 0s - loss: 0.0361 - acc: 1.0000\n",
      "Epoch 227/500\n",
      " - 0s - loss: 0.0355 - acc: 1.0000\n",
      "Epoch 228/500\n",
      " - 0s - loss: 0.0349 - acc: 1.0000\n",
      "Epoch 229/500\n",
      " - 0s - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 230/500\n",
      " - 0s - loss: 0.0336 - acc: 1.0000\n",
      "Epoch 231/500\n",
      " - 0s - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 232/500\n",
      " - 0s - loss: 0.0326 - acc: 1.0000\n",
      "Epoch 233/500\n",
      " - 0s - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 234/500\n",
      " - 0s - loss: 0.0314 - acc: 1.0000\n",
      "Epoch 235/500\n",
      " - 0s - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 236/500\n",
      " - 0s - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 237/500\n",
      " - 0s - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 238/500\n",
      " - 0s - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 239/500\n",
      " - 0s - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 240/500\n",
      " - 0s - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 241/500\n",
      " - 0s - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 242/500\n",
      " - 0s - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.0247 - acc: 1.0000\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.0239 - acc: 1.0000\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.0194 - acc: 1.0000\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.0180 - acc: 1.0000\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.0118 - acc: 1.0000\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.0108 - acc: 1.0000\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 336/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 338/500\n",
      " - 0s - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 339/500\n",
      " - 0s - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.0011 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22dd9a9c4e0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit([data[1:15], ht_input[1:15]], \n",
    "                   np_label[1:15], \n",
    "                   epochs=500,\n",
    "                   batch_size=1,\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 0.] \t 0 \t [-0.8918855] \t [0.08596124] \t [2.2418983 0.        0.        0.       ]\n",
      "[1. 0. 1. 0. 0.] \t 1 \t [0.945177] \t [0.96741253] \t [0.       2.375855 0.       0.      ]\n",
      "[1. 0. 0. 1. 0.] \t 1 \t [0.9474933] \t [0.9608007] \t [0.        0.        2.3816774 0.       ]\n",
      "[1. 0. 0. 0. 1.] \t 0 \t [-0.9995633] \t [0.01498006] \t [0.        0.        0.        2.5125637]\n",
      "[1. 1. 1. 0. 0.] \t 1 \t [0.8690133] \t [0.95793664] \t [0.       2.184405 0.       0.      ]\n",
      "[1. 1. 0. 1. 0.] \t 1 \t [0.8743397] \t [0.95072967] \t [0.       0.       2.197794 0.      ]\n",
      "[1. 1. 0. 0. 1.] \t 0 \t [-0.99982435] \t [0.00095742] \t [2.5132198 0.        0.        2.5132198]\n",
      "[1. 0. 1. 1. 0.] \t 1 \t [0.99978405] \t [0.9989416] \t [0.        2.5131185 2.5131185 0.       ]\n",
      "[1. 0. 1. 0. 1.] \t 0 \t [-0.89656985] \t [0.02310733] \t [0.       0.       0.       2.253673]\n",
      "[1. 0. 0. 1. 1.] \t 0 \t [-0.8921315] \t [0.02354094] \t [0.        0.        0.        2.2425165]\n",
      "[1. 1. 1. 1. 0.] \t 1 \t [0.99946314] \t [0.9989392] \t [0.       2.512312 2.512312 0.      ]\n",
      "[1. 1. 1. 0. 1.] \t 0 \t [-0.95707846] \t [0.00129384] \t [2.4057713 0.        0.        2.4057713]\n",
      "[1. 1. 0. 1. 1.] \t 0 \t [-0.9551753] \t [0.0013113] \t [2.4009871 0.        0.        2.4009871]\n",
      "[1. 0. 1. 1. 1.] \t 1 \t [0.8687182] \t [0.99743986] \t [0.        2.1836634 2.1836634 0.       ]\n"
     ]
    }
   ],
   "source": [
    "report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_present_by_doc(X, human_terms, index, weight):\n",
    "    np_vector = np.zeros([X.shape[0],])\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        if x[index] == 1:\n",
    "            np_vector[i] = np.sign(weight)\n",
    "    \n",
    "    return np_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unigrams(path, X, y):\n",
    "    word_list = []\n",
    "    connotation = {}\n",
    "    \n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            word_list.append(line.strip())\n",
    "            \n",
    "    for word in word_list:\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        for i, doc in enumerate(X):\n",
    "            if word in doc.lower():\n",
    "                if (y[i] == 1):\n",
    "                    pos_count += 1\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    \n",
    "        if pos_count > neg_count:\n",
    "            connotation[word] = 1\n",
    "        else:\n",
    "            connotation[word] = 0\n",
    "    \n",
    "    return word_list, connotation\n",
    "\n",
    "def generate_appearance(X_train_corpus, X_test_corpus, word_list, connotation):\n",
    "    y_train_agreement = []\n",
    "    for i in range(len(X_train_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_train_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_train_agreement.append(doc_agreement)\n",
    "        \n",
    "    y_test_agreement = []\n",
    "    for i in range(len(X_test_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_test_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_test_agreement.append(doc_agreement)\n",
    "        \n",
    "    return np.array(y_train_agreement), np.array(y_test_agreement)\n",
    "\n",
    "# 'imdb-unigrams.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try on IMDB data\n",
    "#### Like the real IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# make sure that the first shape is the IMDB training data. \n",
    "\n",
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "X_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtrain.pickle')\n",
    "X_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtest.pickle')\n",
    "y_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytrain.pickle')\n",
    "y_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df = 100)\n",
    "X_train = cv.fit_transform(X_train_original)\n",
    "X_test = cv.transform(X_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, connotation = load_unigrams('./imdb-unigrams.txt', X_train_original, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_agreement, y_test_agreement = generate_appearance(X_train_original, X_test_original, \n",
    "                                                          word_list, connotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_agreement[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           (None, 83)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, 3641)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               [(None, 1), (None, 1 0           input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_23 (Model)                (None, 1)            3642        input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 1)            0           lambda_2[0][0]                   \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 1)            0           lambda_2[0][1]                   \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 1)            0           lambda_2[0][2]                   \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 1)            0           lambda_2[0][3]                   \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 1)            0           lambda_2[0][4]                   \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 1)            0           lambda_2[0][5]                   \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 1)            0           lambda_2[0][6]                   \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 1)            0           lambda_2[0][7]                   \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 1)            0           lambda_2[0][8]                   \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 1)            0           lambda_2[0][9]                   \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 1)            0           lambda_2[0][10]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 1)            0           lambda_2[0][11]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 1)            0           lambda_2[0][12]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 1)            0           lambda_2[0][13]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 1)            0           lambda_2[0][14]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 1)            0           lambda_2[0][15]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 1)            0           lambda_2[0][16]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 1)            0           lambda_2[0][17]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 1)            0           lambda_2[0][18]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 1)            0           lambda_2[0][19]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 1)            0           lambda_2[0][20]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 1)            0           lambda_2[0][21]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 1)            0           lambda_2[0][22]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 1)            0           lambda_2[0][23]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 1)            0           lambda_2[0][24]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 1)            0           lambda_2[0][25]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 1)            0           lambda_2[0][26]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 1)            0           lambda_2[0][27]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 1)            0           lambda_2[0][28]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 1)            0           lambda_2[0][29]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 1)            0           lambda_2[0][30]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 1)            0           lambda_2[0][31]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 1)            0           lambda_2[0][32]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 1)            0           lambda_2[0][33]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 1)            0           lambda_2[0][34]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_42 (Multiply)          (None, 1)            0           lambda_2[0][35]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_43 (Multiply)          (None, 1)            0           lambda_2[0][36]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_44 (Multiply)          (None, 1)            0           lambda_2[0][37]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_45 (Multiply)          (None, 1)            0           lambda_2[0][38]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_46 (Multiply)          (None, 1)            0           lambda_2[0][39]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_47 (Multiply)          (None, 1)            0           lambda_2[0][40]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_48 (Multiply)          (None, 1)            0           lambda_2[0][41]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_49 (Multiply)          (None, 1)            0           lambda_2[0][42]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_50 (Multiply)          (None, 1)            0           lambda_2[0][43]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_51 (Multiply)          (None, 1)            0           lambda_2[0][44]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_52 (Multiply)          (None, 1)            0           lambda_2[0][45]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_53 (Multiply)          (None, 1)            0           lambda_2[0][46]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_54 (Multiply)          (None, 1)            0           lambda_2[0][47]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_55 (Multiply)          (None, 1)            0           lambda_2[0][48]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_56 (Multiply)          (None, 1)            0           lambda_2[0][49]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_57 (Multiply)          (None, 1)            0           lambda_2[0][50]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_58 (Multiply)          (None, 1)            0           lambda_2[0][51]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_59 (Multiply)          (None, 1)            0           lambda_2[0][52]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_60 (Multiply)          (None, 1)            0           lambda_2[0][53]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_61 (Multiply)          (None, 1)            0           lambda_2[0][54]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_62 (Multiply)          (None, 1)            0           lambda_2[0][55]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_63 (Multiply)          (None, 1)            0           lambda_2[0][56]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_64 (Multiply)          (None, 1)            0           lambda_2[0][57]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_65 (Multiply)          (None, 1)            0           lambda_2[0][58]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_66 (Multiply)          (None, 1)            0           lambda_2[0][59]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_67 (Multiply)          (None, 1)            0           lambda_2[0][60]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_68 (Multiply)          (None, 1)            0           lambda_2[0][61]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_69 (Multiply)          (None, 1)            0           lambda_2[0][62]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_70 (Multiply)          (None, 1)            0           lambda_2[0][63]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_71 (Multiply)          (None, 1)            0           lambda_2[0][64]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_72 (Multiply)          (None, 1)            0           lambda_2[0][65]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_73 (Multiply)          (None, 1)            0           lambda_2[0][66]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_74 (Multiply)          (None, 1)            0           lambda_2[0][67]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_75 (Multiply)          (None, 1)            0           lambda_2[0][68]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_76 (Multiply)          (None, 1)            0           lambda_2[0][69]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_77 (Multiply)          (None, 1)            0           lambda_2[0][70]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_78 (Multiply)          (None, 1)            0           lambda_2[0][71]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_79 (Multiply)          (None, 1)            0           lambda_2[0][72]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_80 (Multiply)          (None, 1)            0           lambda_2[0][73]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_81 (Multiply)          (None, 1)            0           lambda_2[0][74]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_82 (Multiply)          (None, 1)            0           lambda_2[0][75]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_83 (Multiply)          (None, 1)            0           lambda_2[0][76]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_84 (Multiply)          (None, 1)            0           lambda_2[0][77]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_85 (Multiply)          (None, 1)            0           lambda_2[0][78]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_86 (Multiply)          (None, 1)            0           lambda_2[0][79]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_87 (Multiply)          (None, 1)            0           lambda_2[0][80]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_88 (Multiply)          (None, 1)            0           lambda_2[0][81]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_89 (Multiply)          (None, 1)            0           lambda_2[0][82]                  \n",
      "                                                                 model_23[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_layer (Dense)              (None, 1)            1           multiply_7[0][0]                 \n",
      "                                                                 multiply_8[0][0]                 \n",
      "                                                                 multiply_9[0][0]                 \n",
      "                                                                 multiply_10[0][0]                \n",
      "                                                                 multiply_11[0][0]                \n",
      "                                                                 multiply_12[0][0]                \n",
      "                                                                 multiply_13[0][0]                \n",
      "                                                                 multiply_14[0][0]                \n",
      "                                                                 multiply_15[0][0]                \n",
      "                                                                 multiply_16[0][0]                \n",
      "                                                                 multiply_17[0][0]                \n",
      "                                                                 multiply_18[0][0]                \n",
      "                                                                 multiply_19[0][0]                \n",
      "                                                                 multiply_20[0][0]                \n",
      "                                                                 multiply_21[0][0]                \n",
      "                                                                 multiply_22[0][0]                \n",
      "                                                                 multiply_23[0][0]                \n",
      "                                                                 multiply_24[0][0]                \n",
      "                                                                 multiply_25[0][0]                \n",
      "                                                                 multiply_26[0][0]                \n",
      "                                                                 multiply_27[0][0]                \n",
      "                                                                 multiply_28[0][0]                \n",
      "                                                                 multiply_29[0][0]                \n",
      "                                                                 multiply_30[0][0]                \n",
      "                                                                 multiply_31[0][0]                \n",
      "                                                                 multiply_32[0][0]                \n",
      "                                                                 multiply_33[0][0]                \n",
      "                                                                 multiply_34[0][0]                \n",
      "                                                                 multiply_35[0][0]                \n",
      "                                                                 multiply_36[0][0]                \n",
      "                                                                 multiply_37[0][0]                \n",
      "                                                                 multiply_38[0][0]                \n",
      "                                                                 multiply_39[0][0]                \n",
      "                                                                 multiply_40[0][0]                \n",
      "                                                                 multiply_41[0][0]                \n",
      "                                                                 multiply_42[0][0]                \n",
      "                                                                 multiply_43[0][0]                \n",
      "                                                                 multiply_44[0][0]                \n",
      "                                                                 multiply_45[0][0]                \n",
      "                                                                 multiply_46[0][0]                \n",
      "                                                                 multiply_47[0][0]                \n",
      "                                                                 multiply_48[0][0]                \n",
      "                                                                 multiply_49[0][0]                \n",
      "                                                                 multiply_50[0][0]                \n",
      "                                                                 multiply_51[0][0]                \n",
      "                                                                 multiply_52[0][0]                \n",
      "                                                                 multiply_53[0][0]                \n",
      "                                                                 multiply_54[0][0]                \n",
      "                                                                 multiply_55[0][0]                \n",
      "                                                                 multiply_56[0][0]                \n",
      "                                                                 multiply_57[0][0]                \n",
      "                                                                 multiply_58[0][0]                \n",
      "                                                                 multiply_59[0][0]                \n",
      "                                                                 multiply_60[0][0]                \n",
      "                                                                 multiply_61[0][0]                \n",
      "                                                                 multiply_62[0][0]                \n",
      "                                                                 multiply_63[0][0]                \n",
      "                                                                 multiply_64[0][0]                \n",
      "                                                                 multiply_65[0][0]                \n",
      "                                                                 multiply_66[0][0]                \n",
      "                                                                 multiply_67[0][0]                \n",
      "                                                                 multiply_68[0][0]                \n",
      "                                                                 multiply_69[0][0]                \n",
      "                                                                 multiply_70[0][0]                \n",
      "                                                                 multiply_71[0][0]                \n",
      "                                                                 multiply_72[0][0]                \n",
      "                                                                 multiply_73[0][0]                \n",
      "                                                                 multiply_74[0][0]                \n",
      "                                                                 multiply_75[0][0]                \n",
      "                                                                 multiply_76[0][0]                \n",
      "                                                                 multiply_77[0][0]                \n",
      "                                                                 multiply_78[0][0]                \n",
      "                                                                 multiply_79[0][0]                \n",
      "                                                                 multiply_80[0][0]                \n",
      "                                                                 multiply_81[0][0]                \n",
      "                                                                 multiply_82[0][0]                \n",
      "                                                                 multiply_83[0][0]                \n",
      "                                                                 multiply_84[0][0]                \n",
      "                                                                 multiply_85[0][0]                \n",
      "                                                                 multiply_86[0][0]                \n",
      "                                                                 multiply_87[0][0]                \n",
      "                                                                 multiply_88[0][0]                \n",
      "                                                                 multiply_89[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Lambda)            (None, 83)           0           relu_layer[0][0]                 \n",
      "                                                                 relu_layer[1][0]                 \n",
      "                                                                 relu_layer[2][0]                 \n",
      "                                                                 relu_layer[3][0]                 \n",
      "                                                                 relu_layer[4][0]                 \n",
      "                                                                 relu_layer[5][0]                 \n",
      "                                                                 relu_layer[6][0]                 \n",
      "                                                                 relu_layer[7][0]                 \n",
      "                                                                 relu_layer[8][0]                 \n",
      "                                                                 relu_layer[9][0]                 \n",
      "                                                                 relu_layer[10][0]                \n",
      "                                                                 relu_layer[11][0]                \n",
      "                                                                 relu_layer[12][0]                \n",
      "                                                                 relu_layer[13][0]                \n",
      "                                                                 relu_layer[14][0]                \n",
      "                                                                 relu_layer[15][0]                \n",
      "                                                                 relu_layer[16][0]                \n",
      "                                                                 relu_layer[17][0]                \n",
      "                                                                 relu_layer[18][0]                \n",
      "                                                                 relu_layer[19][0]                \n",
      "                                                                 relu_layer[20][0]                \n",
      "                                                                 relu_layer[21][0]                \n",
      "                                                                 relu_layer[22][0]                \n",
      "                                                                 relu_layer[23][0]                \n",
      "                                                                 relu_layer[24][0]                \n",
      "                                                                 relu_layer[25][0]                \n",
      "                                                                 relu_layer[26][0]                \n",
      "                                                                 relu_layer[27][0]                \n",
      "                                                                 relu_layer[28][0]                \n",
      "                                                                 relu_layer[29][0]                \n",
      "                                                                 relu_layer[30][0]                \n",
      "                                                                 relu_layer[31][0]                \n",
      "                                                                 relu_layer[32][0]                \n",
      "                                                                 relu_layer[33][0]                \n",
      "                                                                 relu_layer[34][0]                \n",
      "                                                                 relu_layer[35][0]                \n",
      "                                                                 relu_layer[36][0]                \n",
      "                                                                 relu_layer[37][0]                \n",
      "                                                                 relu_layer[38][0]                \n",
      "                                                                 relu_layer[39][0]                \n",
      "                                                                 relu_layer[40][0]                \n",
      "                                                                 relu_layer[41][0]                \n",
      "                                                                 relu_layer[42][0]                \n",
      "                                                                 relu_layer[43][0]                \n",
      "                                                                 relu_layer[44][0]                \n",
      "                                                                 relu_layer[45][0]                \n",
      "                                                                 relu_layer[46][0]                \n",
      "                                                                 relu_layer[47][0]                \n",
      "                                                                 relu_layer[48][0]                \n",
      "                                                                 relu_layer[49][0]                \n",
      "                                                                 relu_layer[50][0]                \n",
      "                                                                 relu_layer[51][0]                \n",
      "                                                                 relu_layer[52][0]                \n",
      "                                                                 relu_layer[53][0]                \n",
      "                                                                 relu_layer[54][0]                \n",
      "                                                                 relu_layer[55][0]                \n",
      "                                                                 relu_layer[56][0]                \n",
      "                                                                 relu_layer[57][0]                \n",
      "                                                                 relu_layer[58][0]                \n",
      "                                                                 relu_layer[59][0]                \n",
      "                                                                 relu_layer[60][0]                \n",
      "                                                                 relu_layer[61][0]                \n",
      "                                                                 relu_layer[62][0]                \n",
      "                                                                 relu_layer[63][0]                \n",
      "                                                                 relu_layer[64][0]                \n",
      "                                                                 relu_layer[65][0]                \n",
      "                                                                 relu_layer[66][0]                \n",
      "                                                                 relu_layer[67][0]                \n",
      "                                                                 relu_layer[68][0]                \n",
      "                                                                 relu_layer[69][0]                \n",
      "                                                                 relu_layer[70][0]                \n",
      "                                                                 relu_layer[71][0]                \n",
      "                                                                 relu_layer[72][0]                \n",
      "                                                                 relu_layer[73][0]                \n",
      "                                                                 relu_layer[74][0]                \n",
      "                                                                 relu_layer[75][0]                \n",
      "                                                                 relu_layer[76][0]                \n",
      "                                                                 relu_layer[77][0]                \n",
      "                                                                 relu_layer[78][0]                \n",
      "                                                                 relu_layer[79][0]                \n",
      "                                                                 relu_layer[80][0]                \n",
      "                                                                 relu_layer[81][0]                \n",
      "                                                                 relu_layer[82][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            84          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,727\n",
      "Trainable params: 3,727\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the combined model\n",
    "# Combined model\n",
    "human_terms_len = len(word_list)\n",
    "\n",
    "base_model = build_base_model(X_train.shape[1])\n",
    "\n",
    "combined_input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# build the hard coded weight for human terms\n",
    "ht_input_layer = Input(shape=(human_terms_len,))\n",
    "\n",
    "split = Lambda( lambda x: tf.split(x,num_or_size_splits=human_terms_len,axis=1))(ht_input_layer)\n",
    "\n",
    "# get the document prediction\n",
    "label_layer = base_model(combined_input_layer)\n",
    "\n",
    "# multiply and pass it into relu\n",
    "# initialize relu layer\n",
    "\n",
    "relu_layer = Dense(1, activation='relu', name='relu_layer', use_bias=False, kernel_initializer='ones')\n",
    "\n",
    "# stack the multiply layer\n",
    "dense_layer = []\n",
    "for i in range(human_terms_len):\n",
    "    dense_layer.append(relu_layer(Multiply()([split[i], label_layer])))\n",
    "\n",
    "# concat all the result   \n",
    "concat = Lambda( lambda x: tf.concat(x, axis=1), name='concatenate')(dense_layer)\n",
    "\n",
    "# pass it to sigmoid layer\n",
    "output_layer = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "combined_model = Model(inputs=[combined_input_layer, ht_input_layer], outputs=output_layer)\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(loss='mse',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "combined_model.compile(loss='mse',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tanh = y_train_original\n",
    "y_train_tanh[y_train_tanh == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 137s 5ms/step - loss: 0.4010 - acc: 0.7676\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 134s 5ms/step - loss: 0.3367 - acc: 0.8382\n",
      "Epoch 3/10\n",
      " 8992/25000 [=========>....................] - ETA: 1:28 - loss: 0.2817 - acc: 0.8644"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-74ad61a217e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_tanh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_model.fit(X_train, y_train_tanh, batch_size=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.fit(X_train, y_train_tanh, batch_size=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.fit([X_train,\n",
    "                   y_train_agreement])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
