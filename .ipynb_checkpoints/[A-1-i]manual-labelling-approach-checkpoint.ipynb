{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_pickle\n",
    "\n",
    "def open_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset of [relevant,-relevant]\n",
    "\n",
    "X_train_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_xtrain.pickle')\n",
    "X_test_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_xtest.pickle')\n",
    "y_train_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_ytrain.pickle')\n",
    "y_test_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_ytest.pickle')\n",
    "\n",
    "#Load dataset of [whole corpus]\n",
    "\n",
    "X_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtrain.pickle')\n",
    "X_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtest.pickle')\n",
    "y_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytrain.pickle')\n",
    "y_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytest.pickle')\n",
    "\n",
    "#Load dataset of sentence [+/-]\n",
    "\n",
    "X_train_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_xtrain.pickle')\n",
    "X_test_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_xtest.pickle')\n",
    "y_train_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_ytrain.pickle')\n",
    "y_test_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_ytest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666\n",
      "334\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_np_sentence))\n",
    "print(len(X_test_np_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26266\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "cv = CountVectorizer(lowercase=True, min_df=5, binary=True, token_pattern=token)\n",
    "\n",
    "X_tr_baseline = cv.fit_transform(X_train_original)\n",
    "X_te_baseline = cv.transform(X_test_original)\n",
    "\n",
    "print(len(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 26266)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr_baseline.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90968\n",
      "0.8794\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, C=0.01)\n",
    "\n",
    "clf.fit(X_tr_baseline, y_train_original)\n",
    "\n",
    "\n",
    "print(clf.score(X_tr_baseline, y_train_original))\n",
    "print(clf.score(X_te_baseline, y_test_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer on rel,unrel dataset\n",
    "# Question : Why rel/unrel? Because it trained as the first step? \n",
    "# Any advantages on more vocabulary?\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "tf_vectorizer = CountVectorizer(lowercase=True, max_df=1.0, min_df=5, binary=True, token_pattern=token)\n",
    "tf_vectorizer.set_params(ngram_range=(1,1))\n",
    "\n",
    "# rel/unrel sentence\n",
    "X_train_sentence_bow = tf_vectorizer.fit_transform(X_train_sentence)\n",
    "X_test_sentence_bow = tf_vectorizer.transform(X_test_sentence)\n",
    "\n",
    "# whole imdb corpus\n",
    "X_train_original_bow = tf_vectorizer.transform(X_train_original)\n",
    "X_test_original_bow = tf_vectorizer.transform(X_test_original)\n",
    "\n",
    "# neg/pos sentence\n",
    "X_train_np_bow = tf_vectorizer.fit_transform(X_train_np_sentence)\n",
    "X_test_np_bow = tf_vectorizer.transform(X_test_np_sentence) \n",
    "\n",
    "words = tf_vectorizer.get_feature_names()\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8416\n",
      "0.83664\n"
     ]
    }
   ],
   "source": [
    "# Again baseline\n",
    "\n",
    "clf = LogisticRegression(random_state=42, C=0.01)\n",
    "\n",
    "clf.fit(X_train_original_bow, y_train_original)\n",
    "\n",
    "print(clf.score(X_train_original_bow, y_train_original))\n",
    "print(clf.score(X_test_original_bow, y_test_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus\n",
      "(25000,)\n",
      "(25000,)\n",
      "rel/unrel\n",
      "(1333,)\n",
      "(667,)\n",
      "np sentence\n",
      "(666,)\n",
      "(334,)\n"
     ]
    }
   ],
   "source": [
    "print('corpus')\n",
    "print(y_train_original.shape)\n",
    "print(y_test_original.shape)\n",
    "\n",
    "print('rel/unrel')\n",
    "print(y_train_sentence.shape)\n",
    "print(y_test_sentence.shape)\n",
    "\n",
    "print('np sentence')\n",
    "print(y_train_np_sentence.shape)\n",
    "print(y_test_np_sentence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train A [rel,unrel] classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "C=0.01\n",
      "--------------\n",
      "Accuracy\n",
      "Train:\t0.73743 \n",
      "Test:\t0.69265 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.63      0.69       363\n",
      "        1.0       0.63      0.77      0.69       304\n",
      "\n",
      "avg / total       0.70      0.69      0.69       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Okay... Using the function makes me more overwhelmed. Let's do it manually.\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "C = 0.01\n",
    "\n",
    "clf_A = LogisticRegression(random_state=random_state, C=C)\n",
    "clf_A.fit(X_train_sentence_bow, y_train_sentence)\n",
    "\n",
    "y_predict = clf_A.predict(X_test_sentence_bow)\n",
    "\n",
    "print('--------------')\n",
    "print('C=%.2f' %(C))\n",
    "print('--------------')\n",
    "print('Accuracy')\n",
    "print('Train:\\t%.5f ' %(clf_A.score(X_train_sentence_bow, y_train_sentence)))\n",
    "print('Test:\\t%.5f ' %(clf_A.score(X_test_sentence_bow, y_test_sentence)))\n",
    "    \n",
    "print(classification_report(y_test_sentence,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 1 [+,-] classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using whole corpus\n",
    "\n",
    "clf_1 = LogisticRegression(random_state=random_state, C=C)\n",
    "clf_1.fit(X_train_original_bow, y_train_original)\n",
    "\n",
    "# using the [+/-] sentence\n",
    "# clf_2 = LogisticRegression(random_state=random_state, C=C)\n",
    "# clf_2.fit(X_train_sentence_bow, y_train_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the idea ia a very short film with a lot of information.',\n",
       " 'interesting, entertaining and leaves the viewer wanting more.',\n",
       " 'the producer has produced a short film of excellent quality that cannot be compared to any other short film that i have seen.',\n",
       " 'i have rated this film at the highest possible rating.',\n",
       " 'i also recommend that it is shown to office manager and business person in any establishment.',\n",
       " 'what comes out of it is the fact that person with idea are never listened to, their voice is never heard.',\n",
       " 'it is a lesson to be learned by any office that wants to go forward.',\n",
       " \"i hope that the produced will produce a second part to this 'idea'.\",\n",
       " 'i look forward to viewing the sequence.',\n",
       " 'once again congrat to halaqah medium in producing a film of excellence and quality with a lesson in mind.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(X_train_original[1]).raw_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"when i was a kid we always used to be babysat, and we always used to rent a film or see a film at the cinema. this is one of the film we watched. this is one of the stupidest film i have ever seen, i think it might even be a walt disney picture film! a martian is dropped on earth, turns into a human, befriends a human, and is trying everything he can to get back home. but he is distracted by the wonder of the earth. the only good comment i can give is the choice of actor, back to the future's christopher lloyd as the martian, uncle martin, dumb and dumber's jeff daniel as tim o'hara, elizabeth hurley as brace channing and daryl hannah as lizzie. but apart from that it is complete crap. poor!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_original[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when i was a kid we always used to be babysat, and we always used to rent a film or see a film at the cinema.',\n",
       " 'this is one of the film we watched.',\n",
       " 'this is one of the stupidest film i have ever seen, i think it might even be a walt disney picture film!',\n",
       " 'a martian is dropped on earth, turns into a human, befriends a human, and is trying everything he can to get back home.',\n",
       " 'but he is distracted by the wonder of the earth.',\n",
       " \"the only good comment i can give is the choice of actor, back to the future's christopher lloyd as the martian, uncle martin, dumb and dumber's jeff daniel as tim o'hara, elizabeth hurley as brace channing and daryl hannah as lizzie.\",\n",
       " 'but apart from that it is complete crap.',\n",
       " 'poor!']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(X_train_original[5]).raw_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf_vectorizer.transform(TextBlob(X_train_original[5]).raw_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 this is one of the film we watched. \t0.650\n",
      "2 this is one of the stupidest film i have ever seen, i think it might even be a walt disney picture film! \t0.732\n",
      "5 the only good comment i can give is the choice of actor, back to the future's christopher lloyd as the martian, uncle martin, dumb and dumber's jeff daniel as tim o'hara, elizabeth hurley as brace channing and daryl hannah as lizzie. \t0.512\n",
      "6 but apart from that it is complete crap. \t0.608\n",
      "7 poor! \t0.502\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(clf_A.predict_proba(test_set)[:,1]):\n",
    "    if j>0.5:\n",
    "        print(i,TextBlob(X_train_original[5]).raw_sentences[i],\"\\t{:.3f}\".format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(np.array(x).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 this is one of the film we watched. [0.43243437 0.56756563]\n",
      "1 this is one of the stupidest film i have ever seen, i think it might even be a walt disney picture film! [0.42348131 0.57651869]\n",
      "2 the only good comment i can give is the choice of actor, back to the future's christopher lloyd as the martian, uncle martin, dumb and dumber's jeff daniel as tim o'hara, elizabeth hurley as brace channing and daryl hannah as lizzie. [0.41162858 0.58837142]\n",
      "3 but apart from that it is complete crap. [0.51941371 0.48058629]\n",
      "4 poor! [0.63365011 0.36634989]\n"
     ]
    }
   ],
   "source": [
    "x = np.where(clf_A.predict_proba(test_set)[:,1]>0.5)\n",
    "\n",
    "test = test_set[x]\n",
    "\n",
    "for i,j in enumerate(clf_1.predict_proba(test)):\n",
    "    print(i,TextBlob(X_train_original[5]).raw_sentences[np.array(x).flatten()[i]],j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an accuracy function excluding those -1\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "threshold=None\n",
    "highest_confidence_related=True\n",
    "\n",
    "for corpus in X_train_original[0:1]:\n",
    "    '''\n",
    "    Breakdown the corpus into sentence and transform into bag-of-words\n",
    "    '''\n",
    "    sentence_set = tf_vectorizer.transform(TextBlob(corpus).raw_sentences)\n",
    "    \n",
    "    '''\n",
    "    Related classifier given threshold. \n",
    "    threshold, if None, it only predict the label. If float number given, assign the threshold to the sentence with\n",
    "    probability over threshold\n",
    "    '''\n",
    "    if threshold==None:\n",
    "        y_ind_proba = clf_A.predict_proba(sentence_set)\n",
    "        y_ind = clf_A.predict(sentence_set)\n",
    "    else:\n",
    "        y_ind_proba = clf_A.predict_proba(sentence_set)\n",
    "        y_ind = y_ind_proba[:,1]>threshold\n",
    "        \n",
    "    '''\n",
    "    +/- classifier given the sentences from the previous classifier\n",
    "    if 0, assign the label as -1 (which means it does not have any related sentence)\n",
    "    else, classify the sentence into +/- label according to the given sentence. \n",
    "    '''\n",
    "    if np.sum(y_ind) == 0:\n",
    "        y_pred.append(-1)\n",
    "        continue\n",
    "    else:\n",
    "        if highest_confidence_related:\n",
    "            indices = np.array(np.argmax(y_ind_proba[:,1])).flatten()\n",
    "            y = clf_1.predict(sentence_set[indices, :])\n",
    "            y_pred.append(y)\n",
    "        else:\n",
    "            indices = np.array(np.where(y_ind[:,1] == 1)).flatten()\n",
    "            y_np_proba = clf_1.predict_proba(sentence_set[indices, :])\n",
    "            y_neg_proba = np.max(y_np_proba[:,0])\n",
    "            y_pos_proba = np.max(y_np_proba[:,1])\n",
    "            mn, mp = np.max(y_np_proba, axis=1)\n",
    "\n",
    "            if y_pos_proba > y_neg_proba:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "\n",
    "     \n",
    "    \n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1330517bcab8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mn' is not defined"
     ]
    }
   ],
   "source": [
    "mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_original[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
