{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anneke Hidayat\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, TimeDistributed, Embedding\n",
    "from keras.layers import Concatenate, Reshape, Lambda, Multiply, multiply, concatenate\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# make sure that the first shape is the IMDB training data. \n",
    "\n",
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "X_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtrain.pickle')\n",
    "X_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtest.pickle')\n",
    "y_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytrain.pickle')\n",
    "y_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df = 100)\n",
    "X_train = cv.fit_transform(X_train_original)\n",
    "X_test = cv.transform(X_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unigrams(path, X, y):\n",
    "    word_list = []\n",
    "    connotation = {}\n",
    "    \n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            word_list.append(line.strip())\n",
    "            \n",
    "    for word in word_list:\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        for i, doc in enumerate(X):\n",
    "            if word in doc.lower():\n",
    "                if (y[i] == 1):\n",
    "                    pos_count += 1\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    \n",
    "        if pos_count > neg_count:\n",
    "            connotation[word] = 1\n",
    "        else:\n",
    "            connotation[word] = 0\n",
    "    \n",
    "    return word_list, connotation\n",
    "\n",
    "def generate_appearance(X_train_corpus, X_test_corpus, word_list, connotation):\n",
    "    y_train_agreement = []\n",
    "    for i in range(len(X_train_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_train_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_train_agreement.append(doc_agreement)\n",
    "        \n",
    "    y_test_agreement = []\n",
    "    for i in range(len(X_test_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_test_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_test_agreement.append(doc_agreement)\n",
    "        \n",
    "    return np.array(y_train_agreement), np.array(y_test_agreement)\n",
    "\n",
    "# 'imdb-unigrams.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, connotation = load_unigrams('./imdb-unigrams.txt', X_train_original, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_agreement, y_test_agreement = generate_appearance(X_train_original, X_test_original, \n",
    "                                                          word_list, connotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_model(optimizer='Adagrad'):\n",
    "    input_layer = Input(shape=(input_shape,))\n",
    "    tanh_output = Dense(1, activation='tanh', name='tanh_output')(input_layer)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=tanh_output)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "#input_shape, human_terms_shape\n",
    "def build_combined_model(optimizer='adam'):\n",
    "\n",
    "    # input for base model\n",
    "#     base_model = build_base_model(input_shape)\n",
    "    combined_input_layer = Input(shape=(input_shape,))\n",
    "\n",
    "    # build the hard coded weight for human terms and split the input \n",
    "    ht_input_layer = Input(shape=(human_terms_shape,))\n",
    "    split = Lambda( lambda x: tf.split(x,num_or_size_splits=human_terms_shape,axis=1))(ht_input_layer)\n",
    "\n",
    "    # get the document prediction\n",
    "    label_layer = base_model(combined_input_layer)\n",
    "    \n",
    "    # multiply the predicion and the human terms absence -> pass it to relu\n",
    "    dense_layer = []\n",
    "    for i in range(human_terms_len):\n",
    "        dense_layer.append(Dense(\n",
    "            1, \n",
    "            activation='relu', \n",
    "            use_bias=False, \n",
    "            kernel_initializer='ones')(Multiply()([split[i], label_layer])))\n",
    "\n",
    "    # concat all the result and pass it to sigmoid layer\n",
    "    concat = Lambda( lambda x: tf.concat(x, axis=1), name='concatenate')(dense_layer)\n",
    "    output_layer = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "    # build model\n",
    "    combined_model = Model(inputs=[combined_input_layer, ht_input_layer], outputs=output_layer)\n",
    "    combined_model.summary()\n",
    "    \n",
    "\n",
    "    combined_model.compile(loss='mse',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['mae','acc'])\n",
    "    \n",
    "    return base_model, combined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tanh = y_train_original\n",
    "y_train_tanh[y_train_tanh == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 83)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_agreement.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Best: 0.833200 using {'optimizer': 'Adagrad'}\n",
      "0.522400 (0.006081) with: {'optimizer': 'SGD'}\n",
      "0.605120 (0.004240) with: {'optimizer': 'RMSprop'}\n",
      "0.833200 (0.004663) with: {'optimizer': 'Adagrad'}\n",
      "0.690640 (0.008747) with: {'optimizer': 'Adadelta'}\n",
      "0.639200 (0.003653) with: {'optimizer': 'Adam'}\n",
      "0.791840 (0.004609) with: {'optimizer': 'Adamax'}\n",
      "0.509160 (0.011387) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "input_shape=X_train.shape[1]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=build_base_model, epochs=10, batch_size=1, verbose=0)\n",
    "\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train, y_train_tanh)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.833200 using {'optimizer': 'Adagrad'}\n",
      "0.522400 (0.006081) with: {'optimizer': 'SGD'}\n",
      "0.605120 (0.004240) with: {'optimizer': 'RMSprop'}\n",
      "0.833200 (0.004663) with: {'optimizer': 'Adagrad'}\n",
      "0.690640 (0.008747) with: {'optimizer': 'Adadelta'}\n",
      "0.639200 (0.003653) with: {'optimizer': 'Adam'}\n",
      "0.791840 (0.004609) with: {'optimizer': 'Adamax'}\n",
      "0.509160 (0.011387) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "# Best: 0.833200 using {'optimizer': 'Adagrad'}\n",
    "# 0.522400 (0.006081) with: {'optimizer': 'SGD'}\n",
    "# 0.605120 (0.004240) with: {'optimizer': 'RMSprop'}\n",
    "# 0.833200 (0.004663) with: {'optimizer': 'Adagrad'}\n",
    "# 0.690640 (0.008747) with: {'optimizer': 'Adadelta'}\n",
    "# 0.639200 (0.003653) with: {'optimizer': 'Adam'}\n",
    "# 0.791840 (0.004609) with: {'optimizer': 'Adamax'}\n",
    "# 0.509160 (0.011387) with: {'optimizer': 'Nadam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = build_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.4703 - mean_absolute_error: 0.5341 - acc: 0.5502\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.3526 - mean_absolute_error: 0.4279 - acc: 0.6656\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.3251 - mean_absolute_error: 0.4003 - acc: 0.6922\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 25s 1ms/step - loss: 0.3085 - mean_absolute_error: 0.3831 - acc: 0.7098\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.2976 - mean_absolute_error: 0.3711 - acc: 0.7217\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.2890 - mean_absolute_error: 0.3614 - acc: 0.7302\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 25s 1ms/step - loss: 0.2823 - mean_absolute_error: 0.3539 - acc: 0.7376\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 24s 976us/step - loss: 0.2767 - mean_absolute_error: 0.3475 - acc: 0.7435\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 24s 962us/step - loss: 0.2720 - mean_absolute_error: 0.3420 - acc: 0.7488\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 25s 994us/step - loss: 0.2678 - mean_absolute_error: 0.3370 - acc: 0.7523\n"
     ]
    }
   ],
   "source": [
    "base_model_history = base_model.fit(X_train, y_train_tanh, batch_size=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_model_history = combined_model.fit([X_train,y_train_agreement], y_train_original, batch_size=1, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 25000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-0d06a89983b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_agreement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_original\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best: %f using %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'score'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;31m# Regenerate parameter iterable for each fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 25000]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "input_shape=X_train.shape[1]\n",
    "human_terms_shape=len(word_list)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn = build_combined_model, epochs=10, batch_size=1, verbose=0)\n",
    "\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit([X_train, y_train_agreement], y_train_original)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
