{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset of [whole corpus]\n",
    "\n",
    "X_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtrain.pickle')\n",
    "X_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtest.pickle')\n",
    "y_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytrain.pickle')\n",
    "y_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytest.pickle')\n",
    "\n",
    "#Load dataset of sentence [+/-]\n",
    "\n",
    "X_train_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_xtrain.pickle')\n",
    "X_test_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_xtest.pickle')\n",
    "y_train_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_ytrain.pickle')\n",
    "y_test_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_ytest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer on rel,unrel dataset\n",
    "# Question : Why rel/unrel? Because it trained as the first step? \n",
    "# Any advantages on more vocabulary?\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "tf_vectorizer = CountVectorizer(lowercase=True, max_df=1.0, min_df=5, binary=True, token_pattern=token)\n",
    "tf_vectorizer.set_params(ngram_range=(1,1))\n",
    "\n",
    "# whole imdb corpus\n",
    "X_train_original_bow = tf_vectorizer.fit_transform(X_train_original)\n",
    "X_test_original_bow = tf_vectorizer.transform(X_test_original)\n",
    "\n",
    "# positive/negative sentence\n",
    "X_train_np_bow = tf_vectorizer.transform(X_train_np_sentence)\n",
    "X_test_np_bow = tf_vectorizer.transform(X_test_np_sentence) \n",
    "\n",
    "words = tf_vectorizer.get_feature_names()\n",
    "words = np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial variable\n",
    "random_state = 42\n",
    "C = 1\n",
    "\n",
    "# using whole corpus\n",
    "clf_i = LogisticRegression(random_state=random_state, C=C)\n",
    "clf_i.fit(X_train_original_bow, y_train_original)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "\n",
    "document = np.vstack([X_train_original[idx], X_train_original[idx]])\n",
    "sentences = TextBlob(X_train_original[idx]).raw_sentences\n",
    "# \" \".join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = document.flatten()\n",
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_doc = tf_vectorizer.transform(document)\n",
    "x = tf_vectorizer.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 26266)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 26266)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26266)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = []\n",
    "\n",
    "prob_ = clf_i.predict_proba(x_doc)\n",
    "prob = prob_[0]\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    sentences_temp = np.delete(sentences, i, 0)\n",
    "    sent.append(\" \".join(sentences_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prob[0] > prob[1]:\n",
    "    base = 0\n",
    "else:\n",
    "    base = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26266)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_drop = []\n",
    "\n",
    "x_drop = tf_vectorizer.transform(sent)\n",
    "x_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf_i.predict_proba(x_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_drop = np.absolute(probs - prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.absolute(probs[:,base] - prob[base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02318392, 0.97681608])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9768160808833599"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05058436, 0.94941564],\n",
       "       [0.02067961, 0.97932039],\n",
       "       [0.07779213, 0.92220787],\n",
       "       [0.01647496, 0.98352504],\n",
       "       [0.00967595, 0.99032405],\n",
       "       [0.12177675, 0.87822325],\n",
       "       [0.0498918 , 0.9501082 ]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94941564, 0.97932039, 0.92220787, 0.98352504, 0.99032405,\n",
       "       0.87822325, 0.9501082 ])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[:,base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(drops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he only occasionally gives outburst after quietly putting up with more than most could stand under such circumstance.'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gotcha!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_sentence = []\n",
    "disagree = []\n",
    "\n",
    "for i, doc in enumerate(X_train_original):\n",
    "    x = []\n",
    "    x.append(doc)\n",
    "    sentences = TextBlob(doc).raw_sentences\n",
    "    for i,sent in enumerate(sentences):\n",
    "        sentences_temp = np.delete(sentences, i, 0)\n",
    "        x.append(\" \".join(sentences_temp))\n",
    "    \n",
    "    x_cv = tf_vectorizer.transform(x)\n",
    "    probs = clf_i.predict_proba(x_cv)\n",
    "    \n",
    "    prob = probs[0]\n",
    "    probs = np.delete(probs,0,0)\n",
    "\n",
    "    if prob[0] > prob[1]:\n",
    "        base = 0\n",
    "    else:\n",
    "        base = 1\n",
    "        \n",
    "    drops = np.absolute(probs[:,base] - prob[base])\n",
    "    chosen_sentence.append(sentences[np.argmax(drops)])\n",
    "    disagree.append(sentences[np.argmin(drops)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"we even see him buying a bunch when derek's mom takes him to the store to find a gift for him to ing him out of his trauma.\",\n",
       " 'the producer has produced a short film of excellent quality that cannot be compared to any other short film that i have seen.',\n",
       " 'for me, this movie just seemed to fall on its face.',\n",
       " \"we have high-tech international terrorists/criminal who bicker like pre-school kid, stallone's man-of-steel-type resilience toward ice-cold weather, dialog so dumb that it is sometimes almost hilarious, and so on.\",\n",
       " 'the screenplay manages to do what the best of this type of movie does: give factual event and place them meaningfully inside a dramatic framework that makes you feel like you know the person *behind* the facts.9/10 star',\n",
       " 'poor!',\n",
       " '1st watched 12/7/2002 - 3/10(dir-steve purcell): typical mary kate and ashley fare with a few more kiss.',\n",
       " 'azaria (the baby) was never seen again, and the result of her horrendous disappearance caused a true life frenzy all around the world.',\n",
       " 'he first gets sucked into idea of revenge, but then he does not want to take it as far as sammi does.',\n",
       " 'and shows some sign of \"getting\" acting at last.sfx are mainly poor cgi and steal from other movies.the shootout are pitiful - worthy of the a-teamnot even worth seeing for perlman - avoid']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_sentence[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4 out of 5.',\n",
       " 'i have rated this film at the highest possible rating.',\n",
       " 'he is a good guy, and that is always obvious in his performance.',\n",
       " 'nothing.',\n",
       " 'rea makes us feel for this man.',\n",
       " 'this is one of the film we watched.',\n",
       " 'we will see what happens then.',\n",
       " 'meryl streep does immaculate justice to the role of lindy, as she always does.',\n",
       " 'skippy from \"family ty\" play eddie, a wussy \\'metal\\' nerd who gets picked on.',\n",
       " 'mr perlman gives a standout performance (as usual).']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disagree[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chosen_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(disagree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ = chosen_sentence+disagree\n",
    "all_ = np.asarray(all_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.hstack((np.ones(len(chosen_sentence)), np.zeros(len(disagree))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, C=1)\n",
    "x = tf_vectorizer.transform(all_)\n",
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87552"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
