{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "seed(42)\n",
    "set_random_seed(42)\n",
    "\n",
    "from keras.layers import Input, Dense, TimeDistributed, Embedding\n",
    "from keras.layers import Concatenate, Reshape, Lambda, Multiply, multiply, concatenate\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "from dataset_load import *\n",
    "\n",
    "style.use('seaborn-whitegrid')\n",
    "\n",
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "def load_unigrams(path, X, y):\n",
    "    word_list = []\n",
    "    connotation = {}\n",
    "    \n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            word_list.append(line.strip())\n",
    "            \n",
    "    for word in word_list:\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        for i, doc in enumerate(X):\n",
    "            if word in doc.lower():\n",
    "                \n",
    "                if (y[i] == 1):\n",
    "                    pos_count += 1\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    \n",
    "        if pos_count > neg_count:\n",
    "            connotation[word] = 1\n",
    "        else:\n",
    "            connotation[word] = 0\n",
    "    \n",
    "    return word_list, connotation\n",
    "\n",
    "def generate_appearance(X_train_corpus, X_test_corpus, word_list, connotation):\n",
    "    y_train_agreement = []\n",
    "    for i in range(len(X_train_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_train_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_train_agreement.append(doc_agreement)\n",
    "        \n",
    "    y_test_agreement = []\n",
    "    for i in range(len(X_test_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_test_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_test_agreement.append(doc_agreement)\n",
    "        \n",
    "    return np.array(y_train_agreement), np.array(y_test_agreement)\n",
    "\n",
    "# 'imdb-unigrams.txt'\n",
    "import pandas as pd\n",
    "\n",
    "path = r'../../data/womens-ecommerce-clothing-reviews/Womens_Clothing_E-Commerce_Reviews.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "X = list(df['Review Text'])\n",
    "y = list(df['Rating'])\n",
    "y_label = np.asarray(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 842\n",
      "2 1565\n",
      "3 2871\n",
      "4 5077\n",
      "5 13131\n"
     ]
    }
   ],
   "source": [
    "y_label.shape\n",
    "for i in range(1,6):\n",
    "    print(i, np.sum(y_label==i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label[y_label<3] = 0\n",
    "y_label[y_label>3] = 1\n",
    "\n",
    "neutral_indices = np.where(y_label==3)[0]\n",
    "y_label = np.delete(y_label, neutral_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X, neutral_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2407\n",
      "18208\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_label==0))\n",
    "print(np.sum(y_label==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20615"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2)\n",
      "corpus update start\n",
      "corpus update end\n",
      "\n",
      "(75, 2)\n",
      "corpus update start\n",
      "corpus update end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "# split\n",
    "X_train_split, X_test_split, y_train, y_test = train_test_split(X, y_label, test_size=0.33, random_state=42)\n",
    "\n",
    "# preprocessing\n",
    "X_train_corpus_update = update_corpus_contraction(X_train_split)\n",
    "X_test_corpus_update = update_corpus_contraction(X_test_split)\n",
    "\n",
    "# Count vectorizer \n",
    "\n",
    "# count vectorizer\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "cv = CountVectorizer(lowercase=True, max_df=1.0, min_df=100, binary=True, token_pattern=token)\n",
    "cv.set_params(ngram_range=(1,1))\n",
    "\n",
    "cv.fit(X_train_split)\n",
    "\n",
    "X_train = cv.transform(X_train_corpus_update)\n",
    "X_test = cv.transform(X_test_corpus_update)\n",
    "\n",
    "words = cv.get_feature_names()\n",
    "\n",
    "\n",
    "# word_list, connotation = load_unigrams('./amazon-video-unigrams.txt', X_train_corpus_update, y_train)\n",
    "# y_train_agreement, y_test_agreement = generate_appearance(X_train_corpus_update, X_test_corpus_update, \n",
    "#                                                           word_list, connotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_list, connotation = load_unigrams('./amazon-video-unigrams-more.txt', X_train_corpus_update, y_train)\n",
    "# word_list, connotation = load_unigrams('./imdb-unigrams.txt', X_train_corpus_update, y_train)\n",
    "\n",
    "word_list, connotation = load_unigrams('./ecom-unigrams.txt', X_train_corpus_update, y_train)\n",
    "y_train_agreement, y_test_agreement = generate_appearance(X_train_corpus_update, X_test_corpus_update, \n",
    "                                                          word_list, connotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6803, 720)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_agreement_LR = np.copy(y_train_agreement)\n",
    "y_train_agreement_LR[y_train_agreement_LR != 0] = 1\n",
    "\n",
    "y_test_agreement_LR = np.copy(y_test_agreement)\n",
    "y_test_agreement_LR[y_test_agreement_LR != 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9070373588184187\n",
      "0.9026899897104219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(penalty='l1', random_state=42)\n",
    "\n",
    "clf.fit(y_train_agreement_LR, y_train)\n",
    "\n",
    "print(clf.score(y_train_agreement_LR, y_train))\n",
    "print(clf.score(y_test_agreement_LR, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6803, 720)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def history_plot(history, model_name):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "        \n",
    "    title = model_name + 'accuracy'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['tr_acc', 'val_acc'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(history.history['loss'], 'm--')\n",
    "    plt.plot(history.history['val_loss'], 'y--')\n",
    "\n",
    "    title = model_name + 'loss'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['tr_loss', 'val_loss'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/48951109/keras-custom-binary-cross-entropy-loss-function-get-nan-as-output-for-loss\n",
    "\n",
    "# def custom_cross_entropy(y_true, y_pred):\n",
    "#     t_loss = K.max(y_pred,0)-y_pred * y_true + K.log(1+K.exp((-1)*K.abs(y_pred)))\n",
    "#     return K.mean(t_loss)\n",
    "\n",
    "# from keras.initializers import Constant, glorot_uniform\n",
    "\n",
    "# input_layer = Input(shape=(X_train.shape[1],))\n",
    "# tanh_output = Dense(1, activation='sigmoid', kernel_initializer=glorot_uniform(seed=42))(input_layer)\n",
    "# model = Model(inputs=input_layer, outputs=tanh_output)\n",
    "\n",
    "# model.compile(loss=custom_cross_entropy,\n",
    "#              metrics=['acc'],\n",
    "#              optimizer='adam')\n",
    "\n",
    "# model.fit(X_train[:16667], y_train_original[:16667], \n",
    "#          validation_data=([X_train[16667:], y_train_original[16667:]]),\n",
    "#          batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test, y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_train, y_train_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9254 samples, validate on 4558 samples\n",
      "Epoch 1/1\n",
      "9254/9254 [==============================] - 60s 6ms/step - loss: 0.2580 - acc: 0.9002 - val_loss: 0.1994 - val_acc: 0.9142\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant, glorot_uniform\n",
    "\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "tanh_output = Dense(1, activation='sigmoid', kernel_initializer=glorot_uniform(seed=42))(input_layer)\n",
    "model = Model(inputs=input_layer, outputs=tanh_output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             metrics=['acc'],\n",
    "             optimizer='adam')\n",
    "\n",
    "base_history = model.fit(X_train, y_train, \n",
    "                 validation_split=0.33, shuffle=False,\n",
    "                 batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test, y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_train, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9254 samples, validate on 4558 samples\n",
      "Epoch 1/1\n",
      "9254/9254 [==============================] - 265s 29ms/step - loss: 0.3306 - acc: 0.8798 - val_loss: 0.2775 - val_acc: 0.8883\n"
     ]
    }
   ],
   "source": [
    "def layer_split(x):\n",
    "    return tf.split(x,num_or_size_splits=human_terms_len,axis=1)\n",
    "\n",
    "def layer_concat(x):\n",
    "    return tf.concat(x, axis=1)\n",
    "\n",
    "# build the combined model\n",
    "# Combined model\n",
    "human_terms_len = len(word_list)\n",
    "\n",
    "# base_model = build_base_model(X_train.shape[1])\n",
    "\n",
    "combined_input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# build the hard coded weight for human terms\n",
    "ht_input_layer = Input(shape=(human_terms_len,))\n",
    "\n",
    "# split = Lambda( lambda x: tf.split(x,num_or_size_splits=human_terms_len,axis=1))(ht_input_layer)\n",
    "split = Lambda(layer_split)(ht_input_layer)\n",
    "\n",
    "# get the document prediction\n",
    "label_layer = model(combined_input_layer)\n",
    "tanh_norm = Lambda(lambda x: (x*2)-1)(label_layer)\n",
    "# tanh_norm = Lambda(lambda x: tf.scalar_mul(2,x)-1)(label_layer)\n",
    "\n",
    "# do normalize of bipolar sigmoid\n",
    "\n",
    "\n",
    "# stack the multiply layer\n",
    "dense_layer = []\n",
    "for i in range(human_terms_len):\n",
    "    dense_layer.append(Dense(1, activation='relu', use_bias=False)(Multiply()([split[i], tanh_norm])))\n",
    "\n",
    "# concat all the result   \n",
    "# concat = Lambda( lambda x: tf.concat(x, axis=1), name='concatenate')(dense_layer)\n",
    "concat = Lambda(layer_concat, name='concatenate')(dense_layer)\n",
    "\n",
    "\n",
    "# pass it to sigmoid layer\n",
    "output_layer = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "combined_model = Model(inputs=[combined_input_layer, ht_input_layer], outputs=output_layer)\n",
    "# combined_model.summary()\n",
    "\n",
    "\n",
    "combined_model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])\n",
    "\n",
    "# y_train_tanh = y_train_original\n",
    "# y_train_tanh[y_train_tanh == 0] = -1\n",
    "\n",
    "# y_test_tanh = y_test_original\n",
    "# y_test_tanh[y_test_tanh == 0] = -1\n",
    "\n",
    "# base_model_history = base_model.fit(X_train[:16667], y_train_original[:16667], \n",
    "#                                     validation_data=(X_train[16667:], y_train_original[16667:]),\n",
    "#                                     batch_size=1, epochs=1)\n",
    "\n",
    "combined_model_history = combined_model.fit([X_train,y_train_agreement], y_train, \n",
    "                                            validation_split=0.33, shuffle=False,\n",
    "                                            batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_reject(combined_model, X, y_agreement, y):\n",
    "    human_terms_relu_model = Model(inputs=combined_model.input,\n",
    "                                    outputs=combined_model.get_layer('concatenate').output)\n",
    "    predict_relu = human_terms_relu_model.predict([X, y_agreement])\n",
    "    accept_indices = np.where(np.sum(predict_relu, axis=1)!=0)\n",
    "    accept_indices = accept_indices[0]\n",
    "    total_reject = X.shape[0] - len(accept_indices)\n",
    "    rejection_rate = total_reject/X.shape[0]\n",
    "\n",
    "    test_eval = combined_model.evaluate([X[accept_indices], y_agreement[accept_indices]], y[accept_indices])\n",
    "    \n",
    "    return test_eval, rejection_rate, total_reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6803/6803 [==============================] - 1s 168us/step\n",
      "13812/13812 [==============================] - 2s 168us/step\n",
      "4547/4547 [==============================] - 1s 171us/step\n",
      "9300/9300 [==============================] - 2s 168us/step\n"
     ]
    }
   ],
   "source": [
    "test_ev = combined_model.evaluate([X_test, y_test_agreement], y_test)\n",
    "train_ev = combined_model.evaluate([X_train, y_train_agreement], y_train)\n",
    "\n",
    "def accuracy_reject(combined_model, X, y_agreement, y):\n",
    "    human_terms_relu_model = Model(inputs=combined_model.input,\n",
    "                                    outputs=combined_model.get_layer('concatenate').output)\n",
    "    predict_relu = human_terms_relu_model.predict([X, y_agreement])\n",
    "    accept_indices = np.where(np.sum(predict_relu, axis=1)!=0)\n",
    "    accept_indices = accept_indices[0]\n",
    "    total_reject = X.shape[0] - len(accept_indices)\n",
    "    rejection_rate = total_reject/X.shape[0]\n",
    "\n",
    "    test_eval = combined_model.evaluate([X[accept_indices], y_agreement[accept_indices]], y[accept_indices])\n",
    "    \n",
    "    return test_eval, rejection_rate, total_reject\n",
    "\n",
    "test_ev_reject = accuracy_reject(combined_model, X_test, y_test_agreement, y_test)\n",
    "train_ev_reject = accuracy_reject(combined_model, X_train, y_train_agreement, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.270371 \t 0.889806\n",
      "0.284287 \t 0.885786\n",
      "0.177619 \t 0.919785 \t 0.326672 \t 4512\n",
      "0.187798 \t 0.920607 \t 0.331618 \t 2256\n"
     ]
    }
   ],
   "source": [
    "print('%f \\t %f' %(train_ev[0], train_ev[1]))\n",
    "print('%f \\t %f' %(test_ev[0], test_ev[1]))\n",
    "print('%f \\t %f \\t %f \\t %d' %(train_ev_reject[0][0], train_ev_reject[0][1], train_ev_reject[1], train_ev_reject[2]))\n",
    "print('%f \\t %f \\t %f \\t %d' %(test_ev_reject[0][0], test_ev_reject[0][1], test_ev_reject[1], test_ev_reject[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_plot(base_history,'RDclf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_plot(combined_model_history,'TTclf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_model.save('./figure/amazon-joint-50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR1-KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4547/4547 [==============================] - 1s 170us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ht_lr = LogisticRegression(penalty='l1', random_state=42)\n",
    "\n",
    "\n",
    "# Train LR\n",
    "ht_lr.fit(y_train_agreement_LR, y_train)\n",
    "ht_test_pred = ht_lr.predict(y_test_agreement_LR)\n",
    "\n",
    "human_terms_relu_model = Model(inputs=combined_model.input,\n",
    "                                    outputs=combined_model.get_layer('concatenate').output)\n",
    "predict_relu = human_terms_relu_model.predict([X_test, y_test_agreement])\n",
    "accept_indices = np.where(np.sum(predict_relu, axis=1)!=0)\n",
    "accept_indices = accept_indices[0]\n",
    "total_reject = X.shape[0] - len(accept_indices)\n",
    "rejection_rate = total_reject/X.shape[0]\n",
    "\n",
    "test_eval = combined_model.evaluate([X_test[accept_indices], y_test_agreement[accept_indices]], y_test[accept_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9026899897104219, 0.9174798835815785)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1_accept_indices = np.where(np.sum(y_test_agreement_LR, axis=1)!=0)[0]\n",
    "\n",
    "ht_lr.score(y_test_agreement_LR, y_test), ht_lr.score(y_test_agreement_LR[lr1_accept_indices], y_test[lr1_accept_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962, 1125, 169)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_reject_indices = np.where(np.sum(predict_relu, axis=1)==0)[0]\n",
    "\n",
    "lr1_reject_indices = np.where(np.sum(y_test_agreement_LR, axis=1)==0)[0]\n",
    "lr1_correct = np.where(ht_test_pred == y_test)[0]\n",
    "lr1_correct = np.array(list(set(lr1_correct) - set(lr1_reject_indices)))\n",
    "lr1_incorrect = np.where(ht_test_pred != y_test)[0]\n",
    "lr1_incorrect = np.array(list(set(lr1_incorrect) - set(lr1_reject_indices)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "our_reject_lr_reject = list(set(our_reject_indices) & set(lr1_reject_indices))\n",
    "our_reject_lr_correct = list(set(our_reject_indices) & set(lr1_correct))\n",
    "our_reject_lr_incorrect = list(set(our_reject_indices) & set(lr1_incorrect))\n",
    "\n",
    "len(our_reject_lr_reject), len(our_reject_lr_correct), len(our_reject_lr_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_predict = np.squeeze(combined_model.predict([X_test, y_test_agreement]))\n",
    "\n",
    "our_predict_class = np.zeros(len(our_predict))\n",
    "our_predict_class[our_predict >= 0.5] = 1\n",
    "\n",
    "our_correct = np.where(our_predict_class == y_test)[0]\n",
    "our_correct = np.array(list(set(our_correct) - set(our_reject_indices)))\n",
    "our_incorrect = np.where(our_predict_class != y_test)[0]\n",
    "our_incorrect = np.array(list(set(our_incorrect) - set(our_reject_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4112, 74)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_correct_lr_reject = list(set(our_correct) & set(lr1_reject_indices))\n",
    "our_correct_lr_correct = list(set(our_correct) & set(lr1_correct))\n",
    "our_correct_lr_incorrect = list(set(our_correct) & set(lr1_incorrect))\n",
    "\n",
    "len(our_correct_lr_reject), len(our_correct_lr_correct), len(our_correct_lr_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 122, 239)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_incorrect_lr_reject = list(set(our_incorrect) & set(lr1_reject_indices))\n",
    "our_incorrect_lr_correct = list(set(our_incorrect) & set(lr1_correct))\n",
    "our_incorrect_lr_incorrect = list(set(our_incorrect) & set(lr1_incorrect))\n",
    "\n",
    "len(our_incorrect_lr_reject), len(our_incorrect_lr_correct), len(our_incorrect_lr_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
