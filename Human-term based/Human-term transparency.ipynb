{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "#### 1. use kernel_initializer = 'ones' instead of 'zeros' -> the gradients do not flow through the ReLu layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy files\n",
    "np.random.seed(42)\n",
    "EMBEDDING_SIZE = 15\n",
    "X = np.random.randint(2, size=(1000,100))\n",
    "X_val = np.random.randint(2, size=(1000,100))\n",
    "y = np.random.randint(2, size=1000)\n",
    "y_val = np.random.randint(2, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, TimeDistributed, Embedding\n",
    "from keras.layers import Concatenate, Reshape, Lambda, Multiply, multiply, concatenate, ThresholdedReLU\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tanh = []\n",
    "y_tanh_val = []\n",
    "\n",
    "for i in y:\n",
    "    if i==0:\n",
    "        y_tanh.append(-1)\n",
    "    else:\n",
    "        y_tanh.append(1)\n",
    "\n",
    "\n",
    "for i in y_val:\n",
    "    if i==0:\n",
    "        y_tanh_val.append(-1)\n",
    "    else:\n",
    "        y_tanh_val.append(1)\n",
    "        \n",
    "y_tanh = np.asarray(y_tanh)  \n",
    "y_tanh_val = np.asarray(y_tanh_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# make first model\n",
    "\n",
    "def build_base_model(input_shape):\n",
    "    input_layer = Input(shape=(input_shape,))\n",
    "    tanh_output = Dense(1, activation='tanh', name='tanh_output')(input_layer)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=tanh_output)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "base_model = build_base_model(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            101         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 1)            0           input_3[0][0]                    \n",
      "                                                                 model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 1)            0           input_4[0][0]                    \n",
      "                                                                 model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            2           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            3           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 108\n",
      "Trainable params: 108\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Combined model\n",
    "\n",
    "combined_input_layer = Input(shape=(X.shape[1],))\n",
    "\n",
    "ht_1 = Input(shape=(1,))\n",
    "ht_2 = Input(shape=(1,))\n",
    "\n",
    "label_layer = base_model(combined_input_layer)\n",
    "\n",
    "dense_1 = Dense(1, activation='relu')(Multiply()([ht_1, label_layer]))\n",
    "dense_2 = Dense(1, activation='relu')(Multiply()([ht_2, label_layer]))\n",
    "\n",
    "concat = Concatenate()([dense_1, dense_2])\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "combined_model = Model(inputs=[combined_input_layer, ht_1, ht_2], outputs=output_layer)\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(loss='mse',\n",
    "            optimizer='adam',\n",
    "            metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.compile(loss='mse',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make second model\n",
    "# first, make the vector to see if it is appears \n",
    "\n",
    "# we have two terms (human-terms) for now. c1 == pos word, c2 == neg word\n",
    "# 1st column gives the feature index where that particular human_terms located\n",
    "# 2nd column gives whether it is positive/negative word\n",
    "term = [[1,1],[2,-1]]\n",
    "term = np.asarray(term)\n",
    "\n",
    "#assume X is a document vector [1,n] where n is the number of terms\n",
    "\n",
    "def np_present_by_term(X, term):\n",
    "    np_vector = np.zeros([term.shape[0],1])\n",
    "    \n",
    "    for i,(feature_index,np_term) in enumerate(term):\n",
    "        if X[feature_index] == 1:\n",
    "            np_vector[i] = np_term\n",
    "    \n",
    "    return np_vector\n",
    "\n",
    "# Assuming 'term' is a [1X2] vector\n",
    "def np_present_by_doc(X, term):\n",
    "    np_vector = np.zeros([X.shape[0],1])\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        if x[term[0]] == 1:\n",
    "            np_vector[i] = term[1]\n",
    "    \n",
    "    return np_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_1_input = np_present_by_doc(X, term[0])\n",
    "ht_2_input = np_present_by_doc(X, term[1])\n",
    "\n",
    "ht_1_input_val = np_present_by_doc(X_val, term[0])\n",
    "ht_2_input_val = np_present_by_doc(X_val, term[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 1.0916 - acc: 0.2130 - val_loss: 1.2172 - val_acc: 0.1740\n",
      "Epoch 2/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 1.0863 - acc: 0.2090 - val_loss: 1.2118 - val_acc: 0.1700\n",
      "Epoch 3/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 1.0680 - acc: 0.2130 - val_loss: 1.1992 - val_acc: 0.1660\n",
      "Epoch 4/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 1.0545 - acc: 0.2000 - val_loss: 1.1890 - val_acc: 0.1640\n",
      "Epoch 5/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 1.0439 - acc: 0.1960 - val_loss: 1.1838 - val_acc: 0.1560\n",
      "Epoch 6/500\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 1.0331 - acc: 0.1920 - val_loss: 1.1848 - val_acc: 0.1510\n",
      "Epoch 7/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 1.0240 - acc: 0.1960 - val_loss: 1.1801 - val_acc: 0.1510\n",
      "Epoch 8/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 1.0151 - acc: 0.1760 - val_loss: 1.1725 - val_acc: 0.1460\n",
      "Epoch 9/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 1.0068 - acc: 0.1870 - val_loss: 1.1738 - val_acc: 0.1380\n",
      "Epoch 10/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.9975 - acc: 0.1700 - val_loss: 1.1669 - val_acc: 0.1360\n",
      "Epoch 11/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.9905 - acc: 0.1700 - val_loss: 1.1635 - val_acc: 0.1320\n",
      "Epoch 12/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.9821 - acc: 0.1700 - val_loss: 1.1588 - val_acc: 0.1280\n",
      "Epoch 13/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.9767 - acc: 0.1760 - val_loss: 1.1529 - val_acc: 0.1260\n",
      "Epoch 14/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.9707 - acc: 0.1560 - val_loss: 1.1659 - val_acc: 0.1230\n",
      "Epoch 15/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.9647 - acc: 0.1650 - val_loss: 1.1518 - val_acc: 0.1160\n",
      "Epoch 16/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.9567 - acc: 0.1600 - val_loss: 1.1441 - val_acc: 0.1190\n",
      "Epoch 17/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.9528 - acc: 0.1510 - val_loss: 1.1564 - val_acc: 0.1140\n",
      "Epoch 18/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.9513 - acc: 0.1600 - val_loss: 1.1398 - val_acc: 0.1090\n",
      "Epoch 19/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.9441 - acc: 0.1560 - val_loss: 1.1420 - val_acc: 0.1060\n",
      "Epoch 20/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.9381 - acc: 0.1540 - val_loss: 1.1393 - val_acc: 0.1010\n",
      "Epoch 21/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.9396 - acc: 0.1460 - val_loss: 1.1418 - val_acc: 0.0990\n",
      "Epoch 22/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.9333 - acc: 0.1520 - val_loss: 1.1328 - val_acc: 0.0980\n",
      "Epoch 23/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.9313 - acc: 0.1470 - val_loss: 1.1529 - val_acc: 0.1090\n",
      "Epoch 24/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.9317 - acc: 0.1550 - val_loss: 1.1366 - val_acc: 0.0950\n",
      "Epoch 25/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.9237 - acc: 0.1540 - val_loss: 1.1281 - val_acc: 0.0930\n",
      "Epoch 26/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.9204 - acc: 0.1350 - val_loss: 1.1376 - val_acc: 0.0960\n",
      "Epoch 27/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.9192 - acc: 0.1430 - val_loss: 1.1361 - val_acc: 0.0940\n",
      "Epoch 28/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.9165 - acc: 0.1380 - val_loss: 1.1302 - val_acc: 0.0930\n",
      "Epoch 29/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.9143 - acc: 0.1370 - val_loss: 1.1310 - val_acc: 0.0920\n",
      "Epoch 30/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.9125 - acc: 0.1420 - val_loss: 1.1285 - val_acc: 0.0890\n",
      "Epoch 31/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.9118 - acc: 0.1390 - val_loss: 1.1260 - val_acc: 0.0880\n",
      "Epoch 32/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.9081 - acc: 0.1350 - val_loss: 1.1397 - val_acc: 0.0920\n",
      "Epoch 33/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.9074 - acc: 0.1430 - val_loss: 1.1217 - val_acc: 0.0860\n",
      "Epoch 34/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.9066 - acc: 0.1280 - val_loss: 1.1373 - val_acc: 0.0890\n",
      "Epoch 35/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.9026 - acc: 0.1260 - val_loss: 1.1231 - val_acc: 0.0810\n",
      "Epoch 36/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.9049 - acc: 0.1280 - val_loss: 1.1330 - val_acc: 0.0870\n",
      "Epoch 37/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.9052 - acc: 0.1310 - val_loss: 1.1367 - val_acc: 0.0880\n",
      "Epoch 38/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.9020 - acc: 0.1310 - val_loss: 1.1283 - val_acc: 0.0800\n",
      "Epoch 39/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8997 - acc: 0.1270 - val_loss: 1.1273 - val_acc: 0.0790\n",
      "Epoch 40/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8994 - acc: 0.1300 - val_loss: 1.1376 - val_acc: 0.0870\n",
      "Epoch 41/500\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.8393 - acc: 0.156 - 0s 41us/step - loss: 0.9002 - acc: 0.1270 - val_loss: 1.1475 - val_acc: 0.0910\n",
      "Epoch 42/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.9067 - acc: 0.1350 - val_loss: 1.1371 - val_acc: 0.0900\n",
      "Epoch 43/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.8984 - acc: 0.1300 - val_loss: 1.1253 - val_acc: 0.0790\n",
      "Epoch 44/500\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.8960 - acc: 0.1250 - val_loss: 1.1250 - val_acc: 0.0780\n",
      "Epoch 45/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8959 - acc: 0.1170 - val_loss: 1.1306 - val_acc: 0.0830\n",
      "Epoch 46/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8970 - acc: 0.1240 - val_loss: 1.1220 - val_acc: 0.0790\n",
      "Epoch 47/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.9002 - acc: 0.1250 - val_loss: 1.1558 - val_acc: 0.0960\n",
      "Epoch 48/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8968 - acc: 0.1330 - val_loss: 1.1291 - val_acc: 0.0820\n",
      "Epoch 49/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8932 - acc: 0.1100 - val_loss: 1.1381 - val_acc: 0.0910\n",
      "Epoch 50/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8934 - acc: 0.1180 - val_loss: 1.1343 - val_acc: 0.0860\n",
      "Epoch 51/500\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 0.8941 - acc: 0.1130 - val_loss: 1.1354 - val_acc: 0.0850\n",
      "Epoch 52/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8952 - acc: 0.1200 - val_loss: 1.1328 - val_acc: 0.0810\n",
      "Epoch 53/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8932 - acc: 0.1180 - val_loss: 1.1340 - val_acc: 0.0840\n",
      "Epoch 54/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8965 - acc: 0.1320 - val_loss: 1.1225 - val_acc: 0.0810\n",
      "Epoch 55/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8965 - acc: 0.1210 - val_loss: 1.1281 - val_acc: 0.0810\n",
      "Epoch 56/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8958 - acc: 0.1260 - val_loss: 1.1302 - val_acc: 0.0830\n",
      "Epoch 57/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8929 - acc: 0.1190 - val_loss: 1.1297 - val_acc: 0.0830\n",
      "Epoch 58/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8919 - acc: 0.1190 - val_loss: 1.1352 - val_acc: 0.0850\n",
      "Epoch 59/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8966 - acc: 0.1280 - val_loss: 1.1282 - val_acc: 0.0840\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8939 - acc: 0.1290 - val_loss: 1.1270 - val_acc: 0.0840\n",
      "Epoch 61/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8904 - acc: 0.1230 - val_loss: 1.1557 - val_acc: 0.0920\n",
      "Epoch 62/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8911 - acc: 0.1360 - val_loss: 1.1267 - val_acc: 0.0840\n",
      "Epoch 63/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.8953 - acc: 0.1180 - val_loss: 1.1345 - val_acc: 0.0870\n",
      "Epoch 64/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8895 - acc: 0.1210 - val_loss: 1.1388 - val_acc: 0.0860\n",
      "Epoch 65/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.8915 - acc: 0.1200 - val_loss: 1.1359 - val_acc: 0.0860\n",
      "Epoch 66/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8937 - acc: 0.1210 - val_loss: 1.1270 - val_acc: 0.0860\n",
      "Epoch 67/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8934 - acc: 0.1200 - val_loss: 1.1428 - val_acc: 0.0860\n",
      "Epoch 68/500\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.7137 - acc: 0.218 - 0s 43us/step - loss: 0.8898 - acc: 0.1150 - val_loss: 1.1360 - val_acc: 0.0850\n",
      "Epoch 69/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8911 - acc: 0.1160 - val_loss: 1.1478 - val_acc: 0.0900\n",
      "Epoch 70/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8906 - acc: 0.1350 - val_loss: 1.1342 - val_acc: 0.0850\n",
      "Epoch 71/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8922 - acc: 0.1240 - val_loss: 1.1332 - val_acc: 0.0860\n",
      "Epoch 72/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8919 - acc: 0.1240 - val_loss: 1.1347 - val_acc: 0.0870\n",
      "Epoch 73/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8897 - acc: 0.1200 - val_loss: 1.1440 - val_acc: 0.0880\n",
      "Epoch 74/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8912 - acc: 0.1360 - val_loss: 1.1382 - val_acc: 0.0890\n",
      "Epoch 75/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8895 - acc: 0.1230 - val_loss: 1.1454 - val_acc: 0.0900\n",
      "Epoch 76/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8942 - acc: 0.1260 - val_loss: 1.1400 - val_acc: 0.0890\n",
      "Epoch 77/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8913 - acc: 0.1330 - val_loss: 1.1334 - val_acc: 0.0890\n",
      "Epoch 78/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8915 - acc: 0.1260 - val_loss: 1.1405 - val_acc: 0.0890\n",
      "Epoch 79/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8930 - acc: 0.1260 - val_loss: 1.1376 - val_acc: 0.0880\n",
      "Epoch 80/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8895 - acc: 0.1270 - val_loss: 1.1391 - val_acc: 0.0900\n",
      "Epoch 81/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8898 - acc: 0.1290 - val_loss: 1.1500 - val_acc: 0.0900\n",
      "Epoch 82/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8908 - acc: 0.1280 - val_loss: 1.1457 - val_acc: 0.0940\n",
      "Epoch 83/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8939 - acc: 0.1290 - val_loss: 1.1489 - val_acc: 0.0900\n",
      "Epoch 84/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8891 - acc: 0.1200 - val_loss: 1.1459 - val_acc: 0.0910\n",
      "Epoch 85/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8889 - acc: 0.1370 - val_loss: 1.1410 - val_acc: 0.0900\n",
      "Epoch 86/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8920 - acc: 0.1250 - val_loss: 1.1440 - val_acc: 0.0910\n",
      "Epoch 87/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8890 - acc: 0.1260 - val_loss: 1.1408 - val_acc: 0.0870\n",
      "Epoch 88/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8914 - acc: 0.1260 - val_loss: 1.1345 - val_acc: 0.0850\n",
      "Epoch 89/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8894 - acc: 0.1340 - val_loss: 1.1481 - val_acc: 0.0940\n",
      "Epoch 90/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8895 - acc: 0.1240 - val_loss: 1.1529 - val_acc: 0.0900\n",
      "Epoch 91/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8907 - acc: 0.1370 - val_loss: 1.1357 - val_acc: 0.0850\n",
      "Epoch 92/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8918 - acc: 0.1230 - val_loss: 1.1470 - val_acc: 0.0940\n",
      "Epoch 93/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8885 - acc: 0.1280 - val_loss: 1.1449 - val_acc: 0.0930\n",
      "Epoch 94/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8899 - acc: 0.1230 - val_loss: 1.1534 - val_acc: 0.0930\n",
      "Epoch 95/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8886 - acc: 0.1340 - val_loss: 1.1436 - val_acc: 0.0920\n",
      "Epoch 96/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8898 - acc: 0.1310 - val_loss: 1.1370 - val_acc: 0.0840\n",
      "Epoch 97/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8892 - acc: 0.1260 - val_loss: 1.1487 - val_acc: 0.0920\n",
      "Epoch 98/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8892 - acc: 0.1220 - val_loss: 1.1504 - val_acc: 0.0950\n",
      "Epoch 99/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8905 - acc: 0.1200 - val_loss: 1.1641 - val_acc: 0.0960\n",
      "Epoch 100/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8886 - acc: 0.1550 - val_loss: 1.1334 - val_acc: 0.0900\n",
      "Epoch 101/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8957 - acc: 0.1340 - val_loss: 1.1538 - val_acc: 0.0950\n",
      "Epoch 102/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8898 - acc: 0.1290 - val_loss: 1.1544 - val_acc: 0.0930\n",
      "Epoch 103/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8913 - acc: 0.1250 - val_loss: 1.1508 - val_acc: 0.0930\n",
      "Epoch 104/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8910 - acc: 0.1230 - val_loss: 1.1518 - val_acc: 0.0950\n",
      "Epoch 105/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.9030 - acc: 0.1420 - val_loss: 1.1541 - val_acc: 0.0940\n",
      "Epoch 106/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8910 - acc: 0.1390 - val_loss: 1.1493 - val_acc: 0.0940\n",
      "Epoch 107/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8882 - acc: 0.1300 - val_loss: 1.1484 - val_acc: 0.0950\n",
      "Epoch 108/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8895 - acc: 0.1290 - val_loss: 1.1517 - val_acc: 0.0940\n",
      "Epoch 109/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8904 - acc: 0.1290 - val_loss: 1.1513 - val_acc: 0.0950\n",
      "Epoch 110/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8932 - acc: 0.1320 - val_loss: 1.1468 - val_acc: 0.0930\n",
      "Epoch 111/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8923 - acc: 0.1290 - val_loss: 1.1423 - val_acc: 0.0910\n",
      "Epoch 112/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8895 - acc: 0.1350 - val_loss: 1.1470 - val_acc: 0.0950\n",
      "Epoch 113/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8885 - acc: 0.1330 - val_loss: 1.1411 - val_acc: 0.0930\n",
      "Epoch 114/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8934 - acc: 0.1330 - val_loss: 1.1372 - val_acc: 0.0850\n",
      "Epoch 115/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8886 - acc: 0.1260 - val_loss: 1.1508 - val_acc: 0.0950\n",
      "Epoch 116/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8904 - acc: 0.1230 - val_loss: 1.1517 - val_acc: 0.0930\n",
      "Epoch 117/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8874 - acc: 0.1350 - val_loss: 1.1416 - val_acc: 0.0920\n",
      "Epoch 118/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8881 - acc: 0.1320 - val_loss: 1.1635 - val_acc: 0.0980\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8895 - acc: 0.1470 - val_loss: 1.1407 - val_acc: 0.0890\n",
      "Epoch 120/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8891 - acc: 0.1270 - val_loss: 1.1690 - val_acc: 0.1010\n",
      "Epoch 121/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8923 - acc: 0.1490 - val_loss: 1.1357 - val_acc: 0.0850\n",
      "Epoch 122/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8942 - acc: 0.1260 - val_loss: 1.1391 - val_acc: 0.0870\n",
      "Epoch 123/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.8897 - acc: 0.1310 - val_loss: 1.1445 - val_acc: 0.0920\n",
      "Epoch 124/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8891 - acc: 0.1360 - val_loss: 1.1443 - val_acc: 0.0920\n",
      "Epoch 125/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8909 - acc: 0.1250 - val_loss: 1.1423 - val_acc: 0.0910\n",
      "Epoch 126/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8903 - acc: 0.1320 - val_loss: 1.1409 - val_acc: 0.0900\n",
      "Epoch 127/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8909 - acc: 0.1280 - val_loss: 1.1447 - val_acc: 0.0900\n",
      "Epoch 128/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8883 - acc: 0.1280 - val_loss: 1.1564 - val_acc: 0.0940\n",
      "Epoch 129/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8894 - acc: 0.1340 - val_loss: 1.1485 - val_acc: 0.0940\n",
      "Epoch 130/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8881 - acc: 0.1280 - val_loss: 1.1482 - val_acc: 0.0940\n",
      "Epoch 131/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8908 - acc: 0.1280 - val_loss: 1.1604 - val_acc: 0.0970\n",
      "Epoch 132/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8906 - acc: 0.1290 - val_loss: 1.1555 - val_acc: 0.0960\n",
      "Epoch 133/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8900 - acc: 0.1340 - val_loss: 1.1549 - val_acc: 0.0940\n",
      "Epoch 134/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8966 - acc: 0.1590 - val_loss: 1.1374 - val_acc: 0.0850\n",
      "Epoch 135/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8974 - acc: 0.1380 - val_loss: 1.1399 - val_acc: 0.0870\n",
      "Epoch 136/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8915 - acc: 0.1290 - val_loss: 1.1638 - val_acc: 0.1000\n",
      "Epoch 137/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8901 - acc: 0.1490 - val_loss: 1.1401 - val_acc: 0.0870\n",
      "Epoch 138/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.9001 - acc: 0.1400 - val_loss: 1.1691 - val_acc: 0.1030\n",
      "Epoch 139/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8908 - acc: 0.1260 - val_loss: 1.1572 - val_acc: 0.0960\n",
      "Epoch 140/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8903 - acc: 0.1340 - val_loss: 1.1471 - val_acc: 0.0920\n",
      "Epoch 141/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8888 - acc: 0.1320 - val_loss: 1.1476 - val_acc: 0.0940\n",
      "Epoch 142/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8884 - acc: 0.1320 - val_loss: 1.1565 - val_acc: 0.0960\n",
      "Epoch 143/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8884 - acc: 0.1280 - val_loss: 1.1467 - val_acc: 0.0950\n",
      "Epoch 144/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8897 - acc: 0.1380 - val_loss: 1.1526 - val_acc: 0.0950\n",
      "Epoch 145/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8916 - acc: 0.1270 - val_loss: 1.1654 - val_acc: 0.0980\n",
      "Epoch 146/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8883 - acc: 0.1370 - val_loss: 1.1453 - val_acc: 0.0890\n",
      "Epoch 147/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8902 - acc: 0.1370 - val_loss: 1.1475 - val_acc: 0.0930\n",
      "Epoch 148/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8890 - acc: 0.1360 - val_loss: 1.1486 - val_acc: 0.0910\n",
      "Epoch 149/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.8899 - acc: 0.1370 - val_loss: 1.1497 - val_acc: 0.0930\n",
      "Epoch 150/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8886 - acc: 0.1340 - val_loss: 1.1500 - val_acc: 0.0970\n",
      "Epoch 151/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8894 - acc: 0.1350 - val_loss: 1.1514 - val_acc: 0.0960\n",
      "Epoch 152/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8884 - acc: 0.1380 - val_loss: 1.1616 - val_acc: 0.0970\n",
      "Epoch 153/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8914 - acc: 0.1470 - val_loss: 1.1408 - val_acc: 0.0880\n",
      "Epoch 154/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8881 - acc: 0.1390 - val_loss: 1.1665 - val_acc: 0.1000\n",
      "Epoch 155/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8908 - acc: 0.1380 - val_loss: 1.1491 - val_acc: 0.0940\n",
      "Epoch 156/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8902 - acc: 0.1380 - val_loss: 1.1446 - val_acc: 0.0870\n",
      "Epoch 157/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8897 - acc: 0.1360 - val_loss: 1.1517 - val_acc: 0.0960\n",
      "Epoch 158/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8890 - acc: 0.1390 - val_loss: 1.1524 - val_acc: 0.0960\n",
      "Epoch 159/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8937 - acc: 0.1380 - val_loss: 1.1610 - val_acc: 0.0990\n",
      "Epoch 160/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8896 - acc: 0.1450 - val_loss: 1.1475 - val_acc: 0.0900\n",
      "Epoch 161/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8896 - acc: 0.1390 - val_loss: 1.1466 - val_acc: 0.0890\n",
      "Epoch 162/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8908 - acc: 0.1280 - val_loss: 1.1566 - val_acc: 0.0970\n",
      "Epoch 163/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8875 - acc: 0.1410 - val_loss: 1.1426 - val_acc: 0.0900\n",
      "Epoch 164/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8908 - acc: 0.1280 - val_loss: 1.1489 - val_acc: 0.0950\n",
      "Epoch 165/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8902 - acc: 0.1380 - val_loss: 1.1584 - val_acc: 0.0960\n",
      "Epoch 166/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8891 - acc: 0.1370 - val_loss: 1.1509 - val_acc: 0.0970\n",
      "Epoch 167/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8894 - acc: 0.1320 - val_loss: 1.1648 - val_acc: 0.1010\n",
      "Epoch 168/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8903 - acc: 0.1340 - val_loss: 1.1488 - val_acc: 0.0930\n",
      "Epoch 169/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8897 - acc: 0.1360 - val_loss: 1.1553 - val_acc: 0.0950\n",
      "Epoch 170/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8886 - acc: 0.1560 - val_loss: 1.1399 - val_acc: 0.0900\n",
      "Epoch 171/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8957 - acc: 0.1360 - val_loss: 1.1451 - val_acc: 0.0940\n",
      "Epoch 172/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8956 - acc: 0.1400 - val_loss: 1.1410 - val_acc: 0.0900\n",
      "Epoch 173/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8928 - acc: 0.1400 - val_loss: 1.1471 - val_acc: 0.0930\n",
      "Epoch 174/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8893 - acc: 0.1390 - val_loss: 1.1518 - val_acc: 0.0950\n",
      "Epoch 175/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8890 - acc: 0.1360 - val_loss: 1.1667 - val_acc: 0.1000\n",
      "Epoch 176/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8894 - acc: 0.1410 - val_loss: 1.1408 - val_acc: 0.0900\n",
      "Epoch 177/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8928 - acc: 0.1260 - val_loss: 1.1449 - val_acc: 0.0900\n",
      "Epoch 178/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8918 - acc: 0.1350 - val_loss: 1.1693 - val_acc: 0.1000\n",
      "Epoch 179/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8911 - acc: 0.1440 - val_loss: 1.1444 - val_acc: 0.0910\n",
      "Epoch 180/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8891 - acc: 0.1370 - val_loss: 1.1575 - val_acc: 0.0970\n",
      "Epoch 181/500\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.8897 - acc: 0.1390 - val_loss: 1.1442 - val_acc: 0.0890\n",
      "Epoch 182/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.8914 - acc: 0.1320 - val_loss: 1.1499 - val_acc: 0.0960\n",
      "Epoch 183/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8886 - acc: 0.1320 - val_loss: 1.1550 - val_acc: 0.0930\n",
      "Epoch 184/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8893 - acc: 0.1340 - val_loss: 1.1474 - val_acc: 0.0950\n",
      "Epoch 185/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8886 - acc: 0.1340 - val_loss: 1.1499 - val_acc: 0.0930\n",
      "Epoch 186/500\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.9368 - acc: 0.156 - 0s 38us/step - loss: 0.8887 - acc: 0.1380 - val_loss: 1.1540 - val_acc: 0.0950\n",
      "Epoch 187/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8903 - acc: 0.1310 - val_loss: 1.1484 - val_acc: 0.0950\n",
      "Epoch 188/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8933 - acc: 0.1370 - val_loss: 1.1451 - val_acc: 0.0920\n",
      "Epoch 189/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8895 - acc: 0.1400 - val_loss: 1.1469 - val_acc: 0.0940\n",
      "Epoch 190/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8902 - acc: 0.1390 - val_loss: 1.1438 - val_acc: 0.0910\n",
      "Epoch 191/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8893 - acc: 0.1350 - val_loss: 1.1521 - val_acc: 0.0970\n",
      "Epoch 192/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8921 - acc: 0.1380 - val_loss: 1.1453 - val_acc: 0.0940\n",
      "Epoch 193/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8930 - acc: 0.1320 - val_loss: 1.1632 - val_acc: 0.0980\n",
      "Epoch 194/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8896 - acc: 0.1420 - val_loss: 1.1432 - val_acc: 0.0910\n",
      "Epoch 195/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8889 - acc: 0.1330 - val_loss: 1.1509 - val_acc: 0.0970\n",
      "Epoch 196/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8870 - acc: 0.1360 - val_loss: 1.1556 - val_acc: 0.0960\n",
      "Epoch 197/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8902 - acc: 0.1370 - val_loss: 1.1450 - val_acc: 0.0920\n",
      "Epoch 198/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8884 - acc: 0.1300 - val_loss: 1.1591 - val_acc: 0.1000\n",
      "Epoch 199/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8893 - acc: 0.1390 - val_loss: 1.1462 - val_acc: 0.0930\n",
      "Epoch 200/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8886 - acc: 0.1350 - val_loss: 1.1544 - val_acc: 0.0980\n",
      "Epoch 201/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8893 - acc: 0.1340 - val_loss: 1.1454 - val_acc: 0.0930\n",
      "Epoch 202/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8915 - acc: 0.1330 - val_loss: 1.1449 - val_acc: 0.0930\n",
      "Epoch 203/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8913 - acc: 0.1340 - val_loss: 1.1427 - val_acc: 0.0870\n",
      "Epoch 204/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8905 - acc: 0.1470 - val_loss: 1.1426 - val_acc: 0.0880\n",
      "Epoch 205/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8922 - acc: 0.1360 - val_loss: 1.1504 - val_acc: 0.0970\n",
      "Epoch 206/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8925 - acc: 0.1330 - val_loss: 1.1512 - val_acc: 0.0960\n",
      "Epoch 207/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8882 - acc: 0.1310 - val_loss: 1.1534 - val_acc: 0.0990\n",
      "Epoch 208/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8922 - acc: 0.1370 - val_loss: 1.1550 - val_acc: 0.0970\n",
      "Epoch 209/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8874 - acc: 0.1390 - val_loss: 1.1475 - val_acc: 0.0940\n",
      "Epoch 210/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8878 - acc: 0.1320 - val_loss: 1.1482 - val_acc: 0.0940\n",
      "Epoch 211/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8892 - acc: 0.1420 - val_loss: 1.1479 - val_acc: 0.0930\n",
      "Epoch 212/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8942 - acc: 0.1260 - val_loss: 1.1606 - val_acc: 0.0970\n",
      "Epoch 213/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8890 - acc: 0.1440 - val_loss: 1.1443 - val_acc: 0.0890\n",
      "Epoch 214/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8906 - acc: 0.1340 - val_loss: 1.1613 - val_acc: 0.0990\n",
      "Epoch 215/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8917 - acc: 0.1410 - val_loss: 1.1539 - val_acc: 0.0970\n",
      "Epoch 216/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8882 - acc: 0.1350 - val_loss: 1.1581 - val_acc: 0.0970\n",
      "Epoch 217/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8935 - acc: 0.1420 - val_loss: 1.1483 - val_acc: 0.0940\n",
      "Epoch 218/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8884 - acc: 0.1340 - val_loss: 1.1530 - val_acc: 0.0970\n",
      "Epoch 219/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8888 - acc: 0.1370 - val_loss: 1.1601 - val_acc: 0.0980\n",
      "Epoch 220/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8871 - acc: 0.1360 - val_loss: 1.1451 - val_acc: 0.0880\n",
      "Epoch 221/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8936 - acc: 0.1330 - val_loss: 1.1480 - val_acc: 0.0920\n",
      "Epoch 222/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8887 - acc: 0.1390 - val_loss: 1.1531 - val_acc: 0.0950\n",
      "Epoch 223/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8879 - acc: 0.1370 - val_loss: 1.1461 - val_acc: 0.0910\n",
      "Epoch 224/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8938 - acc: 0.1330 - val_loss: 1.1521 - val_acc: 0.0980\n",
      "Epoch 225/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8888 - acc: 0.1320 - val_loss: 1.1518 - val_acc: 0.0980\n",
      "Epoch 226/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8904 - acc: 0.1350 - val_loss: 1.1570 - val_acc: 0.0950\n",
      "Epoch 227/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8893 - acc: 0.1310 - val_loss: 1.1525 - val_acc: 0.0970\n",
      "Epoch 228/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8909 - acc: 0.1320 - val_loss: 1.1464 - val_acc: 0.0930\n",
      "Epoch 229/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8893 - acc: 0.1390 - val_loss: 1.1504 - val_acc: 0.0950\n",
      "Epoch 230/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8941 - acc: 0.1360 - val_loss: 1.1427 - val_acc: 0.0860\n",
      "Epoch 231/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8915 - acc: 0.1330 - val_loss: 1.1560 - val_acc: 0.0970\n",
      "Epoch 232/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.8873 - acc: 0.1340 - val_loss: 1.1459 - val_acc: 0.0910\n",
      "Epoch 233/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8886 - acc: 0.1390 - val_loss: 1.1582 - val_acc: 0.0980\n",
      "Epoch 234/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.8900 - acc: 0.1330 - val_loss: 1.1596 - val_acc: 0.1020\n",
      "Epoch 235/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8890 - acc: 0.1370 - val_loss: 1.1527 - val_acc: 0.0940\n",
      "Epoch 236/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8896 - acc: 0.1350 - val_loss: 1.1490 - val_acc: 0.0940\n",
      "Epoch 237/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8915 - acc: 0.1290 - val_loss: 1.1760 - val_acc: 0.1030\n",
      "Epoch 238/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8938 - acc: 0.1400 - val_loss: 1.1466 - val_acc: 0.0920\n",
      "Epoch 239/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8881 - acc: 0.1390 - val_loss: 1.1504 - val_acc: 0.0940\n",
      "Epoch 240/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8896 - acc: 0.1320 - val_loss: 1.1608 - val_acc: 0.1020\n",
      "Epoch 241/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8925 - acc: 0.1450 - val_loss: 1.1472 - val_acc: 0.0950\n",
      "Epoch 242/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8899 - acc: 0.1280 - val_loss: 1.1676 - val_acc: 0.1010\n",
      "Epoch 243/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8915 - acc: 0.1540 - val_loss: 1.1496 - val_acc: 0.0940\n",
      "Epoch 244/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8888 - acc: 0.1360 - val_loss: 1.1513 - val_acc: 0.0940\n",
      "Epoch 245/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8924 - acc: 0.1370 - val_loss: 1.1440 - val_acc: 0.0900\n",
      "Epoch 246/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8894 - acc: 0.1370 - val_loss: 1.1593 - val_acc: 0.1020\n",
      "Epoch 247/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8885 - acc: 0.1370 - val_loss: 1.1483 - val_acc: 0.0940\n",
      "Epoch 248/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8880 - acc: 0.1360 - val_loss: 1.1552 - val_acc: 0.0950\n",
      "Epoch 249/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8887 - acc: 0.1390 - val_loss: 1.1547 - val_acc: 0.0940\n",
      "Epoch 250/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8894 - acc: 0.1350 - val_loss: 1.1498 - val_acc: 0.0940\n",
      "Epoch 251/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8906 - acc: 0.1340 - val_loss: 1.1514 - val_acc: 0.0950\n",
      "Epoch 252/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8893 - acc: 0.1340 - val_loss: 1.1480 - val_acc: 0.0930\n",
      "Epoch 253/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8887 - acc: 0.1400 - val_loss: 1.1525 - val_acc: 0.0940\n",
      "Epoch 254/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8885 - acc: 0.1260 - val_loss: 1.1658 - val_acc: 0.0990\n",
      "Epoch 255/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8914 - acc: 0.1550 - val_loss: 1.1440 - val_acc: 0.0880\n",
      "Epoch 256/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8881 - acc: 0.1300 - val_loss: 1.1654 - val_acc: 0.1000\n",
      "Epoch 257/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8923 - acc: 0.1410 - val_loss: 1.1452 - val_acc: 0.0880\n",
      "Epoch 258/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8911 - acc: 0.1390 - val_loss: 1.1455 - val_acc: 0.0920\n",
      "Epoch 259/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8931 - acc: 0.1330 - val_loss: 1.1503 - val_acc: 0.0970\n",
      "Epoch 260/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8895 - acc: 0.1370 - val_loss: 1.1646 - val_acc: 0.1040\n",
      "Epoch 261/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8891 - acc: 0.1410 - val_loss: 1.1482 - val_acc: 0.0940\n",
      "Epoch 262/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8923 - acc: 0.1480 - val_loss: 1.1664 - val_acc: 0.1010\n",
      "Epoch 263/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8912 - acc: 0.1310 - val_loss: 1.1642 - val_acc: 0.1020\n",
      "Epoch 264/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8896 - acc: 0.1370 - val_loss: 1.1529 - val_acc: 0.0930\n",
      "Epoch 265/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8875 - acc: 0.1350 - val_loss: 1.1542 - val_acc: 0.0950\n",
      "Epoch 266/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8889 - acc: 0.1350 - val_loss: 1.1503 - val_acc: 0.0980\n",
      "Epoch 267/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8919 - acc: 0.1410 - val_loss: 1.1442 - val_acc: 0.0880\n",
      "Epoch 268/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8864 - acc: 0.1330 - val_loss: 1.1771 - val_acc: 0.1020\n",
      "Epoch 269/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8980 - acc: 0.1430 - val_loss: 1.1570 - val_acc: 0.0960\n",
      "Epoch 270/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8924 - acc: 0.1590 - val_loss: 1.1444 - val_acc: 0.0890\n",
      "Epoch 271/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8931 - acc: 0.1330 - val_loss: 1.1573 - val_acc: 0.0980\n",
      "Epoch 272/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8907 - acc: 0.1370 - val_loss: 1.1699 - val_acc: 0.1000\n",
      "Epoch 273/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.8975 - acc: 0.1390 - val_loss: 1.1756 - val_acc: 0.1010\n",
      "Epoch 274/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.9015 - acc: 0.1480 - val_loss: 1.1454 - val_acc: 0.0910\n",
      "Epoch 275/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8931 - acc: 0.1500 - val_loss: 1.1507 - val_acc: 0.0950\n",
      "Epoch 276/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8877 - acc: 0.1410 - val_loss: 1.1675 - val_acc: 0.1020\n",
      "Epoch 277/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8897 - acc: 0.1450 - val_loss: 1.1469 - val_acc: 0.0950\n",
      "Epoch 278/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8922 - acc: 0.1460 - val_loss: 1.1436 - val_acc: 0.0870\n",
      "Epoch 279/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8884 - acc: 0.1420 - val_loss: 1.1680 - val_acc: 0.1000\n",
      "Epoch 280/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8950 - acc: 0.1410 - val_loss: 1.1544 - val_acc: 0.0980\n",
      "Epoch 281/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8878 - acc: 0.1360 - val_loss: 1.1522 - val_acc: 0.0980\n",
      "Epoch 282/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8883 - acc: 0.1370 - val_loss: 1.1604 - val_acc: 0.1000\n",
      "Epoch 283/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8899 - acc: 0.1330 - val_loss: 1.1532 - val_acc: 0.0980\n",
      "Epoch 284/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8901 - acc: 0.1430 - val_loss: 1.1504 - val_acc: 0.0960\n",
      "Epoch 285/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8903 - acc: 0.1430 - val_loss: 1.1707 - val_acc: 0.1020\n",
      "Epoch 286/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8900 - acc: 0.1420 - val_loss: 1.1493 - val_acc: 0.0940\n",
      "Epoch 287/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8876 - acc: 0.1410 - val_loss: 1.1605 - val_acc: 0.0980\n",
      "Epoch 288/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8868 - acc: 0.1330 - val_loss: 1.1462 - val_acc: 0.0940\n",
      "Epoch 289/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8888 - acc: 0.1370 - val_loss: 1.1492 - val_acc: 0.0970\n",
      "Epoch 290/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8921 - acc: 0.1380 - val_loss: 1.1470 - val_acc: 0.0940\n",
      "Epoch 291/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8900 - acc: 0.1410 - val_loss: 1.1570 - val_acc: 0.0970\n",
      "Epoch 292/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8897 - acc: 0.1360 - val_loss: 1.1685 - val_acc: 0.1030\n",
      "Epoch 293/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8909 - acc: 0.1390 - val_loss: 1.1527 - val_acc: 0.0980\n",
      "Epoch 294/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8935 - acc: 0.1420 - val_loss: 1.1445 - val_acc: 0.0920\n",
      "Epoch 295/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8883 - acc: 0.1420 - val_loss: 1.1588 - val_acc: 0.0970\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8896 - acc: 0.1280 - val_loss: 1.1522 - val_acc: 0.0980\n",
      "Epoch 297/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8972 - acc: 0.1500 - val_loss: 1.1442 - val_acc: 0.0890\n",
      "Epoch 298/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8909 - acc: 0.1360 - val_loss: 1.1490 - val_acc: 0.0910\n",
      "Epoch 299/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8906 - acc: 0.1340 - val_loss: 1.1540 - val_acc: 0.0990\n",
      "Epoch 300/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8938 - acc: 0.1370 - val_loss: 1.1817 - val_acc: 0.1060\n",
      "Epoch 301/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8926 - acc: 0.1470 - val_loss: 1.1486 - val_acc: 0.0940\n",
      "Epoch 302/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8882 - acc: 0.1310 - val_loss: 1.1602 - val_acc: 0.0990\n",
      "Epoch 303/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8892 - acc: 0.1330 - val_loss: 1.1465 - val_acc: 0.0920\n",
      "Epoch 304/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8886 - acc: 0.1360 - val_loss: 1.1614 - val_acc: 0.0970\n",
      "Epoch 305/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8883 - acc: 0.1350 - val_loss: 1.1497 - val_acc: 0.0960\n",
      "Epoch 306/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8893 - acc: 0.1350 - val_loss: 1.1608 - val_acc: 0.0980\n",
      "Epoch 307/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8907 - acc: 0.1430 - val_loss: 1.1554 - val_acc: 0.0950\n",
      "Epoch 308/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8897 - acc: 0.1310 - val_loss: 1.1517 - val_acc: 0.0910\n",
      "Epoch 309/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8891 - acc: 0.1460 - val_loss: 1.1468 - val_acc: 0.0920\n",
      "Epoch 310/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8931 - acc: 0.1330 - val_loss: 1.1501 - val_acc: 0.0920\n",
      "Epoch 311/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8920 - acc: 0.1290 - val_loss: 1.1450 - val_acc: 0.0890\n",
      "Epoch 312/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8892 - acc: 0.1340 - val_loss: 1.1496 - val_acc: 0.0940\n",
      "Epoch 313/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8935 - acc: 0.1300 - val_loss: 1.1630 - val_acc: 0.0990\n",
      "Epoch 314/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8900 - acc: 0.1380 - val_loss: 1.1582 - val_acc: 0.0960\n",
      "Epoch 315/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8897 - acc: 0.1480 - val_loss: 1.1443 - val_acc: 0.0870\n",
      "Epoch 316/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8919 - acc: 0.1260 - val_loss: 1.1616 - val_acc: 0.0970\n",
      "Epoch 317/500\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.8947 - acc: 0.1320 - val_loss: 1.1477 - val_acc: 0.0930\n",
      "Epoch 318/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8888 - acc: 0.1290 - val_loss: 1.1581 - val_acc: 0.0970\n",
      "Epoch 319/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8900 - acc: 0.1430 - val_loss: 1.1453 - val_acc: 0.0870\n",
      "Epoch 320/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8883 - acc: 0.1330 - val_loss: 1.1563 - val_acc: 0.0980\n",
      "Epoch 321/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8921 - acc: 0.1470 - val_loss: 1.1446 - val_acc: 0.0890\n",
      "Epoch 322/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8892 - acc: 0.1370 - val_loss: 1.1503 - val_acc: 0.0940\n",
      "Epoch 323/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8905 - acc: 0.1340 - val_loss: 1.1570 - val_acc: 0.0970\n",
      "Epoch 324/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8940 - acc: 0.1430 - val_loss: 1.1535 - val_acc: 0.0960\n",
      "Epoch 325/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8905 - acc: 0.1310 - val_loss: 1.1514 - val_acc: 0.0930\n",
      "Epoch 326/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8896 - acc: 0.1310 - val_loss: 1.1522 - val_acc: 0.0910\n",
      "Epoch 327/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8894 - acc: 0.1280 - val_loss: 1.1465 - val_acc: 0.0910\n",
      "Epoch 328/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8891 - acc: 0.1390 - val_loss: 1.1569 - val_acc: 0.0960\n",
      "Epoch 329/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8920 - acc: 0.1300 - val_loss: 1.1435 - val_acc: 0.0890\n",
      "Epoch 330/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8905 - acc: 0.1420 - val_loss: 1.1445 - val_acc: 0.0920\n",
      "Epoch 331/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8908 - acc: 0.1350 - val_loss: 1.1602 - val_acc: 0.0990\n",
      "Epoch 332/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8927 - acc: 0.1430 - val_loss: 1.1424 - val_acc: 0.0900\n",
      "Epoch 333/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8892 - acc: 0.1390 - val_loss: 1.1569 - val_acc: 0.0970\n",
      "Epoch 334/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8922 - acc: 0.1350 - val_loss: 1.1542 - val_acc: 0.0950\n",
      "Epoch 335/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8902 - acc: 0.1440 - val_loss: 1.1423 - val_acc: 0.0890\n",
      "Epoch 336/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8942 - acc: 0.1330 - val_loss: 1.1458 - val_acc: 0.0910\n",
      "Epoch 337/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8881 - acc: 0.1340 - val_loss: 1.1509 - val_acc: 0.0950\n",
      "Epoch 338/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8877 - acc: 0.1310 - val_loss: 1.1476 - val_acc: 0.0930\n",
      "Epoch 339/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8881 - acc: 0.1330 - val_loss: 1.1506 - val_acc: 0.0940\n",
      "Epoch 340/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8880 - acc: 0.1300 - val_loss: 1.1559 - val_acc: 0.0970\n",
      "Epoch 341/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8894 - acc: 0.1350 - val_loss: 1.1472 - val_acc: 0.0940\n",
      "Epoch 342/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8892 - acc: 0.1340 - val_loss: 1.1609 - val_acc: 0.0990\n",
      "Epoch 343/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8901 - acc: 0.1340 - val_loss: 1.1541 - val_acc: 0.0970\n",
      "Epoch 344/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8868 - acc: 0.1410 - val_loss: 1.1421 - val_acc: 0.0880\n",
      "Epoch 345/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8916 - acc: 0.1230 - val_loss: 1.1547 - val_acc: 0.0950\n",
      "Epoch 346/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8902 - acc: 0.1350 - val_loss: 1.1489 - val_acc: 0.0930\n",
      "Epoch 347/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8880 - acc: 0.1260 - val_loss: 1.1643 - val_acc: 0.1010\n",
      "Epoch 348/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8984 - acc: 0.1480 - val_loss: 1.1431 - val_acc: 0.0910\n",
      "Epoch 349/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8891 - acc: 0.1310 - val_loss: 1.1540 - val_acc: 0.1000\n",
      "Epoch 350/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8885 - acc: 0.1370 - val_loss: 1.1482 - val_acc: 0.0940\n",
      "Epoch 351/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8898 - acc: 0.1310 - val_loss: 1.1425 - val_acc: 0.0900\n",
      "Epoch 352/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8874 - acc: 0.1300 - val_loss: 1.1593 - val_acc: 0.0990\n",
      "Epoch 353/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.8902 - acc: 0.1330 - val_loss: 1.1489 - val_acc: 0.0960\n",
      "Epoch 354/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8881 - acc: 0.1300 - val_loss: 1.1504 - val_acc: 0.0920\n",
      "Epoch 355/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8903 - acc: 0.1350 - val_loss: 1.1453 - val_acc: 0.0910\n",
      "Epoch 356/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8893 - acc: 0.1310 - val_loss: 1.1662 - val_acc: 0.1010\n",
      "Epoch 357/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8914 - acc: 0.1360 - val_loss: 1.1522 - val_acc: 0.0960\n",
      "Epoch 358/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8899 - acc: 0.1390 - val_loss: 1.1498 - val_acc: 0.0950\n",
      "Epoch 359/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8939 - acc: 0.1430 - val_loss: 1.1463 - val_acc: 0.0910\n",
      "Epoch 360/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8889 - acc: 0.1400 - val_loss: 1.1503 - val_acc: 0.0960\n",
      "Epoch 361/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8888 - acc: 0.1370 - val_loss: 1.1546 - val_acc: 0.0950\n",
      "Epoch 362/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8881 - acc: 0.1330 - val_loss: 1.1454 - val_acc: 0.0900\n",
      "Epoch 363/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8905 - acc: 0.1300 - val_loss: 1.1547 - val_acc: 0.0950\n",
      "Epoch 364/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8879 - acc: 0.1390 - val_loss: 1.1547 - val_acc: 0.0960\n",
      "Epoch 365/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8886 - acc: 0.1470 - val_loss: 1.1483 - val_acc: 0.0940\n",
      "Epoch 366/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8903 - acc: 0.1260 - val_loss: 1.1645 - val_acc: 0.1010\n",
      "Epoch 367/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8893 - acc: 0.1340 - val_loss: 1.1521 - val_acc: 0.0970\n",
      "Epoch 368/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8916 - acc: 0.1340 - val_loss: 1.1508 - val_acc: 0.0960\n",
      "Epoch 369/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8888 - acc: 0.1370 - val_loss: 1.1548 - val_acc: 0.0980\n",
      "Epoch 370/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8880 - acc: 0.1340 - val_loss: 1.1487 - val_acc: 0.0950\n",
      "Epoch 371/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8889 - acc: 0.1340 - val_loss: 1.1570 - val_acc: 0.0970\n",
      "Epoch 372/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8878 - acc: 0.1310 - val_loss: 1.1476 - val_acc: 0.0960\n",
      "Epoch 373/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8902 - acc: 0.1390 - val_loss: 1.1441 - val_acc: 0.0920\n",
      "Epoch 374/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8901 - acc: 0.1340 - val_loss: 1.1563 - val_acc: 0.0980\n",
      "Epoch 375/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8883 - acc: 0.1360 - val_loss: 1.1523 - val_acc: 0.0940\n",
      "Epoch 376/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8918 - acc: 0.1250 - val_loss: 1.1496 - val_acc: 0.0960\n",
      "Epoch 377/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8882 - acc: 0.1320 - val_loss: 1.1515 - val_acc: 0.0960\n",
      "Epoch 378/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8916 - acc: 0.1330 - val_loss: 1.1616 - val_acc: 0.1020\n",
      "Epoch 379/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8874 - acc: 0.1320 - val_loss: 1.1480 - val_acc: 0.0950\n",
      "Epoch 380/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8885 - acc: 0.1300 - val_loss: 1.1492 - val_acc: 0.0960\n",
      "Epoch 381/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8896 - acc: 0.1360 - val_loss: 1.1494 - val_acc: 0.0940\n",
      "Epoch 382/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8921 - acc: 0.1280 - val_loss: 1.1527 - val_acc: 0.0970\n",
      "Epoch 383/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8919 - acc: 0.1310 - val_loss: 1.1627 - val_acc: 0.1000\n",
      "Epoch 384/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8911 - acc: 0.1280 - val_loss: 1.1534 - val_acc: 0.0970\n",
      "Epoch 385/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8888 - acc: 0.1340 - val_loss: 1.1506 - val_acc: 0.0960\n",
      "Epoch 386/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8921 - acc: 0.1300 - val_loss: 1.1653 - val_acc: 0.1030\n",
      "Epoch 387/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8955 - acc: 0.1600 - val_loss: 1.1411 - val_acc: 0.0920\n",
      "Epoch 388/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8948 - acc: 0.1330 - val_loss: 1.1418 - val_acc: 0.0920\n",
      "Epoch 389/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8897 - acc: 0.1290 - val_loss: 1.1611 - val_acc: 0.1000\n",
      "Epoch 390/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8909 - acc: 0.1340 - val_loss: 1.1524 - val_acc: 0.0980\n",
      "Epoch 391/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8892 - acc: 0.1340 - val_loss: 1.1484 - val_acc: 0.0960\n",
      "Epoch 392/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8897 - acc: 0.1360 - val_loss: 1.1426 - val_acc: 0.0900\n",
      "Epoch 393/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8900 - acc: 0.1420 - val_loss: 1.1560 - val_acc: 0.0980\n",
      "Epoch 394/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8888 - acc: 0.1340 - val_loss: 1.1428 - val_acc: 0.0910\n",
      "Epoch 395/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8896 - acc: 0.1320 - val_loss: 1.1487 - val_acc: 0.0950\n",
      "Epoch 396/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8897 - acc: 0.1370 - val_loss: 1.1499 - val_acc: 0.0950\n",
      "Epoch 397/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8901 - acc: 0.1390 - val_loss: 1.1460 - val_acc: 0.0950\n",
      "Epoch 398/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8903 - acc: 0.1450 - val_loss: 1.1425 - val_acc: 0.0890\n",
      "Epoch 399/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8910 - acc: 0.1270 - val_loss: 1.1520 - val_acc: 0.0940\n",
      "Epoch 400/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8884 - acc: 0.1360 - val_loss: 1.1750 - val_acc: 0.1020\n",
      "Epoch 401/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8935 - acc: 0.1490 - val_loss: 1.1456 - val_acc: 0.0910\n",
      "Epoch 402/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8890 - acc: 0.1370 - val_loss: 1.1531 - val_acc: 0.0960\n",
      "Epoch 403/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8909 - acc: 0.1360 - val_loss: 1.1496 - val_acc: 0.0920\n",
      "Epoch 404/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8921 - acc: 0.1370 - val_loss: 1.1739 - val_acc: 0.1030\n",
      "Epoch 405/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8909 - acc: 0.1370 - val_loss: 1.1498 - val_acc: 0.0930\n",
      "Epoch 406/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8892 - acc: 0.1380 - val_loss: 1.1645 - val_acc: 0.0990\n",
      "Epoch 407/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8920 - acc: 0.1380 - val_loss: 1.1428 - val_acc: 0.0890\n",
      "Epoch 408/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8915 - acc: 0.1520 - val_loss: 1.1616 - val_acc: 0.0980\n",
      "Epoch 409/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8920 - acc: 0.1410 - val_loss: 1.1595 - val_acc: 0.0980\n",
      "Epoch 410/500\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 0.8888 - acc: 0.1280 - val_loss: 1.1647 - val_acc: 0.1000\n",
      "Epoch 411/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8940 - acc: 0.1630 - val_loss: 1.1440 - val_acc: 0.0900\n",
      "Epoch 412/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8937 - acc: 0.1340 - val_loss: 1.1512 - val_acc: 0.0940\n",
      "Epoch 413/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8899 - acc: 0.1360 - val_loss: 1.1606 - val_acc: 0.0990\n",
      "Epoch 414/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8902 - acc: 0.1340 - val_loss: 1.1528 - val_acc: 0.0930\n",
      "Epoch 415/500\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.9583 - acc: 0.187 - 0s 46us/step - loss: 0.8902 - acc: 0.1390 - val_loss: 1.1570 - val_acc: 0.0980\n",
      "Epoch 416/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8943 - acc: 0.1490 - val_loss: 1.1428 - val_acc: 0.0900\n",
      "Epoch 417/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8907 - acc: 0.1450 - val_loss: 1.1586 - val_acc: 0.1000\n",
      "Epoch 418/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8902 - acc: 0.1390 - val_loss: 1.1491 - val_acc: 0.0930\n",
      "Epoch 419/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8884 - acc: 0.1340 - val_loss: 1.1682 - val_acc: 0.1000\n",
      "Epoch 420/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8936 - acc: 0.1380 - val_loss: 1.1574 - val_acc: 0.0980\n",
      "Epoch 421/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8905 - acc: 0.1380 - val_loss: 1.1499 - val_acc: 0.0950\n",
      "Epoch 422/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8874 - acc: 0.1340 - val_loss: 1.1626 - val_acc: 0.1000\n",
      "Epoch 423/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8942 - acc: 0.1480 - val_loss: 1.1463 - val_acc: 0.0920\n",
      "Epoch 424/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8927 - acc: 0.1510 - val_loss: 1.1470 - val_acc: 0.0910\n",
      "Epoch 425/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8929 - acc: 0.1380 - val_loss: 1.1505 - val_acc: 0.0910\n",
      "Epoch 426/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8912 - acc: 0.1350 - val_loss: 1.1590 - val_acc: 0.0980\n",
      "Epoch 427/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8883 - acc: 0.1380 - val_loss: 1.1662 - val_acc: 0.0990\n",
      "Epoch 428/500\n",
      "1000/1000 [==============================] - 0s 32us/step - loss: 0.8967 - acc: 0.1510 - val_loss: 1.1493 - val_acc: 0.0930\n",
      "Epoch 429/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8920 - acc: 0.1390 - val_loss: 1.1474 - val_acc: 0.0920\n",
      "Epoch 430/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8924 - acc: 0.1330 - val_loss: 1.1510 - val_acc: 0.0950\n",
      "Epoch 431/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8900 - acc: 0.1380 - val_loss: 1.1485 - val_acc: 0.0910\n",
      "Epoch 432/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8896 - acc: 0.1410 - val_loss: 1.1507 - val_acc: 0.0930\n",
      "Epoch 433/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8889 - acc: 0.1400 - val_loss: 1.1491 - val_acc: 0.0920\n",
      "Epoch 434/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8892 - acc: 0.1340 - val_loss: 1.1633 - val_acc: 0.1000\n",
      "Epoch 435/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8899 - acc: 0.1380 - val_loss: 1.1551 - val_acc: 0.0960\n",
      "Epoch 436/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8895 - acc: 0.1400 - val_loss: 1.1538 - val_acc: 0.0940\n",
      "Epoch 437/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8911 - acc: 0.1300 - val_loss: 1.1510 - val_acc: 0.0920\n",
      "Epoch 438/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8894 - acc: 0.1400 - val_loss: 1.1505 - val_acc: 0.0920\n",
      "Epoch 439/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8876 - acc: 0.1280 - val_loss: 1.1639 - val_acc: 0.1000\n",
      "Epoch 440/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8901 - acc: 0.1490 - val_loss: 1.1528 - val_acc: 0.0930\n",
      "Epoch 441/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8889 - acc: 0.1370 - val_loss: 1.1554 - val_acc: 0.0950\n",
      "Epoch 442/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8889 - acc: 0.1400 - val_loss: 1.1536 - val_acc: 0.0940\n",
      "Epoch 443/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8893 - acc: 0.1370 - val_loss: 1.1526 - val_acc: 0.0950\n",
      "Epoch 444/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8891 - acc: 0.1320 - val_loss: 1.1630 - val_acc: 0.1010\n",
      "Epoch 445/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8880 - acc: 0.1370 - val_loss: 1.1470 - val_acc: 0.0890\n",
      "Epoch 446/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8911 - acc: 0.1330 - val_loss: 1.1571 - val_acc: 0.0960\n",
      "Epoch 447/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8886 - acc: 0.1380 - val_loss: 1.1549 - val_acc: 0.0940\n",
      "Epoch 448/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8897 - acc: 0.1330 - val_loss: 1.1509 - val_acc: 0.0950\n",
      "Epoch 449/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8876 - acc: 0.1340 - val_loss: 1.1559 - val_acc: 0.0970\n",
      "Epoch 450/500\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.8887 - acc: 0.1350 - val_loss: 1.1527 - val_acc: 0.0960\n",
      "Epoch 451/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8882 - acc: 0.1340 - val_loss: 1.1505 - val_acc: 0.0950\n",
      "Epoch 452/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8876 - acc: 0.1350 - val_loss: 1.1616 - val_acc: 0.0980\n",
      "Epoch 453/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8910 - acc: 0.1440 - val_loss: 1.1541 - val_acc: 0.0970\n",
      "Epoch 454/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8893 - acc: 0.1340 - val_loss: 1.1450 - val_acc: 0.0880\n",
      "Epoch 455/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8892 - acc: 0.1310 - val_loss: 1.1543 - val_acc: 0.0970\n",
      "Epoch 456/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8958 - acc: 0.1370 - val_loss: 1.1558 - val_acc: 0.0970\n",
      "Epoch 457/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8885 - acc: 0.1470 - val_loss: 1.1454 - val_acc: 0.0880\n",
      "Epoch 458/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8908 - acc: 0.1250 - val_loss: 1.1570 - val_acc: 0.0970\n",
      "Epoch 459/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8933 - acc: 0.1460 - val_loss: 1.1447 - val_acc: 0.0880\n",
      "Epoch 460/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8896 - acc: 0.1360 - val_loss: 1.1571 - val_acc: 0.0980\n",
      "Epoch 461/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8913 - acc: 0.1310 - val_loss: 1.1774 - val_acc: 0.1040\n",
      "Epoch 462/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8941 - acc: 0.1380 - val_loss: 1.1493 - val_acc: 0.0940\n",
      "Epoch 463/500\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.8872 - acc: 0.1320 - val_loss: 1.1551 - val_acc: 0.0960\n",
      "Epoch 464/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8894 - acc: 0.1380 - val_loss: 1.1479 - val_acc: 0.0960\n",
      "Epoch 465/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8891 - acc: 0.1290 - val_loss: 1.1616 - val_acc: 0.1010\n",
      "Epoch 466/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8917 - acc: 0.1460 - val_loss: 1.1494 - val_acc: 0.0960\n",
      "Epoch 467/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8881 - acc: 0.1330 - val_loss: 1.1586 - val_acc: 0.1010\n",
      "Epoch 468/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8896 - acc: 0.1380 - val_loss: 1.1500 - val_acc: 0.0960\n",
      "Epoch 469/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8937 - acc: 0.1360 - val_loss: 1.1435 - val_acc: 0.0890\n",
      "Epoch 470/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8914 - acc: 0.1310 - val_loss: 1.1455 - val_acc: 0.0930\n",
      "Epoch 471/500\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.8887 - acc: 0.1360 - val_loss: 1.1529 - val_acc: 0.0980\n",
      "Epoch 472/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8875 - acc: 0.1320 - val_loss: 1.1501 - val_acc: 0.0960\n",
      "Epoch 473/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.8892 - acc: 0.1300 - val_loss: 1.1530 - val_acc: 0.0980\n",
      "Epoch 474/500\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.8888 - acc: 0.1380 - val_loss: 1.1452 - val_acc: 0.0890\n",
      "Epoch 475/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8945 - acc: 0.1330 - val_loss: 1.1444 - val_acc: 0.0890\n",
      "Epoch 476/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8907 - acc: 0.1390 - val_loss: 1.1520 - val_acc: 0.0960\n",
      "Epoch 477/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8929 - acc: 0.1420 - val_loss: 1.1559 - val_acc: 0.0980\n",
      "Epoch 478/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8888 - acc: 0.1380 - val_loss: 1.1499 - val_acc: 0.0970\n",
      "Epoch 479/500\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.8882 - acc: 0.1340 - val_loss: 1.1550 - val_acc: 0.0970\n",
      "Epoch 480/500\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.8871 - acc: 0.1380 - val_loss: 1.1488 - val_acc: 0.0950\n",
      "Epoch 481/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8892 - acc: 0.1390 - val_loss: 1.1498 - val_acc: 0.0970\n",
      "Epoch 482/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8887 - acc: 0.1290 - val_loss: 1.1569 - val_acc: 0.0960\n",
      "Epoch 483/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8898 - acc: 0.1340 - val_loss: 1.1636 - val_acc: 0.1000\n",
      "Epoch 484/500\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.8932 - acc: 0.1440 - val_loss: 1.1529 - val_acc: 0.0970\n",
      "Epoch 485/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8916 - acc: 0.1340 - val_loss: 1.1465 - val_acc: 0.0930\n",
      "Epoch 486/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8905 - acc: 0.1360 - val_loss: 1.1460 - val_acc: 0.0930\n",
      "Epoch 487/500\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.8917 - acc: 0.1330 - val_loss: 1.1475 - val_acc: 0.0950\n",
      "Epoch 488/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8886 - acc: 0.1330 - val_loss: 1.1513 - val_acc: 0.0940\n",
      "Epoch 489/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8918 - acc: 0.1280 - val_loss: 1.1610 - val_acc: 0.0980\n",
      "Epoch 490/500\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.8929 - acc: 0.1420 - val_loss: 1.1562 - val_acc: 0.0960\n",
      "Epoch 491/500\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.8899 - acc: 0.1390 - val_loss: 1.1550 - val_acc: 0.0970\n",
      "Epoch 492/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8916 - acc: 0.1370 - val_loss: 1.1498 - val_acc: 0.0940\n",
      "Epoch 493/500\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.8915 - acc: 0.1330 - val_loss: 1.1717 - val_acc: 0.1060\n",
      "Epoch 494/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8891 - acc: 0.1480 - val_loss: 1.1489 - val_acc: 0.0930\n",
      "Epoch 495/500\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.8893 - acc: 0.1380 - val_loss: 1.1577 - val_acc: 0.1020\n",
      "Epoch 496/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8896 - acc: 0.1410 - val_loss: 1.1519 - val_acc: 0.0960\n",
      "Epoch 497/500\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.8897 - acc: 0.1350 - val_loss: 1.1675 - val_acc: 0.1020\n",
      "Epoch 498/500\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.8879 - acc: 0.1410 - val_loss: 1.1508 - val_acc: 0.0960\n",
      "Epoch 499/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8905 - acc: 0.1500 - val_loss: 1.1446 - val_acc: 0.0870\n",
      "Epoch 500/500\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.8893 - acc: 0.1360 - val_loss: 1.1731 - val_acc: 0.1040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b27ace828>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(X, y_tanh, validation_data=(X_val, y_tanh_val), epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 392us/step - loss: 0.2499 - acc: 0.5040 - val_loss: 0.2500 - val_acc: 0.4820\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 99us/step - loss: 0.2496 - acc: 0.5440 - val_loss: 0.2502 - val_acc: 0.4800\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 93us/step - loss: 0.2493 - acc: 0.5380 - val_loss: 0.2505 - val_acc: 0.4690\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.2491 - acc: 0.5410 - val_loss: 0.2507 - val_acc: 0.4730\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 0.2489 - acc: 0.5330 - val_loss: 0.2510 - val_acc: 0.4700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 0.2485 - acc: 0.5410 - val_loss: 0.2511 - val_acc: 0.4730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 92us/step - loss: 0.2482 - acc: 0.5440 - val_loss: 0.2513 - val_acc: 0.4710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 90us/step - loss: 0.2479 - acc: 0.5510 - val_loss: 0.2512 - val_acc: 0.4790\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 0.2473 - acc: 0.5500 - val_loss: 0.2516 - val_acc: 0.4700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 0.2469 - acc: 0.5680 - val_loss: 0.2517 - val_acc: 0.4780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c7bba5ba8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit([X, ht_1_input, ht_2_input], y, \n",
    "                   validation_data=([X_val, ht_1_input_val, ht_2_input_val], y_val), \n",
    "                   epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Domain Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate 16 documents\n",
    "# n1 = negative word with importance 1\n",
    "# p2 = positive word with importance 2\n",
    "# p3 = positive word with importance 3\n",
    "# n4 = negative word with importance 4\n",
    "# movie = neutral word with importance 0\n",
    "\n",
    "word_list = ['movie', 'bad', 'good', 'amazing', 'awful']\n",
    "word_weight = np.asarray([0, -1, 2, 3, -4], dtype='int32')\n",
    "word_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "num = 16\n",
    "data = np.zeros([num, len(word_list)])\n",
    "index=0\n",
    "label = []\n",
    "\n",
    "for i in range(5):\n",
    "    # get the combination\n",
    "    perm = combinations([1,2,3,4], i)\n",
    "    \n",
    "    for j in list(perm):\n",
    "        # always put neutral word\n",
    "        data[index, 0] = 1\n",
    "        \n",
    "        # if its only 1 terms\n",
    "        if i==1:\n",
    "            data[index,j] = 1\n",
    "        else:\n",
    "            for k in j:\n",
    "                data[index, k] = 1\n",
    "        \n",
    "        # calculate weights\n",
    "        \n",
    "        weights = data[index,:] * word_weight\n",
    "        label.append(np.sign(np.sum(weights)))\n",
    "        \n",
    "        index+=1\n",
    "        \n",
    "label = np.asarray(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_label = (label == 1).astype('int32')\n",
    "np_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,\n",
       "       -1.,  1.,  0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               [(None, 1), (None, 1 0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 1)            6           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 1)            0           lambda_1[0][0]                   \n",
      "                                                                 model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 1)            0           lambda_1[0][1]                   \n",
      "                                                                 model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 1)            0           lambda_1[0][2]                   \n",
      "                                                                 model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 1)            0           lambda_1[0][3]                   \n",
      "                                                                 model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            1           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            1           multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            1           multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Lambda)            (None, 4)            0           dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            4           concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the combined model\n",
    "# Combined model\n",
    "###########################################\n",
    "human_terms_len = 4\n",
    "thresholded_relu = ThresholdedReLU(theta=0.9)\n",
    "###########################################\n",
    "\n",
    "base_model = build_base_model(data.shape[1])\n",
    "\n",
    "combined_input_layer = Input(shape=(data.shape[1],))\n",
    "\n",
    "# build the hard coded weight for human terms\n",
    "ht_input_layer = Input(shape=(human_terms_len,))\n",
    "\n",
    "split = Lambda( lambda x: tf.split(x,num_or_size_splits=human_terms_len,axis=1))(ht_input_layer)\n",
    "\n",
    "# get the document prediction\n",
    "label_layer = base_model(combined_input_layer)\n",
    "\n",
    "# multiply and pass it into relu\n",
    "# initialize relu layer\n",
    "\n",
    "# stack the multiply layer\n",
    "dense_layer = []\n",
    "for i in range(human_terms_len):\n",
    "    dense_layer.append(Dense(1, \n",
    "                             activation='relu', \n",
    "                             use_bias=False, \n",
    "                             kernel_initializer='ones')(Multiply()([split[i], label_layer])))\n",
    "\n",
    "# concat all the result   \n",
    "concat = Lambda( lambda x: tf.concat(x, axis=1), name='concatenate')(dense_layer)\n",
    "\n",
    "# pass it to sigmoid layer\n",
    "output_layer = Dense(1, activation='sigmoid', use_bias=False)(concat)\n",
    "\n",
    "combined_model = Model(inputs=[combined_input_layer, ht_input_layer], outputs=output_layer)\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(loss='mse',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "combined_model.compile(loss='mse',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_present_by_doc(X, index, weight):\n",
    "    np_vector = np.zeros([X.shape[0],1])\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        if x[index] == 1:\n",
    "            np_vector[i] = np.sign(weight)\n",
    "#             np_vector[i] = 1\n",
    "    \n",
    "    return np_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to generate the ht's\n",
    "\n",
    "ht_1_input = np_present_by_doc(data, 1, word_weight[1])\n",
    "ht_2_input = np_present_by_doc(data, 2, word_weight[2])\n",
    "ht_3_input = np_present_by_doc(data, 3, word_weight[3])\n",
    "ht_4_input = np_present_by_doc(data, 4, word_weight[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_1_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_input = np.hstack([ht_1_input, ht_2_input, ht_3_input, ht_4_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.],\n",
       "       [-1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., -1.],\n",
       "       [-1.,  1.,  0.,  0.],\n",
       "       [-1.,  0.,  1.,  0.],\n",
       "       [-1.,  0.,  0., -1.],\n",
       "       [ 0.,  1.,  1.,  0.],\n",
       "       [ 0.,  1.,  0., -1.],\n",
       "       [ 0.,  0.,  1., -1.],\n",
       "       [-1.,  1.,  1.,  0.],\n",
       "       [-1.,  1.,  0., -1.],\n",
       "       [-1.,  0.,  1., -1.],\n",
       "       [ 0.,  1.,  1., -1.],\n",
       "       [-1.,  1.,  1., -1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0.] [0.]\n",
      "[1. 1. 0. 0. 0.] [0.]\n",
      "[1. 0. 1. 0. 0.] [0.]\n",
      "[1. 0. 0. 1. 0.] [1.]\n",
      "[1. 0. 0. 0. 1.] [0.]\n",
      "[1. 1. 1. 0. 0.] [0.]\n",
      "[1. 1. 0. 1. 0.] [1.]\n",
      "[1. 1. 0. 0. 1.] [0.]\n",
      "[1. 0. 1. 1. 0.] [1.]\n",
      "[1. 0. 1. 0. 1.] [0.]\n",
      "[1. 0. 0. 1. 1.] [1.]\n",
      "[1. 1. 1. 1. 0.] [1.]\n",
      "[1. 1. 1. 0. 1.] [0.]\n",
      "[1. 1. 0. 1. 1.] [1.]\n",
      "[1. 0. 1. 1. 1.] [1.]\n",
      "[1. 1. 1. 1. 1.] [1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ht_1_input)):\n",
    "    print(data[i], ht_3_input[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adjust y to -> [-1, 1]\n",
    "# label_tanh = []\n",
    "# for i in label:\n",
    "#     if i==0:\n",
    "#         label_tanh.append(-1)\n",
    "#     else:\n",
    "#         label_tanh.append(1)\n",
    "# label_tanh = np.asarray(label_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 0s - loss: 1.4815 - acc: 0.2143\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1.4737 - acc: 0.2143\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 1.4653 - acc: 0.2143\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 1.4576 - acc: 0.2143\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 1.4502 - acc: 0.2143\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 1.4431 - acc: 0.2143\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 1.4333 - acc: 0.2143\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 1.4262 - acc: 0.2143\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 1.4205 - acc: 0.2143\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 1.4098 - acc: 0.2143\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 1.4056 - acc: 0.2143\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 1.3943 - acc: 0.2143\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 1.3858 - acc: 0.2143\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 1.3797 - acc: 0.2143\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 1.3697 - acc: 0.2143\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 1.3614 - acc: 0.2143\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 1.3537 - acc: 0.2143\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 1.3478 - acc: 0.2143\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 1.3389 - acc: 0.2143\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 1.3290 - acc: 0.2143\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 1.3211 - acc: 0.2143\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 1.3137 - acc: 0.2143\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 1.3063 - acc: 0.2143\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 1.2966 - acc: 0.2143\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 1.2900 - acc: 0.2143\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 1.2811 - acc: 0.2143\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 1.2732 - acc: 0.2143\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 1.2655 - acc: 0.2143\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 1.2578 - acc: 0.2143\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 1.2486 - acc: 0.2143\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 1.2425 - acc: 0.2143\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 1.2344 - acc: 0.2143\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 1.2256 - acc: 0.2143\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 1.2181 - acc: 0.2143\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 1.2125 - acc: 0.2143\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 1.2018 - acc: 0.2143\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 1.1944 - acc: 0.2143\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 1.1859 - acc: 0.2143\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 1.1792 - acc: 0.2143\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 1.1704 - acc: 0.2143\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 1.1636 - acc: 0.2143\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 1.1561 - acc: 0.2143\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 1.1481 - acc: 0.2143\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 1.1414 - acc: 0.2143\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 1.1339 - acc: 0.2857\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 1.1264 - acc: 0.2857\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 1.1176 - acc: 0.2857\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 1.1112 - acc: 0.2857\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 1.1039 - acc: 0.2857\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 1.0966 - acc: 0.2857\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 1.0886 - acc: 0.2857\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 1.0821 - acc: 0.2857\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 1.0750 - acc: 0.2857\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 1.0685 - acc: 0.2857\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 1.0599 - acc: 0.2857\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 1.0527 - acc: 0.2857\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 1.0468 - acc: 0.2857\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 1.0397 - acc: 0.2857\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 1.0329 - acc: 0.2857\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 1.0264 - acc: 0.2857\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 1.0179 - acc: 0.2857\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 1.0105 - acc: 0.2857\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 1.0037 - acc: 0.2857\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.9968 - acc: 0.3571\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.9913 - acc: 0.3571\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.9851 - acc: 0.3571\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.9769 - acc: 0.3571\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 0.9704 - acc: 0.3571\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 0.9639 - acc: 0.3571\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 0.9579 - acc: 0.4286\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 0.9511 - acc: 0.4286\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 0.9442 - acc: 0.4286\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 0.9386 - acc: 0.4286\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 0.9320 - acc: 0.4286\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.9264 - acc: 0.4286\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.9184 - acc: 0.4286\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.9133 - acc: 0.4286\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.9064 - acc: 0.4286\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 0.9003 - acc: 0.4286\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.8936 - acc: 0.4286\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 0.8879 - acc: 0.4286\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.8839 - acc: 0.4286\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.8762 - acc: 0.4286\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.8709 - acc: 0.4286\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 0.8659 - acc: 0.4286\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 0.8579 - acc: 0.4286\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 0.8524 - acc: 0.4286\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 0.8467 - acc: 0.4286\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 0.8416 - acc: 0.4286\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 0.8352 - acc: 0.4286\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 0.8318 - acc: 0.4286\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 0.8242 - acc: 0.4286\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 0.8176 - acc: 0.4286\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 0.8128 - acc: 0.4286\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 0.8071 - acc: 0.4286\n",
      "Epoch 96/1000\n",
      " - 0s - loss: 0.8010 - acc: 0.4286\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 0.7953 - acc: 0.4286\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.7908 - acc: 0.4286\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 0.7854 - acc: 0.4286\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 0.7794 - acc: 0.4286\n",
      "Epoch 101/1000\n",
      " - 0s - loss: 0.7746 - acc: 0.4286\n",
      "Epoch 102/1000\n",
      " - 0s - loss: 0.7682 - acc: 0.4286\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 0.7633 - acc: 0.4286\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 0.7573 - acc: 0.4286\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 0.7528 - acc: 0.4286\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 0.7475 - acc: 0.4286\n",
      "Epoch 107/1000\n",
      " - 0s - loss: 0.7417 - acc: 0.4286\n",
      "Epoch 108/1000\n",
      " - 0s - loss: 0.7371 - acc: 0.4286\n",
      "Epoch 109/1000\n",
      " - 0s - loss: 0.7315 - acc: 0.4286\n",
      "Epoch 110/1000\n",
      " - 0s - loss: 0.7268 - acc: 0.4286\n",
      "Epoch 111/1000\n",
      " - 0s - loss: 0.7218 - acc: 0.4286\n",
      "Epoch 112/1000\n",
      " - 0s - loss: 0.7170 - acc: 0.4286\n",
      "Epoch 113/1000\n",
      " - 0s - loss: 0.7117 - acc: 0.4286\n",
      "Epoch 114/1000\n",
      " - 0s - loss: 0.7057 - acc: 0.4286\n",
      "Epoch 115/1000\n",
      " - 0s - loss: 0.7025 - acc: 0.4286\n",
      "Epoch 116/1000\n",
      " - 0s - loss: 0.6958 - acc: 0.4286\n",
      "Epoch 117/1000\n",
      " - 0s - loss: 0.6914 - acc: 0.4286\n",
      "Epoch 118/1000\n",
      " - 0s - loss: 0.6871 - acc: 0.4286\n",
      "Epoch 119/1000\n",
      " - 0s - loss: 0.6812 - acc: 0.4286\n",
      "Epoch 120/1000\n",
      " - 0s - loss: 0.6766 - acc: 0.4286\n",
      "Epoch 121/1000\n",
      " - 0s - loss: 0.6723 - acc: 0.4286\n",
      "Epoch 122/1000\n",
      " - 0s - loss: 0.6677 - acc: 0.4286\n",
      "Epoch 123/1000\n",
      " - 0s - loss: 0.6637 - acc: 0.4286\n",
      "Epoch 124/1000\n",
      " - 0s - loss: 0.6583 - acc: 0.4286\n",
      "Epoch 125/1000\n",
      " - 0s - loss: 0.6533 - acc: 0.4286\n",
      "Epoch 126/1000\n",
      " - 0s - loss: 0.6500 - acc: 0.4286\n",
      "Epoch 127/1000\n",
      " - 0s - loss: 0.6440 - acc: 0.4286\n",
      "Epoch 128/1000\n",
      " - 0s - loss: 0.6393 - acc: 0.4286\n",
      "Epoch 129/1000\n",
      " - 0s - loss: 0.6345 - acc: 0.4286\n",
      "Epoch 130/1000\n",
      " - 0s - loss: 0.6305 - acc: 0.4286\n",
      "Epoch 131/1000\n",
      " - 0s - loss: 0.6256 - acc: 0.4286\n",
      "Epoch 132/1000\n",
      " - 0s - loss: 0.6208 - acc: 0.4286\n",
      "Epoch 133/1000\n",
      " - 0s - loss: 0.6171 - acc: 0.4286\n",
      "Epoch 134/1000\n",
      " - 0s - loss: 0.6128 - acc: 0.3571\n",
      "Epoch 135/1000\n",
      " - 0s - loss: 0.6076 - acc: 0.3571\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.6035 - acc: 0.3571\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.5992 - acc: 0.3571\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.5967 - acc: 0.3571\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.5910 - acc: 0.3571\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.5877 - acc: 0.3571\n",
      "Epoch 141/1000\n",
      " - 0s - loss: 0.5821 - acc: 0.3571\n",
      "Epoch 142/1000\n",
      " - 0s - loss: 0.5773 - acc: 0.3571\n",
      "Epoch 143/1000\n",
      " - 0s - loss: 0.5744 - acc: 0.3571\n",
      "Epoch 144/1000\n",
      " - 0s - loss: 0.5693 - acc: 0.3571\n",
      "Epoch 145/1000\n",
      " - 0s - loss: 0.5662 - acc: 0.3571\n",
      "Epoch 146/1000\n",
      " - 0s - loss: 0.5611 - acc: 0.3571\n",
      "Epoch 147/1000\n",
      " - 0s - loss: 0.5570 - acc: 0.3571\n",
      "Epoch 148/1000\n",
      " - 0s - loss: 0.5548 - acc: 0.3571\n",
      "Epoch 149/1000\n",
      " - 0s - loss: 0.5492 - acc: 0.2857\n",
      "Epoch 150/1000\n",
      " - 0s - loss: 0.5457 - acc: 0.2857\n",
      "Epoch 151/1000\n",
      " - 0s - loss: 0.5411 - acc: 0.2857\n",
      "Epoch 152/1000\n",
      " - 0s - loss: 0.5375 - acc: 0.2857\n",
      "Epoch 153/1000\n",
      " - 0s - loss: 0.5336 - acc: 0.2857\n",
      "Epoch 154/1000\n",
      " - 0s - loss: 0.5292 - acc: 0.2857\n",
      "Epoch 155/1000\n",
      " - 0s - loss: 0.5252 - acc: 0.2857\n",
      "Epoch 156/1000\n",
      " - 0s - loss: 0.5226 - acc: 0.2857\n",
      "Epoch 157/1000\n",
      " - 0s - loss: 0.5183 - acc: 0.2857\n",
      "Epoch 158/1000\n",
      " - 0s - loss: 0.5140 - acc: 0.2857\n",
      "Epoch 159/1000\n",
      " - 0s - loss: 0.5117 - acc: 0.2857\n",
      "Epoch 160/1000\n",
      " - 0s - loss: 0.5070 - acc: 0.2857\n",
      "Epoch 161/1000\n",
      " - 0s - loss: 0.5031 - acc: 0.2857\n",
      "Epoch 162/1000\n",
      " - 0s - loss: 0.4999 - acc: 0.2857\n",
      "Epoch 163/1000\n",
      " - 0s - loss: 0.4980 - acc: 0.2857\n",
      "Epoch 164/1000\n",
      " - 0s - loss: 0.4931 - acc: 0.2857\n",
      "Epoch 165/1000\n",
      " - 0s - loss: 0.4895 - acc: 0.2857\n",
      "Epoch 166/1000\n",
      " - 0s - loss: 0.4848 - acc: 0.2857\n",
      "Epoch 167/1000\n",
      " - 0s - loss: 0.4822 - acc: 0.2857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      " - 0s - loss: 0.4781 - acc: 0.2857\n",
      "Epoch 169/1000\n",
      " - 0s - loss: 0.4757 - acc: 0.2857\n",
      "Epoch 170/1000\n",
      " - 0s - loss: 0.4722 - acc: 0.2857\n",
      "Epoch 171/1000\n",
      " - 0s - loss: 0.4684 - acc: 0.2857\n",
      "Epoch 172/1000\n",
      " - 0s - loss: 0.4654 - acc: 0.2857\n",
      "Epoch 173/1000\n",
      " - 0s - loss: 0.4621 - acc: 0.2857\n",
      "Epoch 174/1000\n",
      " - 0s - loss: 0.4583 - acc: 0.2857\n",
      "Epoch 175/1000\n",
      " - 0s - loss: 0.4550 - acc: 0.2857\n",
      "Epoch 176/1000\n",
      " - 0s - loss: 0.4532 - acc: 0.2857\n",
      "Epoch 177/1000\n",
      " - 0s - loss: 0.4489 - acc: 0.3571\n",
      "Epoch 178/1000\n",
      " - 0s - loss: 0.4456 - acc: 0.3571\n",
      "Epoch 179/1000\n",
      " - 0s - loss: 0.4421 - acc: 0.3571\n",
      "Epoch 180/1000\n",
      " - 0s - loss: 0.4390 - acc: 0.4286\n",
      "Epoch 181/1000\n",
      " - 0s - loss: 0.4365 - acc: 0.4286\n",
      "Epoch 182/1000\n",
      " - 0s - loss: 0.4331 - acc: 0.4286\n",
      "Epoch 183/1000\n",
      " - 0s - loss: 0.4300 - acc: 0.4286\n",
      "Epoch 184/1000\n",
      " - 0s - loss: 0.4272 - acc: 0.4286\n",
      "Epoch 185/1000\n",
      " - 0s - loss: 0.4243 - acc: 0.4286\n",
      "Epoch 186/1000\n",
      " - 0s - loss: 0.4213 - acc: 0.4286\n",
      "Epoch 187/1000\n",
      " - 0s - loss: 0.4198 - acc: 0.4286\n",
      "Epoch 188/1000\n",
      " - 0s - loss: 0.4156 - acc: 0.4286\n",
      "Epoch 189/1000\n",
      " - 0s - loss: 0.4127 - acc: 0.4286\n",
      "Epoch 190/1000\n",
      " - 0s - loss: 0.4104 - acc: 0.4286\n",
      "Epoch 191/1000\n",
      " - 0s - loss: 0.4072 - acc: 0.4286\n",
      "Epoch 192/1000\n",
      " - 0s - loss: 0.4049 - acc: 0.4286\n",
      "Epoch 193/1000\n",
      " - 0s - loss: 0.4017 - acc: 0.4286\n",
      "Epoch 194/1000\n",
      " - 0s - loss: 0.4002 - acc: 0.4286\n",
      "Epoch 195/1000\n",
      " - 0s - loss: 0.3972 - acc: 0.4286\n",
      "Epoch 196/1000\n",
      " - 0s - loss: 0.3932 - acc: 0.4286\n",
      "Epoch 197/1000\n",
      " - 0s - loss: 0.3912 - acc: 0.4286\n",
      "Epoch 198/1000\n",
      " - 0s - loss: 0.3883 - acc: 0.4286\n",
      "Epoch 199/1000\n",
      " - 0s - loss: 0.3875 - acc: 0.4286\n",
      "Epoch 200/1000\n",
      " - 0s - loss: 0.3836 - acc: 0.4286\n",
      "Epoch 201/1000\n",
      " - 0s - loss: 0.3805 - acc: 0.4286\n",
      "Epoch 202/1000\n",
      " - 0s - loss: 0.3784 - acc: 0.4286\n",
      "Epoch 203/1000\n",
      " - 0s - loss: 0.3762 - acc: 0.4286\n",
      "Epoch 204/1000\n",
      " - 0s - loss: 0.3733 - acc: 0.4286\n",
      "Epoch 205/1000\n",
      " - 0s - loss: 0.3708 - acc: 0.4286\n",
      "Epoch 206/1000\n",
      " - 0s - loss: 0.3687 - acc: 0.4286\n",
      "Epoch 207/1000\n",
      " - 0s - loss: 0.3657 - acc: 0.4286\n",
      "Epoch 208/1000\n",
      " - 0s - loss: 0.3643 - acc: 0.4286\n",
      "Epoch 209/1000\n",
      " - 0s - loss: 0.3627 - acc: 0.4286\n",
      "Epoch 210/1000\n",
      " - 0s - loss: 0.3596 - acc: 0.4286\n",
      "Epoch 211/1000\n",
      " - 0s - loss: 0.3573 - acc: 0.4286\n",
      "Epoch 212/1000\n",
      " - 0s - loss: 0.3546 - acc: 0.4286\n",
      "Epoch 213/1000\n",
      " - 0s - loss: 0.3524 - acc: 0.4286\n",
      "Epoch 214/1000\n",
      " - 0s - loss: 0.3501 - acc: 0.4286\n",
      "Epoch 215/1000\n",
      " - 0s - loss: 0.3479 - acc: 0.4286\n",
      "Epoch 216/1000\n",
      " - 0s - loss: 0.3457 - acc: 0.4286\n",
      "Epoch 217/1000\n",
      " - 0s - loss: 0.3437 - acc: 0.4286\n",
      "Epoch 218/1000\n",
      " - 0s - loss: 0.3413 - acc: 0.4286\n",
      "Epoch 219/1000\n",
      " - 0s - loss: 0.3396 - acc: 0.4286\n",
      "Epoch 220/1000\n",
      " - 0s - loss: 0.3380 - acc: 0.4286\n",
      "Epoch 221/1000\n",
      " - 0s - loss: 0.3381 - acc: 0.4286\n",
      "Epoch 222/1000\n",
      " - 0s - loss: 0.3339 - acc: 0.4286\n",
      "Epoch 223/1000\n",
      " - 0s - loss: 0.3316 - acc: 0.4286\n",
      "Epoch 224/1000\n",
      " - 0s - loss: 0.3291 - acc: 0.4286\n",
      "Epoch 225/1000\n",
      " - 0s - loss: 0.3280 - acc: 0.4286\n",
      "Epoch 226/1000\n",
      " - 0s - loss: 0.3259 - acc: 0.4286\n",
      "Epoch 227/1000\n",
      " - 0s - loss: 0.3239 - acc: 0.4286\n",
      "Epoch 228/1000\n",
      " - 0s - loss: 0.3220 - acc: 0.4286\n",
      "Epoch 229/1000\n",
      " - 0s - loss: 0.3196 - acc: 0.4286\n",
      "Epoch 230/1000\n",
      " - 0s - loss: 0.3184 - acc: 0.4286\n",
      "Epoch 231/1000\n",
      " - 0s - loss: 0.3164 - acc: 0.4286\n",
      "Epoch 232/1000\n",
      " - 0s - loss: 0.3143 - acc: 0.4286\n",
      "Epoch 233/1000\n",
      " - 0s - loss: 0.3126 - acc: 0.5000\n",
      "Epoch 234/1000\n",
      " - 0s - loss: 0.3115 - acc: 0.5000\n",
      "Epoch 235/1000\n",
      " - 0s - loss: 0.3101 - acc: 0.5000\n",
      "Epoch 236/1000\n",
      " - 0s - loss: 0.3081 - acc: 0.5000\n",
      "Epoch 237/1000\n",
      " - 0s - loss: 0.3055 - acc: 0.5000\n",
      "Epoch 238/1000\n",
      " - 0s - loss: 0.3047 - acc: 0.5000\n",
      "Epoch 239/1000\n",
      " - 0s - loss: 0.3021 - acc: 0.5714\n",
      "Epoch 240/1000\n",
      " - 0s - loss: 0.3003 - acc: 0.5714\n",
      "Epoch 241/1000\n",
      " - 0s - loss: 0.2997 - acc: 0.5714\n",
      "Epoch 242/1000\n",
      " - 0s - loss: 0.2975 - acc: 0.5714\n",
      "Epoch 243/1000\n",
      " - 0s - loss: 0.2959 - acc: 0.5714\n",
      "Epoch 244/1000\n",
      " - 0s - loss: 0.2939 - acc: 0.5714\n",
      "Epoch 245/1000\n",
      " - 0s - loss: 0.2928 - acc: 0.5714\n",
      "Epoch 246/1000\n",
      " - 0s - loss: 0.2912 - acc: 0.5714\n",
      "Epoch 247/1000\n",
      " - 0s - loss: 0.2894 - acc: 0.5714\n",
      "Epoch 248/1000\n",
      " - 0s - loss: 0.2880 - acc: 0.5714\n",
      "Epoch 249/1000\n",
      " - 0s - loss: 0.2867 - acc: 0.5714\n",
      "Epoch 250/1000\n",
      " - 0s - loss: 0.2851 - acc: 0.5714\n",
      "Epoch 251/1000\n",
      " - 0s - loss: 0.2835 - acc: 0.5714\n",
      "Epoch 252/1000\n",
      " - 0s - loss: 0.2825 - acc: 0.5714\n",
      "Epoch 253/1000\n",
      " - 0s - loss: 0.2810 - acc: 0.5714\n",
      "Epoch 254/1000\n",
      " - 0s - loss: 0.2793 - acc: 0.5714\n",
      "Epoch 255/1000\n",
      " - 0s - loss: 0.2778 - acc: 0.5714\n",
      "Epoch 256/1000\n",
      " - 0s - loss: 0.2773 - acc: 0.5714\n",
      "Epoch 257/1000\n",
      " - 0s - loss: 0.2751 - acc: 0.5714\n",
      "Epoch 258/1000\n",
      " - 0s - loss: 0.2738 - acc: 0.5714\n",
      "Epoch 259/1000\n",
      " - 0s - loss: 0.2727 - acc: 0.5714\n",
      "Epoch 260/1000\n",
      " - 0s - loss: 0.2709 - acc: 0.5714\n",
      "Epoch 261/1000\n",
      " - 0s - loss: 0.2709 - acc: 0.5714\n",
      "Epoch 262/1000\n",
      " - 0s - loss: 0.2683 - acc: 0.5714\n",
      "Epoch 263/1000\n",
      " - 0s - loss: 0.2669 - acc: 0.5714\n",
      "Epoch 264/1000\n",
      " - 0s - loss: 0.2657 - acc: 0.5714\n",
      "Epoch 265/1000\n",
      " - 0s - loss: 0.2645 - acc: 0.5714\n",
      "Epoch 266/1000\n",
      " - 0s - loss: 0.2635 - acc: 0.5714\n",
      "Epoch 267/1000\n",
      " - 0s - loss: 0.2623 - acc: 0.5714\n",
      "Epoch 268/1000\n",
      " - 0s - loss: 0.2608 - acc: 0.5714\n",
      "Epoch 269/1000\n",
      " - 0s - loss: 0.2596 - acc: 0.5714\n",
      "Epoch 270/1000\n",
      " - 0s - loss: 0.2583 - acc: 0.5714\n",
      "Epoch 271/1000\n",
      " - 0s - loss: 0.2574 - acc: 0.5714\n",
      "Epoch 272/1000\n",
      " - 0s - loss: 0.2565 - acc: 0.5714\n",
      "Epoch 273/1000\n",
      " - 0s - loss: 0.2550 - acc: 0.5714\n",
      "Epoch 274/1000\n",
      " - 0s - loss: 0.2552 - acc: 0.5714\n",
      "Epoch 275/1000\n",
      " - 0s - loss: 0.2529 - acc: 0.5714\n",
      "Epoch 276/1000\n",
      " - 0s - loss: 0.2518 - acc: 0.5714\n",
      "Epoch 277/1000\n",
      " - 0s - loss: 0.2507 - acc: 0.5714\n",
      "Epoch 278/1000\n",
      " - 0s - loss: 0.2497 - acc: 0.5714\n",
      "Epoch 279/1000\n",
      " - 0s - loss: 0.2489 - acc: 0.5714\n",
      "Epoch 280/1000\n",
      " - 0s - loss: 0.2474 - acc: 0.5714\n",
      "Epoch 281/1000\n",
      " - 0s - loss: 0.2461 - acc: 0.5714\n",
      "Epoch 282/1000\n",
      " - 0s - loss: 0.2451 - acc: 0.5714\n",
      "Epoch 283/1000\n",
      " - 0s - loss: 0.2441 - acc: 0.5714\n",
      "Epoch 284/1000\n",
      " - 0s - loss: 0.2427 - acc: 0.5714\n",
      "Epoch 285/1000\n",
      " - 0s - loss: 0.2423 - acc: 0.5714\n",
      "Epoch 286/1000\n",
      " - 0s - loss: 0.2405 - acc: 0.5714\n",
      "Epoch 287/1000\n",
      " - 0s - loss: 0.2399 - acc: 0.5714\n",
      "Epoch 288/1000\n",
      " - 0s - loss: 0.2388 - acc: 0.5714\n",
      "Epoch 289/1000\n",
      " - 0s - loss: 0.2377 - acc: 0.5714\n",
      "Epoch 290/1000\n",
      " - 0s - loss: 0.2369 - acc: 0.5714\n",
      "Epoch 291/1000\n",
      " - 0s - loss: 0.2363 - acc: 0.5714\n",
      "Epoch 292/1000\n",
      " - 0s - loss: 0.2348 - acc: 0.5714\n",
      "Epoch 293/1000\n",
      " - 0s - loss: 0.2340 - acc: 0.5714\n",
      "Epoch 294/1000\n",
      " - 0s - loss: 0.2327 - acc: 0.5714\n",
      "Epoch 295/1000\n",
      " - 0s - loss: 0.2319 - acc: 0.5714\n",
      "Epoch 296/1000\n",
      " - 0s - loss: 0.2310 - acc: 0.5714\n",
      "Epoch 297/1000\n",
      " - 0s - loss: 0.2299 - acc: 0.5714\n",
      "Epoch 298/1000\n",
      " - 0s - loss: 0.2290 - acc: 0.5714\n",
      "Epoch 299/1000\n",
      " - 0s - loss: 0.2282 - acc: 0.5714\n",
      "Epoch 300/1000\n",
      " - 0s - loss: 0.2272 - acc: 0.5714\n",
      "Epoch 301/1000\n",
      " - 0s - loss: 0.2264 - acc: 0.5714\n",
      "Epoch 302/1000\n",
      " - 0s - loss: 0.2253 - acc: 0.5714\n",
      "Epoch 303/1000\n",
      " - 0s - loss: 0.2246 - acc: 0.5714\n",
      "Epoch 304/1000\n",
      " - 0s - loss: 0.2235 - acc: 0.5714\n",
      "Epoch 305/1000\n",
      " - 0s - loss: 0.2227 - acc: 0.5714\n",
      "Epoch 306/1000\n",
      " - 0s - loss: 0.2226 - acc: 0.5714\n",
      "Epoch 307/1000\n",
      " - 0s - loss: 0.2215 - acc: 0.5714\n",
      "Epoch 308/1000\n",
      " - 0s - loss: 0.2205 - acc: 0.5714\n",
      "Epoch 309/1000\n",
      " - 0s - loss: 0.2195 - acc: 0.5714\n",
      "Epoch 310/1000\n",
      " - 0s - loss: 0.2184 - acc: 0.5714\n",
      "Epoch 311/1000\n",
      " - 0s - loss: 0.2176 - acc: 0.5714\n",
      "Epoch 312/1000\n",
      " - 0s - loss: 0.2174 - acc: 0.5714\n",
      "Epoch 313/1000\n",
      " - 0s - loss: 0.2160 - acc: 0.5714\n",
      "Epoch 314/1000\n",
      " - 0s - loss: 0.2158 - acc: 0.5714\n",
      "Epoch 315/1000\n",
      " - 0s - loss: 0.2149 - acc: 0.5714\n",
      "Epoch 316/1000\n",
      " - 0s - loss: 0.2140 - acc: 0.5714\n",
      "Epoch 317/1000\n",
      " - 0s - loss: 0.2128 - acc: 0.5714\n",
      "Epoch 318/1000\n",
      " - 0s - loss: 0.2122 - acc: 0.5714\n",
      "Epoch 319/1000\n",
      " - 0s - loss: 0.2114 - acc: 0.5714\n",
      "Epoch 320/1000\n",
      " - 0s - loss: 0.2109 - acc: 0.5714\n",
      "Epoch 321/1000\n",
      " - 0s - loss: 0.2101 - acc: 0.5714\n",
      "Epoch 322/1000\n",
      " - 0s - loss: 0.2089 - acc: 0.5714\n",
      "Epoch 323/1000\n",
      " - 0s - loss: 0.2083 - acc: 0.5714\n",
      "Epoch 324/1000\n",
      " - 0s - loss: 0.2077 - acc: 0.5714\n",
      "Epoch 325/1000\n",
      " - 0s - loss: 0.2069 - acc: 0.5714\n",
      "Epoch 326/1000\n",
      " - 0s - loss: 0.2062 - acc: 0.5714\n",
      "Epoch 327/1000\n",
      " - 0s - loss: 0.2053 - acc: 0.5714\n",
      "Epoch 328/1000\n",
      " - 0s - loss: 0.2045 - acc: 0.5714\n",
      "Epoch 329/1000\n",
      " - 0s - loss: 0.2038 - acc: 0.5714\n",
      "Epoch 330/1000\n",
      " - 0s - loss: 0.2030 - acc: 0.5714\n",
      "Epoch 331/1000\n",
      " - 0s - loss: 0.2026 - acc: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/1000\n",
      " - 0s - loss: 0.2018 - acc: 0.5714\n",
      "Epoch 333/1000\n",
      " - 0s - loss: 0.2009 - acc: 0.5714\n",
      "Epoch 334/1000\n",
      " - 0s - loss: 0.2002 - acc: 0.5714\n",
      "Epoch 335/1000\n",
      " - 0s - loss: 0.1995 - acc: 0.5714\n",
      "Epoch 336/1000\n",
      " - 0s - loss: 0.1988 - acc: 0.5714\n",
      "Epoch 337/1000\n",
      " - 0s - loss: 0.1983 - acc: 0.5714\n",
      "Epoch 338/1000\n",
      " - 0s - loss: 0.1974 - acc: 0.5714\n",
      "Epoch 339/1000\n",
      " - 0s - loss: 0.1966 - acc: 0.5714\n",
      "Epoch 340/1000\n",
      " - 0s - loss: 0.1959 - acc: 0.5714\n",
      "Epoch 341/1000\n",
      " - 0s - loss: 0.1954 - acc: 0.5714\n",
      "Epoch 342/1000\n",
      " - 0s - loss: 0.1947 - acc: 0.5714\n",
      "Epoch 343/1000\n",
      " - 0s - loss: 0.1938 - acc: 0.5714\n",
      "Epoch 344/1000\n",
      " - 0s - loss: 0.1933 - acc: 0.5714\n",
      "Epoch 345/1000\n",
      " - 0s - loss: 0.1925 - acc: 0.5714\n",
      "Epoch 346/1000\n",
      " - 0s - loss: 0.1921 - acc: 0.5714\n",
      "Epoch 347/1000\n",
      " - 0s - loss: 0.1919 - acc: 0.5714\n",
      "Epoch 348/1000\n",
      " - 0s - loss: 0.1910 - acc: 0.5714\n",
      "Epoch 349/1000\n",
      " - 0s - loss: 0.1902 - acc: 0.5714\n",
      "Epoch 350/1000\n",
      " - 0s - loss: 0.1895 - acc: 0.5714\n",
      "Epoch 351/1000\n",
      " - 0s - loss: 0.1890 - acc: 0.5714\n",
      "Epoch 352/1000\n",
      " - 0s - loss: 0.1880 - acc: 0.5714\n",
      "Epoch 353/1000\n",
      " - 0s - loss: 0.1875 - acc: 0.5714\n",
      "Epoch 354/1000\n",
      " - 0s - loss: 0.1878 - acc: 0.5714\n",
      "Epoch 355/1000\n",
      " - 0s - loss: 0.1859 - acc: 0.5714\n",
      "Epoch 356/1000\n",
      " - 0s - loss: 0.1860 - acc: 0.5714\n",
      "Epoch 357/1000\n",
      " - 0s - loss: 0.1849 - acc: 0.5714\n",
      "Epoch 358/1000\n",
      " - 0s - loss: 0.1843 - acc: 0.5714\n",
      "Epoch 359/1000\n",
      " - 0s - loss: 0.1837 - acc: 0.5714\n",
      "Epoch 360/1000\n",
      " - 0s - loss: 0.1830 - acc: 0.5714\n",
      "Epoch 361/1000\n",
      " - 0s - loss: 0.1824 - acc: 0.5714\n",
      "Epoch 362/1000\n",
      " - 0s - loss: 0.1818 - acc: 0.5714\n",
      "Epoch 363/1000\n",
      " - 0s - loss: 0.1813 - acc: 0.5714\n",
      "Epoch 364/1000\n",
      " - 0s - loss: 0.1810 - acc: 0.5714\n",
      "Epoch 365/1000\n",
      " - 0s - loss: 0.1802 - acc: 0.5714\n",
      "Epoch 366/1000\n",
      " - 0s - loss: 0.1799 - acc: 0.5714\n",
      "Epoch 367/1000\n",
      " - 0s - loss: 0.1791 - acc: 0.5714\n",
      "Epoch 368/1000\n",
      " - 0s - loss: 0.1785 - acc: 0.5714\n",
      "Epoch 369/1000\n",
      " - 0s - loss: 0.1776 - acc: 0.5714\n",
      "Epoch 370/1000\n",
      " - 0s - loss: 0.1774 - acc: 0.5714\n",
      "Epoch 371/1000\n",
      " - 0s - loss: 0.1766 - acc: 0.5714\n",
      "Epoch 372/1000\n",
      " - 0s - loss: 0.1760 - acc: 0.5714\n",
      "Epoch 373/1000\n",
      " - 0s - loss: 0.1764 - acc: 0.5714\n",
      "Epoch 374/1000\n",
      " - 0s - loss: 0.1753 - acc: 0.5714\n",
      "Epoch 375/1000\n",
      " - 0s - loss: 0.1743 - acc: 0.5714\n",
      "Epoch 376/1000\n",
      " - 0s - loss: 0.1737 - acc: 0.5714\n",
      "Epoch 377/1000\n",
      " - 0s - loss: 0.1732 - acc: 0.5714\n",
      "Epoch 378/1000\n",
      " - 0s - loss: 0.1727 - acc: 0.5714\n",
      "Epoch 379/1000\n",
      " - 0s - loss: 0.1724 - acc: 0.5714\n",
      "Epoch 380/1000\n",
      " - 0s - loss: 0.1715 - acc: 0.5714\n",
      "Epoch 381/1000\n",
      " - 0s - loss: 0.1709 - acc: 0.5714\n",
      "Epoch 382/1000\n",
      " - 0s - loss: 0.1705 - acc: 0.5714\n",
      "Epoch 383/1000\n",
      " - 0s - loss: 0.1698 - acc: 0.5714\n",
      "Epoch 384/1000\n",
      " - 0s - loss: 0.1699 - acc: 0.5714\n",
      "Epoch 385/1000\n",
      " - 0s - loss: 0.1692 - acc: 0.5714\n",
      "Epoch 386/1000\n",
      " - 0s - loss: 0.1684 - acc: 0.5714\n",
      "Epoch 387/1000\n",
      " - 0s - loss: 0.1677 - acc: 0.5714\n",
      "Epoch 388/1000\n",
      " - 0s - loss: 0.1671 - acc: 0.5714\n",
      "Epoch 389/1000\n",
      " - 0s - loss: 0.1667 - acc: 0.5714\n",
      "Epoch 390/1000\n",
      " - 0s - loss: 0.1664 - acc: 0.5714\n",
      "Epoch 391/1000\n",
      " - 0s - loss: 0.1658 - acc: 0.5714\n",
      "Epoch 392/1000\n",
      " - 0s - loss: 0.1652 - acc: 0.6429\n",
      "Epoch 393/1000\n",
      " - 0s - loss: 0.1650 - acc: 0.6429\n",
      "Epoch 394/1000\n",
      " - 0s - loss: 0.1639 - acc: 0.6429\n",
      "Epoch 395/1000\n",
      " - 0s - loss: 0.1639 - acc: 0.6429\n",
      "Epoch 396/1000\n",
      " - 0s - loss: 0.1629 - acc: 0.6429\n",
      "Epoch 397/1000\n",
      " - 0s - loss: 0.1629 - acc: 0.6429\n",
      "Epoch 398/1000\n",
      " - 0s - loss: 0.1621 - acc: 0.6429\n",
      "Epoch 399/1000\n",
      " - 0s - loss: 0.1617 - acc: 0.6429\n",
      "Epoch 400/1000\n",
      " - 0s - loss: 0.1613 - acc: 0.6429\n",
      "Epoch 401/1000\n",
      " - 0s - loss: 0.1607 - acc: 0.6429\n",
      "Epoch 402/1000\n",
      " - 0s - loss: 0.1608 - acc: 0.6429\n",
      "Epoch 403/1000\n",
      " - 0s - loss: 0.1594 - acc: 0.6429\n",
      "Epoch 404/1000\n",
      " - 0s - loss: 0.1590 - acc: 0.6429\n",
      "Epoch 405/1000\n",
      " - 0s - loss: 0.1585 - acc: 0.6429\n",
      "Epoch 406/1000\n",
      " - 0s - loss: 0.1584 - acc: 0.6429\n",
      "Epoch 407/1000\n",
      " - 0s - loss: 0.1576 - acc: 0.6429\n",
      "Epoch 408/1000\n",
      " - 0s - loss: 0.1571 - acc: 0.6429\n",
      "Epoch 409/1000\n",
      " - 0s - loss: 0.1573 - acc: 0.6429\n",
      "Epoch 410/1000\n",
      " - 0s - loss: 0.1560 - acc: 0.6429\n",
      "Epoch 411/1000\n",
      " - 0s - loss: 0.1557 - acc: 0.6429\n",
      "Epoch 412/1000\n",
      " - 0s - loss: 0.1550 - acc: 0.6429\n",
      "Epoch 413/1000\n",
      " - 0s - loss: 0.1547 - acc: 0.6429\n",
      "Epoch 414/1000\n",
      " - 0s - loss: 0.1543 - acc: 0.6429\n",
      "Epoch 415/1000\n",
      " - 0s - loss: 0.1536 - acc: 0.6429\n",
      "Epoch 416/1000\n",
      " - 0s - loss: 0.1530 - acc: 0.6429\n",
      "Epoch 417/1000\n",
      " - 0s - loss: 0.1526 - acc: 0.6429\n",
      "Epoch 418/1000\n",
      " - 0s - loss: 0.1522 - acc: 0.6429\n",
      "Epoch 419/1000\n",
      " - 0s - loss: 0.1522 - acc: 0.6429\n",
      "Epoch 420/1000\n",
      " - 0s - loss: 0.1512 - acc: 0.6429\n",
      "Epoch 421/1000\n",
      " - 0s - loss: 0.1508 - acc: 0.6429\n",
      "Epoch 422/1000\n",
      " - 0s - loss: 0.1502 - acc: 0.6429\n",
      "Epoch 423/1000\n",
      " - 0s - loss: 0.1502 - acc: 0.6429\n",
      "Epoch 424/1000\n",
      " - 0s - loss: 0.1494 - acc: 0.6429\n",
      "Epoch 425/1000\n",
      " - 0s - loss: 0.1489 - acc: 0.6429\n",
      "Epoch 426/1000\n",
      " - 0s - loss: 0.1485 - acc: 0.6429\n",
      "Epoch 427/1000\n",
      " - 0s - loss: 0.1484 - acc: 0.6429\n",
      "Epoch 428/1000\n",
      " - 0s - loss: 0.1477 - acc: 0.6429\n",
      "Epoch 429/1000\n",
      " - 0s - loss: 0.1472 - acc: 0.6429\n",
      "Epoch 430/1000\n",
      " - 0s - loss: 0.1467 - acc: 0.6429\n",
      "Epoch 431/1000\n",
      " - 0s - loss: 0.1464 - acc: 0.6429\n",
      "Epoch 432/1000\n",
      " - 0s - loss: 0.1459 - acc: 0.6429\n",
      "Epoch 433/1000\n",
      " - 0s - loss: 0.1454 - acc: 0.6429\n",
      "Epoch 434/1000\n",
      " - 0s - loss: 0.1453 - acc: 0.6429\n",
      "Epoch 435/1000\n",
      " - 0s - loss: 0.1448 - acc: 0.7143\n",
      "Epoch 436/1000\n",
      " - 0s - loss: 0.1439 - acc: 0.7143\n",
      "Epoch 437/1000\n",
      " - 0s - loss: 0.1436 - acc: 0.7143\n",
      "Epoch 438/1000\n",
      " - 0s - loss: 0.1433 - acc: 0.7143\n",
      "Epoch 439/1000\n",
      " - 0s - loss: 0.1433 - acc: 0.7143\n",
      "Epoch 440/1000\n",
      " - 0s - loss: 0.1422 - acc: 0.7143\n",
      "Epoch 441/1000\n",
      " - 0s - loss: 0.1419 - acc: 0.7143\n",
      "Epoch 442/1000\n",
      " - 0s - loss: 0.1414 - acc: 0.7143\n",
      "Epoch 443/1000\n",
      " - 0s - loss: 0.1411 - acc: 0.7857\n",
      "Epoch 444/1000\n",
      " - 0s - loss: 0.1407 - acc: 0.7143\n",
      "Epoch 445/1000\n",
      " - 0s - loss: 0.1400 - acc: 0.7143\n",
      "Epoch 446/1000\n",
      " - 0s - loss: 0.1397 - acc: 0.7143\n",
      "Epoch 447/1000\n",
      " - 0s - loss: 0.1393 - acc: 0.7857\n",
      "Epoch 448/1000\n",
      " - 0s - loss: 0.1389 - acc: 0.7857\n",
      "Epoch 449/1000\n",
      " - 0s - loss: 0.1387 - acc: 0.7857\n",
      "Epoch 450/1000\n",
      " - 0s - loss: 0.1380 - acc: 0.7857\n",
      "Epoch 451/1000\n",
      " - 0s - loss: 0.1376 - acc: 0.7857\n",
      "Epoch 452/1000\n",
      " - 0s - loss: 0.1372 - acc: 0.7857\n",
      "Epoch 453/1000\n",
      " - 0s - loss: 0.1368 - acc: 0.7857\n",
      "Epoch 454/1000\n",
      " - 0s - loss: 0.1364 - acc: 0.7857\n",
      "Epoch 455/1000\n",
      " - 0s - loss: 0.1362 - acc: 0.7857\n",
      "Epoch 456/1000\n",
      " - 0s - loss: 0.1362 - acc: 0.7857\n",
      "Epoch 457/1000\n",
      " - 0s - loss: 0.1351 - acc: 0.7857\n",
      "Epoch 458/1000\n",
      " - 0s - loss: 0.1349 - acc: 0.7857\n",
      "Epoch 459/1000\n",
      " - 0s - loss: 0.1344 - acc: 0.7857\n",
      "Epoch 460/1000\n",
      " - 0s - loss: 0.1339 - acc: 0.7857\n",
      "Epoch 461/1000\n",
      " - 0s - loss: 0.1336 - acc: 0.7857\n",
      "Epoch 462/1000\n",
      " - 0s - loss: 0.1333 - acc: 0.7857\n",
      "Epoch 463/1000\n",
      " - 0s - loss: 0.1327 - acc: 0.7857\n",
      "Epoch 464/1000\n",
      " - 0s - loss: 0.1326 - acc: 0.7857\n",
      "Epoch 465/1000\n",
      " - 0s - loss: 0.1318 - acc: 0.7857\n",
      "Epoch 466/1000\n",
      " - 0s - loss: 0.1315 - acc: 0.7857\n",
      "Epoch 467/1000\n",
      " - 0s - loss: 0.1314 - acc: 0.7857\n",
      "Epoch 468/1000\n",
      " - 0s - loss: 0.1315 - acc: 0.7857\n",
      "Epoch 469/1000\n",
      " - 0s - loss: 0.1306 - acc: 0.7857\n",
      "Epoch 470/1000\n",
      " - 0s - loss: 0.1300 - acc: 0.7857\n",
      "Epoch 471/1000\n",
      " - 0s - loss: 0.1296 - acc: 0.8571\n",
      "Epoch 472/1000\n",
      " - 0s - loss: 0.1291 - acc: 0.7857\n",
      "Epoch 473/1000\n",
      " - 0s - loss: 0.1289 - acc: 0.7857\n",
      "Epoch 474/1000\n",
      " - 0s - loss: 0.1284 - acc: 0.8571\n",
      "Epoch 475/1000\n",
      " - 0s - loss: 0.1280 - acc: 0.8571\n",
      "Epoch 476/1000\n",
      " - 0s - loss: 0.1277 - acc: 0.8571\n",
      "Epoch 477/1000\n",
      " - 0s - loss: 0.1272 - acc: 0.8571\n",
      "Epoch 478/1000\n",
      " - 0s - loss: 0.1271 - acc: 0.8571\n",
      "Epoch 479/1000\n",
      " - 0s - loss: 0.1264 - acc: 0.8571\n",
      "Epoch 480/1000\n",
      " - 0s - loss: 0.1262 - acc: 0.8571\n",
      "Epoch 481/1000\n",
      " - 0s - loss: 0.1260 - acc: 0.8571\n",
      "Epoch 482/1000\n",
      " - 0s - loss: 0.1255 - acc: 0.8571\n",
      "Epoch 483/1000\n",
      " - 0s - loss: 0.1252 - acc: 0.8571\n",
      "Epoch 484/1000\n",
      " - 0s - loss: 0.1245 - acc: 0.8571\n",
      "Epoch 485/1000\n",
      " - 0s - loss: 0.1242 - acc: 0.8571\n",
      "Epoch 486/1000\n",
      " - 0s - loss: 0.1238 - acc: 0.8571\n",
      "Epoch 487/1000\n",
      " - 0s - loss: 0.1235 - acc: 0.8571\n",
      "Epoch 488/1000\n",
      " - 0s - loss: 0.1230 - acc: 0.8571\n",
      "Epoch 489/1000\n",
      " - 0s - loss: 0.1229 - acc: 0.8571\n",
      "Epoch 490/1000\n",
      " - 0s - loss: 0.1224 - acc: 0.8571\n",
      "Epoch 491/1000\n",
      " - 0s - loss: 0.1223 - acc: 0.8571\n",
      "Epoch 492/1000\n",
      " - 0s - loss: 0.1217 - acc: 0.8571\n",
      "Epoch 493/1000\n",
      " - 0s - loss: 0.1212 - acc: 0.8571\n",
      "Epoch 494/1000\n",
      " - 0s - loss: 0.1208 - acc: 0.8571\n",
      "Epoch 495/1000\n",
      " - 0s - loss: 0.1206 - acc: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/1000\n",
      " - 0s - loss: 0.1200 - acc: 0.8571\n",
      "Epoch 497/1000\n",
      " - 0s - loss: 0.1201 - acc: 0.8571\n",
      "Epoch 498/1000\n",
      " - 0s - loss: 0.1199 - acc: 0.8571\n",
      "Epoch 499/1000\n",
      " - 0s - loss: 0.1191 - acc: 0.8571\n",
      "Epoch 500/1000\n",
      " - 0s - loss: 0.1187 - acc: 0.8571\n",
      "Epoch 501/1000\n",
      " - 0s - loss: 0.1183 - acc: 0.8571\n",
      "Epoch 502/1000\n",
      " - 0s - loss: 0.1182 - acc: 0.8571\n",
      "Epoch 503/1000\n",
      " - 0s - loss: 0.1177 - acc: 0.8571\n",
      "Epoch 504/1000\n",
      " - 0s - loss: 0.1173 - acc: 0.8571\n",
      "Epoch 505/1000\n",
      " - 0s - loss: 0.1169 - acc: 0.8571\n",
      "Epoch 506/1000\n",
      " - 0s - loss: 0.1165 - acc: 0.8571\n",
      "Epoch 507/1000\n",
      " - 0s - loss: 0.1162 - acc: 0.8571\n",
      "Epoch 508/1000\n",
      " - 0s - loss: 0.1164 - acc: 0.8571\n",
      "Epoch 509/1000\n",
      " - 0s - loss: 0.1155 - acc: 0.8571\n",
      "Epoch 510/1000\n",
      " - 0s - loss: 0.1154 - acc: 0.8571\n",
      "Epoch 511/1000\n",
      " - 0s - loss: 0.1149 - acc: 0.8571\n",
      "Epoch 512/1000\n",
      " - 0s - loss: 0.1145 - acc: 0.8571\n",
      "Epoch 513/1000\n",
      " - 0s - loss: 0.1143 - acc: 0.8571\n",
      "Epoch 514/1000\n",
      " - 0s - loss: 0.1138 - acc: 0.8571\n",
      "Epoch 515/1000\n",
      " - 0s - loss: 0.1137 - acc: 0.8571\n",
      "Epoch 516/1000\n",
      " - 0s - loss: 0.1132 - acc: 0.8571\n",
      "Epoch 517/1000\n",
      " - 0s - loss: 0.1128 - acc: 0.8571\n",
      "Epoch 518/1000\n",
      " - 0s - loss: 0.1127 - acc: 0.8571\n",
      "Epoch 519/1000\n",
      " - 0s - loss: 0.1123 - acc: 0.8571\n",
      "Epoch 520/1000\n",
      " - 0s - loss: 0.1121 - acc: 0.8571\n",
      "Epoch 521/1000\n",
      " - 0s - loss: 0.1115 - acc: 0.8571\n",
      "Epoch 522/1000\n",
      " - 0s - loss: 0.1111 - acc: 0.8571\n",
      "Epoch 523/1000\n",
      " - 0s - loss: 0.1108 - acc: 0.8571\n",
      "Epoch 524/1000\n",
      " - 0s - loss: 0.1103 - acc: 0.8571\n",
      "Epoch 525/1000\n",
      " - 0s - loss: 0.1102 - acc: 0.8571\n",
      "Epoch 526/1000\n",
      " - 0s - loss: 0.1098 - acc: 0.8571\n",
      "Epoch 527/1000\n",
      " - 0s - loss: 0.1095 - acc: 0.8571\n",
      "Epoch 528/1000\n",
      " - 0s - loss: 0.1093 - acc: 0.8571\n",
      "Epoch 529/1000\n",
      " - 0s - loss: 0.1088 - acc: 0.8571\n",
      "Epoch 530/1000\n",
      " - 0s - loss: 0.1087 - acc: 0.8571\n",
      "Epoch 531/1000\n",
      " - 0s - loss: 0.1082 - acc: 0.8571\n",
      "Epoch 532/1000\n",
      " - 0s - loss: 0.1079 - acc: 0.8571\n",
      "Epoch 533/1000\n",
      " - 0s - loss: 0.1076 - acc: 0.8571\n",
      "Epoch 534/1000\n",
      " - 0s - loss: 0.1073 - acc: 0.8571\n",
      "Epoch 535/1000\n",
      " - 0s - loss: 0.1069 - acc: 0.8571\n",
      "Epoch 536/1000\n",
      " - 0s - loss: 0.1066 - acc: 0.8571\n",
      "Epoch 537/1000\n",
      " - 0s - loss: 0.1062 - acc: 0.8571\n",
      "Epoch 538/1000\n",
      " - 0s - loss: 0.1062 - acc: 0.8571\n",
      "Epoch 539/1000\n",
      " - 0s - loss: 0.1058 - acc: 0.8571\n",
      "Epoch 540/1000\n",
      " - 0s - loss: 0.1053 - acc: 0.8571\n",
      "Epoch 541/1000\n",
      " - 0s - loss: 0.1050 - acc: 0.8571\n",
      "Epoch 542/1000\n",
      " - 0s - loss: 0.1046 - acc: 0.8571\n",
      "Epoch 543/1000\n",
      " - 0s - loss: 0.1043 - acc: 0.8571\n",
      "Epoch 544/1000\n",
      " - 0s - loss: 0.1042 - acc: 0.8571\n",
      "Epoch 545/1000\n",
      " - 0s - loss: 0.1042 - acc: 0.8571\n",
      "Epoch 546/1000\n",
      " - 0s - loss: 0.1036 - acc: 0.8571\n",
      "Epoch 547/1000\n",
      " - 0s - loss: 0.1032 - acc: 0.8571\n",
      "Epoch 548/1000\n",
      " - 0s - loss: 0.1028 - acc: 0.8571\n",
      "Epoch 549/1000\n",
      " - 0s - loss: 0.1026 - acc: 0.8571\n",
      "Epoch 550/1000\n",
      " - 0s - loss: 0.1023 - acc: 0.8571\n",
      "Epoch 551/1000\n",
      " - 0s - loss: 0.1019 - acc: 0.8571\n",
      "Epoch 552/1000\n",
      " - 0s - loss: 0.1017 - acc: 0.8571\n",
      "Epoch 553/1000\n",
      " - 0s - loss: 0.1012 - acc: 0.8571\n",
      "Epoch 554/1000\n",
      " - 0s - loss: 0.1010 - acc: 0.8571\n",
      "Epoch 555/1000\n",
      " - 0s - loss: 0.1006 - acc: 0.8571\n",
      "Epoch 556/1000\n",
      " - 0s - loss: 0.1004 - acc: 0.9286\n",
      "Epoch 557/1000\n",
      " - 0s - loss: 0.1001 - acc: 0.8571\n",
      "Epoch 558/1000\n",
      " - 0s - loss: 0.0999 - acc: 0.9286\n",
      "Epoch 559/1000\n",
      " - 0s - loss: 0.0998 - acc: 0.9286\n",
      "Epoch 560/1000\n",
      " - 0s - loss: 0.0994 - acc: 0.9286\n",
      "Epoch 561/1000\n",
      " - 0s - loss: 0.0989 - acc: 0.9286\n",
      "Epoch 562/1000\n",
      " - 0s - loss: 0.0985 - acc: 0.9286\n",
      "Epoch 563/1000\n",
      " - 0s - loss: 0.0984 - acc: 0.9286\n",
      "Epoch 564/1000\n",
      " - 0s - loss: 0.0980 - acc: 0.9286\n",
      "Epoch 565/1000\n",
      " - 0s - loss: 0.0977 - acc: 0.9286\n",
      "Epoch 566/1000\n",
      " - 0s - loss: 0.0979 - acc: 0.9286\n",
      "Epoch 567/1000\n",
      " - 0s - loss: 0.0971 - acc: 0.9286\n",
      "Epoch 568/1000\n",
      " - 0s - loss: 0.0971 - acc: 0.9286\n",
      "Epoch 569/1000\n",
      " - 0s - loss: 0.0967 - acc: 0.9286\n",
      "Epoch 570/1000\n",
      " - 0s - loss: 0.0963 - acc: 0.9286\n",
      "Epoch 571/1000\n",
      " - 0s - loss: 0.0960 - acc: 0.9286\n",
      "Epoch 572/1000\n",
      " - 0s - loss: 0.0958 - acc: 0.9286\n",
      "Epoch 573/1000\n",
      " - 0s - loss: 0.0954 - acc: 0.9286\n",
      "Epoch 574/1000\n",
      " - 0s - loss: 0.0952 - acc: 0.9286\n",
      "Epoch 575/1000\n",
      " - 0s - loss: 0.0948 - acc: 0.9286\n",
      "Epoch 576/1000\n",
      " - 0s - loss: 0.0946 - acc: 0.9286\n",
      "Epoch 577/1000\n",
      " - 0s - loss: 0.0943 - acc: 0.9286\n",
      "Epoch 578/1000\n",
      " - 0s - loss: 0.0939 - acc: 0.9286\n",
      "Epoch 579/1000\n",
      " - 0s - loss: 0.0938 - acc: 0.9286\n",
      "Epoch 580/1000\n",
      " - 0s - loss: 0.0938 - acc: 0.9286\n",
      "Epoch 581/1000\n",
      " - 0s - loss: 0.0931 - acc: 0.9286\n",
      "Epoch 582/1000\n",
      " - 0s - loss: 0.0929 - acc: 0.9286\n",
      "Epoch 583/1000\n",
      " - 0s - loss: 0.0926 - acc: 0.9286\n",
      "Epoch 584/1000\n",
      " - 0s - loss: 0.0923 - acc: 0.9286\n",
      "Epoch 585/1000\n",
      " - 0s - loss: 0.0921 - acc: 0.9286\n",
      "Epoch 586/1000\n",
      " - 0s - loss: 0.0918 - acc: 0.9286\n",
      "Epoch 587/1000\n",
      " - 0s - loss: 0.0915 - acc: 0.9286\n",
      "Epoch 588/1000\n",
      " - 0s - loss: 0.0913 - acc: 0.9286\n",
      "Epoch 589/1000\n",
      " - 0s - loss: 0.0910 - acc: 0.9286\n",
      "Epoch 590/1000\n",
      " - 0s - loss: 0.0908 - acc: 0.9286\n",
      "Epoch 591/1000\n",
      " - 0s - loss: 0.0907 - acc: 0.9286\n",
      "Epoch 592/1000\n",
      " - 0s - loss: 0.0901 - acc: 0.9286\n",
      "Epoch 593/1000\n",
      " - 0s - loss: 0.0899 - acc: 0.9286\n",
      "Epoch 594/1000\n",
      " - 0s - loss: 0.0899 - acc: 0.9286\n",
      "Epoch 595/1000\n",
      " - 0s - loss: 0.0893 - acc: 0.9286\n",
      "Epoch 596/1000\n",
      " - 0s - loss: 0.0895 - acc: 1.0000\n",
      "Epoch 597/1000\n",
      " - 0s - loss: 0.0887 - acc: 1.0000\n",
      "Epoch 598/1000\n",
      " - 0s - loss: 0.0886 - acc: 1.0000\n",
      "Epoch 599/1000\n",
      " - 0s - loss: 0.0882 - acc: 1.0000\n",
      "Epoch 600/1000\n",
      " - 0s - loss: 0.0880 - acc: 1.0000\n",
      "Epoch 601/1000\n",
      " - 0s - loss: 0.0876 - acc: 1.0000\n",
      "Epoch 602/1000\n",
      " - 0s - loss: 0.0876 - acc: 1.0000\n",
      "Epoch 603/1000\n",
      " - 0s - loss: 0.0871 - acc: 1.0000\n",
      "Epoch 604/1000\n",
      " - 0s - loss: 0.0871 - acc: 1.0000\n",
      "Epoch 605/1000\n",
      " - 0s - loss: 0.0867 - acc: 1.0000\n",
      "Epoch 606/1000\n",
      " - 0s - loss: 0.0866 - acc: 1.0000\n",
      "Epoch 607/1000\n",
      " - 0s - loss: 0.0862 - acc: 1.0000\n",
      "Epoch 608/1000\n",
      " - 0s - loss: 0.0859 - acc: 1.0000\n",
      "Epoch 609/1000\n",
      " - 0s - loss: 0.0856 - acc: 1.0000\n",
      "Epoch 610/1000\n",
      " - 0s - loss: 0.0859 - acc: 1.0000\n",
      "Epoch 611/1000\n",
      " - 0s - loss: 0.0852 - acc: 1.0000\n",
      "Epoch 612/1000\n",
      " - 0s - loss: 0.0849 - acc: 1.0000\n",
      "Epoch 613/1000\n",
      " - 0s - loss: 0.0848 - acc: 1.0000\n",
      "Epoch 614/1000\n",
      " - 0s - loss: 0.0844 - acc: 1.0000\n",
      "Epoch 615/1000\n",
      " - 0s - loss: 0.0840 - acc: 1.0000\n",
      "Epoch 616/1000\n",
      " - 0s - loss: 0.0839 - acc: 1.0000\n",
      "Epoch 617/1000\n",
      " - 0s - loss: 0.0837 - acc: 1.0000\n",
      "Epoch 618/1000\n",
      " - 0s - loss: 0.0834 - acc: 1.0000\n",
      "Epoch 619/1000\n",
      " - 0s - loss: 0.0831 - acc: 1.0000\n",
      "Epoch 620/1000\n",
      " - 0s - loss: 0.0827 - acc: 1.0000\n",
      "Epoch 621/1000\n",
      " - 0s - loss: 0.0826 - acc: 1.0000\n",
      "Epoch 622/1000\n",
      " - 0s - loss: 0.0824 - acc: 1.0000\n",
      "Epoch 623/1000\n",
      " - 0s - loss: 0.0820 - acc: 1.0000\n",
      "Epoch 624/1000\n",
      " - 0s - loss: 0.0819 - acc: 1.0000\n",
      "Epoch 625/1000\n",
      " - 0s - loss: 0.0817 - acc: 1.0000\n",
      "Epoch 626/1000\n",
      " - 0s - loss: 0.0815 - acc: 1.0000\n",
      "Epoch 627/1000\n",
      " - 0s - loss: 0.0811 - acc: 1.0000\n",
      "Epoch 628/1000\n",
      " - 0s - loss: 0.0808 - acc: 1.0000\n",
      "Epoch 629/1000\n",
      " - 0s - loss: 0.0810 - acc: 1.0000\n",
      "Epoch 630/1000\n",
      " - 0s - loss: 0.0804 - acc: 1.0000\n",
      "Epoch 631/1000\n",
      " - 0s - loss: 0.0802 - acc: 1.0000\n",
      "Epoch 632/1000\n",
      " - 0s - loss: 0.0800 - acc: 1.0000\n",
      "Epoch 633/1000\n",
      " - 0s - loss: 0.0798 - acc: 1.0000\n",
      "Epoch 634/1000\n",
      " - 0s - loss: 0.0794 - acc: 1.0000\n",
      "Epoch 635/1000\n",
      " - 0s - loss: 0.0792 - acc: 1.0000\n",
      "Epoch 636/1000\n",
      " - 0s - loss: 0.0791 - acc: 1.0000\n",
      "Epoch 637/1000\n",
      " - 0s - loss: 0.0787 - acc: 1.0000\n",
      "Epoch 638/1000\n",
      " - 0s - loss: 0.0785 - acc: 1.0000\n",
      "Epoch 639/1000\n",
      " - 0s - loss: 0.0786 - acc: 1.0000\n",
      "Epoch 640/1000\n",
      " - 0s - loss: 0.0779 - acc: 1.0000\n",
      "Epoch 641/1000\n",
      " - 0s - loss: 0.0778 - acc: 1.0000\n",
      "Epoch 642/1000\n",
      " - 0s - loss: 0.0778 - acc: 1.0000\n",
      "Epoch 643/1000\n",
      " - 0s - loss: 0.0772 - acc: 1.0000\n",
      "Epoch 644/1000\n",
      " - 0s - loss: 0.0771 - acc: 1.0000\n",
      "Epoch 645/1000\n",
      " - 0s - loss: 0.0769 - acc: 1.0000\n",
      "Epoch 646/1000\n",
      " - 0s - loss: 0.0767 - acc: 1.0000\n",
      "Epoch 647/1000\n",
      " - 0s - loss: 0.0764 - acc: 1.0000\n",
      "Epoch 648/1000\n",
      " - 0s - loss: 0.0765 - acc: 1.0000\n",
      "Epoch 649/1000\n",
      " - 0s - loss: 0.0761 - acc: 1.0000\n",
      "Epoch 650/1000\n",
      " - 0s - loss: 0.0759 - acc: 1.0000\n",
      "Epoch 651/1000\n",
      " - 0s - loss: 0.0754 - acc: 1.0000\n",
      "Epoch 652/1000\n",
      " - 0s - loss: 0.0755 - acc: 1.0000\n",
      "Epoch 653/1000\n",
      " - 0s - loss: 0.0751 - acc: 1.0000\n",
      "Epoch 654/1000\n",
      " - 0s - loss: 0.0747 - acc: 1.0000\n",
      "Epoch 655/1000\n",
      " - 0s - loss: 0.0748 - acc: 1.0000\n",
      "Epoch 656/1000\n",
      " - 0s - loss: 0.0743 - acc: 1.0000\n",
      "Epoch 657/1000\n",
      " - 0s - loss: 0.0740 - acc: 1.0000\n",
      "Epoch 658/1000\n",
      " - 0s - loss: 0.0739 - acc: 1.0000\n",
      "Epoch 659/1000\n",
      " - 0s - loss: 0.0739 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/1000\n",
      " - 0s - loss: 0.0734 - acc: 1.0000\n",
      "Epoch 661/1000\n",
      " - 0s - loss: 0.0733 - acc: 1.0000\n",
      "Epoch 662/1000\n",
      " - 0s - loss: 0.0733 - acc: 1.0000\n",
      "Epoch 663/1000\n",
      " - 0s - loss: 0.0727 - acc: 1.0000\n",
      "Epoch 664/1000\n",
      " - 0s - loss: 0.0727 - acc: 1.0000\n",
      "Epoch 665/1000\n",
      " - 0s - loss: 0.0724 - acc: 1.0000\n",
      "Epoch 666/1000\n",
      " - 0s - loss: 0.0722 - acc: 1.0000\n",
      "Epoch 667/1000\n",
      " - 0s - loss: 0.0720 - acc: 1.0000\n",
      "Epoch 668/1000\n",
      " - 0s - loss: 0.0717 - acc: 1.0000\n",
      "Epoch 669/1000\n",
      " - 0s - loss: 0.0715 - acc: 1.0000\n",
      "Epoch 670/1000\n",
      " - 0s - loss: 0.0713 - acc: 1.0000\n",
      "Epoch 671/1000\n",
      " - 0s - loss: 0.0712 - acc: 1.0000\n",
      "Epoch 672/1000\n",
      " - 0s - loss: 0.0710 - acc: 1.0000\n",
      "Epoch 673/1000\n",
      " - 0s - loss: 0.0708 - acc: 1.0000\n",
      "Epoch 674/1000\n",
      " - 0s - loss: 0.0705 - acc: 1.0000\n",
      "Epoch 675/1000\n",
      " - 0s - loss: 0.0703 - acc: 1.0000\n",
      "Epoch 676/1000\n",
      " - 0s - loss: 0.0701 - acc: 1.0000\n",
      "Epoch 677/1000\n",
      " - 0s - loss: 0.0697 - acc: 1.0000\n",
      "Epoch 678/1000\n",
      " - 0s - loss: 0.0696 - acc: 1.0000\n",
      "Epoch 679/1000\n",
      " - 0s - loss: 0.0693 - acc: 1.0000\n",
      "Epoch 680/1000\n",
      " - 0s - loss: 0.0692 - acc: 1.0000\n",
      "Epoch 681/1000\n",
      " - 0s - loss: 0.0691 - acc: 1.0000\n",
      "Epoch 682/1000\n",
      " - 0s - loss: 0.0687 - acc: 1.0000\n",
      "Epoch 683/1000\n",
      " - 0s - loss: 0.0685 - acc: 1.0000\n",
      "Epoch 684/1000\n",
      " - 0s - loss: 0.0684 - acc: 1.0000\n",
      "Epoch 685/1000\n",
      " - 0s - loss: 0.0681 - acc: 1.0000\n",
      "Epoch 686/1000\n",
      " - 0s - loss: 0.0681 - acc: 1.0000\n",
      "Epoch 687/1000\n",
      " - 0s - loss: 0.0677 - acc: 1.0000\n",
      "Epoch 688/1000\n",
      " - 0s - loss: 0.0676 - acc: 1.0000\n",
      "Epoch 689/1000\n",
      " - 0s - loss: 0.0675 - acc: 1.0000\n",
      "Epoch 690/1000\n",
      " - 0s - loss: 0.0671 - acc: 1.0000\n",
      "Epoch 691/1000\n",
      " - 0s - loss: 0.0670 - acc: 1.0000\n",
      "Epoch 692/1000\n",
      " - 0s - loss: 0.0668 - acc: 1.0000\n",
      "Epoch 693/1000\n",
      " - 0s - loss: 0.0666 - acc: 1.0000\n",
      "Epoch 694/1000\n",
      " - 0s - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 695/1000\n",
      " - 0s - loss: 0.0661 - acc: 1.0000\n",
      "Epoch 696/1000\n",
      " - 0s - loss: 0.0660 - acc: 1.0000\n",
      "Epoch 697/1000\n",
      " - 0s - loss: 0.0659 - acc: 1.0000\n",
      "Epoch 698/1000\n",
      " - 0s - loss: 0.0655 - acc: 1.0000\n",
      "Epoch 699/1000\n",
      " - 0s - loss: 0.0653 - acc: 1.0000\n",
      "Epoch 700/1000\n",
      " - 0s - loss: 0.0651 - acc: 1.0000\n",
      "Epoch 701/1000\n",
      " - 0s - loss: 0.0653 - acc: 1.0000\n",
      "Epoch 702/1000\n",
      " - 0s - loss: 0.0648 - acc: 1.0000\n",
      "Epoch 703/1000\n",
      " - 0s - loss: 0.0646 - acc: 1.0000\n",
      "Epoch 704/1000\n",
      " - 0s - loss: 0.0643 - acc: 1.0000\n",
      "Epoch 705/1000\n",
      " - 0s - loss: 0.0642 - acc: 1.0000\n",
      "Epoch 706/1000\n",
      " - 0s - loss: 0.0640 - acc: 1.0000\n",
      "Epoch 707/1000\n",
      " - 0s - loss: 0.0638 - acc: 1.0000\n",
      "Epoch 708/1000\n",
      " - 0s - loss: 0.0635 - acc: 1.0000\n",
      "Epoch 709/1000\n",
      " - 0s - loss: 0.0633 - acc: 1.0000\n",
      "Epoch 710/1000\n",
      " - 0s - loss: 0.0633 - acc: 1.0000\n",
      "Epoch 711/1000\n",
      " - 0s - loss: 0.0629 - acc: 1.0000\n",
      "Epoch 712/1000\n",
      " - 0s - loss: 0.0628 - acc: 1.0000\n",
      "Epoch 713/1000\n",
      " - 0s - loss: 0.0625 - acc: 1.0000\n",
      "Epoch 714/1000\n",
      " - 0s - loss: 0.0624 - acc: 1.0000\n",
      "Epoch 715/1000\n",
      " - 0s - loss: 0.0623 - acc: 1.0000\n",
      "Epoch 716/1000\n",
      " - 0s - loss: 0.0621 - acc: 1.0000\n",
      "Epoch 717/1000\n",
      " - 0s - loss: 0.0618 - acc: 1.0000\n",
      "Epoch 718/1000\n",
      " - 0s - loss: 0.0617 - acc: 1.0000\n",
      "Epoch 719/1000\n",
      " - 0s - loss: 0.0616 - acc: 1.0000\n",
      "Epoch 720/1000\n",
      " - 0s - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 721/1000\n",
      " - 0s - loss: 0.0611 - acc: 1.0000\n",
      "Epoch 722/1000\n",
      " - 0s - loss: 0.0609 - acc: 1.0000\n",
      "Epoch 723/1000\n",
      " - 0s - loss: 0.0608 - acc: 1.0000\n",
      "Epoch 724/1000\n",
      " - 0s - loss: 0.0610 - acc: 1.0000\n",
      "Epoch 725/1000\n",
      " - 0s - loss: 0.0603 - acc: 1.0000\n",
      "Epoch 726/1000\n",
      " - 0s - loss: 0.0603 - acc: 1.0000\n",
      "Epoch 727/1000\n",
      " - 0s - loss: 0.0601 - acc: 1.0000\n",
      "Epoch 728/1000\n",
      " - 0s - loss: 0.0599 - acc: 1.0000\n",
      "Epoch 729/1000\n",
      " - 0s - loss: 0.0596 - acc: 1.0000\n",
      "Epoch 730/1000\n",
      " - 0s - loss: 0.0595 - acc: 1.0000\n",
      "Epoch 731/1000\n",
      " - 0s - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 732/1000\n",
      " - 0s - loss: 0.0591 - acc: 1.0000\n",
      "Epoch 733/1000\n",
      " - 0s - loss: 0.0589 - acc: 1.0000\n",
      "Epoch 734/1000\n",
      " - 0s - loss: 0.0588 - acc: 1.0000\n",
      "Epoch 735/1000\n",
      " - 0s - loss: 0.0585 - acc: 1.0000\n",
      "Epoch 736/1000\n",
      " - 0s - loss: 0.0585 - acc: 1.0000\n",
      "Epoch 737/1000\n",
      " - 0s - loss: 0.0583 - acc: 1.0000\n",
      "Epoch 738/1000\n",
      " - 0s - loss: 0.0580 - acc: 1.0000\n",
      "Epoch 739/1000\n",
      " - 0s - loss: 0.0579 - acc: 1.0000\n",
      "Epoch 740/1000\n",
      " - 0s - loss: 0.0576 - acc: 1.0000\n",
      "Epoch 741/1000\n",
      " - 0s - loss: 0.0576 - acc: 1.0000\n",
      "Epoch 742/1000\n",
      " - 0s - loss: 0.0573 - acc: 1.0000\n",
      "Epoch 743/1000\n",
      " - 0s - loss: 0.0571 - acc: 1.0000\n",
      "Epoch 744/1000\n",
      " - 0s - loss: 0.0570 - acc: 1.0000\n",
      "Epoch 745/1000\n",
      " - 0s - loss: 0.0567 - acc: 1.0000\n",
      "Epoch 746/1000\n",
      " - 0s - loss: 0.0567 - acc: 1.0000\n",
      "Epoch 747/1000\n",
      " - 0s - loss: 0.0565 - acc: 1.0000\n",
      "Epoch 748/1000\n",
      " - 0s - loss: 0.0564 - acc: 1.0000\n",
      "Epoch 749/1000\n",
      " - 0s - loss: 0.0561 - acc: 1.0000\n",
      "Epoch 750/1000\n",
      " - 0s - loss: 0.0560 - acc: 1.0000\n",
      "Epoch 751/1000\n",
      " - 0s - loss: 0.0557 - acc: 1.0000\n",
      "Epoch 752/1000\n",
      " - 0s - loss: 0.0556 - acc: 1.0000\n",
      "Epoch 753/1000\n",
      " - 0s - loss: 0.0554 - acc: 1.0000\n",
      "Epoch 754/1000\n",
      " - 0s - loss: 0.0554 - acc: 1.0000\n",
      "Epoch 755/1000\n",
      " - 0s - loss: 0.0552 - acc: 1.0000\n",
      "Epoch 756/1000\n",
      " - 0s - loss: 0.0549 - acc: 1.0000\n",
      "Epoch 757/1000\n",
      " - 0s - loss: 0.0548 - acc: 1.0000\n",
      "Epoch 758/1000\n",
      " - 0s - loss: 0.0548 - acc: 1.0000\n",
      "Epoch 759/1000\n",
      " - 0s - loss: 0.0544 - acc: 1.0000\n",
      "Epoch 760/1000\n",
      " - 0s - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 761/1000\n",
      " - 0s - loss: 0.0541 - acc: 1.0000\n",
      "Epoch 762/1000\n",
      " - 0s - loss: 0.0542 - acc: 1.0000\n",
      "Epoch 763/1000\n",
      " - 0s - loss: 0.0538 - acc: 1.0000\n",
      "Epoch 764/1000\n",
      " - 0s - loss: 0.0536 - acc: 1.0000\n",
      "Epoch 765/1000\n",
      " - 0s - loss: 0.0535 - acc: 1.0000\n",
      "Epoch 766/1000\n",
      " - 0s - loss: 0.0535 - acc: 1.0000\n",
      "Epoch 767/1000\n",
      " - 0s - loss: 0.0532 - acc: 1.0000\n",
      "Epoch 768/1000\n",
      " - 0s - loss: 0.0531 - acc: 1.0000\n",
      "Epoch 769/1000\n",
      " - 0s - loss: 0.0529 - acc: 1.0000\n",
      "Epoch 770/1000\n",
      " - 0s - loss: 0.0530 - acc: 1.0000\n",
      "Epoch 771/1000\n",
      " - 0s - loss: 0.0525 - acc: 1.0000\n",
      "Epoch 772/1000\n",
      " - 0s - loss: 0.0523 - acc: 1.0000\n",
      "Epoch 773/1000\n",
      " - 0s - loss: 0.0523 - acc: 1.0000\n",
      "Epoch 774/1000\n",
      " - 0s - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 775/1000\n",
      " - 0s - loss: 0.0520 - acc: 1.0000\n",
      "Epoch 776/1000\n",
      " - 0s - loss: 0.0517 - acc: 1.0000\n",
      "Epoch 777/1000\n",
      " - 0s - loss: 0.0515 - acc: 1.0000\n",
      "Epoch 778/1000\n",
      " - 0s - loss: 0.0514 - acc: 1.0000\n",
      "Epoch 779/1000\n",
      " - 0s - loss: 0.0513 - acc: 1.0000\n",
      "Epoch 780/1000\n",
      " - 0s - loss: 0.0512 - acc: 1.0000\n",
      "Epoch 781/1000\n",
      " - 0s - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 782/1000\n",
      " - 0s - loss: 0.0508 - acc: 1.0000\n",
      "Epoch 783/1000\n",
      " - 0s - loss: 0.0506 - acc: 1.0000\n",
      "Epoch 784/1000\n",
      " - 0s - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 785/1000\n",
      " - 0s - loss: 0.0503 - acc: 1.0000\n",
      "Epoch 786/1000\n",
      " - 0s - loss: 0.0501 - acc: 1.0000\n",
      "Epoch 787/1000\n",
      " - 0s - loss: 0.0500 - acc: 1.0000\n",
      "Epoch 788/1000\n",
      " - 0s - loss: 0.0498 - acc: 1.0000\n",
      "Epoch 789/1000\n",
      " - 0s - loss: 0.0499 - acc: 1.0000\n",
      "Epoch 790/1000\n",
      " - 0s - loss: 0.0496 - acc: 1.0000\n",
      "Epoch 791/1000\n",
      " - 0s - loss: 0.0494 - acc: 1.0000\n",
      "Epoch 792/1000\n",
      " - 0s - loss: 0.0492 - acc: 1.0000\n",
      "Epoch 793/1000\n",
      " - 0s - loss: 0.0490 - acc: 1.0000\n",
      "Epoch 794/1000\n",
      " - 0s - loss: 0.0490 - acc: 1.0000\n",
      "Epoch 795/1000\n",
      " - 0s - loss: 0.0488 - acc: 1.0000\n",
      "Epoch 796/1000\n",
      " - 0s - loss: 0.0486 - acc: 1.0000\n",
      "Epoch 797/1000\n",
      " - 0s - loss: 0.0486 - acc: 1.0000\n",
      "Epoch 798/1000\n",
      " - 0s - loss: 0.0485 - acc: 1.0000\n",
      "Epoch 799/1000\n",
      " - 0s - loss: 0.0481 - acc: 1.0000\n",
      "Epoch 800/1000\n",
      " - 0s - loss: 0.0481 - acc: 1.0000\n",
      "Epoch 801/1000\n",
      " - 0s - loss: 0.0479 - acc: 1.0000\n",
      "Epoch 802/1000\n",
      " - 0s - loss: 0.0479 - acc: 1.0000\n",
      "Epoch 803/1000\n",
      " - 0s - loss: 0.0477 - acc: 1.0000\n",
      "Epoch 804/1000\n",
      " - 0s - loss: 0.0474 - acc: 1.0000\n",
      "Epoch 805/1000\n",
      " - 0s - loss: 0.0474 - acc: 1.0000\n",
      "Epoch 806/1000\n",
      " - 0s - loss: 0.0473 - acc: 1.0000\n",
      "Epoch 807/1000\n",
      " - 0s - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 808/1000\n",
      " - 0s - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 809/1000\n",
      " - 0s - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 810/1000\n",
      " - 0s - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 811/1000\n",
      " - 0s - loss: 0.0465 - acc: 1.0000\n",
      "Epoch 812/1000\n",
      " - 0s - loss: 0.0464 - acc: 1.0000\n",
      "Epoch 813/1000\n",
      " - 0s - loss: 0.0462 - acc: 1.0000\n",
      "Epoch 814/1000\n",
      " - 0s - loss: 0.0460 - acc: 1.0000\n",
      "Epoch 815/1000\n",
      " - 0s - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 816/1000\n",
      " - 0s - loss: 0.0457 - acc: 1.0000\n",
      "Epoch 817/1000\n",
      " - 0s - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 818/1000\n",
      " - 0s - loss: 0.0455 - acc: 1.0000\n",
      "Epoch 819/1000\n",
      " - 0s - loss: 0.0454 - acc: 1.0000\n",
      "Epoch 820/1000\n",
      " - 0s - loss: 0.0452 - acc: 1.0000\n",
      "Epoch 821/1000\n",
      " - 0s - loss: 0.0450 - acc: 1.0000\n",
      "Epoch 822/1000\n",
      " - 0s - loss: 0.0449 - acc: 1.0000\n",
      "Epoch 823/1000\n",
      " - 0s - loss: 0.0450 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 824/1000\n",
      " - 0s - loss: 0.0446 - acc: 1.0000\n",
      "Epoch 825/1000\n",
      " - 0s - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 826/1000\n",
      " - 0s - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 827/1000\n",
      " - 0s - loss: 0.0443 - acc: 1.0000\n",
      "Epoch 828/1000\n",
      " - 0s - loss: 0.0442 - acc: 1.0000\n",
      "Epoch 829/1000\n",
      " - 0s - loss: 0.0441 - acc: 1.0000\n",
      "Epoch 830/1000\n",
      " - 0s - loss: 0.0441 - acc: 1.0000\n",
      "Epoch 831/1000\n",
      " - 0s - loss: 0.0437 - acc: 1.0000\n",
      "Epoch 832/1000\n",
      " - 0s - loss: 0.0436 - acc: 1.0000\n",
      "Epoch 833/1000\n",
      " - 0s - loss: 0.0435 - acc: 1.0000\n",
      "Epoch 834/1000\n",
      " - 0s - loss: 0.0433 - acc: 1.0000\n",
      "Epoch 835/1000\n",
      " - 0s - loss: 0.0433 - acc: 1.0000\n",
      "Epoch 836/1000\n",
      " - 0s - loss: 0.0432 - acc: 1.0000\n",
      "Epoch 837/1000\n",
      " - 0s - loss: 0.0431 - acc: 1.0000\n",
      "Epoch 838/1000\n",
      " - 0s - loss: 0.0428 - acc: 1.0000\n",
      "Epoch 839/1000\n",
      " - 0s - loss: 0.0427 - acc: 1.0000\n",
      "Epoch 840/1000\n",
      " - 0s - loss: 0.0426 - acc: 1.0000\n",
      "Epoch 841/1000\n",
      " - 0s - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 842/1000\n",
      " - 0s - loss: 0.0423 - acc: 1.0000\n",
      "Epoch 843/1000\n",
      " - 0s - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 844/1000\n",
      " - 0s - loss: 0.0420 - acc: 1.0000\n",
      "Epoch 845/1000\n",
      " - 0s - loss: 0.0419 - acc: 1.0000\n",
      "Epoch 846/1000\n",
      " - 0s - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 847/1000\n",
      " - 0s - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 848/1000\n",
      " - 0s - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 849/1000\n",
      " - 0s - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 850/1000\n",
      " - 0s - loss: 0.0412 - acc: 1.0000\n",
      "Epoch 851/1000\n",
      " - 0s - loss: 0.0412 - acc: 1.0000\n",
      "Epoch 852/1000\n",
      " - 0s - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 853/1000\n",
      " - 0s - loss: 0.0409 - acc: 1.0000\n",
      "Epoch 854/1000\n",
      " - 0s - loss: 0.0407 - acc: 1.0000\n",
      "Epoch 855/1000\n",
      " - 0s - loss: 0.0406 - acc: 1.0000\n",
      "Epoch 856/1000\n",
      " - 0s - loss: 0.0404 - acc: 1.0000\n",
      "Epoch 857/1000\n",
      " - 0s - loss: 0.0404 - acc: 1.0000\n",
      "Epoch 858/1000\n",
      " - 0s - loss: 0.0403 - acc: 1.0000\n",
      "Epoch 859/1000\n",
      " - 0s - loss: 0.0402 - acc: 1.0000\n",
      "Epoch 860/1000\n",
      " - 0s - loss: 0.0400 - acc: 1.0000\n",
      "Epoch 861/1000\n",
      " - 0s - loss: 0.0398 - acc: 1.0000\n",
      "Epoch 862/1000\n",
      " - 0s - loss: 0.0398 - acc: 1.0000\n",
      "Epoch 863/1000\n",
      " - 0s - loss: 0.0397 - acc: 1.0000\n",
      "Epoch 864/1000\n",
      " - 0s - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 865/1000\n",
      " - 0s - loss: 0.0394 - acc: 1.0000\n",
      "Epoch 866/1000\n",
      " - 0s - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 867/1000\n",
      " - 0s - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 868/1000\n",
      " - 0s - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 869/1000\n",
      " - 0s - loss: 0.0389 - acc: 1.0000\n",
      "Epoch 870/1000\n",
      " - 0s - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 871/1000\n",
      " - 0s - loss: 0.0387 - acc: 1.0000\n",
      "Epoch 872/1000\n",
      " - 0s - loss: 0.0386 - acc: 1.0000\n",
      "Epoch 873/1000\n",
      " - 0s - loss: 0.0387 - acc: 1.0000\n",
      "Epoch 874/1000\n",
      " - 0s - loss: 0.0383 - acc: 1.0000\n",
      "Epoch 875/1000\n",
      " - 0s - loss: 0.0382 - acc: 1.0000\n",
      "Epoch 876/1000\n",
      " - 0s - loss: 0.0382 - acc: 1.0000\n",
      "Epoch 877/1000\n",
      " - 0s - loss: 0.0380 - acc: 1.0000\n",
      "Epoch 878/1000\n",
      " - 0s - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 879/1000\n",
      " - 0s - loss: 0.0377 - acc: 1.0000\n",
      "Epoch 880/1000\n",
      " - 0s - loss: 0.0376 - acc: 1.0000\n",
      "Epoch 881/1000\n",
      " - 0s - loss: 0.0375 - acc: 1.0000\n",
      "Epoch 882/1000\n",
      " - 0s - loss: 0.0374 - acc: 1.0000\n",
      "Epoch 883/1000\n",
      " - 0s - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 884/1000\n",
      " - 0s - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 885/1000\n",
      " - 0s - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 886/1000\n",
      " - 0s - loss: 0.0369 - acc: 1.0000\n",
      "Epoch 887/1000\n",
      " - 0s - loss: 0.0368 - acc: 1.0000\n",
      "Epoch 888/1000\n",
      " - 0s - loss: 0.0367 - acc: 1.0000\n",
      "Epoch 889/1000\n",
      " - 0s - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 890/1000\n",
      " - 0s - loss: 0.0365 - acc: 1.0000\n",
      "Epoch 891/1000\n",
      " - 0s - loss: 0.0365 - acc: 1.0000\n",
      "Epoch 892/1000\n",
      " - 0s - loss: 0.0363 - acc: 1.0000\n",
      "Epoch 893/1000\n",
      " - 0s - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 894/1000\n",
      " - 0s - loss: 0.0360 - acc: 1.0000\n",
      "Epoch 895/1000\n",
      " - 0s - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 896/1000\n",
      " - 0s - loss: 0.0358 - acc: 1.0000\n",
      "Epoch 897/1000\n",
      " - 0s - loss: 0.0358 - acc: 1.0000\n",
      "Epoch 898/1000\n",
      " - 0s - loss: 0.0358 - acc: 1.0000\n",
      "Epoch 899/1000\n",
      " - 0s - loss: 0.0355 - acc: 1.0000\n",
      "Epoch 900/1000\n",
      " - 0s - loss: 0.0354 - acc: 1.0000\n",
      "Epoch 901/1000\n",
      " - 0s - loss: 0.0353 - acc: 1.0000\n",
      "Epoch 902/1000\n",
      " - 0s - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 903/1000\n",
      " - 0s - loss: 0.0352 - acc: 1.0000\n",
      "Epoch 904/1000\n",
      " - 0s - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 905/1000\n",
      " - 0s - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 906/1000\n",
      " - 0s - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 907/1000\n",
      " - 0s - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 908/1000\n",
      " - 0s - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 909/1000\n",
      " - 0s - loss: 0.0345 - acc: 1.0000\n",
      "Epoch 910/1000\n",
      " - 0s - loss: 0.0343 - acc: 1.0000\n",
      "Epoch 911/1000\n",
      " - 0s - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 912/1000\n",
      " - 0s - loss: 0.0341 - acc: 1.0000\n",
      "Epoch 913/1000\n",
      " - 0s - loss: 0.0341 - acc: 1.0000\n",
      "Epoch 914/1000\n",
      " - 0s - loss: 0.0340 - acc: 1.0000\n",
      "Epoch 915/1000\n",
      " - 0s - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 916/1000\n",
      " - 0s - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 917/1000\n",
      " - 0s - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 918/1000\n",
      " - 0s - loss: 0.0335 - acc: 1.0000\n",
      "Epoch 919/1000\n",
      " - 0s - loss: 0.0336 - acc: 1.0000\n",
      "Epoch 920/1000\n",
      " - 0s - loss: 0.0333 - acc: 1.0000\n",
      "Epoch 921/1000\n",
      " - 0s - loss: 0.0332 - acc: 1.0000\n",
      "Epoch 922/1000\n",
      " - 0s - loss: 0.0330 - acc: 1.0000\n",
      "Epoch 923/1000\n",
      " - 0s - loss: 0.0330 - acc: 1.0000\n",
      "Epoch 924/1000\n",
      " - 0s - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 925/1000\n",
      " - 0s - loss: 0.0327 - acc: 1.0000\n",
      "Epoch 926/1000\n",
      " - 0s - loss: 0.0328 - acc: 1.0000\n",
      "Epoch 927/1000\n",
      " - 0s - loss: 0.0326 - acc: 1.0000\n",
      "Epoch 928/1000\n",
      " - 0s - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 929/1000\n",
      " - 0s - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 930/1000\n",
      " - 0s - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 931/1000\n",
      " - 0s - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 932/1000\n",
      " - 0s - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 933/1000\n",
      " - 0s - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 934/1000\n",
      " - 0s - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 935/1000\n",
      " - 0s - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 936/1000\n",
      " - 0s - loss: 0.0317 - acc: 1.0000\n",
      "Epoch 937/1000\n",
      " - 0s - loss: 0.0316 - acc: 1.0000\n",
      "Epoch 938/1000\n",
      " - 0s - loss: 0.0315 - acc: 1.0000\n",
      "Epoch 939/1000\n",
      " - 0s - loss: 0.0314 - acc: 1.0000\n",
      "Epoch 940/1000\n",
      " - 0s - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 941/1000\n",
      " - 0s - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 942/1000\n",
      " - 0s - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 943/1000\n",
      " - 0s - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 944/1000\n",
      " - 0s - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 945/1000\n",
      " - 0s - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 946/1000\n",
      " - 0s - loss: 0.0307 - acc: 1.0000\n",
      "Epoch 947/1000\n",
      " - 0s - loss: 0.0306 - acc: 1.0000\n",
      "Epoch 948/1000\n",
      " - 0s - loss: 0.0305 - acc: 1.0000\n",
      "Epoch 949/1000\n",
      " - 0s - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 950/1000\n",
      " - 0s - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 951/1000\n",
      " - 0s - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 952/1000\n",
      " - 0s - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 953/1000\n",
      " - 0s - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 954/1000\n",
      " - 0s - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 955/1000\n",
      " - 0s - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 956/1000\n",
      " - 0s - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 957/1000\n",
      " - 0s - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 958/1000\n",
      " - 0s - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 959/1000\n",
      " - 0s - loss: 0.0295 - acc: 1.0000\n",
      "Epoch 960/1000\n",
      " - 0s - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 961/1000\n",
      " - 0s - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 962/1000\n",
      " - 0s - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 963/1000\n",
      " - 0s - loss: 0.0291 - acc: 1.0000\n",
      "Epoch 964/1000\n",
      " - 0s - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 965/1000\n",
      " - 0s - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 966/1000\n",
      " - 0s - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 967/1000\n",
      " - 0s - loss: 0.0288 - acc: 1.0000\n",
      "Epoch 968/1000\n",
      " - 0s - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 969/1000\n",
      " - 0s - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 970/1000\n",
      " - 0s - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 971/1000\n",
      " - 0s - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 972/1000\n",
      " - 0s - loss: 0.0283 - acc: 1.0000\n",
      "Epoch 973/1000\n",
      " - 0s - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 974/1000\n",
      " - 0s - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 975/1000\n",
      " - 0s - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 976/1000\n",
      " - 0s - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 977/1000\n",
      " - 0s - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 978/1000\n",
      " - 0s - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 979/1000\n",
      " - 0s - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 980/1000\n",
      " - 0s - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 981/1000\n",
      " - 0s - loss: 0.0276 - acc: 1.0000\n",
      "Epoch 982/1000\n",
      " - 0s - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 983/1000\n",
      " - 0s - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 984/1000\n",
      " - 0s - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 985/1000\n",
      " - 0s - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 986/1000\n",
      " - 0s - loss: 0.0271 - acc: 1.0000\n",
      "Epoch 987/1000\n",
      " - 0s - loss: 0.0270 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/1000\n",
      " - 0s - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 989/1000\n",
      " - 0s - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 990/1000\n",
      " - 0s - loss: 0.0268 - acc: 1.0000\n",
      "Epoch 991/1000\n",
      " - 0s - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 992/1000\n",
      " - 0s - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 993/1000\n",
      " - 0s - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 994/1000\n",
      " - 0s - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 995/1000\n",
      " - 0s - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 996/1000\n",
      " - 0s - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 997/1000\n",
      " - 0s - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 998/1000\n",
      " - 0s - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 999/1000\n",
      " - 0s - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 1000/1000\n",
      " - 0s - loss: 0.0260 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b27ad9f98>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(data[1:15], label[1:15], epochs=1000, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 0.] -1.0 [-0.7302062]\n",
      "[1. 0. 1. 0. 0.] 1.0 [0.9110876]\n",
      "[1. 0. 0. 1. 0.] 1.0 [0.9110301]\n",
      "[1. 0. 0. 0. 1.] -1.0 [-0.9953436]\n",
      "[1. 1. 1. 0. 0.] 1.0 [0.78812593]\n",
      "[1. 1. 0. 1. 0.] 1.0 [0.78799784]\n",
      "[1. 1. 0. 0. 1.] -1.0 [-0.99816906]\n",
      "[1. 0. 1. 1. 0.] 1.0 [0.9982811]\n",
      "[1. 0. 1. 0. 1.] -1.0 [-0.7757178]\n",
      "[1. 0. 0. 1. 1.] -1.0 [-0.77585226]\n",
      "[1. 1. 1. 1. 0.] 1.0 [0.9956281]\n",
      "[1. 1. 1. 0. 1.] -1.0 [-0.9054998]\n",
      "[1. 1. 0. 1. 1.] -1.0 [-0.9055607]\n",
      "[1. 0. 1. 1. 1.] 1.0 [0.7446197]\n"
     ]
    }
   ],
   "source": [
    "y = base_model.predict(data[1:15])\n",
    "for i in range(len(y)):\n",
    "    print(data[i+1], label[i+1], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 0s - loss: 0.3313 - acc: 0.3571\n",
      "Epoch 2/500\n",
      " - 0s - loss: 0.3264 - acc: 0.3571\n",
      "Epoch 3/500\n",
      " - 0s - loss: 0.3211 - acc: 0.3571\n",
      "Epoch 4/500\n",
      " - 0s - loss: 0.3161 - acc: 0.3571\n",
      "Epoch 5/500\n",
      " - 0s - loss: 0.3112 - acc: 0.3571\n",
      "Epoch 6/500\n",
      " - 0s - loss: 0.3064 - acc: 0.3571\n",
      "Epoch 7/500\n",
      " - 0s - loss: 0.3018 - acc: 0.3571\n",
      "Epoch 8/500\n",
      " - 0s - loss: 0.2967 - acc: 0.3571\n",
      "Epoch 9/500\n",
      " - 0s - loss: 0.2920 - acc: 0.3571\n",
      "Epoch 10/500\n",
      " - 0s - loss: 0.2876 - acc: 0.3571\n",
      "Epoch 11/500\n",
      " - 0s - loss: 0.2828 - acc: 0.3571\n",
      "Epoch 12/500\n",
      " - 0s - loss: 0.2785 - acc: 0.3571\n",
      "Epoch 13/500\n",
      " - 0s - loss: 0.2742 - acc: 0.3571\n",
      "Epoch 14/500\n",
      " - 0s - loss: 0.2699 - acc: 0.3571\n",
      "Epoch 15/500\n",
      " - 0s - loss: 0.2654 - acc: 0.3571\n",
      "Epoch 16/500\n",
      " - 0s - loss: 0.2616 - acc: 0.3571\n",
      "Epoch 17/500\n",
      " - 0s - loss: 0.2573 - acc: 0.3571\n",
      "Epoch 18/500\n",
      " - 0s - loss: 0.2532 - acc: 0.3571\n",
      "Epoch 19/500\n",
      " - 0s - loss: 0.2498 - acc: 0.3571\n",
      "Epoch 20/500\n",
      " - 0s - loss: 0.2456 - acc: 0.3571\n",
      "Epoch 21/500\n",
      " - 0s - loss: 0.2423 - acc: 0.3571\n",
      "Epoch 22/500\n",
      " - 0s - loss: 0.2384 - acc: 0.3571\n",
      "Epoch 23/500\n",
      " - 0s - loss: 0.2351 - acc: 0.3571\n",
      "Epoch 24/500\n",
      " - 0s - loss: 0.2316 - acc: 0.3571\n",
      "Epoch 25/500\n",
      " - 0s - loss: 0.2283 - acc: 0.3571\n",
      "Epoch 26/500\n",
      " - 0s - loss: 0.2252 - acc: 0.3571\n",
      "Epoch 27/500\n",
      " - 0s - loss: 0.2222 - acc: 0.3571\n",
      "Epoch 28/500\n",
      " - 0s - loss: 0.2191 - acc: 0.3571\n",
      "Epoch 29/500\n",
      " - 0s - loss: 0.2165 - acc: 0.3571\n",
      "Epoch 30/500\n",
      " - 0s - loss: 0.2138 - acc: 0.3571\n",
      "Epoch 31/500\n",
      " - 0s - loss: 0.2109 - acc: 0.3571\n",
      "Epoch 32/500\n",
      " - 0s - loss: 0.2091 - acc: 0.3571\n",
      "Epoch 33/500\n",
      " - 0s - loss: 0.2077 - acc: 0.3571\n",
      "Epoch 34/500\n",
      " - 0s - loss: 0.2064 - acc: 0.3571\n",
      "Epoch 35/500\n",
      " - 0s - loss: 0.2049 - acc: 0.4286\n",
      "Epoch 36/500\n",
      " - 0s - loss: 0.2037 - acc: 0.4286\n",
      "Epoch 37/500\n",
      " - 0s - loss: 0.2026 - acc: 0.4286\n",
      "Epoch 38/500\n",
      " - 0s - loss: 0.2013 - acc: 0.4286\n",
      "Epoch 39/500\n",
      " - 0s - loss: 0.2001 - acc: 0.4286\n",
      "Epoch 40/500\n",
      " - 0s - loss: 0.1991 - acc: 0.4286\n",
      "Epoch 41/500\n",
      " - 0s - loss: 0.1981 - acc: 0.4286\n",
      "Epoch 42/500\n",
      " - 0s - loss: 0.1971 - acc: 0.4286\n",
      "Epoch 43/500\n",
      " - 0s - loss: 0.1960 - acc: 0.5000\n",
      "Epoch 44/500\n",
      " - 0s - loss: 0.1952 - acc: 0.5000\n",
      "Epoch 45/500\n",
      " - 0s - loss: 0.1941 - acc: 0.5000\n",
      "Epoch 46/500\n",
      " - 0s - loss: 0.1931 - acc: 0.5000\n",
      "Epoch 47/500\n",
      " - 0s - loss: 0.1923 - acc: 0.5000\n",
      "Epoch 48/500\n",
      " - 0s - loss: 0.1913 - acc: 0.5000\n",
      "Epoch 49/500\n",
      " - 0s - loss: 0.1905 - acc: 0.5000\n",
      "Epoch 50/500\n",
      " - 0s - loss: 0.1897 - acc: 0.5000\n",
      "Epoch 51/500\n",
      " - 0s - loss: 0.1887 - acc: 0.5000\n",
      "Epoch 52/500\n",
      " - 0s - loss: 0.1881 - acc: 0.5000\n",
      "Epoch 53/500\n",
      " - 0s - loss: 0.1873 - acc: 0.5000\n",
      "Epoch 54/500\n",
      " - 0s - loss: 0.1866 - acc: 0.5000\n",
      "Epoch 55/500\n",
      " - 0s - loss: 0.1859 - acc: 0.5000\n",
      "Epoch 56/500\n",
      " - 0s - loss: 0.1852 - acc: 0.5000\n",
      "Epoch 57/500\n",
      " - 0s - loss: 0.1843 - acc: 0.5000\n",
      "Epoch 58/500\n",
      " - 0s - loss: 0.1837 - acc: 0.5000\n",
      "Epoch 59/500\n",
      " - 0s - loss: 0.1829 - acc: 0.5000\n",
      "Epoch 60/500\n",
      " - 0s - loss: 0.1824 - acc: 0.5714\n",
      "Epoch 61/500\n",
      " - 0s - loss: 0.1816 - acc: 0.5714\n",
      "Epoch 62/500\n",
      " - 0s - loss: 0.1810 - acc: 0.5714\n",
      "Epoch 63/500\n",
      " - 0s - loss: 0.1804 - acc: 0.5714\n",
      "Epoch 64/500\n",
      " - 0s - loss: 0.1797 - acc: 0.5714\n",
      "Epoch 65/500\n",
      " - 0s - loss: 0.1792 - acc: 0.5714\n",
      "Epoch 66/500\n",
      " - 0s - loss: 0.1786 - acc: 0.5714\n",
      "Epoch 67/500\n",
      " - 0s - loss: 0.1781 - acc: 0.5714\n",
      "Epoch 68/500\n",
      " - 0s - loss: 0.1775 - acc: 0.5714\n",
      "Epoch 69/500\n",
      " - 0s - loss: 0.1771 - acc: 0.5714\n",
      "Epoch 70/500\n",
      " - 0s - loss: 0.1766 - acc: 0.5714\n",
      "Epoch 71/500\n",
      " - 0s - loss: 0.1759 - acc: 0.5714\n",
      "Epoch 72/500\n",
      " - 0s - loss: 0.1754 - acc: 0.5714\n",
      "Epoch 73/500\n",
      " - 0s - loss: 0.1752 - acc: 0.5714\n",
      "Epoch 74/500\n",
      " - 0s - loss: 0.1745 - acc: 0.5714\n",
      "Epoch 75/500\n",
      " - 0s - loss: 0.1742 - acc: 0.5714\n",
      "Epoch 76/500\n",
      " - 0s - loss: 0.1736 - acc: 0.5714\n",
      "Epoch 77/500\n",
      " - 0s - loss: 0.1731 - acc: 0.5714\n",
      "Epoch 78/500\n",
      " - 0s - loss: 0.1725 - acc: 0.5714\n",
      "Epoch 79/500\n",
      " - 0s - loss: 0.1720 - acc: 0.5714\n",
      "Epoch 80/500\n",
      " - 0s - loss: 0.1715 - acc: 0.5714\n",
      "Epoch 81/500\n",
      " - 0s - loss: 0.1710 - acc: 0.5714\n",
      "Epoch 82/500\n",
      " - 0s - loss: 0.1706 - acc: 0.5714\n",
      "Epoch 83/500\n",
      " - 0s - loss: 0.1701 - acc: 0.5714\n",
      "Epoch 84/500\n",
      " - 0s - loss: 0.1696 - acc: 0.5714\n",
      "Epoch 85/500\n",
      " - 0s - loss: 0.1692 - acc: 0.5714\n",
      "Epoch 86/500\n",
      " - 0s - loss: 0.1687 - acc: 0.5714\n",
      "Epoch 87/500\n",
      " - 0s - loss: 0.1681 - acc: 0.5714\n",
      "Epoch 88/500\n",
      " - 0s - loss: 0.1677 - acc: 0.5714\n",
      "Epoch 89/500\n",
      " - 0s - loss: 0.1673 - acc: 0.5714\n",
      "Epoch 90/500\n",
      " - 0s - loss: 0.1668 - acc: 0.5714\n",
      "Epoch 91/500\n",
      " - 0s - loss: 0.1664 - acc: 0.5714\n",
      "Epoch 92/500\n",
      " - 0s - loss: 0.1659 - acc: 0.5714\n",
      "Epoch 93/500\n",
      " - 0s - loss: 0.1654 - acc: 0.5714\n",
      "Epoch 94/500\n",
      " - 0s - loss: 0.1649 - acc: 0.5714\n",
      "Epoch 95/500\n",
      " - 0s - loss: 0.1646 - acc: 0.5714\n",
      "Epoch 96/500\n",
      " - 0s - loss: 0.1640 - acc: 0.5714\n",
      "Epoch 97/500\n",
      " - 0s - loss: 0.1635 - acc: 0.5714\n",
      "Epoch 98/500\n",
      " - 0s - loss: 0.1631 - acc: 0.5714\n",
      "Epoch 99/500\n",
      " - 0s - loss: 0.1626 - acc: 0.5714\n",
      "Epoch 100/500\n",
      " - 0s - loss: 0.1621 - acc: 0.5714\n",
      "Epoch 101/500\n",
      " - 0s - loss: 0.1617 - acc: 0.7857\n",
      "Epoch 102/500\n",
      " - 0s - loss: 0.1612 - acc: 0.7857\n",
      "Epoch 103/500\n",
      " - 0s - loss: 0.1608 - acc: 0.7857\n",
      "Epoch 104/500\n",
      " - 0s - loss: 0.1603 - acc: 0.7857\n",
      "Epoch 105/500\n",
      " - 0s - loss: 0.1598 - acc: 0.7857\n",
      "Epoch 106/500\n",
      " - 0s - loss: 0.1593 - acc: 0.7857\n",
      "Epoch 107/500\n",
      " - 0s - loss: 0.1587 - acc: 0.7857\n",
      "Epoch 108/500\n",
      " - 0s - loss: 0.1583 - acc: 0.7857\n",
      "Epoch 109/500\n",
      " - 0s - loss: 0.1577 - acc: 0.7857\n",
      "Epoch 110/500\n",
      " - 0s - loss: 0.1573 - acc: 0.7857\n",
      "Epoch 111/500\n",
      " - 0s - loss: 0.1567 - acc: 0.7857\n",
      "Epoch 112/500\n",
      " - 0s - loss: 0.1562 - acc: 0.7857\n",
      "Epoch 113/500\n",
      " - 0s - loss: 0.1557 - acc: 0.7857\n",
      "Epoch 114/500\n",
      " - 0s - loss: 0.1552 - acc: 0.7857\n",
      "Epoch 115/500\n",
      " - 0s - loss: 0.1547 - acc: 0.7857\n",
      "Epoch 116/500\n",
      " - 0s - loss: 0.1541 - acc: 0.7857\n",
      "Epoch 117/500\n",
      " - 0s - loss: 0.1537 - acc: 0.7857\n",
      "Epoch 118/500\n",
      " - 0s - loss: 0.1531 - acc: 0.7857\n",
      "Epoch 119/500\n",
      " - 0s - loss: 0.1526 - acc: 0.7857\n",
      "Epoch 120/500\n",
      " - 0s - loss: 0.1521 - acc: 0.7857\n",
      "Epoch 121/500\n",
      " - 0s - loss: 0.1516 - acc: 0.7857\n",
      "Epoch 122/500\n",
      " - 0s - loss: 0.1510 - acc: 0.7857\n",
      "Epoch 123/500\n",
      " - 0s - loss: 0.1504 - acc: 0.7857\n",
      "Epoch 124/500\n",
      " - 0s - loss: 0.1498 - acc: 0.7857\n",
      "Epoch 125/500\n",
      " - 0s - loss: 0.1492 - acc: 0.7857\n",
      "Epoch 126/500\n",
      " - 0s - loss: 0.1485 - acc: 0.7857\n",
      "Epoch 127/500\n",
      " - 0s - loss: 0.1478 - acc: 0.7857\n",
      "Epoch 128/500\n",
      " - 0s - loss: 0.1471 - acc: 0.7857\n",
      "Epoch 129/500\n",
      " - 0s - loss: 0.1464 - acc: 0.7857\n",
      "Epoch 130/500\n",
      " - 0s - loss: 0.1457 - acc: 0.7857\n",
      "Epoch 131/500\n",
      " - 0s - loss: 0.1448 - acc: 0.7857\n",
      "Epoch 132/500\n",
      " - 0s - loss: 0.1439 - acc: 0.7857\n",
      "Epoch 133/500\n",
      " - 0s - loss: 0.1431 - acc: 0.7857\n",
      "Epoch 134/500\n",
      " - 0s - loss: 0.1421 - acc: 0.7857\n",
      "Epoch 135/500\n",
      " - 0s - loss: 0.1414 - acc: 0.7857\n",
      "Epoch 136/500\n",
      " - 0s - loss: 0.1404 - acc: 0.7857\n",
      "Epoch 137/500\n",
      " - 0s - loss: 0.1393 - acc: 0.7857\n",
      "Epoch 138/500\n",
      " - 0s - loss: 0.1383 - acc: 0.7857\n",
      "Epoch 139/500\n",
      " - 0s - loss: 0.1374 - acc: 0.7857\n",
      "Epoch 140/500\n",
      " - 0s - loss: 0.1361 - acc: 0.7857\n",
      "Epoch 141/500\n",
      " - 0s - loss: 0.1351 - acc: 0.7857\n",
      "Epoch 142/500\n",
      " - 0s - loss: 0.1339 - acc: 0.7857\n",
      "Epoch 143/500\n",
      " - 0s - loss: 0.1326 - acc: 0.7857\n",
      "Epoch 144/500\n",
      " - 0s - loss: 0.1315 - acc: 0.7857\n",
      "Epoch 145/500\n",
      " - 0s - loss: 0.1301 - acc: 0.7857\n",
      "Epoch 146/500\n",
      " - 0s - loss: 0.1289 - acc: 0.7857\n",
      "Epoch 147/500\n",
      " - 0s - loss: 0.1278 - acc: 0.7857\n",
      "Epoch 148/500\n",
      " - 0s - loss: 0.1263 - acc: 0.7857\n",
      "Epoch 149/500\n",
      " - 0s - loss: 0.1251 - acc: 0.7857\n",
      "Epoch 150/500\n",
      " - 0s - loss: 0.1236 - acc: 0.7857\n",
      "Epoch 151/500\n",
      " - 0s - loss: 0.1222 - acc: 0.7857\n",
      "Epoch 152/500\n",
      " - 0s - loss: 0.1212 - acc: 0.7857\n",
      "Epoch 153/500\n",
      " - 0s - loss: 0.1195 - acc: 0.7857\n",
      "Epoch 154/500\n",
      " - 0s - loss: 0.1181 - acc: 0.7857\n",
      "Epoch 155/500\n",
      " - 0s - loss: 0.1168 - acc: 0.7857\n",
      "Epoch 156/500\n",
      " - 0s - loss: 0.1153 - acc: 0.7857\n",
      "Epoch 157/500\n",
      " - 0s - loss: 0.1139 - acc: 0.7857\n",
      "Epoch 158/500\n",
      " - 0s - loss: 0.1127 - acc: 0.7857\n",
      "Epoch 159/500\n",
      " - 0s - loss: 0.1112 - acc: 0.7857\n",
      "Epoch 160/500\n",
      " - 0s - loss: 0.1100 - acc: 0.7857\n",
      "Epoch 161/500\n",
      " - 0s - loss: 0.1086 - acc: 0.7857\n",
      "Epoch 162/500\n",
      " - 0s - loss: 0.1076 - acc: 0.7857\n",
      "Epoch 163/500\n",
      " - 0s - loss: 0.1059 - acc: 0.7857\n",
      "Epoch 164/500\n",
      " - 0s - loss: 0.1050 - acc: 0.7857\n",
      "Epoch 165/500\n",
      " - 0s - loss: 0.1036 - acc: 0.7857\n",
      "Epoch 166/500\n",
      " - 0s - loss: 0.1024 - acc: 0.7857\n",
      "Epoch 167/500\n",
      " - 0s - loss: 0.1012 - acc: 0.7857\n",
      "Epoch 168/500\n",
      " - 0s - loss: 0.1000 - acc: 0.7857\n",
      "Epoch 169/500\n",
      " - 0s - loss: 0.0989 - acc: 0.7857\n",
      "Epoch 170/500\n",
      " - 0s - loss: 0.0978 - acc: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/500\n",
      " - 0s - loss: 0.0969 - acc: 0.7857\n",
      "Epoch 172/500\n",
      " - 0s - loss: 0.0956 - acc: 0.7857\n",
      "Epoch 173/500\n",
      " - 0s - loss: 0.0948 - acc: 0.7857\n",
      "Epoch 174/500\n",
      " - 0s - loss: 0.0938 - acc: 0.7857\n",
      "Epoch 175/500\n",
      " - 0s - loss: 0.0927 - acc: 0.7857\n",
      "Epoch 176/500\n",
      " - 0s - loss: 0.0919 - acc: 0.7857\n",
      "Epoch 177/500\n",
      " - 0s - loss: 0.0909 - acc: 0.7857\n",
      "Epoch 178/500\n",
      " - 0s - loss: 0.0901 - acc: 0.7857\n",
      "Epoch 179/500\n",
      " - 0s - loss: 0.0891 - acc: 0.7857\n",
      "Epoch 180/500\n",
      " - 0s - loss: 0.0883 - acc: 0.7857\n",
      "Epoch 181/500\n",
      " - 0s - loss: 0.0875 - acc: 0.7857\n",
      "Epoch 182/500\n",
      " - 0s - loss: 0.0867 - acc: 0.7857\n",
      "Epoch 183/500\n",
      " - 0s - loss: 0.0860 - acc: 0.7857\n",
      "Epoch 184/500\n",
      " - 0s - loss: 0.0853 - acc: 0.7857\n",
      "Epoch 185/500\n",
      " - 0s - loss: 0.0845 - acc: 0.7857\n",
      "Epoch 186/500\n",
      " - 0s - loss: 0.0837 - acc: 0.7857\n",
      "Epoch 187/500\n",
      " - 0s - loss: 0.0831 - acc: 0.7857\n",
      "Epoch 188/500\n",
      " - 0s - loss: 0.0824 - acc: 0.7857\n",
      "Epoch 189/500\n",
      " - 0s - loss: 0.0817 - acc: 1.0000\n",
      "Epoch 190/500\n",
      " - 0s - loss: 0.0811 - acc: 1.0000\n",
      "Epoch 191/500\n",
      " - 0s - loss: 0.0806 - acc: 1.0000\n",
      "Epoch 192/500\n",
      " - 0s - loss: 0.0798 - acc: 1.0000\n",
      "Epoch 193/500\n",
      " - 0s - loss: 0.0793 - acc: 1.0000\n",
      "Epoch 194/500\n",
      " - 0s - loss: 0.0787 - acc: 1.0000\n",
      "Epoch 195/500\n",
      " - 0s - loss: 0.0781 - acc: 1.0000\n",
      "Epoch 196/500\n",
      " - 0s - loss: 0.0777 - acc: 1.0000\n",
      "Epoch 197/500\n",
      " - 0s - loss: 0.0770 - acc: 1.0000\n",
      "Epoch 198/500\n",
      " - 0s - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 199/500\n",
      " - 0s - loss: 0.0760 - acc: 1.0000\n",
      "Epoch 200/500\n",
      " - 0s - loss: 0.0755 - acc: 1.0000\n",
      "Epoch 201/500\n",
      " - 0s - loss: 0.0751 - acc: 1.0000\n",
      "Epoch 202/500\n",
      " - 0s - loss: 0.0745 - acc: 1.0000\n",
      "Epoch 203/500\n",
      " - 0s - loss: 0.0741 - acc: 1.0000\n",
      "Epoch 204/500\n",
      " - 0s - loss: 0.0736 - acc: 1.0000\n",
      "Epoch 205/500\n",
      " - 0s - loss: 0.0731 - acc: 1.0000\n",
      "Epoch 206/500\n",
      " - 0s - loss: 0.0727 - acc: 1.0000\n",
      "Epoch 207/500\n",
      " - 0s - loss: 0.0723 - acc: 1.0000\n",
      "Epoch 208/500\n",
      " - 0s - loss: 0.0718 - acc: 1.0000\n",
      "Epoch 209/500\n",
      " - 0s - loss: 0.0714 - acc: 1.0000\n",
      "Epoch 210/500\n",
      " - 0s - loss: 0.0709 - acc: 1.0000\n",
      "Epoch 211/500\n",
      " - 0s - loss: 0.0706 - acc: 1.0000\n",
      "Epoch 212/500\n",
      " - 0s - loss: 0.0702 - acc: 1.0000\n",
      "Epoch 213/500\n",
      " - 0s - loss: 0.0697 - acc: 1.0000\n",
      "Epoch 214/500\n",
      " - 0s - loss: 0.0693 - acc: 1.0000\n",
      "Epoch 215/500\n",
      " - 0s - loss: 0.0689 - acc: 1.0000\n",
      "Epoch 216/500\n",
      " - 0s - loss: 0.0686 - acc: 1.0000\n",
      "Epoch 217/500\n",
      " - 0s - loss: 0.0681 - acc: 1.0000\n",
      "Epoch 218/500\n",
      " - 0s - loss: 0.0678 - acc: 1.0000\n",
      "Epoch 219/500\n",
      " - 0s - loss: 0.0674 - acc: 1.0000\n",
      "Epoch 220/500\n",
      " - 0s - loss: 0.0671 - acc: 1.0000\n",
      "Epoch 221/500\n",
      " - 0s - loss: 0.0667 - acc: 1.0000\n",
      "Epoch 222/500\n",
      " - 0s - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 223/500\n",
      " - 0s - loss: 0.0660 - acc: 1.0000\n",
      "Epoch 224/500\n",
      " - 0s - loss: 0.0656 - acc: 1.0000\n",
      "Epoch 225/500\n",
      " - 0s - loss: 0.0652 - acc: 1.0000\n",
      "Epoch 226/500\n",
      " - 0s - loss: 0.0648 - acc: 1.0000\n",
      "Epoch 227/500\n",
      " - 0s - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 228/500\n",
      " - 0s - loss: 0.0641 - acc: 1.0000\n",
      "Epoch 229/500\n",
      " - 0s - loss: 0.0638 - acc: 1.0000\n",
      "Epoch 230/500\n",
      " - 0s - loss: 0.0634 - acc: 1.0000\n",
      "Epoch 231/500\n",
      " - 0s - loss: 0.0630 - acc: 1.0000\n",
      "Epoch 232/500\n",
      " - 0s - loss: 0.0627 - acc: 1.0000\n",
      "Epoch 233/500\n",
      " - 0s - loss: 0.0623 - acc: 1.0000\n",
      "Epoch 234/500\n",
      " - 0s - loss: 0.0619 - acc: 1.0000\n",
      "Epoch 235/500\n",
      " - 0s - loss: 0.0616 - acc: 1.0000\n",
      "Epoch 236/500\n",
      " - 0s - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 237/500\n",
      " - 0s - loss: 0.0609 - acc: 1.0000\n",
      "Epoch 238/500\n",
      " - 0s - loss: 0.0605 - acc: 1.0000\n",
      "Epoch 239/500\n",
      " - 0s - loss: 0.0601 - acc: 1.0000\n",
      "Epoch 240/500\n",
      " - 0s - loss: 0.0597 - acc: 1.0000\n",
      "Epoch 241/500\n",
      " - 0s - loss: 0.0594 - acc: 1.0000\n",
      "Epoch 242/500\n",
      " - 0s - loss: 0.0590 - acc: 1.0000\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.0586 - acc: 1.0000\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.0582 - acc: 1.0000\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.0578 - acc: 1.0000\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.0574 - acc: 1.0000\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.0571 - acc: 1.0000\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.0566 - acc: 1.0000\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.0562 - acc: 1.0000\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.0559 - acc: 1.0000\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.0554 - acc: 1.0000\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.0550 - acc: 1.0000\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.0546 - acc: 1.0000\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.0542 - acc: 1.0000\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.0537 - acc: 1.0000\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.0532 - acc: 1.0000\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.0529 - acc: 1.0000\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.0524 - acc: 1.0000\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.0519 - acc: 1.0000\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.0514 - acc: 1.0000\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.0500 - acc: 1.0000\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.0495 - acc: 1.0000\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.0490 - acc: 1.0000\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.0485 - acc: 1.0000\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.0480 - acc: 1.0000\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.0475 - acc: 1.0000\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.0465 - acc: 1.0000\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.0460 - acc: 1.0000\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.0455 - acc: 1.0000\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.0449 - acc: 1.0000\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.0438 - acc: 1.0000\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.0433 - acc: 1.0000\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.0428 - acc: 1.0000\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.0406 - acc: 1.0000\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.0400 - acc: 1.0000\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.0396 - acc: 1.0000\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.0389 - acc: 1.0000\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.0383 - acc: 1.0000\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.0378 - acc: 1.0000\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.0367 - acc: 1.0000\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.0361 - acc: 1.0000\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.0350 - acc: 1.0000\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.0333 - acc: 1.0000\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.0322 - acc: 1.0000\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.0307 - acc: 1.0000\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.0291 - acc: 1.0000\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.0276 - acc: 1.0000\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.0239 - acc: 1.0000\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.0231 - acc: 1.0000\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.0199 - acc: 1.0000\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 338/500\n",
      " - 0s - loss: 0.0151 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/500\n",
      " - 0s - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.0016 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b27a78748>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.fit([data[1:15], ht_input[1:15]], \n",
    "                   np_label[1:15], \n",
    "                   epochs=500,\n",
    "                   batch_size=1,\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.10182971],\n",
       "        [-0.3855561 ],\n",
       "        [ 2.3171604 ],\n",
       "        [ 2.0895085 ],\n",
       "        [-3.093571  ]], dtype=float32),\n",
       " array([-0.63574654], dtype=float32),\n",
       " array([[2.594885]], dtype=float32),\n",
       " array([[2.4404867]], dtype=float32),\n",
       " array([[2.2996926]], dtype=float32),\n",
       " array([[1.8188928]], dtype=float32),\n",
       " array([[-1.3551998],\n",
       "        [ 1.4264638],\n",
       "        [ 2.0924454],\n",
       "        [-1.5386447]], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_weight = combined_model.get_weights()\n",
    "net_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_sign \t Tanh_w \t ReLu_w \t sigmoid_w \t word_importance\n",
      "-1 \t -0.3855561 \t [2.594885] \t -1.3551998 \t [-3.5165877]\n",
      "1 \t 2.3171604 \t [2.4404867] \t 1.4264638 \t [3.481266]\n",
      "1 \t 2.0895085 \t [2.2996926] \t 2.0924454 \t [4.811981]\n",
      "-1 \t -3.093571 \t [1.8188928] \t -1.5386447 \t [-2.7986298]\n"
     ]
    }
   ],
   "source": [
    "print('word_sign \\t Tanh_w \\t ReLu_w \\t sigmoid_w \\t word_importance')\n",
    "\n",
    "for i in range(4):\n",
    "    print(np.sign(word_weight[i+1]), '\\t', net_weight[0].flatten()[i+1], \n",
    "          '\\t', net_weight[i+2].flatten(), '\\t',net_weight[6].flatten()[i], '\\t',\n",
    "         net_weight[i+2].flatten()*net_weight[6].flatten()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report():\n",
    "    for i in range(1,15):\n",
    "        bm = base_model.predict(np.reshape(data[i], (1,5)))\n",
    "        \n",
    "        cm = combined_model.predict([np.reshape(data[i], (1,5)), \n",
    "                                np.reshape(ht_input[i], (1,4))])\n",
    "        \n",
    "#         document_output = 'multiply'\n",
    "#         document_predict = Model(inputs=combined_model.input,\n",
    "#                                      outputs=combined_model.get_layer(document_output).output)\n",
    "#         doc_output = document_predict.predict([np.reshape(data[i], (1,5)), \n",
    "#                                       ht_1_input[i], \n",
    "#                                       ht_2_input[i], \n",
    "#                                       ht_3_input[i], \n",
    "#                                       ht_4_input[i]])\n",
    "        \n",
    "        layer_name = 'concatenate'\n",
    "        concat_after_relu = Model(inputs=combined_model.input,\n",
    "                                     outputs=combined_model.get_layer(layer_name).output)\n",
    "        concat_output = concat_after_relu.predict([np.reshape(data[i], (1,5)), \n",
    "                                     np.reshape(ht_input[i], (1,4))])\n",
    "        \n",
    "        print(data[i], '\\t', np_label[i], '\\t', bm.flatten(), '\\t', cm.flatten(), '\\t',concat_output.flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 0. 0.] \t 0 \t [-0.8086557] \t [0.05500743] \t [2.0983686 0.        0.        0.       ]\n",
      "[1. 0. 1. 0. 0.] \t 1 \t [0.9185369] \t [0.9607466] \t [0.       2.241677 0.       0.      ]\n",
      "[1. 0. 0. 1. 0.] \t 1 \t [0.8745086] \t [0.98534364] \t [0.       0.       2.011101 0.      ]\n",
      "[1. 0. 0. 0. 1.] \t 0 \t [-0.99906] \t [0.05754076] \t [0.       0.       0.       1.817183]\n",
      "[1. 1. 1. 0. 0.] \t 1 \t [0.83182406] \t [0.9476385] \t [0.        2.0300555 0.        0.       ]\n",
      "[1. 1. 0. 1. 0.] \t 1 \t [0.74710757] \t [0.97327507] \t [0.        0.        1.7181177 0.       ]\n",
      "[1. 1. 0. 0. 1.] \t 0 \t [-0.99956506] \t [0.00181026] \t [2.5937564 0.        0.        1.8181018]\n",
      "[1. 0. 1. 1. 0.] \t 1 \t [0.99870026] \t [0.9997471] \t [0.        2.4373147 2.2967036 0.       ]\n",
      "[1. 0. 1. 0. 1.] \t 0 \t [-0.90764403] \t [0.07309035] \t [0.        0.        0.        1.6509073]\n",
      "[1. 0. 0. 1. 1.] \t 0 \t [-0.94041646] \t [0.06711479] \t [0.        0.        0.        1.7105168]\n",
      "[1. 1. 1. 1. 0.] \t 1 \t [0.9971921] \t [0.999744] \t [0.        2.433634  2.2932353 0.       ]\n",
      "[1. 1. 1. 0. 1.] \t 0 \t [-0.9561983] \t [0.00237922] \t [2.4812248 0.        0.        1.7392222]\n",
      "[1. 1. 0. 1. 1.] \t 0 \t [-0.9719942] \t [0.00215382] \t [2.5222132 0.        0.        1.7679533]\n",
      "[1. 0. 1. 1. 1.] \t 1 \t [0.51940286] \t [0.9867122] \t [0.        1.2675958 1.194467  0.       ]\n"
     ]
    }
   ],
   "source": [
    "report()\n",
    "# need to modify the ht_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  2,  3, -4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# base_model.save('overfit_base_model.h5')\n",
    "# combined_model.save('overfit_combined_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm = base_model.predict(np.reshape(data[test_idx], (1,5)))\n",
    "# print(bm)\n",
    "\n",
    "# before jointly trained.\n",
    "# 0.7995629"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB network Model\n",
    "#### concat and split layer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               [(None, 1), (None, 1 0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_19 (Model)                (None, 1)            6           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 1)            0           lambda_2[0][0]                   \n",
      "                                                                 model_19[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 1)            0           lambda_2[0][1]                   \n",
      "                                                                 model_19[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 1)            0           lambda_2[0][2]                   \n",
      "                                                                 model_19[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 1)            0           lambda_2[0][3]                   \n",
      "                                                                 model_19[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_layer (Dense)              (None, 1)            1           multiply_7[0][0]                 \n",
      "                                                                 multiply_8[0][0]                 \n",
      "                                                                 multiply_9[0][0]                 \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Lambda)            (None, 4)            0           relu_layer[0][0]                 \n",
      "                                                                 relu_layer[1][0]                 \n",
      "                                                                 relu_layer[2][0]                 \n",
      "                                                                 relu_layer[3][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            5           concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the combined model\n",
    "# Combined model\n",
    "human_terms_len = 4\n",
    "\n",
    "base_model = build_base_model(data.shape[1])\n",
    "\n",
    "combined_input_layer = Input(shape=(data.shape[1],))\n",
    "\n",
    "# build the hard coded weight for human terms\n",
    "ht_input_layer = Input(shape=(human_terms_len,))\n",
    "\n",
    "split = Lambda( lambda x: tf.split(x,num_or_size_splits=human_terms_len,axis=1))(ht_input_layer)\n",
    "\n",
    "# get the document prediction\n",
    "label_layer = base_model(combined_input_layer)\n",
    "\n",
    "# multiply and pass it into relu\n",
    "# initialize relu layer\n",
    "\n",
    "relu_layer = Dense(1, activation='relu', name='relu_layer', use_bias=False, kernel_initializer='ones')\n",
    "\n",
    "# stack the multiply layer\n",
    "dense_layer = []\n",
    "for i in range(human_terms_len):\n",
    "    dense_layer.append(relu_layer(Multiply()([split[i], label_layer])))\n",
    "\n",
    "# concat all the result   \n",
    "concat = Lambda( lambda x: tf.concat(x, axis=1), name='concatenate')(dense_layer)\n",
    "\n",
    "# pass it to sigmoid layer\n",
    "output_layer = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "combined_model = Model(inputs=[combined_input_layer, ht_input_layer], outputs=output_layer)\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(loss='mse',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "combined_model.compile(loss='mse',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 0s - loss: 0.5107 - acc: 0.2857\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 0.5044 - acc: 0.2857\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 0.4991 - acc: 0.2857\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 0.4932 - acc: 0.2857\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 0.4893 - acc: 0.3571\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 0.4838 - acc: 0.3571\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 0.4799 - acc: 0.3571\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 0.4756 - acc: 0.3571\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 0.4712 - acc: 0.3571\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 0.4674 - acc: 0.3571\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 0.4628 - acc: 0.3571\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 0.4587 - acc: 0.3571\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 0.4563 - acc: 0.3571\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 0.4517 - acc: 0.3571\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 0.4472 - acc: 0.3571\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 0.4442 - acc: 0.3571\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 0.4405 - acc: 0.3571\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 0.4377 - acc: 0.3571\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 0.4343 - acc: 0.3571\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 0.4304 - acc: 0.3571\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 0.4272 - acc: 0.4286\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 0.4266 - acc: 0.4286\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 0.4215 - acc: 0.4286\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 0.4192 - acc: 0.4286\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 0.4151 - acc: 0.4286\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 0.4117 - acc: 0.4286\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 0.4091 - acc: 0.4286\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 0.4061 - acc: 0.4286\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 0.4032 - acc: 0.4286\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 0.4004 - acc: 0.4286\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 0.3974 - acc: 0.4286\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 0.3953 - acc: 0.4286\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 0.3923 - acc: 0.4286\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 0.3902 - acc: 0.4286\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 0.3870 - acc: 0.4286\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 0.3846 - acc: 0.4286\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 0.3818 - acc: 0.4286\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 0.3789 - acc: 0.4286\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 0.3772 - acc: 0.4286\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 0.3739 - acc: 0.4286\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 0.3718 - acc: 0.4286\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 0.3688 - acc: 0.4286\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 0.3675 - acc: 0.4286\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 0.3648 - acc: 0.4286\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 0.3624 - acc: 0.4286\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 0.3593 - acc: 0.4286\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 0.3570 - acc: 0.4286\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 0.3552 - acc: 0.4286\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 0.3526 - acc: 0.4286\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 0.3504 - acc: 0.4286\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 0.3486 - acc: 0.4286\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 0.3470 - acc: 0.4286\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 0.3435 - acc: 0.4286\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 0.3416 - acc: 0.4286\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 0.3398 - acc: 0.4286\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 0.3372 - acc: 0.4286\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 0.3357 - acc: 0.4286\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 0.3344 - acc: 0.4286\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 0.3317 - acc: 0.4286\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 0.3295 - acc: 0.4286\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 0.3271 - acc: 0.4286\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 0.3258 - acc: 0.4286\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 0.3231 - acc: 0.4286\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.3217 - acc: 0.4286\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.3193 - acc: 0.4286\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.3178 - acc: 0.4286\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.3157 - acc: 0.4286\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 0.3141 - acc: 0.4286\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 0.3120 - acc: 0.4286\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 0.3116 - acc: 0.4286\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 0.3081 - acc: 0.4286\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 0.3066 - acc: 0.4286\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 0.3054 - acc: 0.4286\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 0.3036 - acc: 0.4286\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.3015 - acc: 0.4286\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.2995 - acc: 0.4286\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.2981 - acc: 0.4286\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.2969 - acc: 0.4286\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 0.2950 - acc: 0.4286\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.2941 - acc: 0.4286\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 0.2913 - acc: 0.4286\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.2898 - acc: 0.4286\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.2883 - acc: 0.4286\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.2868 - acc: 0.4286\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 0.2850 - acc: 0.4286\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 0.2837 - acc: 0.4286\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 0.2827 - acc: 0.4286\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 0.2820 - acc: 0.4286\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 0.2794 - acc: 0.3571\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 0.2772 - acc: 0.4286\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 0.2763 - acc: 0.4286\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 0.2750 - acc: 0.4286\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 0.2729 - acc: 0.4286\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 0.2717 - acc: 0.4286\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 0.2702 - acc: 0.4286\n",
      "Epoch 96/1000\n",
      " - 0s - loss: 0.2689 - acc: 0.4286\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 0.2671 - acc: 0.4286\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.2658 - acc: 0.4286\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 0.2643 - acc: 0.4286\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 0.2631 - acc: 0.4286\n",
      "Epoch 101/1000\n",
      " - 0s - loss: 0.2626 - acc: 0.4286\n",
      "Epoch 102/1000\n",
      " - 0s - loss: 0.2609 - acc: 0.4286\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 0.2600 - acc: 0.4286\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 0.2576 - acc: 0.4286\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 0.2568 - acc: 0.4286\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 0.2564 - acc: 0.4286\n",
      "Epoch 107/1000\n",
      " - 0s - loss: 0.2539 - acc: 0.4286\n",
      "Epoch 108/1000\n",
      " - 0s - loss: 0.2528 - acc: 0.4286\n",
      "Epoch 109/1000\n",
      " - 0s - loss: 0.2516 - acc: 0.4286\n",
      "Epoch 110/1000\n",
      " - 0s - loss: 0.2505 - acc: 0.4286\n",
      "Epoch 111/1000\n",
      " - 0s - loss: 0.2489 - acc: 0.4286\n",
      "Epoch 112/1000\n",
      " - 0s - loss: 0.2478 - acc: 0.4286\n",
      "Epoch 113/1000\n",
      " - 0s - loss: 0.2466 - acc: 0.4286\n",
      "Epoch 114/1000\n",
      " - 0s - loss: 0.2457 - acc: 0.4286\n",
      "Epoch 115/1000\n",
      " - 0s - loss: 0.2441 - acc: 0.4286\n",
      "Epoch 116/1000\n",
      " - 0s - loss: 0.2429 - acc: 0.4286\n",
      "Epoch 117/1000\n",
      " - 0s - loss: 0.2424 - acc: 0.5000\n",
      "Epoch 118/1000\n",
      " - 0s - loss: 0.2406 - acc: 0.5000\n",
      "Epoch 119/1000\n",
      " - 0s - loss: 0.2394 - acc: 0.5000\n",
      "Epoch 120/1000\n",
      " - 0s - loss: 0.2381 - acc: 0.5000\n",
      "Epoch 121/1000\n",
      " - 0s - loss: 0.2369 - acc: 0.5000\n",
      "Epoch 122/1000\n",
      " - 0s - loss: 0.2359 - acc: 0.5000\n",
      "Epoch 123/1000\n",
      " - 0s - loss: 0.2351 - acc: 0.5000\n",
      "Epoch 124/1000\n",
      " - 0s - loss: 0.2345 - acc: 0.5000\n",
      "Epoch 125/1000\n",
      " - 0s - loss: 0.2323 - acc: 0.5000\n",
      "Epoch 126/1000\n",
      " - 0s - loss: 0.2317 - acc: 0.5000\n",
      "Epoch 127/1000\n",
      " - 0s - loss: 0.2316 - acc: 0.5000\n",
      "Epoch 128/1000\n",
      " - 0s - loss: 0.2297 - acc: 0.5714\n",
      "Epoch 129/1000\n",
      " - 0s - loss: 0.2289 - acc: 0.5714\n",
      "Epoch 130/1000\n",
      " - 0s - loss: 0.2272 - acc: 0.5714\n",
      "Epoch 131/1000\n",
      " - 0s - loss: 0.2262 - acc: 0.5714\n",
      "Epoch 132/1000\n",
      " - 0s - loss: 0.2253 - acc: 0.5714\n",
      "Epoch 133/1000\n",
      " - 0s - loss: 0.2240 - acc: 0.5714\n",
      "Epoch 134/1000\n",
      " - 0s - loss: 0.2231 - acc: 0.5714\n",
      "Epoch 135/1000\n",
      " - 0s - loss: 0.2223 - acc: 0.5714\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.2209 - acc: 0.5714\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.2200 - acc: 0.5714\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.2192 - acc: 0.5714\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.2182 - acc: 0.5714\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.2172 - acc: 0.5714\n",
      "Epoch 141/1000\n",
      " - 0s - loss: 0.2165 - acc: 0.5714\n",
      "Epoch 142/1000\n",
      " - 0s - loss: 0.2152 - acc: 0.5714\n",
      "Epoch 143/1000\n",
      " - 0s - loss: 0.2144 - acc: 0.5714\n",
      "Epoch 144/1000\n",
      " - 0s - loss: 0.2132 - acc: 0.5714\n",
      "Epoch 145/1000\n",
      " - 0s - loss: 0.2122 - acc: 0.5714\n",
      "Epoch 146/1000\n",
      " - 0s - loss: 0.2117 - acc: 0.5714\n",
      "Epoch 147/1000\n",
      " - 0s - loss: 0.2106 - acc: 0.5714\n",
      "Epoch 148/1000\n",
      " - 0s - loss: 0.2095 - acc: 0.5714\n",
      "Epoch 149/1000\n",
      " - 0s - loss: 0.2086 - acc: 0.5714\n",
      "Epoch 150/1000\n",
      " - 0s - loss: 0.2076 - acc: 0.5714\n",
      "Epoch 151/1000\n",
      " - 0s - loss: 0.2065 - acc: 0.5714\n",
      "Epoch 152/1000\n",
      " - 0s - loss: 0.2058 - acc: 0.5714\n",
      "Epoch 153/1000\n",
      " - 0s - loss: 0.2050 - acc: 0.5714\n",
      "Epoch 154/1000\n",
      " - 0s - loss: 0.2049 - acc: 0.5714\n",
      "Epoch 155/1000\n",
      " - 0s - loss: 0.2033 - acc: 0.5714\n",
      "Epoch 156/1000\n",
      " - 0s - loss: 0.2024 - acc: 0.5714\n",
      "Epoch 157/1000\n",
      " - 0s - loss: 0.2012 - acc: 0.6429\n",
      "Epoch 158/1000\n",
      " - 0s - loss: 0.2013 - acc: 0.6429\n",
      "Epoch 159/1000\n",
      " - 0s - loss: 0.2000 - acc: 0.6429\n",
      "Epoch 160/1000\n",
      " - 0s - loss: 0.1988 - acc: 0.6429\n",
      "Epoch 161/1000\n",
      " - 0s - loss: 0.1978 - acc: 0.6429\n",
      "Epoch 162/1000\n",
      " - 0s - loss: 0.1972 - acc: 0.7143\n",
      "Epoch 163/1000\n",
      " - 0s - loss: 0.1963 - acc: 0.7143\n",
      "Epoch 164/1000\n",
      " - 0s - loss: 0.1956 - acc: 0.7143\n",
      "Epoch 165/1000\n",
      " - 0s - loss: 0.1945 - acc: 0.7143\n",
      "Epoch 166/1000\n",
      " - 0s - loss: 0.1937 - acc: 0.7143\n",
      "Epoch 167/1000\n",
      " - 0s - loss: 0.1927 - acc: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      " - 0s - loss: 0.1921 - acc: 0.7143\n",
      "Epoch 169/1000\n",
      " - 0s - loss: 0.1914 - acc: 0.7143\n",
      "Epoch 170/1000\n",
      " - 0s - loss: 0.1906 - acc: 0.7143\n",
      "Epoch 171/1000\n",
      " - 0s - loss: 0.1895 - acc: 0.7143\n",
      "Epoch 172/1000\n",
      " - 0s - loss: 0.1889 - acc: 0.7143\n",
      "Epoch 173/1000\n",
      " - 0s - loss: 0.1880 - acc: 0.7143\n",
      "Epoch 174/1000\n",
      " - 0s - loss: 0.1876 - acc: 0.7143\n",
      "Epoch 175/1000\n",
      " - 0s - loss: 0.1866 - acc: 0.7143\n",
      "Epoch 176/1000\n",
      " - 0s - loss: 0.1857 - acc: 0.7143\n",
      "Epoch 177/1000\n",
      " - 0s - loss: 0.1852 - acc: 0.7143\n",
      "Epoch 178/1000\n",
      " - 0s - loss: 0.1844 - acc: 0.7143\n",
      "Epoch 179/1000\n",
      " - 0s - loss: 0.1839 - acc: 0.7143\n",
      "Epoch 180/1000\n",
      " - 0s - loss: 0.1829 - acc: 0.7143\n",
      "Epoch 181/1000\n",
      " - 0s - loss: 0.1820 - acc: 0.7143\n",
      "Epoch 182/1000\n",
      " - 0s - loss: 0.1812 - acc: 0.7143\n",
      "Epoch 183/1000\n",
      " - 0s - loss: 0.1806 - acc: 0.7143\n",
      "Epoch 184/1000\n",
      " - 0s - loss: 0.1797 - acc: 0.7143\n",
      "Epoch 185/1000\n",
      " - 0s - loss: 0.1796 - acc: 0.7143\n",
      "Epoch 186/1000\n",
      " - 0s - loss: 0.1791 - acc: 0.7143\n",
      "Epoch 187/1000\n",
      " - 0s - loss: 0.1776 - acc: 0.7143\n",
      "Epoch 188/1000\n",
      " - 0s - loss: 0.1772 - acc: 0.7143\n",
      "Epoch 189/1000\n",
      " - 0s - loss: 0.1762 - acc: 0.7143\n",
      "Epoch 190/1000\n",
      " - 0s - loss: 0.1758 - acc: 0.7143\n",
      "Epoch 191/1000\n",
      " - 0s - loss: 0.1748 - acc: 0.7143\n",
      "Epoch 192/1000\n",
      " - 0s - loss: 0.1743 - acc: 0.7143\n",
      "Epoch 193/1000\n",
      " - 0s - loss: 0.1733 - acc: 0.7857\n",
      "Epoch 194/1000\n",
      " - 0s - loss: 0.1727 - acc: 0.7857\n",
      "Epoch 195/1000\n",
      " - 0s - loss: 0.1722 - acc: 0.7857\n",
      "Epoch 196/1000\n",
      " - 0s - loss: 0.1714 - acc: 0.7857\n",
      "Epoch 197/1000\n",
      " - 0s - loss: 0.1706 - acc: 0.7857\n",
      "Epoch 198/1000\n",
      " - 0s - loss: 0.1701 - acc: 0.7857\n",
      "Epoch 199/1000\n",
      " - 0s - loss: 0.1695 - acc: 0.8571\n",
      "Epoch 200/1000\n",
      " - 0s - loss: 0.1687 - acc: 0.8571\n",
      "Epoch 201/1000\n",
      " - 0s - loss: 0.1683 - acc: 0.8571\n",
      "Epoch 202/1000\n",
      " - 0s - loss: 0.1676 - acc: 0.7857\n",
      "Epoch 203/1000\n",
      " - 0s - loss: 0.1670 - acc: 0.8571\n",
      "Epoch 204/1000\n",
      " - 0s - loss: 0.1659 - acc: 0.8571\n",
      "Epoch 205/1000\n",
      " - 0s - loss: 0.1658 - acc: 0.8571\n",
      "Epoch 206/1000\n",
      " - 0s - loss: 0.1649 - acc: 0.8571\n",
      "Epoch 207/1000\n",
      " - 0s - loss: 0.1640 - acc: 0.8571\n",
      "Epoch 208/1000\n",
      " - 0s - loss: 0.1636 - acc: 0.8571\n",
      "Epoch 209/1000\n",
      " - 0s - loss: 0.1628 - acc: 0.8571\n",
      "Epoch 210/1000\n",
      " - 0s - loss: 0.1626 - acc: 0.8571\n",
      "Epoch 211/1000\n",
      " - 0s - loss: 0.1615 - acc: 0.8571\n",
      "Epoch 212/1000\n",
      " - 0s - loss: 0.1609 - acc: 0.8571\n",
      "Epoch 213/1000\n",
      " - 0s - loss: 0.1604 - acc: 0.8571\n",
      "Epoch 214/1000\n",
      " - 0s - loss: 0.1596 - acc: 0.8571\n",
      "Epoch 215/1000\n",
      " - 0s - loss: 0.1595 - acc: 0.8571\n",
      "Epoch 216/1000\n",
      " - 0s - loss: 0.1585 - acc: 0.8571\n",
      "Epoch 217/1000\n",
      " - 0s - loss: 0.1577 - acc: 0.8571\n",
      "Epoch 218/1000\n",
      " - 0s - loss: 0.1572 - acc: 0.8571\n",
      "Epoch 219/1000\n",
      " - 0s - loss: 0.1569 - acc: 0.8571\n",
      "Epoch 220/1000\n",
      " - 0s - loss: 0.1560 - acc: 0.8571\n",
      "Epoch 221/1000\n",
      " - 0s - loss: 0.1557 - acc: 0.8571\n",
      "Epoch 222/1000\n",
      " - 0s - loss: 0.1549 - acc: 0.8571\n",
      "Epoch 223/1000\n",
      " - 0s - loss: 0.1545 - acc: 0.8571\n",
      "Epoch 224/1000\n",
      " - 0s - loss: 0.1540 - acc: 0.8571\n",
      "Epoch 225/1000\n",
      " - 0s - loss: 0.1532 - acc: 0.8571\n",
      "Epoch 226/1000\n",
      " - 0s - loss: 0.1525 - acc: 0.8571\n",
      "Epoch 227/1000\n",
      " - 0s - loss: 0.1523 - acc: 0.8571\n",
      "Epoch 228/1000\n",
      " - 0s - loss: 0.1513 - acc: 0.8571\n",
      "Epoch 229/1000\n",
      " - 0s - loss: 0.1511 - acc: 0.8571\n",
      "Epoch 230/1000\n",
      " - 0s - loss: 0.1506 - acc: 0.8571\n",
      "Epoch 231/1000\n",
      " - 0s - loss: 0.1500 - acc: 0.8571\n",
      "Epoch 232/1000\n",
      " - 0s - loss: 0.1493 - acc: 0.8571\n",
      "Epoch 233/1000\n",
      " - 0s - loss: 0.1485 - acc: 0.8571\n",
      "Epoch 234/1000\n",
      " - 0s - loss: 0.1483 - acc: 0.8571\n",
      "Epoch 235/1000\n",
      " - 0s - loss: 0.1477 - acc: 0.8571\n",
      "Epoch 236/1000\n",
      " - 0s - loss: 0.1469 - acc: 0.8571\n",
      "Epoch 237/1000\n",
      " - 0s - loss: 0.1464 - acc: 0.8571\n",
      "Epoch 238/1000\n",
      " - 0s - loss: 0.1458 - acc: 0.8571\n",
      "Epoch 239/1000\n",
      " - 0s - loss: 0.1453 - acc: 0.8571\n",
      "Epoch 240/1000\n",
      " - 0s - loss: 0.1446 - acc: 0.8571\n",
      "Epoch 241/1000\n",
      " - 0s - loss: 0.1446 - acc: 0.8571\n",
      "Epoch 242/1000\n",
      " - 0s - loss: 0.1439 - acc: 0.8571\n",
      "Epoch 243/1000\n",
      " - 0s - loss: 0.1433 - acc: 0.8571\n",
      "Epoch 244/1000\n",
      " - 0s - loss: 0.1426 - acc: 0.8571\n",
      "Epoch 245/1000\n",
      " - 0s - loss: 0.1421 - acc: 0.8571\n",
      "Epoch 246/1000\n",
      " - 0s - loss: 0.1417 - acc: 0.8571\n",
      "Epoch 247/1000\n",
      " - 0s - loss: 0.1412 - acc: 0.8571\n",
      "Epoch 248/1000\n",
      " - 0s - loss: 0.1410 - acc: 0.8571\n",
      "Epoch 249/1000\n",
      " - 0s - loss: 0.1399 - acc: 0.8571\n",
      "Epoch 250/1000\n",
      " - 0s - loss: 0.1396 - acc: 0.8571\n",
      "Epoch 251/1000\n",
      " - 0s - loss: 0.1390 - acc: 0.8571\n",
      "Epoch 252/1000\n",
      " - 0s - loss: 0.1386 - acc: 0.8571\n",
      "Epoch 253/1000\n",
      " - 0s - loss: 0.1379 - acc: 0.8571\n",
      "Epoch 254/1000\n",
      " - 0s - loss: 0.1374 - acc: 0.8571\n",
      "Epoch 255/1000\n",
      " - 0s - loss: 0.1372 - acc: 0.8571\n",
      "Epoch 256/1000\n",
      " - 0s - loss: 0.1364 - acc: 0.8571\n",
      "Epoch 257/1000\n",
      " - 0s - loss: 0.1358 - acc: 0.8571\n",
      "Epoch 258/1000\n",
      " - 0s - loss: 0.1356 - acc: 0.8571\n",
      "Epoch 259/1000\n",
      " - 0s - loss: 0.1354 - acc: 0.8571\n",
      "Epoch 260/1000\n",
      " - 0s - loss: 0.1345 - acc: 0.8571\n",
      "Epoch 261/1000\n",
      " - 0s - loss: 0.1339 - acc: 0.8571\n",
      "Epoch 262/1000\n",
      " - 0s - loss: 0.1334 - acc: 0.8571\n",
      "Epoch 263/1000\n",
      " - 0s - loss: 0.1329 - acc: 0.8571\n",
      "Epoch 264/1000\n",
      " - 0s - loss: 0.1326 - acc: 0.8571\n",
      "Epoch 265/1000\n",
      " - 0s - loss: 0.1321 - acc: 0.8571\n",
      "Epoch 266/1000\n",
      " - 0s - loss: 0.1316 - acc: 0.8571\n",
      "Epoch 267/1000\n",
      " - 0s - loss: 0.1312 - acc: 0.8571\n",
      "Epoch 268/1000\n",
      " - 0s - loss: 0.1307 - acc: 0.8571\n",
      "Epoch 269/1000\n",
      " - 0s - loss: 0.1305 - acc: 0.8571\n",
      "Epoch 270/1000\n",
      " - 0s - loss: 0.1297 - acc: 0.8571\n",
      "Epoch 271/1000\n",
      " - 0s - loss: 0.1293 - acc: 0.8571\n",
      "Epoch 272/1000\n",
      " - 0s - loss: 0.1292 - acc: 0.8571\n",
      "Epoch 273/1000\n",
      " - 0s - loss: 0.1283 - acc: 0.8571\n",
      "Epoch 274/1000\n",
      " - 0s - loss: 0.1282 - acc: 0.8571\n",
      "Epoch 275/1000\n",
      " - 0s - loss: 0.1281 - acc: 0.8571\n",
      "Epoch 276/1000\n",
      " - 0s - loss: 0.1269 - acc: 0.8571\n",
      "Epoch 277/1000\n",
      " - 0s - loss: 0.1266 - acc: 0.8571\n",
      "Epoch 278/1000\n",
      " - 0s - loss: 0.1262 - acc: 0.8571\n",
      "Epoch 279/1000\n",
      " - 0s - loss: 0.1260 - acc: 0.8571\n",
      "Epoch 280/1000\n",
      " - 0s - loss: 0.1251 - acc: 0.8571\n",
      "Epoch 281/1000\n",
      " - 0s - loss: 0.1247 - acc: 0.8571\n",
      "Epoch 282/1000\n",
      " - 0s - loss: 0.1246 - acc: 0.8571\n",
      "Epoch 283/1000\n",
      " - 0s - loss: 0.1243 - acc: 0.8571\n",
      "Epoch 284/1000\n",
      " - 0s - loss: 0.1234 - acc: 0.8571\n",
      "Epoch 285/1000\n",
      " - 0s - loss: 0.1231 - acc: 0.8571\n",
      "Epoch 286/1000\n",
      " - 0s - loss: 0.1226 - acc: 0.8571\n",
      "Epoch 287/1000\n",
      " - 0s - loss: 0.1221 - acc: 0.8571\n",
      "Epoch 288/1000\n",
      " - 0s - loss: 0.1216 - acc: 0.8571\n",
      "Epoch 289/1000\n",
      " - 0s - loss: 0.1212 - acc: 0.8571\n",
      "Epoch 290/1000\n",
      " - 0s - loss: 0.1210 - acc: 0.8571\n",
      "Epoch 291/1000\n",
      " - 0s - loss: 0.1207 - acc: 0.8571\n",
      "Epoch 292/1000\n",
      " - 0s - loss: 0.1205 - acc: 0.8571\n",
      "Epoch 293/1000\n",
      " - 0s - loss: 0.1200 - acc: 0.8571\n",
      "Epoch 294/1000\n",
      " - 0s - loss: 0.1193 - acc: 0.8571\n",
      "Epoch 295/1000\n",
      " - 0s - loss: 0.1187 - acc: 0.8571\n",
      "Epoch 296/1000\n",
      " - 0s - loss: 0.1184 - acc: 0.8571\n",
      "Epoch 297/1000\n",
      " - 0s - loss: 0.1179 - acc: 0.8571\n",
      "Epoch 298/1000\n",
      " - 0s - loss: 0.1180 - acc: 0.8571\n",
      "Epoch 299/1000\n",
      " - 0s - loss: 0.1170 - acc: 0.8571\n",
      "Epoch 300/1000\n",
      " - 0s - loss: 0.1166 - acc: 0.8571\n",
      "Epoch 301/1000\n",
      " - 0s - loss: 0.1163 - acc: 0.8571\n",
      "Epoch 302/1000\n",
      " - 0s - loss: 0.1160 - acc: 0.8571\n",
      "Epoch 303/1000\n",
      " - 0s - loss: 0.1157 - acc: 0.8571\n",
      "Epoch 304/1000\n",
      " - 0s - loss: 0.1150 - acc: 0.8571\n",
      "Epoch 305/1000\n",
      " - 0s - loss: 0.1147 - acc: 0.8571\n",
      "Epoch 306/1000\n",
      " - 0s - loss: 0.1147 - acc: 0.8571\n",
      "Epoch 307/1000\n",
      " - 0s - loss: 0.1139 - acc: 0.8571\n",
      "Epoch 308/1000\n",
      " - 0s - loss: 0.1135 - acc: 0.8571\n",
      "Epoch 309/1000\n",
      " - 0s - loss: 0.1131 - acc: 0.8571\n",
      "Epoch 310/1000\n",
      " - 0s - loss: 0.1127 - acc: 0.8571\n",
      "Epoch 311/1000\n",
      " - 0s - loss: 0.1122 - acc: 0.8571\n",
      "Epoch 312/1000\n",
      " - 0s - loss: 0.1119 - acc: 0.8571\n",
      "Epoch 313/1000\n",
      " - 0s - loss: 0.1116 - acc: 0.8571\n",
      "Epoch 314/1000\n",
      " - 0s - loss: 0.1114 - acc: 0.8571\n",
      "Epoch 315/1000\n",
      " - 0s - loss: 0.1112 - acc: 0.8571\n",
      "Epoch 316/1000\n",
      " - 0s - loss: 0.1109 - acc: 0.8571\n",
      "Epoch 317/1000\n",
      " - 0s - loss: 0.1102 - acc: 0.9286\n",
      "Epoch 318/1000\n",
      " - 0s - loss: 0.1096 - acc: 0.9286\n",
      "Epoch 319/1000\n",
      " - 0s - loss: 0.1093 - acc: 0.9286\n",
      "Epoch 320/1000\n",
      " - 0s - loss: 0.1089 - acc: 0.9286\n",
      "Epoch 321/1000\n",
      " - 0s - loss: 0.1085 - acc: 0.9286\n",
      "Epoch 322/1000\n",
      " - 0s - loss: 0.1080 - acc: 0.9286\n",
      "Epoch 323/1000\n",
      " - 0s - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 324/1000\n",
      " - 0s - loss: 0.1075 - acc: 1.0000\n",
      "Epoch 325/1000\n",
      " - 0s - loss: 0.1073 - acc: 1.0000\n",
      "Epoch 326/1000\n",
      " - 0s - loss: 0.1068 - acc: 1.0000\n",
      "Epoch 327/1000\n",
      " - 0s - loss: 0.1063 - acc: 1.0000\n",
      "Epoch 328/1000\n",
      " - 0s - loss: 0.1060 - acc: 1.0000\n",
      "Epoch 329/1000\n",
      " - 0s - loss: 0.1057 - acc: 1.0000\n",
      "Epoch 330/1000\n",
      " - 0s - loss: 0.1052 - acc: 1.0000\n",
      "Epoch 331/1000\n",
      " - 0s - loss: 0.1048 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/1000\n",
      " - 0s - loss: 0.1046 - acc: 1.0000\n",
      "Epoch 333/1000\n",
      " - 0s - loss: 0.1040 - acc: 1.0000\n",
      "Epoch 334/1000\n",
      " - 0s - loss: 0.1037 - acc: 1.0000\n",
      "Epoch 335/1000\n",
      " - 0s - loss: 0.1034 - acc: 1.0000\n",
      "Epoch 336/1000\n",
      " - 0s - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 337/1000\n",
      " - 0s - loss: 0.1026 - acc: 1.0000\n",
      "Epoch 338/1000\n",
      " - 0s - loss: 0.1023 - acc: 1.0000\n",
      "Epoch 339/1000\n",
      " - 0s - loss: 0.1020 - acc: 1.0000\n",
      "Epoch 340/1000\n",
      " - 0s - loss: 0.1018 - acc: 1.0000\n",
      "Epoch 341/1000\n",
      " - 0s - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 342/1000\n",
      " - 0s - loss: 0.1012 - acc: 1.0000\n",
      "Epoch 343/1000\n",
      " - 0s - loss: 0.1006 - acc: 1.0000\n",
      "Epoch 344/1000\n",
      " - 0s - loss: 0.1003 - acc: 1.0000\n",
      "Epoch 345/1000\n",
      " - 0s - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 346/1000\n",
      " - 0s - loss: 0.0996 - acc: 1.0000\n",
      "Epoch 347/1000\n",
      " - 0s - loss: 0.0993 - acc: 1.0000\n",
      "Epoch 348/1000\n",
      " - 0s - loss: 0.0989 - acc: 1.0000\n",
      "Epoch 349/1000\n",
      " - 0s - loss: 0.0986 - acc: 1.0000\n",
      "Epoch 350/1000\n",
      " - 0s - loss: 0.0983 - acc: 1.0000\n",
      "Epoch 351/1000\n",
      " - 0s - loss: 0.0980 - acc: 1.0000\n",
      "Epoch 352/1000\n",
      " - 0s - loss: 0.0976 - acc: 1.0000\n",
      "Epoch 353/1000\n",
      " - 0s - loss: 0.0972 - acc: 1.0000\n",
      "Epoch 354/1000\n",
      " - 0s - loss: 0.0969 - acc: 1.0000\n",
      "Epoch 355/1000\n",
      " - 0s - loss: 0.0969 - acc: 1.0000\n",
      "Epoch 356/1000\n",
      " - 0s - loss: 0.0970 - acc: 1.0000\n",
      "Epoch 357/1000\n",
      " - 0s - loss: 0.0960 - acc: 1.0000\n",
      "Epoch 358/1000\n",
      " - 0s - loss: 0.0957 - acc: 1.0000\n",
      "Epoch 359/1000\n",
      " - 0s - loss: 0.0954 - acc: 1.0000\n",
      "Epoch 360/1000\n",
      " - 0s - loss: 0.0949 - acc: 1.0000\n",
      "Epoch 361/1000\n",
      " - 0s - loss: 0.0947 - acc: 1.0000\n",
      "Epoch 362/1000\n",
      " - 0s - loss: 0.0943 - acc: 1.0000\n",
      "Epoch 363/1000\n",
      " - 0s - loss: 0.0941 - acc: 1.0000\n",
      "Epoch 364/1000\n",
      " - 0s - loss: 0.0938 - acc: 1.0000\n",
      "Epoch 365/1000\n",
      " - 0s - loss: 0.0934 - acc: 1.0000\n",
      "Epoch 366/1000\n",
      " - 0s - loss: 0.0931 - acc: 1.0000\n",
      "Epoch 367/1000\n",
      " - 0s - loss: 0.0928 - acc: 1.0000\n",
      "Epoch 368/1000\n",
      " - 0s - loss: 0.0926 - acc: 1.0000\n",
      "Epoch 369/1000\n",
      " - 0s - loss: 0.0922 - acc: 1.0000\n",
      "Epoch 370/1000\n",
      " - 0s - loss: 0.0920 - acc: 1.0000\n",
      "Epoch 371/1000\n",
      " - 0s - loss: 0.0915 - acc: 1.0000\n",
      "Epoch 372/1000\n",
      " - 0s - loss: 0.0913 - acc: 1.0000\n",
      "Epoch 373/1000\n",
      " - 0s - loss: 0.0912 - acc: 1.0000\n",
      "Epoch 374/1000\n",
      " - 0s - loss: 0.0908 - acc: 1.0000\n",
      "Epoch 375/1000\n",
      " - 0s - loss: 0.0906 - acc: 1.0000\n",
      "Epoch 376/1000\n",
      " - 0s - loss: 0.0902 - acc: 1.0000\n",
      "Epoch 377/1000\n",
      " - 0s - loss: 0.0898 - acc: 1.0000\n",
      "Epoch 378/1000\n",
      " - 0s - loss: 0.0893 - acc: 1.0000\n",
      "Epoch 379/1000\n",
      " - 0s - loss: 0.0891 - acc: 1.0000\n",
      "Epoch 380/1000\n",
      " - 0s - loss: 0.0889 - acc: 1.0000\n",
      "Epoch 381/1000\n",
      " - 0s - loss: 0.0885 - acc: 1.0000\n",
      "Epoch 382/1000\n",
      " - 0s - loss: 0.0884 - acc: 1.0000\n",
      "Epoch 383/1000\n",
      " - 0s - loss: 0.0879 - acc: 1.0000\n",
      "Epoch 384/1000\n",
      " - 0s - loss: 0.0879 - acc: 1.0000\n",
      "Epoch 385/1000\n",
      " - 0s - loss: 0.0873 - acc: 1.0000\n",
      "Epoch 386/1000\n",
      " - 0s - loss: 0.0870 - acc: 1.0000\n",
      "Epoch 387/1000\n",
      " - 0s - loss: 0.0869 - acc: 1.0000\n",
      "Epoch 388/1000\n",
      " - 0s - loss: 0.0865 - acc: 1.0000\n",
      "Epoch 389/1000\n",
      " - 0s - loss: 0.0862 - acc: 1.0000\n",
      "Epoch 390/1000\n",
      " - 0s - loss: 0.0860 - acc: 1.0000\n",
      "Epoch 391/1000\n",
      " - 0s - loss: 0.0857 - acc: 1.0000\n",
      "Epoch 392/1000\n",
      " - 0s - loss: 0.0853 - acc: 1.0000\n",
      "Epoch 393/1000\n",
      " - 0s - loss: 0.0851 - acc: 1.0000\n",
      "Epoch 394/1000\n",
      " - 0s - loss: 0.0849 - acc: 1.0000\n",
      "Epoch 395/1000\n",
      " - 0s - loss: 0.0844 - acc: 1.0000\n",
      "Epoch 396/1000\n",
      " - 0s - loss: 0.0841 - acc: 1.0000\n",
      "Epoch 397/1000\n",
      " - 0s - loss: 0.0839 - acc: 1.0000\n",
      "Epoch 398/1000\n",
      " - 0s - loss: 0.0836 - acc: 1.0000\n",
      "Epoch 399/1000\n",
      " - 0s - loss: 0.0834 - acc: 1.0000\n",
      "Epoch 400/1000\n",
      " - 0s - loss: 0.0831 - acc: 1.0000\n",
      "Epoch 401/1000\n",
      " - 0s - loss: 0.0828 - acc: 1.0000\n",
      "Epoch 402/1000\n",
      " - 0s - loss: 0.0827 - acc: 1.0000\n",
      "Epoch 403/1000\n",
      " - 0s - loss: 0.0825 - acc: 1.0000\n",
      "Epoch 404/1000\n",
      " - 0s - loss: 0.0820 - acc: 1.0000\n",
      "Epoch 405/1000\n",
      " - 0s - loss: 0.0818 - acc: 1.0000\n",
      "Epoch 406/1000\n",
      " - 0s - loss: 0.0815 - acc: 1.0000\n",
      "Epoch 407/1000\n",
      " - 0s - loss: 0.0812 - acc: 1.0000\n",
      "Epoch 408/1000\n",
      " - 0s - loss: 0.0810 - acc: 1.0000\n",
      "Epoch 409/1000\n",
      " - 0s - loss: 0.0806 - acc: 1.0000\n",
      "Epoch 410/1000\n",
      " - 0s - loss: 0.0803 - acc: 1.0000\n",
      "Epoch 411/1000\n",
      " - 0s - loss: 0.0801 - acc: 1.0000\n",
      "Epoch 412/1000\n",
      " - 0s - loss: 0.0801 - acc: 1.0000\n",
      "Epoch 413/1000\n",
      " - 0s - loss: 0.0800 - acc: 1.0000\n",
      "Epoch 414/1000\n",
      " - 0s - loss: 0.0793 - acc: 1.0000\n",
      "Epoch 415/1000\n",
      " - 0s - loss: 0.0790 - acc: 1.0000\n",
      "Epoch 416/1000\n",
      " - 0s - loss: 0.0791 - acc: 1.0000\n",
      "Epoch 417/1000\n",
      " - 0s - loss: 0.0786 - acc: 1.0000\n",
      "Epoch 418/1000\n",
      " - 0s - loss: 0.0785 - acc: 1.0000\n",
      "Epoch 419/1000\n",
      " - 0s - loss: 0.0780 - acc: 1.0000\n",
      "Epoch 420/1000\n",
      " - 0s - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 421/1000\n",
      " - 0s - loss: 0.0775 - acc: 1.0000\n",
      "Epoch 422/1000\n",
      " - 0s - loss: 0.0772 - acc: 1.0000\n",
      "Epoch 423/1000\n",
      " - 0s - loss: 0.0770 - acc: 1.0000\n",
      "Epoch 424/1000\n",
      " - 0s - loss: 0.0768 - acc: 1.0000\n",
      "Epoch 425/1000\n",
      " - 0s - loss: 0.0767 - acc: 1.0000\n",
      "Epoch 426/1000\n",
      " - 0s - loss: 0.0762 - acc: 1.0000\n",
      "Epoch 427/1000\n",
      " - 0s - loss: 0.0759 - acc: 1.0000\n",
      "Epoch 428/1000\n",
      " - 0s - loss: 0.0758 - acc: 1.0000\n",
      "Epoch 429/1000\n",
      " - 0s - loss: 0.0755 - acc: 1.0000\n",
      "Epoch 430/1000\n",
      " - 0s - loss: 0.0753 - acc: 1.0000\n",
      "Epoch 431/1000\n",
      " - 0s - loss: 0.0752 - acc: 1.0000\n",
      "Epoch 432/1000\n",
      " - 0s - loss: 0.0748 - acc: 1.0000\n",
      "Epoch 433/1000\n",
      " - 0s - loss: 0.0745 - acc: 1.0000\n",
      "Epoch 434/1000\n",
      " - 0s - loss: 0.0743 - acc: 1.0000\n",
      "Epoch 435/1000\n",
      " - 0s - loss: 0.0742 - acc: 1.0000\n",
      "Epoch 436/1000\n",
      " - 0s - loss: 0.0741 - acc: 1.0000\n",
      "Epoch 437/1000\n",
      " - 0s - loss: 0.0735 - acc: 1.0000\n",
      "Epoch 438/1000\n",
      " - 0s - loss: 0.0734 - acc: 1.0000\n",
      "Epoch 439/1000\n",
      " - 0s - loss: 0.0731 - acc: 1.0000\n",
      "Epoch 440/1000\n",
      " - 0s - loss: 0.0729 - acc: 1.0000\n",
      "Epoch 441/1000\n",
      " - 0s - loss: 0.0726 - acc: 1.0000\n",
      "Epoch 442/1000\n",
      " - 0s - loss: 0.0723 - acc: 1.0000\n",
      "Epoch 443/1000\n",
      " - 0s - loss: 0.0721 - acc: 1.0000\n",
      "Epoch 444/1000\n",
      " - 0s - loss: 0.0718 - acc: 1.0000\n",
      "Epoch 445/1000\n",
      " - 0s - loss: 0.0719 - acc: 1.0000\n",
      "Epoch 446/1000\n",
      " - 0s - loss: 0.0715 - acc: 1.0000\n",
      "Epoch 447/1000\n",
      " - 0s - loss: 0.0711 - acc: 1.0000\n",
      "Epoch 448/1000\n",
      " - 0s - loss: 0.0710 - acc: 1.0000\n",
      "Epoch 449/1000\n",
      " - 0s - loss: 0.0707 - acc: 1.0000\n",
      "Epoch 450/1000\n",
      " - 0s - loss: 0.0706 - acc: 1.0000\n",
      "Epoch 451/1000\n",
      " - 0s - loss: 0.0703 - acc: 1.0000\n",
      "Epoch 452/1000\n",
      " - 0s - loss: 0.0700 - acc: 1.0000\n",
      "Epoch 453/1000\n",
      " - 0s - loss: 0.0699 - acc: 1.0000\n",
      "Epoch 454/1000\n",
      " - 0s - loss: 0.0696 - acc: 1.0000\n",
      "Epoch 455/1000\n",
      " - 0s - loss: 0.0695 - acc: 1.0000\n",
      "Epoch 456/1000\n",
      " - 0s - loss: 0.0690 - acc: 1.0000\n",
      "Epoch 457/1000\n",
      " - 0s - loss: 0.0688 - acc: 1.0000\n",
      "Epoch 458/1000\n",
      " - 0s - loss: 0.0687 - acc: 1.0000\n",
      "Epoch 459/1000\n",
      " - 0s - loss: 0.0684 - acc: 1.0000\n",
      "Epoch 460/1000\n",
      " - 0s - loss: 0.0683 - acc: 1.0000\n",
      "Epoch 461/1000\n",
      " - 0s - loss: 0.0680 - acc: 1.0000\n",
      "Epoch 462/1000\n",
      " - 0s - loss: 0.0678 - acc: 1.0000\n",
      "Epoch 463/1000\n",
      " - 0s - loss: 0.0675 - acc: 1.0000\n",
      "Epoch 464/1000\n",
      " - 0s - loss: 0.0674 - acc: 1.0000\n",
      "Epoch 465/1000\n",
      " - 0s - loss: 0.0671 - acc: 1.0000\n",
      "Epoch 466/1000\n",
      " - 0s - loss: 0.0669 - acc: 1.0000\n",
      "Epoch 467/1000\n",
      " - 0s - loss: 0.0667 - acc: 1.0000\n",
      "Epoch 468/1000\n",
      " - 0s - loss: 0.0666 - acc: 1.0000\n",
      "Epoch 469/1000\n",
      " - 0s - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 470/1000\n",
      " - 0s - loss: 0.0663 - acc: 1.0000\n",
      "Epoch 471/1000\n",
      " - 0s - loss: 0.0658 - acc: 1.0000\n",
      "Epoch 472/1000\n",
      " - 0s - loss: 0.0655 - acc: 1.0000\n",
      "Epoch 473/1000\n",
      " - 0s - loss: 0.0654 - acc: 1.0000\n",
      "Epoch 474/1000\n",
      " - 0s - loss: 0.0651 - acc: 1.0000\n",
      "Epoch 475/1000\n",
      " - 0s - loss: 0.0649 - acc: 1.0000\n",
      "Epoch 476/1000\n",
      " - 0s - loss: 0.0647 - acc: 1.0000\n",
      "Epoch 477/1000\n",
      " - 0s - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 478/1000\n",
      " - 0s - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 479/1000\n",
      " - 0s - loss: 0.0641 - acc: 1.0000\n",
      "Epoch 480/1000\n",
      " - 0s - loss: 0.0639 - acc: 1.0000\n",
      "Epoch 481/1000\n",
      " - 0s - loss: 0.0637 - acc: 1.0000\n",
      "Epoch 482/1000\n",
      " - 0s - loss: 0.0634 - acc: 1.0000\n",
      "Epoch 483/1000\n",
      " - 0s - loss: 0.0633 - acc: 1.0000\n",
      "Epoch 484/1000\n",
      " - 0s - loss: 0.0631 - acc: 1.0000\n",
      "Epoch 485/1000\n",
      " - 0s - loss: 0.0631 - acc: 1.0000\n",
      "Epoch 486/1000\n",
      " - 0s - loss: 0.0627 - acc: 1.0000\n",
      "Epoch 487/1000\n",
      " - 0s - loss: 0.0625 - acc: 1.0000\n",
      "Epoch 488/1000\n",
      " - 0s - loss: 0.0623 - acc: 1.0000\n",
      "Epoch 489/1000\n",
      " - 0s - loss: 0.0620 - acc: 1.0000\n",
      "Epoch 490/1000\n",
      " - 0s - loss: 0.0619 - acc: 1.0000\n",
      "Epoch 491/1000\n",
      " - 0s - loss: 0.0616 - acc: 1.0000\n",
      "Epoch 492/1000\n",
      " - 0s - loss: 0.0617 - acc: 1.0000\n",
      "Epoch 493/1000\n",
      " - 0s - loss: 0.0612 - acc: 1.0000\n",
      "Epoch 494/1000\n",
      " - 0s - loss: 0.0610 - acc: 1.0000\n",
      "Epoch 495/1000\n",
      " - 0s - loss: 0.0608 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/1000\n",
      " - 0s - loss: 0.0608 - acc: 1.0000\n",
      "Epoch 497/1000\n",
      " - 0s - loss: 0.0604 - acc: 1.0000\n",
      "Epoch 498/1000\n",
      " - 0s - loss: 0.0603 - acc: 1.0000\n",
      "Epoch 499/1000\n",
      " - 0s - loss: 0.0600 - acc: 1.0000\n",
      "Epoch 500/1000\n",
      " - 0s - loss: 0.0600 - acc: 1.0000\n",
      "Epoch 501/1000\n",
      " - 0s - loss: 0.0597 - acc: 1.0000\n",
      "Epoch 502/1000\n",
      " - 0s - loss: 0.0595 - acc: 1.0000\n",
      "Epoch 503/1000\n",
      " - 0s - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 504/1000\n",
      " - 0s - loss: 0.0590 - acc: 1.0000\n",
      "Epoch 505/1000\n",
      " - 0s - loss: 0.0589 - acc: 1.0000\n",
      "Epoch 506/1000\n",
      " - 0s - loss: 0.0587 - acc: 1.0000\n",
      "Epoch 507/1000\n",
      " - 0s - loss: 0.0585 - acc: 1.0000\n",
      "Epoch 508/1000\n",
      " - 0s - loss: 0.0583 - acc: 1.0000\n",
      "Epoch 509/1000\n",
      " - 0s - loss: 0.0583 - acc: 1.0000\n",
      "Epoch 510/1000\n",
      " - 0s - loss: 0.0580 - acc: 1.0000\n",
      "Epoch 511/1000\n",
      " - 0s - loss: 0.0578 - acc: 1.0000\n",
      "Epoch 512/1000\n",
      " - 0s - loss: 0.0576 - acc: 1.0000\n",
      "Epoch 513/1000\n",
      " - 0s - loss: 0.0575 - acc: 1.0000\n",
      "Epoch 514/1000\n",
      " - 0s - loss: 0.0573 - acc: 1.0000\n",
      "Epoch 515/1000\n",
      " - 0s - loss: 0.0571 - acc: 1.0000\n",
      "Epoch 516/1000\n",
      " - 0s - loss: 0.0569 - acc: 1.0000\n",
      "Epoch 517/1000\n",
      " - 0s - loss: 0.0568 - acc: 1.0000\n",
      "Epoch 518/1000\n",
      " - 0s - loss: 0.0565 - acc: 1.0000\n",
      "Epoch 519/1000\n",
      " - 0s - loss: 0.0564 - acc: 1.0000\n",
      "Epoch 520/1000\n",
      " - 0s - loss: 0.0561 - acc: 1.0000\n",
      "Epoch 521/1000\n",
      " - 0s - loss: 0.0559 - acc: 1.0000\n",
      "Epoch 522/1000\n",
      " - 0s - loss: 0.0558 - acc: 1.0000\n",
      "Epoch 523/1000\n",
      " - 0s - loss: 0.0557 - acc: 1.0000\n",
      "Epoch 524/1000\n",
      " - 0s - loss: 0.0554 - acc: 1.0000\n",
      "Epoch 525/1000\n",
      " - 0s - loss: 0.0553 - acc: 1.0000\n",
      "Epoch 526/1000\n",
      " - 0s - loss: 0.0552 - acc: 1.0000\n",
      "Epoch 527/1000\n",
      " - 0s - loss: 0.0548 - acc: 1.0000\n",
      "Epoch 528/1000\n",
      " - 0s - loss: 0.0547 - acc: 1.0000\n",
      "Epoch 529/1000\n",
      " - 0s - loss: 0.0545 - acc: 1.0000\n",
      "Epoch 530/1000\n",
      " - 0s - loss: 0.0544 - acc: 1.0000\n",
      "Epoch 531/1000\n",
      " - 0s - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 532/1000\n",
      " - 0s - loss: 0.0540 - acc: 1.0000\n",
      "Epoch 533/1000\n",
      " - 0s - loss: 0.0539 - acc: 1.0000\n",
      "Epoch 534/1000\n",
      " - 0s - loss: 0.0537 - acc: 1.0000\n",
      "Epoch 535/1000\n",
      " - 0s - loss: 0.0536 - acc: 1.0000\n",
      "Epoch 536/1000\n",
      " - 0s - loss: 0.0533 - acc: 1.0000\n",
      "Epoch 537/1000\n",
      " - 0s - loss: 0.0533 - acc: 1.0000\n",
      "Epoch 538/1000\n",
      " - 0s - loss: 0.0531 - acc: 1.0000\n",
      "Epoch 539/1000\n",
      " - 0s - loss: 0.0527 - acc: 1.0000\n",
      "Epoch 540/1000\n",
      " - 0s - loss: 0.0527 - acc: 1.0000\n",
      "Epoch 541/1000\n",
      " - 0s - loss: 0.0526 - acc: 1.0000\n",
      "Epoch 542/1000\n",
      " - 0s - loss: 0.0524 - acc: 1.0000\n",
      "Epoch 543/1000\n",
      " - 0s - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 544/1000\n",
      " - 0s - loss: 0.0520 - acc: 1.0000\n",
      "Epoch 545/1000\n",
      " - 0s - loss: 0.0517 - acc: 1.0000\n",
      "Epoch 546/1000\n",
      " - 0s - loss: 0.0516 - acc: 1.0000\n",
      "Epoch 547/1000\n",
      " - 0s - loss: 0.0514 - acc: 1.0000\n",
      "Epoch 548/1000\n",
      " - 0s - loss: 0.0513 - acc: 1.0000\n",
      "Epoch 549/1000\n",
      " - 0s - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 550/1000\n",
      " - 0s - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 551/1000\n",
      " - 0s - loss: 0.0509 - acc: 1.0000\n",
      "Epoch 552/1000\n",
      " - 0s - loss: 0.0506 - acc: 1.0000\n",
      "Epoch 553/1000\n",
      " - 0s - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 554/1000\n",
      " - 0s - loss: 0.0503 - acc: 1.0000\n",
      "Epoch 555/1000\n",
      " - 0s - loss: 0.0503 - acc: 1.0000\n",
      "Epoch 556/1000\n",
      " - 0s - loss: 0.0503 - acc: 1.0000\n",
      "Epoch 557/1000\n",
      " - 0s - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 558/1000\n",
      " - 0s - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 559/1000\n",
      " - 0s - loss: 0.0495 - acc: 1.0000\n",
      "Epoch 560/1000\n",
      " - 0s - loss: 0.0494 - acc: 1.0000\n",
      "Epoch 561/1000\n",
      " - 0s - loss: 0.0491 - acc: 1.0000\n",
      "Epoch 562/1000\n",
      " - 0s - loss: 0.0491 - acc: 1.0000\n",
      "Epoch 563/1000\n",
      " - 0s - loss: 0.0489 - acc: 1.0000\n",
      "Epoch 564/1000\n",
      " - 0s - loss: 0.0487 - acc: 1.0000\n",
      "Epoch 565/1000\n",
      " - 0s - loss: 0.0487 - acc: 1.0000\n",
      "Epoch 566/1000\n",
      " - 0s - loss: 0.0483 - acc: 1.0000\n",
      "Epoch 567/1000\n",
      " - 0s - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 568/1000\n",
      " - 0s - loss: 0.0480 - acc: 1.0000\n",
      "Epoch 569/1000\n",
      " - 0s - loss: 0.0479 - acc: 1.0000\n",
      "Epoch 570/1000\n",
      " - 0s - loss: 0.0478 - acc: 1.0000\n",
      "Epoch 571/1000\n",
      " - 0s - loss: 0.0476 - acc: 1.0000\n",
      "Epoch 572/1000\n",
      " - 0s - loss: 0.0474 - acc: 1.0000\n",
      "Epoch 573/1000\n",
      " - 0s - loss: 0.0473 - acc: 1.0000\n",
      "Epoch 574/1000\n",
      " - 0s - loss: 0.0472 - acc: 1.0000\n",
      "Epoch 575/1000\n",
      " - 0s - loss: 0.0470 - acc: 1.0000\n",
      "Epoch 576/1000\n",
      " - 0s - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 577/1000\n",
      " - 0s - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 578/1000\n",
      " - 0s - loss: 0.0465 - acc: 1.0000\n",
      "Epoch 579/1000\n",
      " - 0s - loss: 0.0466 - acc: 1.0000\n",
      "Epoch 580/1000\n",
      " - 0s - loss: 0.0465 - acc: 1.0000\n",
      "Epoch 581/1000\n",
      " - 0s - loss: 0.0461 - acc: 1.0000\n",
      "Epoch 582/1000\n",
      " - 0s - loss: 0.0460 - acc: 1.0000\n",
      "Epoch 583/1000\n",
      " - 0s - loss: 0.0458 - acc: 1.0000\n",
      "Epoch 584/1000\n",
      " - 0s - loss: 0.0458 - acc: 1.0000\n",
      "Epoch 585/1000\n",
      " - 0s - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 586/1000\n",
      " - 0s - loss: 0.0454 - acc: 1.0000\n",
      "Epoch 587/1000\n",
      " - 0s - loss: 0.0452 - acc: 1.0000\n",
      "Epoch 588/1000\n",
      " - 0s - loss: 0.0452 - acc: 1.0000\n",
      "Epoch 589/1000\n",
      " - 0s - loss: 0.0450 - acc: 1.0000\n",
      "Epoch 590/1000\n",
      " - 0s - loss: 0.0448 - acc: 1.0000\n",
      "Epoch 591/1000\n",
      " - 0s - loss: 0.0448 - acc: 1.0000\n",
      "Epoch 592/1000\n",
      " - 0s - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 593/1000\n",
      " - 0s - loss: 0.0443 - acc: 1.0000\n",
      "Epoch 594/1000\n",
      " - 0s - loss: 0.0443 - acc: 1.0000\n",
      "Epoch 595/1000\n",
      " - 0s - loss: 0.0440 - acc: 1.0000\n",
      "Epoch 596/1000\n",
      " - 0s - loss: 0.0439 - acc: 1.0000\n",
      "Epoch 597/1000\n",
      " - 0s - loss: 0.0438 - acc: 1.0000\n",
      "Epoch 598/1000\n",
      " - 0s - loss: 0.0437 - acc: 1.0000\n",
      "Epoch 599/1000\n",
      " - 0s - loss: 0.0436 - acc: 1.0000\n",
      "Epoch 600/1000\n",
      " - 0s - loss: 0.0434 - acc: 1.0000\n",
      "Epoch 601/1000\n",
      " - 0s - loss: 0.0432 - acc: 1.0000\n",
      "Epoch 602/1000\n",
      " - 0s - loss: 0.0431 - acc: 1.0000\n",
      "Epoch 603/1000\n",
      " - 0s - loss: 0.0430 - acc: 1.0000\n",
      "Epoch 604/1000\n",
      " - 0s - loss: 0.0428 - acc: 1.0000\n",
      "Epoch 605/1000\n",
      " - 0s - loss: 0.0427 - acc: 1.0000\n",
      "Epoch 606/1000\n",
      " - 0s - loss: 0.0426 - acc: 1.0000\n",
      "Epoch 607/1000\n",
      " - 0s - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 608/1000\n",
      " - 0s - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 609/1000\n",
      " - 0s - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 610/1000\n",
      " - 0s - loss: 0.0420 - acc: 1.0000\n",
      "Epoch 611/1000\n",
      " - 0s - loss: 0.0420 - acc: 1.0000\n",
      "Epoch 612/1000\n",
      " - 0s - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 613/1000\n",
      " - 0s - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 614/1000\n",
      " - 0s - loss: 0.0415 - acc: 1.0000\n",
      "Epoch 615/1000\n",
      " - 0s - loss: 0.0413 - acc: 1.0000\n",
      "Epoch 616/1000\n",
      " - 0s - loss: 0.0412 - acc: 1.0000\n",
      "Epoch 617/1000\n",
      " - 0s - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 618/1000\n",
      " - 0s - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 619/1000\n",
      " - 0s - loss: 0.0408 - acc: 1.0000\n",
      "Epoch 620/1000\n",
      " - 0s - loss: 0.0407 - acc: 1.0000\n",
      "Epoch 621/1000\n",
      " - 0s - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 622/1000\n",
      " - 0s - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 623/1000\n",
      " - 0s - loss: 0.0404 - acc: 1.0000\n",
      "Epoch 624/1000\n",
      " - 0s - loss: 0.0401 - acc: 1.0000\n",
      "Epoch 625/1000\n",
      " - 0s - loss: 0.0401 - acc: 1.0000\n",
      "Epoch 626/1000\n",
      " - 0s - loss: 0.0399 - acc: 1.0000\n",
      "Epoch 627/1000\n",
      " - 0s - loss: 0.0398 - acc: 1.0000\n",
      "Epoch 628/1000\n",
      " - 0s - loss: 0.0397 - acc: 1.0000\n",
      "Epoch 629/1000\n",
      " - 0s - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 630/1000\n",
      " - 0s - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 631/1000\n",
      " - 0s - loss: 0.0394 - acc: 1.0000\n",
      "Epoch 632/1000\n",
      " - 0s - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 633/1000\n",
      " - 0s - loss: 0.0389 - acc: 1.0000\n",
      "Epoch 634/1000\n",
      " - 0s - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 635/1000\n",
      " - 0s - loss: 0.0387 - acc: 1.0000\n",
      "Epoch 636/1000\n",
      " - 0s - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 637/1000\n",
      " - 0s - loss: 0.0385 - acc: 1.0000\n",
      "Epoch 638/1000\n",
      " - 0s - loss: 0.0384 - acc: 1.0000\n",
      "Epoch 639/1000\n",
      " - 0s - loss: 0.0383 - acc: 1.0000\n",
      "Epoch 640/1000\n",
      " - 0s - loss: 0.0382 - acc: 1.0000\n",
      "Epoch 641/1000\n",
      " - 0s - loss: 0.0380 - acc: 1.0000\n",
      "Epoch 642/1000\n",
      " - 0s - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 643/1000\n",
      " - 0s - loss: 0.0378 - acc: 1.0000\n",
      "Epoch 644/1000\n",
      " - 0s - loss: 0.0377 - acc: 1.0000\n",
      "Epoch 645/1000\n",
      " - 0s - loss: 0.0375 - acc: 1.0000\n",
      "Epoch 646/1000\n",
      " - 0s - loss: 0.0374 - acc: 1.0000\n",
      "Epoch 647/1000\n",
      " - 0s - loss: 0.0375 - acc: 1.0000\n",
      "Epoch 648/1000\n",
      " - 0s - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 649/1000\n",
      " - 0s - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 650/1000\n",
      " - 0s - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 651/1000\n",
      " - 0s - loss: 0.0369 - acc: 1.0000\n",
      "Epoch 652/1000\n",
      " - 0s - loss: 0.0367 - acc: 1.0000\n",
      "Epoch 653/1000\n",
      " - 0s - loss: 0.0366 - acc: 1.0000\n",
      "Epoch 654/1000\n",
      " - 0s - loss: 0.0365 - acc: 1.0000\n",
      "Epoch 655/1000\n",
      " - 0s - loss: 0.0365 - acc: 1.0000\n",
      "Epoch 656/1000\n",
      " - 0s - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 657/1000\n",
      " - 0s - loss: 0.0361 - acc: 1.0000\n",
      "Epoch 658/1000\n",
      " - 0s - loss: 0.0360 - acc: 1.0000\n",
      "Epoch 659/1000\n",
      " - 0s - loss: 0.0359 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/1000\n",
      " - 0s - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 661/1000\n",
      " - 0s - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 662/1000\n",
      " - 0s - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 663/1000\n",
      " - 0s - loss: 0.0354 - acc: 1.0000\n",
      "Epoch 664/1000\n",
      " - 0s - loss: 0.0353 - acc: 1.0000\n",
      "Epoch 665/1000\n",
      " - 0s - loss: 0.0353 - acc: 1.0000\n",
      "Epoch 666/1000\n",
      " - 0s - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 667/1000\n",
      " - 0s - loss: 0.0350 - acc: 1.0000\n",
      "Epoch 668/1000\n",
      " - 0s - loss: 0.0349 - acc: 1.0000\n",
      "Epoch 669/1000\n",
      " - 0s - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 670/1000\n",
      " - 0s - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 671/1000\n",
      " - 0s - loss: 0.0345 - acc: 1.0000\n",
      "Epoch 672/1000\n",
      " - 0s - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 673/1000\n",
      " - 0s - loss: 0.0343 - acc: 1.0000\n",
      "Epoch 674/1000\n",
      " - 0s - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 675/1000\n",
      " - 0s - loss: 0.0341 - acc: 1.0000\n",
      "Epoch 676/1000\n",
      " - 0s - loss: 0.0341 - acc: 1.0000\n",
      "Epoch 677/1000\n",
      " - 0s - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 678/1000\n",
      " - 0s - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 679/1000\n",
      " - 0s - loss: 0.0338 - acc: 1.0000\n",
      "Epoch 680/1000\n",
      " - 0s - loss: 0.0336 - acc: 1.0000\n",
      "Epoch 681/1000\n",
      " - 0s - loss: 0.0334 - acc: 1.0000\n",
      "Epoch 682/1000\n",
      " - 0s - loss: 0.0333 - acc: 1.0000\n",
      "Epoch 683/1000\n",
      " - 0s - loss: 0.0333 - acc: 1.0000\n",
      "Epoch 684/1000\n",
      " - 0s - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 685/1000\n",
      " - 0s - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 686/1000\n",
      " - 0s - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 687/1000\n",
      " - 0s - loss: 0.0328 - acc: 1.0000\n",
      "Epoch 688/1000\n",
      " - 0s - loss: 0.0327 - acc: 1.0000\n",
      "Epoch 689/1000\n",
      " - 0s - loss: 0.0326 - acc: 1.0000\n",
      "Epoch 690/1000\n",
      " - 0s - loss: 0.0326 - acc: 1.0000\n",
      "Epoch 691/1000\n",
      " - 0s - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 692/1000\n",
      " - 0s - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 693/1000\n",
      " - 0s - loss: 0.0322 - acc: 1.0000\n",
      "Epoch 694/1000\n",
      " - 0s - loss: 0.0321 - acc: 1.0000\n",
      "Epoch 695/1000\n",
      " - 0s - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 696/1000\n",
      " - 0s - loss: 0.0319 - acc: 1.0000\n",
      "Epoch 697/1000\n",
      " - 0s - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 698/1000\n",
      " - 0s - loss: 0.0317 - acc: 1.0000\n",
      "Epoch 699/1000\n",
      " - 0s - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 700/1000\n",
      " - 0s - loss: 0.0315 - acc: 1.0000\n",
      "Epoch 701/1000\n",
      " - 0s - loss: 0.0313 - acc: 1.0000\n",
      "Epoch 702/1000\n",
      " - 0s - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 703/1000\n",
      " - 0s - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 704/1000\n",
      " - 0s - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 705/1000\n",
      " - 0s - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 706/1000\n",
      " - 0s - loss: 0.0309 - acc: 1.0000\n",
      "Epoch 707/1000\n",
      " - 0s - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 708/1000\n",
      " - 0s - loss: 0.0306 - acc: 1.0000\n",
      "Epoch 709/1000\n",
      " - 0s - loss: 0.0305 - acc: 1.0000\n",
      "Epoch 710/1000\n",
      " - 0s - loss: 0.0305 - acc: 1.0000\n",
      "Epoch 711/1000\n",
      " - 0s - loss: 0.0305 - acc: 1.0000\n",
      "Epoch 712/1000\n",
      " - 0s - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 713/1000\n",
      " - 0s - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 714/1000\n",
      " - 0s - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 715/1000\n",
      " - 0s - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 716/1000\n",
      " - 0s - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 717/1000\n",
      " - 0s - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 718/1000\n",
      " - 0s - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 719/1000\n",
      " - 0s - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 720/1000\n",
      " - 0s - loss: 0.0295 - acc: 1.0000\n",
      "Epoch 721/1000\n",
      " - 0s - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 722/1000\n",
      " - 0s - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 723/1000\n",
      " - 0s - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 724/1000\n",
      " - 0s - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 725/1000\n",
      " - 0s - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 726/1000\n",
      " - 0s - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 727/1000\n",
      " - 0s - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 728/1000\n",
      " - 0s - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 729/1000\n",
      " - 0s - loss: 0.0287 - acc: 1.0000\n",
      "Epoch 730/1000\n",
      " - 0s - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 731/1000\n",
      " - 0s - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 732/1000\n",
      " - 0s - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 733/1000\n",
      " - 0s - loss: 0.0283 - acc: 1.0000\n",
      "Epoch 734/1000\n",
      " - 0s - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 735/1000\n",
      " - 0s - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 736/1000\n",
      " - 0s - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 737/1000\n",
      " - 0s - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 738/1000\n",
      " - 0s - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 739/1000\n",
      " - 0s - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 740/1000\n",
      " - 0s - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 741/1000\n",
      " - 0s - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 742/1000\n",
      " - 0s - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 743/1000\n",
      " - 0s - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 744/1000\n",
      " - 0s - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 745/1000\n",
      " - 0s - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 746/1000\n",
      " - 0s - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 747/1000\n",
      " - 0s - loss: 0.0271 - acc: 1.0000\n",
      "Epoch 748/1000\n",
      " - 0s - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 749/1000\n",
      " - 0s - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 750/1000\n",
      " - 0s - loss: 0.0268 - acc: 1.0000\n",
      "Epoch 751/1000\n",
      " - 0s - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 752/1000\n",
      " - 0s - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 753/1000\n",
      " - 0s - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 754/1000\n",
      " - 0s - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 755/1000\n",
      " - 0s - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 756/1000\n",
      " - 0s - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 757/1000\n",
      " - 0s - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 758/1000\n",
      " - 0s - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 759/1000\n",
      " - 0s - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 760/1000\n",
      " - 0s - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 761/1000\n",
      " - 0s - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 762/1000\n",
      " - 0s - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 763/1000\n",
      " - 0s - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 764/1000\n",
      " - 0s - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 765/1000\n",
      " - 0s - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 766/1000\n",
      " - 0s - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 767/1000\n",
      " - 0s - loss: 0.0254 - acc: 1.0000\n",
      "Epoch 768/1000\n",
      " - 0s - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 769/1000\n",
      " - 0s - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 770/1000\n",
      " - 0s - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 771/1000\n",
      " - 0s - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 772/1000\n",
      " - 0s - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 773/1000\n",
      " - 0s - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 774/1000\n",
      " - 0s - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 775/1000\n",
      " - 0s - loss: 0.0247 - acc: 1.0000\n",
      "Epoch 776/1000\n",
      " - 0s - loss: 0.0247 - acc: 1.0000\n",
      "Epoch 777/1000\n",
      " - 0s - loss: 0.0246 - acc: 1.0000\n",
      "Epoch 778/1000\n",
      " - 0s - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 779/1000\n",
      " - 0s - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 780/1000\n",
      " - 0s - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 781/1000\n",
      " - 0s - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 782/1000\n",
      " - 0s - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 783/1000\n",
      " - 0s - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 784/1000\n",
      " - 0s - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 785/1000\n",
      " - 0s - loss: 0.0240 - acc: 1.0000\n",
      "Epoch 786/1000\n",
      " - 0s - loss: 0.0239 - acc: 1.0000\n",
      "Epoch 787/1000\n",
      " - 0s - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 788/1000\n",
      " - 0s - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 789/1000\n",
      " - 0s - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 790/1000\n",
      " - 0s - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 791/1000\n",
      " - 0s - loss: 0.0236 - acc: 1.0000\n",
      "Epoch 792/1000\n",
      " - 0s - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 793/1000\n",
      " - 0s - loss: 0.0234 - acc: 1.0000\n",
      "Epoch 794/1000\n",
      " - 0s - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 795/1000\n",
      " - 0s - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 796/1000\n",
      " - 0s - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 797/1000\n",
      " - 0s - loss: 0.0231 - acc: 1.0000\n",
      "Epoch 798/1000\n",
      " - 0s - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 799/1000\n",
      " - 0s - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 800/1000\n",
      " - 0s - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 801/1000\n",
      " - 0s - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 802/1000\n",
      " - 0s - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 803/1000\n",
      " - 0s - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 804/1000\n",
      " - 0s - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 805/1000\n",
      " - 0s - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 806/1000\n",
      " - 0s - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 807/1000\n",
      " - 0s - loss: 0.0223 - acc: 1.0000\n",
      "Epoch 808/1000\n",
      " - 0s - loss: 0.0223 - acc: 1.0000\n",
      "Epoch 809/1000\n",
      " - 0s - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 810/1000\n",
      " - 0s - loss: 0.0222 - acc: 1.0000\n",
      "Epoch 811/1000\n",
      " - 0s - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 812/1000\n",
      " - 0s - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 813/1000\n",
      " - 0s - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 814/1000\n",
      " - 0s - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 815/1000\n",
      " - 0s - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 816/1000\n",
      " - 0s - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 817/1000\n",
      " - 0s - loss: 0.0216 - acc: 1.0000\n",
      "Epoch 818/1000\n",
      " - 0s - loss: 0.0216 - acc: 1.0000\n",
      "Epoch 819/1000\n",
      " - 0s - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 820/1000\n",
      " - 0s - loss: 0.0216 - acc: 1.0000\n",
      "Epoch 821/1000\n",
      " - 0s - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 822/1000\n",
      " - 0s - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 823/1000\n",
      " - 0s - loss: 0.0213 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 824/1000\n",
      " - 0s - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 825/1000\n",
      " - 0s - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 826/1000\n",
      " - 0s - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 827/1000\n",
      " - 0s - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 828/1000\n",
      " - 0s - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 829/1000\n",
      " - 0s - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 830/1000\n",
      " - 0s - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 831/1000\n",
      " - 0s - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 832/1000\n",
      " - 0s - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 833/1000\n",
      " - 0s - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 834/1000\n",
      " - 0s - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 835/1000\n",
      " - 0s - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 836/1000\n",
      " - 0s - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 837/1000\n",
      " - 0s - loss: 0.0203 - acc: 1.0000\n",
      "Epoch 838/1000\n",
      " - 0s - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 839/1000\n",
      " - 0s - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 840/1000\n",
      " - 0s - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 841/1000\n",
      " - 0s - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 842/1000\n",
      " - 0s - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 843/1000\n",
      " - 0s - loss: 0.0199 - acc: 1.0000\n",
      "Epoch 844/1000\n",
      " - 0s - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 845/1000\n",
      " - 0s - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 846/1000\n",
      " - 0s - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 847/1000\n",
      " - 0s - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 848/1000\n",
      " - 0s - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 849/1000\n",
      " - 0s - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 850/1000\n",
      " - 0s - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 851/1000\n",
      " - 0s - loss: 0.0194 - acc: 1.0000\n",
      "Epoch 852/1000\n",
      " - 0s - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 853/1000\n",
      " - 0s - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 854/1000\n",
      " - 0s - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 855/1000\n",
      " - 0s - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 856/1000\n",
      " - 0s - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 857/1000\n",
      " - 0s - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 858/1000\n",
      " - 0s - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 859/1000\n",
      " - 0s - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 860/1000\n",
      " - 0s - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 861/1000\n",
      " - 0s - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 862/1000\n",
      " - 0s - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 863/1000\n",
      " - 0s - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 864/1000\n",
      " - 0s - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 865/1000\n",
      " - 0s - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 866/1000\n",
      " - 0s - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 867/1000\n",
      " - 0s - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 868/1000\n",
      " - 0s - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 869/1000\n",
      " - 0s - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 870/1000\n",
      " - 0s - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 871/1000\n",
      " - 0s - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 872/1000\n",
      " - 0s - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 873/1000\n",
      " - 0s - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 874/1000\n",
      " - 0s - loss: 0.0180 - acc: 1.0000\n",
      "Epoch 875/1000\n",
      " - 0s - loss: 0.0180 - acc: 1.0000\n",
      "Epoch 876/1000\n",
      " - 0s - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 877/1000\n",
      " - 0s - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 878/1000\n",
      " - 0s - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 879/1000\n",
      " - 0s - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 880/1000\n",
      " - 0s - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 881/1000\n",
      " - 0s - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 882/1000\n",
      " - 0s - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 883/1000\n",
      " - 0s - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 884/1000\n",
      " - 0s - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 885/1000\n",
      " - 0s - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 886/1000\n",
      " - 0s - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 887/1000\n",
      " - 0s - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 888/1000\n",
      " - 0s - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 889/1000\n",
      " - 0s - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 890/1000\n",
      " - 0s - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 891/1000\n",
      " - 0s - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 892/1000\n",
      " - 0s - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 893/1000\n",
      " - 0s - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 894/1000\n",
      " - 0s - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 895/1000\n",
      " - 0s - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 896/1000\n",
      " - 0s - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 897/1000\n",
      " - 0s - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 898/1000\n",
      " - 0s - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 899/1000\n",
      " - 0s - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 900/1000\n",
      " - 0s - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 901/1000\n",
      " - 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 902/1000\n",
      " - 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 903/1000\n",
      " - 0s - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 904/1000\n",
      " - 0s - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 905/1000\n",
      " - 0s - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 906/1000\n",
      " - 0s - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 907/1000\n",
      " - 0s - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 908/1000\n",
      " - 0s - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 909/1000\n",
      " - 0s - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 910/1000\n",
      " - 0s - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 911/1000\n",
      " - 0s - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 912/1000\n",
      " - 0s - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 913/1000\n",
      " - 0s - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 914/1000\n",
      " - 0s - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 915/1000\n",
      " - 0s - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 916/1000\n",
      " - 0s - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 917/1000\n",
      " - 0s - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 918/1000\n",
      " - 0s - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 919/1000\n",
      " - 0s - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 920/1000\n",
      " - 0s - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 921/1000\n",
      " - 0s - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 922/1000\n",
      " - 0s - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 923/1000\n",
      " - 0s - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 924/1000\n",
      " - 0s - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 925/1000\n",
      " - 0s - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 926/1000\n",
      " - 0s - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 927/1000\n",
      " - 0s - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 928/1000\n",
      " - 0s - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 929/1000\n",
      " - 0s - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 930/1000\n",
      " - 0s - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 931/1000\n",
      " - 0s - loss: 0.0150 - acc: 1.0000\n",
      "Epoch 932/1000\n",
      " - 0s - loss: 0.0150 - acc: 1.0000\n",
      "Epoch 933/1000\n",
      " - 0s - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 934/1000\n",
      " - 0s - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 935/1000\n",
      " - 0s - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 936/1000\n",
      " - 0s - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 937/1000\n",
      " - 0s - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 938/1000\n",
      " - 0s - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 939/1000\n",
      " - 0s - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 940/1000\n",
      " - 0s - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 941/1000\n",
      " - 0s - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 942/1000\n",
      " - 0s - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 943/1000\n",
      " - 0s - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 944/1000\n",
      " - 0s - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 945/1000\n",
      " - 0s - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 946/1000\n",
      " - 0s - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 947/1000\n",
      " - 0s - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 948/1000\n",
      " - 0s - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 949/1000\n",
      " - 0s - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 950/1000\n",
      " - 0s - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 951/1000\n",
      " - 0s - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 952/1000\n",
      " - 0s - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 953/1000\n",
      " - 0s - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 954/1000\n",
      " - 0s - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 955/1000\n",
      " - 0s - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 956/1000\n",
      " - 0s - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 957/1000\n",
      " - 0s - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 958/1000\n",
      " - 0s - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 959/1000\n",
      " - 0s - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 960/1000\n",
      " - 0s - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 961/1000\n",
      " - 0s - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 962/1000\n",
      " - 0s - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 963/1000\n",
      " - 0s - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 964/1000\n",
      " - 0s - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 965/1000\n",
      " - 0s - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 966/1000\n",
      " - 0s - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 967/1000\n",
      " - 0s - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 968/1000\n",
      " - 0s - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 969/1000\n",
      " - 0s - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 970/1000\n",
      " - 0s - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 971/1000\n",
      " - 0s - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 972/1000\n",
      " - 0s - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 973/1000\n",
      " - 0s - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 974/1000\n",
      " - 0s - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 975/1000\n",
      " - 0s - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 976/1000\n",
      " - 0s - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 977/1000\n",
      " - 0s - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 978/1000\n",
      " - 0s - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 979/1000\n",
      " - 0s - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 980/1000\n",
      " - 0s - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 981/1000\n",
      " - 0s - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 982/1000\n",
      " - 0s - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 983/1000\n",
      " - 0s - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 984/1000\n",
      " - 0s - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 985/1000\n",
      " - 0s - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 986/1000\n",
      " - 0s - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 987/1000\n",
      " - 0s - loss: 0.0125 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/1000\n",
      " - 0s - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 989/1000\n",
      " - 0s - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 990/1000\n",
      " - 0s - loss: 0.0124 - acc: 1.0000\n",
      "Epoch 991/1000\n",
      " - 0s - loss: 0.0124 - acc: 1.0000\n",
      "Epoch 992/1000\n",
      " - 0s - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 993/1000\n",
      " - 0s - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 994/1000\n",
      " - 0s - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 995/1000\n",
      " - 0s - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 996/1000\n",
      " - 0s - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 997/1000\n",
      " - 0s - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 998/1000\n",
      " - 0s - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 999/1000\n",
      " - 0s - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 1000/1000\n",
      " - 0s - loss: 0.0120 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b27ac5978>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(data[1:15], label[1:15], epochs=1000, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.fit([data[1:15], ht_input[1:15]], \n",
    "                   np_label[1:15], \n",
    "                   epochs=500,\n",
    "                   batch_size=1,\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_present_by_doc(X, human_terms, index, weight):\n",
    "    np_vector = np.zeros([X.shape[0],])\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        if x[index] == 1:\n",
    "            np_vector[i] = np.sign(weight)\n",
    "    \n",
    "    return np_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unigrams(path, X, y):\n",
    "    word_list = []\n",
    "    connotation = {}\n",
    "    \n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            word_list.append(line.strip())\n",
    "            \n",
    "    for word in word_list:\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        for i, doc in enumerate(X):\n",
    "            if word in doc.lower():\n",
    "                if (y[i] == 1):\n",
    "                    pos_count += 1\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    \n",
    "        if pos_count > neg_count:\n",
    "            connotation[word] = 1\n",
    "        else:\n",
    "            connotation[word] = 0\n",
    "    \n",
    "    return word_list, connotation\n",
    "\n",
    "def generate_appearance(X_train_corpus, X_test_corpus, word_list, connotation):\n",
    "    y_train_agreement = []\n",
    "    for i in range(len(X_train_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_train_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_train_agreement.append(doc_agreement)\n",
    "        \n",
    "    y_test_agreement = []\n",
    "    for i in range(len(X_test_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_test_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_test_agreement.append(doc_agreement)\n",
    "        \n",
    "    return np.array(y_train_agreement), np.array(y_test_agreement)\n",
    "\n",
    "# 'imdb-unigrams.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try on IMDB data\n",
    "#### Like the real IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# make sure that the first shape is the IMDB training data. \n",
    "\n",
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "X_train_original = open_pickle('../../data/imdb/imdb_original_preprocessed_xtrain.pickle')\n",
    "X_test_original = open_pickle('../../data/imdb/imdb_original_preprocessed_xtest.pickle')\n",
    "y_train_original = open_pickle('../../data/imdb/imdb_original_preprocessed_ytrain.pickle')\n",
    "y_test_original = open_pickle('../../data/imdb/imdb_original_preprocessed_ytest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df = 100)\n",
    "X_train = cv.fit_transform(X_train_original)\n",
    "X_test = cv.transform(X_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, connotation = load_unigrams('./imdb-unigrams.txt', X_train_original, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_agreement, y_test_agreement = generate_appearance(X_train_original, X_test_original, \n",
    "                                                          word_list, connotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_agreement[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 3641)              0         \n",
      "_________________________________________________________________\n",
      "tanh_output (Dense)          (None, 1)                 3642      \n",
      "=================================================================\n",
      "Total params: 3,642\n",
      "Trainable params: 3,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 83)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 3641)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               [(None, 1), (None, 1 0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_21 (Model)                (None, 1)            3642        input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 1)            0           lambda_3[0][0]                   \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 1)            0           lambda_3[0][1]                   \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 1)            0           lambda_3[0][2]                   \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 1)            0           lambda_3[0][3]                   \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 1)            0           lambda_3[0][4]                   \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 1)            0           lambda_3[0][5]                   \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 1)            0           lambda_3[0][6]                   \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 1)            0           lambda_3[0][7]                   \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 1)            0           lambda_3[0][8]                   \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 1)            0           lambda_3[0][9]                   \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 1)            0           lambda_3[0][10]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 1)            0           lambda_3[0][11]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 1)            0           lambda_3[0][12]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 1)            0           lambda_3[0][13]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 1)            0           lambda_3[0][14]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 1)            0           lambda_3[0][15]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 1)            0           lambda_3[0][16]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 1)            0           lambda_3[0][17]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 1)            0           lambda_3[0][18]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 1)            0           lambda_3[0][19]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 1)            0           lambda_3[0][20]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 1)            0           lambda_3[0][21]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 1)            0           lambda_3[0][22]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 1)            0           lambda_3[0][23]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 1)            0           lambda_3[0][24]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 1)            0           lambda_3[0][25]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 1)            0           lambda_3[0][26]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 1)            0           lambda_3[0][27]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 1)            0           lambda_3[0][28]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 1)            0           lambda_3[0][29]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 1)            0           lambda_3[0][30]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_42 (Multiply)          (None, 1)            0           lambda_3[0][31]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_43 (Multiply)          (None, 1)            0           lambda_3[0][32]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_44 (Multiply)          (None, 1)            0           lambda_3[0][33]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_45 (Multiply)          (None, 1)            0           lambda_3[0][34]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_46 (Multiply)          (None, 1)            0           lambda_3[0][35]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_47 (Multiply)          (None, 1)            0           lambda_3[0][36]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_48 (Multiply)          (None, 1)            0           lambda_3[0][37]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_49 (Multiply)          (None, 1)            0           lambda_3[0][38]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_50 (Multiply)          (None, 1)            0           lambda_3[0][39]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_51 (Multiply)          (None, 1)            0           lambda_3[0][40]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_52 (Multiply)          (None, 1)            0           lambda_3[0][41]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_53 (Multiply)          (None, 1)            0           lambda_3[0][42]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_54 (Multiply)          (None, 1)            0           lambda_3[0][43]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_55 (Multiply)          (None, 1)            0           lambda_3[0][44]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_56 (Multiply)          (None, 1)            0           lambda_3[0][45]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_57 (Multiply)          (None, 1)            0           lambda_3[0][46]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_58 (Multiply)          (None, 1)            0           lambda_3[0][47]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_59 (Multiply)          (None, 1)            0           lambda_3[0][48]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_60 (Multiply)          (None, 1)            0           lambda_3[0][49]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_61 (Multiply)          (None, 1)            0           lambda_3[0][50]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_62 (Multiply)          (None, 1)            0           lambda_3[0][51]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_63 (Multiply)          (None, 1)            0           lambda_3[0][52]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_64 (Multiply)          (None, 1)            0           lambda_3[0][53]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_65 (Multiply)          (None, 1)            0           lambda_3[0][54]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_66 (Multiply)          (None, 1)            0           lambda_3[0][55]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_67 (Multiply)          (None, 1)            0           lambda_3[0][56]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_68 (Multiply)          (None, 1)            0           lambda_3[0][57]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_69 (Multiply)          (None, 1)            0           lambda_3[0][58]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_70 (Multiply)          (None, 1)            0           lambda_3[0][59]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_71 (Multiply)          (None, 1)            0           lambda_3[0][60]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_72 (Multiply)          (None, 1)            0           lambda_3[0][61]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_73 (Multiply)          (None, 1)            0           lambda_3[0][62]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_74 (Multiply)          (None, 1)            0           lambda_3[0][63]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_75 (Multiply)          (None, 1)            0           lambda_3[0][64]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_76 (Multiply)          (None, 1)            0           lambda_3[0][65]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_77 (Multiply)          (None, 1)            0           lambda_3[0][66]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_78 (Multiply)          (None, 1)            0           lambda_3[0][67]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_79 (Multiply)          (None, 1)            0           lambda_3[0][68]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_80 (Multiply)          (None, 1)            0           lambda_3[0][69]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_81 (Multiply)          (None, 1)            0           lambda_3[0][70]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_82 (Multiply)          (None, 1)            0           lambda_3[0][71]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_83 (Multiply)          (None, 1)            0           lambda_3[0][72]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_84 (Multiply)          (None, 1)            0           lambda_3[0][73]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_85 (Multiply)          (None, 1)            0           lambda_3[0][74]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_86 (Multiply)          (None, 1)            0           lambda_3[0][75]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_87 (Multiply)          (None, 1)            0           lambda_3[0][76]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_88 (Multiply)          (None, 1)            0           lambda_3[0][77]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_89 (Multiply)          (None, 1)            0           lambda_3[0][78]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_90 (Multiply)          (None, 1)            0           lambda_3[0][79]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_91 (Multiply)          (None, 1)            0           lambda_3[0][80]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_92 (Multiply)          (None, 1)            0           lambda_3[0][81]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_93 (Multiply)          (None, 1)            0           lambda_3[0][82]                  \n",
      "                                                                 model_21[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_layer (Dense)              (None, 1)            1           multiply_11[0][0]                \n",
      "                                                                 multiply_12[0][0]                \n",
      "                                                                 multiply_13[0][0]                \n",
      "                                                                 multiply_14[0][0]                \n",
      "                                                                 multiply_15[0][0]                \n",
      "                                                                 multiply_16[0][0]                \n",
      "                                                                 multiply_17[0][0]                \n",
      "                                                                 multiply_18[0][0]                \n",
      "                                                                 multiply_19[0][0]                \n",
      "                                                                 multiply_20[0][0]                \n",
      "                                                                 multiply_21[0][0]                \n",
      "                                                                 multiply_22[0][0]                \n",
      "                                                                 multiply_23[0][0]                \n",
      "                                                                 multiply_24[0][0]                \n",
      "                                                                 multiply_25[0][0]                \n",
      "                                                                 multiply_26[0][0]                \n",
      "                                                                 multiply_27[0][0]                \n",
      "                                                                 multiply_28[0][0]                \n",
      "                                                                 multiply_29[0][0]                \n",
      "                                                                 multiply_30[0][0]                \n",
      "                                                                 multiply_31[0][0]                \n",
      "                                                                 multiply_32[0][0]                \n",
      "                                                                 multiply_33[0][0]                \n",
      "                                                                 multiply_34[0][0]                \n",
      "                                                                 multiply_35[0][0]                \n",
      "                                                                 multiply_36[0][0]                \n",
      "                                                                 multiply_37[0][0]                \n",
      "                                                                 multiply_38[0][0]                \n",
      "                                                                 multiply_39[0][0]                \n",
      "                                                                 multiply_40[0][0]                \n",
      "                                                                 multiply_41[0][0]                \n",
      "                                                                 multiply_42[0][0]                \n",
      "                                                                 multiply_43[0][0]                \n",
      "                                                                 multiply_44[0][0]                \n",
      "                                                                 multiply_45[0][0]                \n",
      "                                                                 multiply_46[0][0]                \n",
      "                                                                 multiply_47[0][0]                \n",
      "                                                                 multiply_48[0][0]                \n",
      "                                                                 multiply_49[0][0]                \n",
      "                                                                 multiply_50[0][0]                \n",
      "                                                                 multiply_51[0][0]                \n",
      "                                                                 multiply_52[0][0]                \n",
      "                                                                 multiply_53[0][0]                \n",
      "                                                                 multiply_54[0][0]                \n",
      "                                                                 multiply_55[0][0]                \n",
      "                                                                 multiply_56[0][0]                \n",
      "                                                                 multiply_57[0][0]                \n",
      "                                                                 multiply_58[0][0]                \n",
      "                                                                 multiply_59[0][0]                \n",
      "                                                                 multiply_60[0][0]                \n",
      "                                                                 multiply_61[0][0]                \n",
      "                                                                 multiply_62[0][0]                \n",
      "                                                                 multiply_63[0][0]                \n",
      "                                                                 multiply_64[0][0]                \n",
      "                                                                 multiply_65[0][0]                \n",
      "                                                                 multiply_66[0][0]                \n",
      "                                                                 multiply_67[0][0]                \n",
      "                                                                 multiply_68[0][0]                \n",
      "                                                                 multiply_69[0][0]                \n",
      "                                                                 multiply_70[0][0]                \n",
      "                                                                 multiply_71[0][0]                \n",
      "                                                                 multiply_72[0][0]                \n",
      "                                                                 multiply_73[0][0]                \n",
      "                                                                 multiply_74[0][0]                \n",
      "                                                                 multiply_75[0][0]                \n",
      "                                                                 multiply_76[0][0]                \n",
      "                                                                 multiply_77[0][0]                \n",
      "                                                                 multiply_78[0][0]                \n",
      "                                                                 multiply_79[0][0]                \n",
      "                                                                 multiply_80[0][0]                \n",
      "                                                                 multiply_81[0][0]                \n",
      "                                                                 multiply_82[0][0]                \n",
      "                                                                 multiply_83[0][0]                \n",
      "                                                                 multiply_84[0][0]                \n",
      "                                                                 multiply_85[0][0]                \n",
      "                                                                 multiply_86[0][0]                \n",
      "                                                                 multiply_87[0][0]                \n",
      "                                                                 multiply_88[0][0]                \n",
      "                                                                 multiply_89[0][0]                \n",
      "                                                                 multiply_90[0][0]                \n",
      "                                                                 multiply_91[0][0]                \n",
      "                                                                 multiply_92[0][0]                \n",
      "                                                                 multiply_93[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Lambda)            (None, 83)           0           relu_layer[0][0]                 \n",
      "                                                                 relu_layer[1][0]                 \n",
      "                                                                 relu_layer[2][0]                 \n",
      "                                                                 relu_layer[3][0]                 \n",
      "                                                                 relu_layer[4][0]                 \n",
      "                                                                 relu_layer[5][0]                 \n",
      "                                                                 relu_layer[6][0]                 \n",
      "                                                                 relu_layer[7][0]                 \n",
      "                                                                 relu_layer[8][0]                 \n",
      "                                                                 relu_layer[9][0]                 \n",
      "                                                                 relu_layer[10][0]                \n",
      "                                                                 relu_layer[11][0]                \n",
      "                                                                 relu_layer[12][0]                \n",
      "                                                                 relu_layer[13][0]                \n",
      "                                                                 relu_layer[14][0]                \n",
      "                                                                 relu_layer[15][0]                \n",
      "                                                                 relu_layer[16][0]                \n",
      "                                                                 relu_layer[17][0]                \n",
      "                                                                 relu_layer[18][0]                \n",
      "                                                                 relu_layer[19][0]                \n",
      "                                                                 relu_layer[20][0]                \n",
      "                                                                 relu_layer[21][0]                \n",
      "                                                                 relu_layer[22][0]                \n",
      "                                                                 relu_layer[23][0]                \n",
      "                                                                 relu_layer[24][0]                \n",
      "                                                                 relu_layer[25][0]                \n",
      "                                                                 relu_layer[26][0]                \n",
      "                                                                 relu_layer[27][0]                \n",
      "                                                                 relu_layer[28][0]                \n",
      "                                                                 relu_layer[29][0]                \n",
      "                                                                 relu_layer[30][0]                \n",
      "                                                                 relu_layer[31][0]                \n",
      "                                                                 relu_layer[32][0]                \n",
      "                                                                 relu_layer[33][0]                \n",
      "                                                                 relu_layer[34][0]                \n",
      "                                                                 relu_layer[35][0]                \n",
      "                                                                 relu_layer[36][0]                \n",
      "                                                                 relu_layer[37][0]                \n",
      "                                                                 relu_layer[38][0]                \n",
      "                                                                 relu_layer[39][0]                \n",
      "                                                                 relu_layer[40][0]                \n",
      "                                                                 relu_layer[41][0]                \n",
      "                                                                 relu_layer[42][0]                \n",
      "                                                                 relu_layer[43][0]                \n",
      "                                                                 relu_layer[44][0]                \n",
      "                                                                 relu_layer[45][0]                \n",
      "                                                                 relu_layer[46][0]                \n",
      "                                                                 relu_layer[47][0]                \n",
      "                                                                 relu_layer[48][0]                \n",
      "                                                                 relu_layer[49][0]                \n",
      "                                                                 relu_layer[50][0]                \n",
      "                                                                 relu_layer[51][0]                \n",
      "                                                                 relu_layer[52][0]                \n",
      "                                                                 relu_layer[53][0]                \n",
      "                                                                 relu_layer[54][0]                \n",
      "                                                                 relu_layer[55][0]                \n",
      "                                                                 relu_layer[56][0]                \n",
      "                                                                 relu_layer[57][0]                \n",
      "                                                                 relu_layer[58][0]                \n",
      "                                                                 relu_layer[59][0]                \n",
      "                                                                 relu_layer[60][0]                \n",
      "                                                                 relu_layer[61][0]                \n",
      "                                                                 relu_layer[62][0]                \n",
      "                                                                 relu_layer[63][0]                \n",
      "                                                                 relu_layer[64][0]                \n",
      "                                                                 relu_layer[65][0]                \n",
      "                                                                 relu_layer[66][0]                \n",
      "                                                                 relu_layer[67][0]                \n",
      "                                                                 relu_layer[68][0]                \n",
      "                                                                 relu_layer[69][0]                \n",
      "                                                                 relu_layer[70][0]                \n",
      "                                                                 relu_layer[71][0]                \n",
      "                                                                 relu_layer[72][0]                \n",
      "                                                                 relu_layer[73][0]                \n",
      "                                                                 relu_layer[74][0]                \n",
      "                                                                 relu_layer[75][0]                \n",
      "                                                                 relu_layer[76][0]                \n",
      "                                                                 relu_layer[77][0]                \n",
      "                                                                 relu_layer[78][0]                \n",
      "                                                                 relu_layer[79][0]                \n",
      "                                                                 relu_layer[80][0]                \n",
      "                                                                 relu_layer[81][0]                \n",
      "                                                                 relu_layer[82][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            84          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,727\n",
      "Trainable params: 3,727\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the combined model\n",
    "# Combined model\n",
    "human_terms_len = len(word_list)\n",
    "\n",
    "base_model = build_base_model(X_train.shape[1])\n",
    "\n",
    "combined_input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# build the hard coded weight for human terms\n",
    "ht_input_layer = Input(shape=(human_terms_len,))\n",
    "\n",
    "split = Lambda( lambda x: tf.split(x,num_or_size_splits=human_terms_len,axis=1))(ht_input_layer)\n",
    "\n",
    "# get the document prediction\n",
    "label_layer = base_model(combined_input_layer)\n",
    "\n",
    "# multiply and pass it into relu\n",
    "# initialize relu layer\n",
    "\n",
    "relu_layer = Dense(1, activation='relu', name='relu_layer', use_bias=False, kernel_initializer='ones')\n",
    "\n",
    "# stack the multiply layer\n",
    "dense_layer = []\n",
    "for i in range(human_terms_len):\n",
    "    dense_layer.append(relu_layer(Multiply()([split[i], label_layer])))\n",
    "\n",
    "# concat all the result   \n",
    "concat = Lambda( lambda x: tf.concat(x, axis=1), name='concatenate')(dense_layer)\n",
    "\n",
    "# pass it to sigmoid layer\n",
    "output_layer = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "combined_model = Model(inputs=[combined_input_layer, ht_input_layer], outputs=output_layer)\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(loss='mse',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "combined_model.compile(loss='mse',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tanh = y_train_original\n",
    "y_train_tanh[y_train_tanh == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.4482 - acc: 0.7250\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.3393 - acc: 0.8346\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.3063 - acc: 0.8583\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 34s 1ms/step - loss: 0.2879 - acc: 0.8701\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 55s 2ms/step - loss: 0.2683 - acc: 0.8843\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 65s 3ms/step - loss: 0.2582 - acc: 0.8898\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.2473 - acc: 0.8960\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.2373 - acc: 0.9006\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 25s 1ms/step - loss: 0.2295 - acc: 0.9069\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.2253 - acc: 0.9102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b303f6f60>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.fit(X_train, y_train_tanh, batch_size=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 70s 3ms/step - loss: 0.6972 - acc: 0.3758\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 77s 3ms/step - loss: 0.6653 - acc: 0.3855\n",
      "Epoch 3/10\n",
      " 5307/25000 [=====>........................] - ETA: 57s - loss: 0.6599 - acc: 0.3895"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-b46207e2953d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m combined_model.fit([X_train,\n\u001b[0;32m      2\u001b[0m                    y_train_agreement], y_train_original,\n\u001b[1;32m----> 3\u001b[1;33m                   batch_size=1, epochs=10)\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "combined_model.fit([X_train,\n",
    "                   y_train_agreement], y_train_original,\n",
    "                  batch_size=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
