{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2)\n",
      "corpus update start\n",
      "corpus update end\n",
      "\n",
      "(75, 2)\n",
      "corpus update start\n",
      "corpus update end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "seed(42)\n",
    "set_random_seed(42)\n",
    "\n",
    "from keras.layers import Input, Dense, TimeDistributed, Embedding\n",
    "from keras.layers import Concatenate, Reshape, Lambda, Multiply, multiply, concatenate\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "from dataset_load import *\n",
    "\n",
    "style.use('seaborn-whitegrid')\n",
    "\n",
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "def load_unigrams(path, X, y):\n",
    "    word_list = []\n",
    "    connotation = {}\n",
    "    \n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            word_list.append(line.strip())\n",
    "            \n",
    "    for word in word_list:\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        for i, doc in enumerate(X):\n",
    "            if word in doc.lower():\n",
    "                \n",
    "                if (y[i] == 1):\n",
    "                    pos_count += 1\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    \n",
    "        if pos_count > neg_count:\n",
    "            connotation[word] = 1\n",
    "        else:\n",
    "            connotation[word] = 0\n",
    "    \n",
    "    return word_list, connotation\n",
    "\n",
    "def generate_appearance(X_train_corpus, X_test_corpus, word_list, connotation):\n",
    "    y_train_agreement = []\n",
    "    for i in range(len(X_train_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_train_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_train_agreement.append(doc_agreement)\n",
    "        \n",
    "    y_test_agreement = []\n",
    "    for i in range(len(X_test_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_test_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_test_agreement.append(doc_agreement)\n",
    "        \n",
    "    return np.array(y_train_agreement), np.array(y_test_agreement)\n",
    "\n",
    "# 'imdb-unigrams.txt'\n",
    "path = r\"../../data/reviews_Amazon_Instant_Video_5.json.gz\"\n",
    "\n",
    "X, y = extract_review_amazon(path, 'reviewText')\n",
    "y_label = np.asarray(y)\n",
    "\n",
    "neutral_indices = np.where(y_label == 3)[0]\n",
    "y_label[y_label<3] = 0\n",
    "y_label[y_label>3] = 1\n",
    "\n",
    "X_discarded = np.delete(X,neutral_indices)\n",
    "y_discarded = np.delete(y_label, neutral_indices)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "# split\n",
    "X_train_split, X_test_split, y_train, y_test = train_test_split(X_discarded, y_discarded, test_size=0.33, random_state=42)\n",
    "\n",
    "# preprocessing\n",
    "X_train_corpus_update = update_corpus_contraction(X_train_split)\n",
    "X_test_corpus_update = update_corpus_contraction(X_test_split)\n",
    "\n",
    "# Count vectorizer \n",
    "\n",
    "# count vectorizer\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "cv = CountVectorizer(lowercase=True, max_df=1.0, min_df=100, binary=True, token_pattern=token)\n",
    "cv.set_params(ngram_range=(1,1))\n",
    "\n",
    "cv.fit(X_train_split)\n",
    "\n",
    "X_train = cv.transform(X_train_corpus_update)\n",
    "X_test = cv.transform(X_test_corpus_update)\n",
    "\n",
    "words = cv.get_feature_names()\n",
    "\n",
    "\n",
    "word_list, connotation = load_unigrams('./amazon-video-unigrams-more.txt', X_train_corpus_update, y_train)\n",
    "# word_list, connotation = load_unigrams('./imdb-unigrams.txt', X_train_corpus_update, y_train)\n",
    "# word_list, connotation = load_unigrams('./ecom-unigrams.txt', X_train_corpus_update, y_train)\n",
    "\n",
    "y_train_agreement, y_test_agreement = generate_appearance(X_train_corpus_update, X_test_corpus_update, \n",
    "                                                          word_list, connotation)\n",
    "\n",
    "def history_plot(history, model_name):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "        \n",
    "    title = model_name + 'accuracy'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['tr_acc', 'val_acc'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(history.history['loss'], 'm--')\n",
    "    plt.plot(history.history['val_loss'], 'y--')\n",
    "\n",
    "    title = model_name + 'loss'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['tr_loss', 'val_loss'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/48951109/keras-custom-binary-cross-entropy-loss-function-get-nan-as-output-for-loss\n",
    "\n",
    "# def custom_cross_entropy(y_true, y_pred):\n",
    "#     t_loss = K.max(y_pred,0)-y_pred * y_true + K.log(1+K.exp((-1)*K.abs(y_pred)))\n",
    "#     return K.mean(t_loss)\n",
    "\n",
    "# from keras.initializers import Constant, glorot_uniform\n",
    "\n",
    "# input_layer = Input(shape=(X_train.shape[1],))\n",
    "# tanh_output = Dense(1, activation='sigmoid', kernel_initializer=glorot_uniform(seed=42))(input_layer)\n",
    "# model = Model(inputs=input_layer, outputs=tanh_output)\n",
    "\n",
    "# model.compile(loss=custom_cross_entropy,\n",
    "#              metrics=['acc'],\n",
    "#              optimizer='adam')\n",
    "\n",
    "# model.fit(X_train[:16667], y_train_original[:16667], \n",
    "#          validation_data=([X_train[16667:], y_train_original[16667:]]),\n",
    "#          batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test, y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_train, y_train_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import Constant, glorot_uniform\n",
    "\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "tanh_output = Dense(1, activation='sigmoid', kernel_initializer=glorot_uniform(seed=42))(input_layer)\n",
    "model = Model(inputs=input_layer, outputs=tanh_output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             metrics=['acc'],\n",
    "             optimizer='adam')\n",
    "\n",
    "# base_history = model.fit(X_train[:16667], y_train_original[:16667], \n",
    "#                  validation_data=([X_train[16667:], y_train_original[16667:]]),\n",
    "#                  batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test, y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_train, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14786 samples, validate on 7283 samples\n",
      "Epoch 1/1\n",
      "14786/14786 [==============================] - 560s 38ms/step - loss: 0.3423 - acc: 0.8916 - val_loss: 0.3042 - val_acc: 0.8970\n"
     ]
    }
   ],
   "source": [
    "def layer_split(x):\n",
    "    return tf.split(x,num_or_size_splits=human_terms_len,axis=1)\n",
    "\n",
    "def layer_concat(x):\n",
    "    return tf.concat(x, axis=1)\n",
    "\n",
    "# build the combined model\n",
    "# Combined model\n",
    "human_terms_len = len(word_list)\n",
    "\n",
    "# base_model = build_base_model(X_train.shape[1])\n",
    "\n",
    "combined_input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# build the hard coded weight for human terms\n",
    "ht_input_layer = Input(shape=(human_terms_len,))\n",
    "\n",
    "# split = Lambda( lambda x: tf.split(x,num_or_size_splits=human_terms_len,axis=1))(ht_input_layer)\n",
    "split = Lambda(layer_split)(ht_input_layer)\n",
    "\n",
    "# get the document prediction\n",
    "label_layer = model(combined_input_layer)\n",
    "tanh_norm = Lambda(lambda x: (x*2)-1)(label_layer)\n",
    "# tanh_norm = Lambda(lambda x: tf.scalar_mul(2,x)-1)(label_layer)\n",
    "\n",
    "# do normalize of bipolar sigmoid\n",
    "\n",
    "\n",
    "# stack the multiply layer\n",
    "dense_layer = []\n",
    "for i in range(human_terms_len):\n",
    "    dense_layer.append(Dense(1, activation='relu', use_bias=False)(Multiply()([split[i], tanh_norm])))\n",
    "\n",
    "# concat all the result   \n",
    "# concat = Lambda( lambda x: tf.concat(x, axis=1), name='concatenate')(dense_layer)\n",
    "concat = Lambda(layer_concat, name='concatenate')(dense_layer)\n",
    "\n",
    "\n",
    "# pass it to sigmoid layer\n",
    "output_layer = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "combined_model = Model(inputs=[combined_input_layer, ht_input_layer], outputs=output_layer)\n",
    "# combined_model.summary()\n",
    "\n",
    "\n",
    "combined_model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])\n",
    "\n",
    "# y_train_tanh = y_train_original\n",
    "# y_train_tanh[y_train_tanh == 0] = -1\n",
    "\n",
    "# y_test_tanh = y_test_original\n",
    "# y_test_tanh[y_test_tanh == 0] = -1\n",
    "\n",
    "# base_model_history = base_model.fit(X_train[:16667], y_train_original[:16667], \n",
    "#                                     validation_data=(X_train[16667:], y_train_original[16667:]),\n",
    "#                                     batch_size=1, epochs=1)\n",
    "\n",
    "combined_model_history = combined_model.fit([X_train,y_train_agreement], y_train, \n",
    "                                            validation_split=0.33, shuffle=False,\n",
    "                                            batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_reject(combined_model, X, y_agreement, y):\n",
    "    human_terms_relu_model = Model(inputs=combined_model.input,\n",
    "                                    outputs=combined_model.get_layer('concatenate').output)\n",
    "    predict_relu = human_terms_relu_model.predict([X, y_agreement])\n",
    "    accept_indices = np.where(np.sum(predict_relu, axis=1)!=0)\n",
    "    accept_indices = accept_indices[0]\n",
    "    total_reject = X.shape[0] - len(accept_indices)\n",
    "    rejection_rate = total_reject/X.shape[0]\n",
    "\n",
    "    test_eval = combined_model.evaluate([X[accept_indices], y_agreement[accept_indices]], y[accept_indices])\n",
    "    \n",
    "    return test_eval, rejection_rate, total_reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10870/10870 [==============================] - 2s 199us/step\n",
      "22069/22069 [==============================] - 4s 199us/step\n",
      "5725/5725 [==============================] - 1s 200us/step\n",
      "11566/11566 [==============================] - 2s 199us/step\n"
     ]
    }
   ],
   "source": [
    "test_ev = combined_model.evaluate([X_test, y_test_agreement], y_test)\n",
    "train_ev = combined_model.evaluate([X_train, y_train_agreement], y_train)\n",
    "\n",
    "def accuracy_reject(combined_model, X, y_agreement, y):\n",
    "    human_terms_relu_model = Model(inputs=combined_model.input,\n",
    "                                    outputs=combined_model.get_layer('concatenate').output)\n",
    "    predict_relu = human_terms_relu_model.predict([X, y_agreement])\n",
    "    accept_indices = np.where(np.sum(predict_relu, axis=1)!=0)\n",
    "    accept_indices = accept_indices[0]\n",
    "    total_reject = X.shape[0] - len(accept_indices)\n",
    "    rejection_rate = total_reject/X.shape[0]\n",
    "\n",
    "    test_eval = combined_model.evaluate([X[accept_indices], y_agreement[accept_indices]], y[accept_indices])\n",
    "    \n",
    "    return test_eval, rejection_rate, total_reject\n",
    "\n",
    "test_ev_reject = accuracy_reject(combined_model, X_test, y_test_agreement, y_test)\n",
    "train_ev_reject = accuracy_reject(combined_model, X_train, y_train_agreement, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.305779 \t 0.896325\n",
      "0.300423 \t 0.900092\n",
      "0.248583 \t 0.911032 \t 0.475916 \t 10503\n",
      "0.255891 \t 0.908646 \t 0.473321 \t 5145\n"
     ]
    }
   ],
   "source": [
    "print('%f \\t %f' %(train_ev[0], train_ev[1]))\n",
    "print('%f \\t %f' %(test_ev[0], test_ev[1]))\n",
    "print('%f \\t %f \\t %f \\t %d' %(train_ev_reject[0][0], train_ev_reject[0][1], train_ev_reject[1], train_ev_reject[2]))\n",
    "print('%f \\t %f \\t %f \\t %d' %(test_ev_reject[0][0], test_ev_reject[0][1], test_ev_reject[1], test_ev_reject[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_plot(base_history,'RDclf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAESCAYAAAAYMKWkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAeFUlEQVR4nO3df7RVZb3v8Tcg3ASTII+gqDU0xoddlClXhQhBQXSUWSYVI6+EkeURhnrsF97UkI7KyFGoB/MMFe9OTI+eUyoK/gLxEG6vcdY1vda630o9HRUUJEEQtnuD+/4x59bF/jn3Ym82a67PawwHaz7PnHM9X8DPnjxrrvn0aWpqwszM8qlvbw/AzMx6jkPezCzHHPJmZjnmkDczyzGHvJlZjjnkzcxybL/eHoBZd5J0E3BSunkUsA7YAQwAmoBG4CCSv/uvpftdHRG3t3O+fwQOiojzJX0ZuBH4N2BLc3tP1WLWHRzylisR8ffNryX9J/A/ImJN6T6S5gGHRcS3unj6LwL/HBFXpuFvts9zyJsBkvoCC4EzSK72b4qIhSX9lwBfAt6RNBzYVNL3UeAW4Ij02Gsi4leS9gNuBj4D9Af+D3AuUN9We0Rs6+EyrQp5Tt4sMQP4NDASOA74rqRjmzsj4ufAA8DPS/+1kLoVeDQiBHwB+IWkw4HPAyOAGuBjwJ+BsR20m3U7h7xZ4nPAv0bEzojYAgh4prODJH0AOBm4CSAiXgJWk3wusBH4JMk0z8CI+J8RsaKDdrNu55A3SxwEbG7eiIi3IyLLg50OAna2mGp5Ezg4IuqAi4F/AF6TdIekwe21d1slZiUc8maJN0gCGwBJwyUdmOG4jcB+Lfb9MPA6QETcExETgY8Cg4FLOmo3624OebPEUuDrkgZI+iBQRzJn3qGIeAd4DPg2gKSRJB+orpT0LUmXpvttAgJoaq+9B2oy8901Zqk7SebJ/0Jy98svIuJpSV/IcOy3gVskfQtoILlTZp2ke4H/JenPwE6SMJ8J9Gun3azb9fHz5M3M8svTNWZmOeaQNzPLMYe8mVmOOeTNzHLMIW9mlmP73C2UhULBt/uYmZVhzJgxfVq27XMhDzBmzJjeHkKXFYtFamo6/e5MblRbveCaq0Wl1lwoFNps93SNmVmOOeTNzHLMIW9mlmMOeTOzHHPIm5nlmEPezCzHHPJmZjnmkDczyzGHfEaPPPJIpv3mzp3LqlWreng0ZmbZOOQzeOWVV1i2bFlvD8PMrMv2yccadOaZSc+0ajv4qwcz4oIR7Nq+i+c+91yr/uEzh3PIzENoeKOBP0z7w259xzxxTIfvN3/+fJ577jlGjRrFGWecwSuvvMKSJUvo169fu8c0NjZyxRVX8PLLL9PQ0MCFF17IZz/7WW6++WYee+wx+vbty0knncT555/fZpuZWXeoyJDf22bNmsWvfvUrRo4cyYsvvsidd97Z6THLli1jwIAB3HHHHbz++uvMmDGDRx55hNtuu401a9bQr18/7rrrLoA228zMukNFhnxHV979BvbrsH/AQQM6vXLvyKc+9alM+z3//POccMIJAAwbNowBAwawefNmTj31VM4991xOP/10zjjjDIA228zMuoPn5Luof//+mfctXSS9oaGBvn37cuWVVzJv3jw2btzIOeecw86dO9tsMzPrDg75DPr27dvl4P3kJz/J008/DcD69evp27cvffr0YdGiRRx11FHMmTOHwYMH8/rrr7dq27ZtW0+UYWZVqCKna/a2o446ij/+8Y8cdthhDBkyJNMxn//85/nd737HOeecQ2NjI/Pnz+eDH/wgb775JtOmTWPgwIEcc8wxjBgxolXbhz70oR6uyMyqRaaQl7QQGAs0ARdFxNqSvvOAWcAu4FlgdkQ0pX37A88DP4mIWkmHA0uAfsB64JyIeKcb6+kRQ4cO5Yknnsi074IFC957fdVVV7Xqv/zyyzO1mZl1h05DXtJEYGREjJNUA9wGjEv7BgLTgQkR0Sjp8bSvLj38MuBvJaebD9wYEf8q6Wrgm8BN3VbNXtLQ0MCsWbN2a3v77bcZPXo08+fP76VRmZm1luVKfjJwH0BEFCUNkXRgRLwVEdvT/ubAHwy8lm6PAj4OlH6LaBLQfBP4A8D3qMCQHzBgAEuWLNmtrVKXDDOzfMvywetwYGPJ9sa07T2S5gIvAPdExItp88+AS1qca1DJ9MwG4JAuj9jMzDIr54PXVquBR8QCSdcDyyWtAY4CnoqIlyRlPk+zYrFYxrB6V319fUWOu1zVVi+45mqRt5qzhPw6dr9yP5TkQ1MkDQVGR8TqiNgh6SFgPDAGOFLS6cBhwDuSXgG2Sdo/InYAI9Jzt1KJ0x7VNl1TbfWCa64WlVpzoVBosz3LdM2jwDQASccC6yJia9rXH6iVdEC6fTwQEfG1iDguIsYCt5LcXbMCWAGcle57FvBwOcWYmVk2nYZ8RNQBBUl1wA3AbEkzJZ0ZEa+T3DGzStJTwBvA0g5O92PgG5J+CwwFfrnHFexDTj75ZN5+++12+5sfc2BmtrdkmpOPiLktmp4t6asFajs4dl7J6/XAKV0ZoJmZla8iv/H6zDOTWrUdfPBXGTHiAnbt2s5zz32uVf/w4TM55JCZNDS8wR/+MG23vmOOeaLD9zvzzDO58cYbOfTQQ3n11VeZPXs2w4YNY/v27dTX13P55Zd36Zk2EcH8+fPp27cvgwYNYsGCBfTr14+LL76YhoYGGhoauOKKKzjiiCNatX3iE5/I/D5mZhUZ8nvblClTWLVqFWeffTYrV65kypQpjBo1iilTpvDUU09xyy23cMEFF2Q+31VXXcUPfvADjj76aBYvXsztt9/OqFGjGDZsGFdffTUvv/wyL730Eq+++mqrNjOzrqjIkO/oyrtfv4Ed9g8YcFCnV+4tTZ06lQULFrwX8pdeeimLFy9m8eLFNDQ0MHDgwC6d74UXXuDoo48Gknn6RYsWMX36dK677jquuOIKpk6dyoknnsiGDRtatZmZdYWfQpnByJEj2bBhA+vXr2fr1q2sWLGCYcOGcddddzFv3rw9OndjYyN9+/bl4IMP5v7772fq1KncddddLFq0qM02M7OuqMgr+d4wadIkFi5cyMknn8ybb75J85e8VqxYQWNjY5fONXLkSJ555hmOOeYY1q5dy+jRo6mrq6OxsZGJEyfysY99jHnz5rXZZmbWFQ75jE455RSmT5/O0qVL2b59Oz/84Q95+OGHOfvss3nwwQdZuXJl5nNddtllXHnllfTp04fBgwdzzTXXsHnzZr7//e9z66230qdPHy688EKGDx/eqs3MrCv6lK5etC8oFApNY8aM6e1hdFmlfkuuXNVWL7jmalGpNRcKBcaMGdPqcTG+ku9mK1eupLa2tlX7jBkzOOUUf0XAzPYuh3w3mzx5MpMnT+7tYZiZAb67xsws1xzyZmY55pA3M8sxh7yZWY455M3Mcswhb2aWYw55M7Mcc8ibmeVYpi9DSVoIjAWagIsiYm1J33nALGAXyYpRs4H9SVaLGgZ8gGSN1wcl1ZIs8r0pPfzaiFjWLZWYmVkrnYa8pInAyIgYJ6kGuA0Yl/YNBKYDEyKiUdLjad/hwH9ExE8lfQR4DHgwPeWlEfFgqzcyM7Nul+VKfjJwH0BEFCUNkXRgRLwVEdvT/ubAHwy8li7+3exw4JVuHreZmWWQZU5+OLCxZHtj2vYeSXOBF4B7IuLFkvY64E7g4pLd50h6XNK/SDqo7JGbmVmnOn3UsKSbgWURcX+6vQb4ZkT8qcV++wPLgcsi4smS9k8DtwNHAycDmyLi9+kPhsMiYk7peQqFQlNXl9PbF9TX1/OBD3ygt4ex11RbveCaq0Wl1rx9+/ayHzW8jt2v3A8F1gNIGgqMjojVEbFD0kPAeEn1wIaIeDkN9P2Av4uI0pU1lgI3tfWGlfgs50p9BnW5qq1ecM3VolJrLhQKbbZnma55FJgGIOlYYF1EbE37+gO1kg5It48HAjgR+G56zDDgAOANSb+WdGS67yTg+S5XYmZmmXV6JR8RdZIK6fz6u8BsSTOBLRFxr6T5wCpJO0luoVxKctvkYkm/JbmdcnZEvCtpEXC3pO3ANuDcninLzMwg433yETG3RdOzJX21JPfEl9oBfL2N86wCjuvSCM3MrGz+xquZWY455M3Mcswhb2aWYw55M7Mcc8ibmeWYQ97MLMcc8mZmOeaQNzPLMYe8mVmOOeTNzHLMIW9mlmMOeTOzHHPIm5nlmEPezCzHHPJmZjnmkDczyzGHvJlZjmVaGUrSQmAs0ARcFBFrS/rOA2YBu0hWjJpNsuRfLTCMZCnAn0TEg5IOB5YA/UgWAz8nIt7ptmrMzGw3nV7JS5oIjIyIcSRhfkNJ30BgOjAhIsYDo4BxwBeA/4iIicBXgZ+nh8wHboyICcBfgG92Yy1mZtZCliv5ycB9ABFRlDRE0oER8VZEbE/7mwN/MPBaRNSVHH848Er6ehJwfvr6AeB7wE17XIWZmbUpy5z8cGBjyfbGtO09kuYCLwD3RMSLJe11wJ3AxWnToJLpmQ3AIWWO28zMMsg0J99Cn5YNEbFA0vXAcklrIuLJtP0zkj4N3CHp6M7O06xYLJYxrN5VX19fkeMuV7XVC665WuSt5iwhv47dr9wPJfnQFElDgdERsToidkh6CBgvqR7YEBEvR8TvJe0H/B2wTdL+EbEDGJGeu5Wampo9KKl3FIvFihx3uaqtXnDN1aJSay4UCm22Z5mueRSYBiDpWGBdRGxN+/oDtZIOSLePBwI4Efhuesww4ADgDWAFcFa671nAw10txMzMsus05NMPUQvp/PoNwGxJMyWdGRGvk9wxs0rSUyRBvhT4Z+BgSb8FlgGzI+Jd4MfAN9L2ocAve6QqMzMDMs7JR8TcFk3PlvTVktwTX2oH8PU2zrMeOKVLIzQzs7L5G69mZjnmkDczyzGHvJlZjjnkzcxyzCFvZpZjDnkzsxxzyJuZ5ZhD3swsxxzyZmY55pA3M8sxh7yZWY455M3Mcswhb2aWYw55M7Mcc8ibmeWYQ97MLMcc8mZmOZZpZShJC4GxQBNwUUSsLek7D5gF7CJZMWp2RDRJ+ikwIX2PayLiN5JqgTHApvTwayNiWXcVY2Zmu+s05CVNBEZGxDhJNcBtwLi0byAwHZgQEY2SHgfGSfpvwOj0mA8DzwC/SU95aUQ82BPFmJnZ7rJcyU8G7gOIiKKkIZIOjIi3ImJ72t8c+IOB14C/Ar9Lj98MDJLUr9tHb2ZmHcoS8sOBQsn2xrTtreYGSXOBi4DrIuLFtPnt9NdZwPKI2CUJYI6kS4ANwJyIeGPPSjAzs/ZkmpNvoU/LhohYIOl6YLmkNRHxJICkL5KE/NR01yXApoj4ffqDYR4wp+X5isViGcPqXfX19RU57nJVW73gmqtF3mrOEvLrSK7cmx0KrAeQNJRk7n11ROyQ9BAwHnhS0qnAj4DTImILQESsLDnPUuCmtt6wpqamy4X0tmKxWJHjLle11QuuuVpUas2FQqHN9iy3UD4KTAOQdCywLiK2pn39gVpJB6TbxwMhaTBwLXB6RPyt+USSfi3pyHRzEvB8F+swM7Mu6PRKPiLqJBUk1QHvArMlzQS2RMS9kuYDqyTtJLmFcilwHnAQcE86Dw8wA1gE3C1pO7ANOLe7CzIzs/dlmpOPiLktmp4t6asFalv035z+19J/AcdlH56Zme0Jf+PVzCzHHPJmZjnmkDczyzGHvJlZjjnkzcxyzCFvZpZjDnkzsxxzyJuZ5ZhD3swsxxzyZmY55pA3M8sxh7yZWY455M3Mcswhb2aWYw55M7Mcc8ibmeWYQ97MLMcyrQwlaSEwFmgCLoqItSV95wGzgF0kK0bNjogmST8FJqTvcU1E/EbS4cASoB/JYuDnRMQ73VmQmZm9r9MreUkTgZERMY4kzG8o6RsITAcmRMR4YBQwTtJJwOj0mNOA69JD5gM3RsQE4C/AN7uzGDMz212W6ZrJwH0AEVEEhkg6MN3eHhGTI6IxDfzBwGvAauAr6fGbgUGS+gGTSBb6BngAmNJdhZiZWWtZQn44sLFke2Pa9h5Jc4EXgHsi4sWI2BURb6fds4DlEbELGFQyPbMBOGSPRm9mZh3KNCffQp+WDRGxQNL1wHJJayLiSQBJXyQJ+alZztOsWCyWMazeVV9fX5HjLle11QuuuVrkreYsIb+O3a/cDyX50BRJQ0nm3ldHxA5JDwHjgSclnQr8CDgtIrakx26TtH9E7ABGpOdupaamprxqelGxWKzIcZer2uoF11wtKrXmQqHQZnuW6ZpHgWkAko4F1kXE1rSvP1Ar6YB0+3ggJA0GrgVOj4i/lZxrBXBW+vos4OGuFGFmZl3T6ZV8RNRJKkiqA94FZkuaCWyJiHslzQdWSdpJcgvlUuA84CDgHknNp5oB/Bi4XdJ3gL8Cv+zugszM7H2Z5uQjYm6LpmdL+mqB2hb9N6f/teWUjGMzM7M95G+8mpnlmEPezCzHHPJmZjnmkDczyzGHvJlZjjnkzcxyzCFvZpZjDnkzsxxzyJuZ5ZhD3swsxxzyZmY55pA3M8sxh7yZWY455M3Mcswhb2aWYw55M7Mcc8ibmeVYppWhJC0ExgJNwEURsbak7zxgFrCLZMWo2RHRJGk0cD+wMCIWpfvWAmOATenh10bEsm6qxczMWug05CVNBEZGxDhJNcBtwLi0byAwHZgQEY2SHgfGSXoW+CdgZRunvDQiHuy2CszMrF1ZpmsmA/cBREQRGCLpwHR7e0RMTgN+IDAYeA14B/gcsK5nhm1mZllkma4ZDhRKtjembW81N0iaC1wEXBcRL6bNOyW1db45ki4BNgBzIuKNcgZuZmadyzQn30Kflg0RsUDS9cBySWsi4sl2jl0CbIqI36c/GOYBc1ruVCwWyxhW76qvr6/IcZer2uoF11wt8lZzlpBfR3Ll3uxQYD2ApKHA6IhYHRE7JD0EjAfaDPmIKJ2jXwrc1NZ+NTU1GYa1bykWixU57nJVW73gmqtFpdZcKBTabM8yJ/8oMA1A0rHAuojYmvb1B2olHZBuHw9EeyeS9GtJR6abk4DnM7y/mZmVqdMr+Yiok1SQVAe8C8yWNBPYEhH3SpoPrJK0k+QWyqWSxgA/Az4KNEqaBnwZWATcLWk7sA04tyeKMjOzRKY5+YiY26Lp2ZK+WqC2RX+B5Eq9pVXAcZlHZ2Zme8TfeDUzyzGHvJlZjjnkzcxyzCFvZpZjDnkzsxxzyJuZ5ZhD3swsxxzyZmY55pA3M8sxh7yZWY455M3Mcswhb2aWYw55M7Mcc8ibmeWYQ97MLMcc8mZmOeaQNzPLsUwrQ0laCIwFmoCLImJtSd95wCxgF8mKUbMjoknSaOB+YGFELEr3PRxYAvQjWQz8nIh4pxvrMTOzEp1eyUuaCIyMiHEkYX5DSd9AYDowISLGA6OAcZIGAf8ErGxxuvnAjRExAfgL8M1uqcLMzNqUZbpmMnAfQEQUgSGSDky3t0fE5IhoTAN/MPAa8A7wOWBdi3NNApamrx8ApuxxBWZm1q4sIT8c2FiyvTFte4+kucALwD0R8WJE7IyIHW2ca1DJ9MwG4JAyxmxmZhllmpNvoU/LhohYIOl6YLmkNRHxZDnnaVYsFssYVu+qr6+vyHGXq9rqBddcLfJWc5aQX8fuV+6HknxoiqShwOiIWB0ROyQ9BIwH2gv5bZL2T6/yR9B6OgeAmpqarOPfZxSLxYocd7mqrV5wzdWiUmsuFApttmeZrnkUmAYg6VhgXURsTfv6A7WSDki3jweig3OtAM5KX58FPJzh/c3MrEydXslHRJ2kgqQ64F1gtqSZwJaIuFfSfGCVpJ0kt1AulTQG+BnwUaBR0jTgy8CPgdslfQf4K/DLnijKzMwSmebkI2Jui6ZnS/pqgdoW/QWSO2nackq2oZmZ2Z7yN17NzHLMIW9mlmMOeTOzHHPIm5nlmEPezCzHHPJmZjnmkDczyzGHvJlZjjnkzcxyzCFvZpZjDnkzsxxzyJuZ5ZhD3swsxxzyZmY55pA3M8sxh7yZWY455M3McizTylCSFgJjgSbgoohYW9J3HjAL2EWyYtTsiGhq6xhJtcAYYFN6+LURsay7ijEzs911GvKSJgIjI2KcpBrgNmBc2jcQmA5MiIhGSY8D4yT1b+8Y4NKIeLAnijEzs91lma6ZDNwHEBFFYIikA9Pt7RExOQ34gcBg4LWOjjEzs70nS8gPBzaWbG9M294jaS7wAnBPRLzYyTFzJD0u6V8kHVT2yM3MrFOZ5uRb6NOyISIWSLoeWC5pTQfHLAE2RcTv0x8M84A5LXcuFotlDKt31dfXV+S4y1Vt9YJrrhZ5qzlLyK9j9yv3Q4H1AJKGAqMjYnVE7JD0EDC+vWMi4k8lbUuBm9p6w5qamuwV7COKxWJFjrtc1VYvuOZqUak1FwqFNtuzTNc8CkwDkHQssC4itqZ9/YFaSQek28cD0d4xkn4t6ch030nA810vxczMsur0Sj4i6iQVJNUB7wKzJc0EtkTEvZLmA6sk7SS5hXJpegvlbsekp1sE3C1pO7ANOLcHajIzs1SmOfmImNui6dmSvlqgNsMxRMQq4LgujdDMzMrmb7yameWYQ97MLMcc8mZmOeaQNzPLMYe8mVmOOeTNzHLMIW9mlmMOeTOzHOvT1NTU22PYTaFQ2LcGZGZWIcaMGdPqAZL7XMibmVn38XSNmVmOOeTNzHKsnEVDqlK6bm0t8BGSRcvPTVfBKt3nbOBikidv3hwRi0v6hgH/DzgzIp7YS8PeI+XWLGk/YDFwFMnfse9FRFuLyexTOlmwfgpwNcnvw/KI+Elnx1SCMmv+KTCB5M/2moj4zV4f+B4op+a0b3+Sx6P/JH0wY0XwlXx2Xwc2R8RngauAa0o7JQ0CrgCmkDwr/x/SRVWaXQvsFpAVoNyazwHeTo+bBfx8bw66HKUL1pOM+YYWu9wAnEWyKM5USR/PcMw+rcyaTyJZKGgccBpw3d4c854qp+aSvsuAv+2VgXYjh3x2k4F709crSP4SlDoBWBsRWyJiB/Bk8z6STga2Av93L421u5Rb8x3AJek+G4EP74Wx7ql2F59PF7r5W0S8HBHvAsvT/St9wfpyal4NfCU9fjMwSFK/vT7y8pVTM5JGAR8HlvXKqPeAQz679xYnT/8CNEka0FZ/agNwSLrPj4Ef7a2BdqOyao6IxoioT9suBu7cG4PdQx0tPt9mnZ0cUwm6XHNE7IqIt9O2WSRTGrt6fKTdp5w/Z4Cf8f6FS0XxnHwbJH0L+FaL5hNabLe6H7Wd/rnALRGxWVJ3DK9HdHPNzeecDRwLfGHPRtcrOqq1vb7Ofn/2dZlrlvRFkpCf2qMj6nmd1ixpBvBURLy0L/8/3B6HfBsi4lbg1tI2SbUkP+mfTT+Q7BMRDSW7tFy8fATwv4FvAP0kzSH5IPJ4SV+JiD/0YAld1s01I2kWSbh/KSIae3Do3aXdBevb6BuRtjV0cEwlKKdmJJ1K8i/T0yJiy14YZ3cqp+bPA0dKOh04DHhH0isRsWIvjHePebomu0d5fy7yC8CqFv1PA8dJ+lC6sPl44LcRMT4ixkbEWJL5vAv2tYDvQFk1p3Ob5wNfLpm22de1u2B9RPwncKCkj6Z3Dp2e7t/RIveVoMs1SxpMchPB6RFRcR9CUkbNEfG1iDgu/X/4VpK7ayoi4MFX8l1xN3CKpDXAO8BMAElzgX+PiKfS14+Q3Jp1ZQVe5bRUVs2SfkjyYevykn/eTm3xr4B9SmcL1gN/D9yV7n53RPwJ+FM7C9ZXhHJqlvRt4CDgnpI/2xkR8V97efhlKfPPuaL5sQZmZjnm6RozsxxzyJuZ5ZhD3swsxxzyZmY55pA3M8sxh7xZN5FUm35hxmyf4ZA3M8sx3ydvVSl9cuLNwJFAf5JHJl8BrAX+O7A/8LWI+Gv6/PTxJF8eXBQRSyQdA/yC5As1dRHx/fQxEJuATwBHAGdHxDN7tzKz3flK3qrV14H1EXES8CXefy76prTtV8DFkk4keX76eOBkYJ6kD5I8d/w7afswSR9Jj2+KiNOA60meW2TWqxzyVq0+A3xJ0hPAv5FcuQ8geW4+wFOASK7q/x0gfcTuH4GRgCLiubR9RkT8NT2ueQWsV4HBPV+GWcf87BqrVg3AVRHR/JwS0sBvvvDpQ/I8niZ2fxztAJIpmnfbOe/OkteV/uhhywFfyVu1ehr4IoCkgyVdnbZPSH8dR3LVvpZkaUPSJ20eBfwZ+KOkE9L2xZJq9t7QzbJzyFu1ugfYlj6N8AHgt2n7EZIeJpmzvy5dgLwgaTXwGDA3nba5CPhZ+oTON9Ol5Mz2Ob67xiyVTtfMiYjne3ssZt3FV/JmZjnmK3kzsxzzlbyZWY455M3Mcswhb2aWYw55M7Mcc8ibmeWYQ97MLMf+P6nG7LrmfWkSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_plot(combined_model_history,'TTclf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_model.save('./figure/amazon-joint-50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other experiment here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR1-KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9096470161765372\n",
      "0.9108555657773689\n",
      "5725/5725 [==============================] - 1s 203us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "y_train_agreement_LR = np.copy(y_train_agreement)\n",
    "y_train_agreement_LR[y_train_agreement_LR != 0] = 1\n",
    "\n",
    "y_test_agreement_LR = np.copy(y_test_agreement)\n",
    "y_test_agreement_LR[y_test_agreement_LR != 0] = 1\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(penalty='l1', random_state=42)\n",
    "\n",
    "clf.fit(y_train_agreement_LR, y_train)\n",
    "\n",
    "print(clf.score(y_train_agreement_LR, y_train))\n",
    "print(clf.score(y_test_agreement_LR, y_test))\n",
    "\n",
    "ht_lr = LogisticRegression(penalty='l1', random_state=42)\n",
    "\n",
    "\n",
    "# Train LR\n",
    "ht_lr.fit(y_train_agreement_LR, y_train)\n",
    "ht_test_pred = ht_lr.predict(y_test_agreement_LR)\n",
    "\n",
    "human_terms_relu_model = Model(inputs=combined_model.input,\n",
    "                                    outputs=combined_model.get_layer('concatenate').output)\n",
    "predict_relu = human_terms_relu_model.predict([X_test, y_test_agreement])\n",
    "accept_indices = np.where(np.sum(predict_relu, axis=1)!=0)\n",
    "accept_indices = accept_indices[0]\n",
    "total_reject = X_test.shape[0] - len(accept_indices)\n",
    "rejection_rate = total_reject/X_test.shape[0]\n",
    "\n",
    "test_eval = combined_model.evaluate([X_test[accept_indices], y_test_agreement[accept_indices]], y_test[accept_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9108555657773689, 0.920536756126021)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1_accept_indices = np.where(np.sum(y_test_agreement_LR, axis=1)!=0)[0]\n",
    "\n",
    "ht_lr.score(y_test_agreement_LR, y_test), ht_lr.score(y_test_agreement_LR[lr1_accept_indices], y_test[lr1_accept_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2300, 2609, 236)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_reject_indices = np.where(np.sum(predict_relu, axis=1)==0)[0]\n",
    "\n",
    "lr1_reject_indices = np.where(np.sum(y_test_agreement_LR, axis=1)==0)[0]\n",
    "lr1_correct = np.where(ht_test_pred == y_test)[0]\n",
    "lr1_correct = np.array(list(set(lr1_correct) - set(lr1_reject_indices)))\n",
    "lr1_incorrect = np.where(ht_test_pred != y_test)[0]\n",
    "lr1_incorrect = np.array(list(set(lr1_incorrect) - set(lr1_reject_indices)))\n",
    "\n",
    "our_reject_lr_reject = list(set(our_reject_indices) & set(lr1_reject_indices))\n",
    "our_reject_lr_correct = list(set(our_reject_indices) & set(lr1_correct))\n",
    "our_reject_lr_incorrect = list(set(our_reject_indices) & set(lr1_incorrect))\n",
    "\n",
    "len(our_reject_lr_reject), len(our_reject_lr_correct), len(our_reject_lr_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_predict = np.squeeze(combined_model.predict([X_test, y_test_agreement]))\n",
    "\n",
    "our_predict_class = np.zeros(len(our_predict))\n",
    "our_predict_class[our_predict >= 0.5] = 1\n",
    "\n",
    "our_correct = np.where(our_predict_class == y_test)[0]\n",
    "our_correct = np.array(list(set(our_correct) - set(our_reject_indices)))\n",
    "our_incorrect = np.where(our_predict_class != y_test)[0]\n",
    "our_incorrect = np.array(list(set(our_incorrect) - set(our_reject_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5118, 84)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_correct_lr_reject = list(set(our_correct) & set(lr1_reject_indices))\n",
    "our_correct_lr_correct = list(set(our_correct) & set(lr1_correct))\n",
    "our_correct_lr_incorrect = list(set(our_correct) & set(lr1_incorrect))\n",
    "\n",
    "len(our_correct_lr_reject), len(our_correct_lr_correct), len(our_correct_lr_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 162, 361)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_incorrect_lr_reject = list(set(our_incorrect) & set(lr1_reject_indices))\n",
    "our_incorrect_lr_correct = list(set(our_incorrect) & set(lr1_correct))\n",
    "our_incorrect_lr_incorrect = list(set(our_incorrect) & set(lr1_incorrect))\n",
    "\n",
    "len(our_incorrect_lr_reject), len(our_incorrect_lr_correct), len(our_incorrect_lr_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
