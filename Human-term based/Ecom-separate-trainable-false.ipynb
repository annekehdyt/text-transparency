{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "seed(42)\n",
    "set_random_seed(42)\n",
    "\n",
    "from keras.layers import Input, Dense, TimeDistributed, Embedding\n",
    "from keras.layers import Concatenate, Reshape, Lambda, Multiply, multiply, concatenate\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "from dataset_load import *\n",
    "\n",
    "style.use('seaborn-whitegrid')\n",
    "\n",
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X\n",
    "\n",
    "def load_unigrams(path, X, y):\n",
    "    word_list = []\n",
    "    connotation = {}\n",
    "    \n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            word_list.append(line.strip())\n",
    "            \n",
    "    for word in word_list:\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        for i, doc in enumerate(X):\n",
    "            if word in doc.lower():\n",
    "                \n",
    "                if (y[i] == 1):\n",
    "                    pos_count += 1\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    \n",
    "        if pos_count > neg_count:\n",
    "            connotation[word] = 1\n",
    "        else:\n",
    "            connotation[word] = 0\n",
    "    \n",
    "    return word_list, connotation\n",
    "\n",
    "def generate_appearance(X_train_corpus, X_test_corpus, word_list, connotation):\n",
    "    y_train_agreement = []\n",
    "    for i in range(len(X_train_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_train_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_train_agreement.append(doc_agreement)\n",
    "        \n",
    "    y_test_agreement = []\n",
    "    for i in range(len(X_test_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_test_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_test_agreement.append(doc_agreement)\n",
    "        \n",
    "    return np.array(y_train_agreement), np.array(y_test_agreement)\n",
    "\n",
    "# 'imdb-unigrams.txt'\n",
    "import pandas as pd\n",
    "\n",
    "path = r'../../data/womens-ecommerce-clothing-reviews/Womens_Clothing_E-Commerce_Reviews.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "X = list(df['Review Text'])\n",
    "y = list(df['Rating'])\n",
    "y_label = np.asarray(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 842\n",
      "2 1565\n",
      "3 2871\n",
      "4 5077\n",
      "5 13131\n"
     ]
    }
   ],
   "source": [
    "y_label.shape\n",
    "for i in range(1,6):\n",
    "    print(i, np.sum(y_label==i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label[y_label<3] = 0\n",
    "y_label[y_label>3] = 1\n",
    "\n",
    "neutral_indices = np.where(y_label==3)[0]\n",
    "y_label = np.delete(y_label, neutral_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X, neutral_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2407\n",
      "18208\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_label==0))\n",
    "print(np.sum(y_label==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20615"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2)\n",
      "corpus update start\n",
      "corpus update end\n",
      "\n",
      "(75, 2)\n",
      "corpus update start\n",
      "corpus update end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "# split\n",
    "X_train_split, X_test_split, y_train, y_test = train_test_split(X, y_label, test_size=0.33, random_state=42)\n",
    "\n",
    "# preprocessing\n",
    "X_train_corpus_update = update_corpus_contraction(X_train_split)\n",
    "X_test_corpus_update = update_corpus_contraction(X_test_split)\n",
    "\n",
    "# Count vectorizer \n",
    "\n",
    "# count vectorizer\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "cv = CountVectorizer(lowercase=True, max_df=1.0, min_df=100, binary=True, token_pattern=token)\n",
    "cv.set_params(ngram_range=(1,1))\n",
    "\n",
    "cv.fit(X_train_split)\n",
    "\n",
    "X_train = cv.transform(X_train_corpus_update)\n",
    "X_test = cv.transform(X_test_corpus_update)\n",
    "\n",
    "words = cv.get_feature_names()\n",
    "\n",
    "\n",
    "# word_list, connotation = load_unigrams('./amazon-video-unigrams.txt', X_train_corpus_update, y_train)\n",
    "# y_train_agreement, y_test_agreement = generate_appearance(X_train_corpus_update, X_test_corpus_update, \n",
    "#                                                           word_list, connotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_list, connotation = load_unigrams('./amazon-video-unigrams-more.txt', X_train_corpus_update, y_train)\n",
    "# word_list, connotation = load_unigrams('./imdb-unigrams.txt', X_train_corpus_update, y_train)\n",
    "word_list, connotation = load_unigrams('./ecom-unigrams.txt', X_train_corpus_update, y_train)\n",
    "\n",
    "y_train_agreement, y_test_agreement = generate_appearance(X_train_corpus_update, X_test_corpus_update, \n",
    "                                                          word_list, connotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6803, 720)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9477266145380828\n",
      "0.927237983242687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6803, 720)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def history_plot(history, model_name):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "        \n",
    "    title = model_name + 'accuracy'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['tr_acc', 'val_acc'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(history.history['loss'], 'm--')\n",
    "    plt.plot(history.history['val_loss'], 'y--')\n",
    "\n",
    "    title = model_name + 'loss'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['tr_loss', 'val_loss'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/48951109/keras-custom-binary-cross-entropy-loss-function-get-nan-as-output-for-loss\n",
    "\n",
    "# def custom_cross_entropy(y_true, y_pred):\n",
    "#     t_loss = K.max(y_pred,0)-y_pred * y_true + K.log(1+K.exp((-1)*K.abs(y_pred)))\n",
    "#     return K.mean(t_loss)\n",
    "\n",
    "# from keras.initializers import Constant, glorot_uniform\n",
    "\n",
    "# input_layer = Input(shape=(X_train.shape[1],))\n",
    "# tanh_output = Dense(1, activation='sigmoid', kernel_initializer=glorot_uniform(seed=42))(input_layer)\n",
    "# model = Model(inputs=input_layer, outputs=tanh_output)\n",
    "\n",
    "# model.compile(loss=custom_cross_entropy,\n",
    "#              metrics=['acc'],\n",
    "#              optimizer='adam')\n",
    "\n",
    "# model.fit(X_train[:16667], y_train_original[:16667], \n",
    "#          validation_data=([X_train[16667:], y_train_original[16667:]]),\n",
    "#          batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test, y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_train, y_train_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9254 samples, validate on 4558 samples\n",
      "Epoch 1/1\n",
      "9254/9254 [==============================] - 26s 3ms/step - loss: 0.2580 - acc: 0.9002 - val_loss: 0.1994 - val_acc: 0.9144\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant, glorot_uniform\n",
    "\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "tanh_output = Dense(1, activation='sigmoid', kernel_initializer=glorot_uniform(seed=42))(input_layer)\n",
    "model = Model(inputs=input_layer, outputs=tanh_output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             metrics=['acc'],\n",
    "             optimizer='adam')\n",
    "\n",
    "base_history = model.fit(X_train, y_train, \n",
    "                 validation_split=0.33, shuffle=False,\n",
    "                 batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_test, y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(X_train, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9254 samples, validate on 4558 samples\n",
      "Epoch 1/1\n",
      "9254/9254 [==============================] - 74s 8ms/step - loss: 0.3481 - acc: 0.8754 - val_loss: 0.3082 - val_acc: 0.8831\n"
     ]
    }
   ],
   "source": [
    "def layer_split(x):\n",
    "    return tf.split(x,num_or_size_splits=human_terms_len,axis=1)\n",
    "\n",
    "def layer_concat(x):\n",
    "    return tf.concat(x, axis=1)\n",
    "\n",
    "# build the combined model\n",
    "# Combined model\n",
    "human_terms_len = len(word_list)\n",
    "\n",
    "# base_model = build_base_model(X_train.shape[1])\n",
    "\n",
    "combined_input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# build the hard coded weight for human terms\n",
    "ht_input_layer = Input(shape=(human_terms_len,))\n",
    "\n",
    "# split = Lambda( lambda x: tf.split(x,num_or_size_splits=human_terms_len,axis=1))(ht_input_layer)\n",
    "split = Lambda(layer_split)(ht_input_layer)\n",
    "\n",
    "# get the document prediction\n",
    "label_layer = model(combined_input_layer)\n",
    "tanh_norm = Lambda(lambda x: (x*2)-1)(label_layer)\n",
    "# tanh_norm = Lambda(lambda x: tf.scalar_mul(2,x)-1)(label_layer)\n",
    "\n",
    "# do normalize of bipolar sigmoid\n",
    "\n",
    "\n",
    "# stack the multiply layer\n",
    "dense_layer = []\n",
    "for i in range(human_terms_len):\n",
    "    dense_layer.append(Dense(1, activation='relu', use_bias=False)(Multiply()([split[i], tanh_norm])))\n",
    "\n",
    "# concat all the result   \n",
    "# concat = Lambda( lambda x: tf.concat(x, axis=1), name='concatenate')(dense_layer)\n",
    "concat = Lambda(layer_concat, name='concatenate')(dense_layer)\n",
    "\n",
    "\n",
    "# pass it to sigmoid layer\n",
    "output_layer = Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "combined_model = Model(inputs=[combined_input_layer, ht_input_layer], outputs=output_layer)\n",
    "# combined_model.summary()\n",
    "\n",
    "\n",
    "combined_model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['acc'])\n",
    "\n",
    "# y_train_tanh = y_train_original\n",
    "# y_train_tanh[y_train_tanh == 0] = -1\n",
    "\n",
    "# y_test_tanh = y_test_original\n",
    "# y_test_tanh[y_test_tanh == 0] = -1\n",
    "\n",
    "# base_model_history = base_model.fit(X_train[:16667], y_train_original[:16667], \n",
    "#                                     validation_data=(X_train[16667:], y_train_original[16667:]),\n",
    "#                                     batch_size=1, epochs=1)\n",
    "\n",
    "combined_model_history = combined_model.fit([X_train,y_train_agreement], y_train, \n",
    "                                            validation_split=0.33, shuffle=False,\n",
    "                                            batch_size=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_reject(combined_model, X, y_agreement, y):\n",
    "    human_terms_relu_model = Model(inputs=combined_model.input,\n",
    "                                    outputs=combined_model.get_layer('concatenate').output)\n",
    "    predict_relu = human_terms_relu_model.predict([X, y_agreement])\n",
    "    accept_indices = np.where(np.sum(predict_relu, axis=1)!=0)\n",
    "    accept_indices = accept_indices[0]\n",
    "    total_reject = X.shape[0] - len(accept_indices)\n",
    "    rejection_rate = total_reject/X.shape[0]\n",
    "\n",
    "    test_eval = combined_model.evaluate([X[accept_indices], y_agreement[accept_indices]], y[accept_indices])\n",
    "    \n",
    "    return test_eval, rejection_rate, total_reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6803/6803 [==============================] - 1s 93us/step\n",
      "13812/13812 [==============================] - 1s 92us/step\n",
      "4421/4421 [==============================] - 0s 93us/step\n",
      "8882/8882 [==============================] - 1s 92us/step\n"
     ]
    }
   ],
   "source": [
    "test_ev = combined_model.evaluate([X_test, y_test_agreement], y_test)\n",
    "train_ev = combined_model.evaluate([X_train, y_train_agreement], y_train)\n",
    "\n",
    "def accuracy_reject(combined_model, X, y_agreement, y):\n",
    "    human_terms_relu_model = Model(inputs=combined_model.input,\n",
    "                                    outputs=combined_model.get_layer('concatenate').output)\n",
    "    predict_relu = human_terms_relu_model.predict([X, y_agreement])\n",
    "    accept_indices = np.where(np.sum(predict_relu, axis=1)!=0)\n",
    "    accept_indices = accept_indices[0]\n",
    "    total_reject = X.shape[0] - len(accept_indices)\n",
    "    rejection_rate = total_reject/X.shape[0]\n",
    "\n",
    "    test_eval = combined_model.evaluate([X[accept_indices], y_agreement[accept_indices]], y[accept_indices])\n",
    "    \n",
    "    return test_eval, rejection_rate, total_reject\n",
    "\n",
    "test_ev_reject = accuracy_reject(combined_model, X_test, y_test_agreement, y_test)\n",
    "train_ev_reject = accuracy_reject(combined_model, X_train, y_train_agreement, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.302875 \t 0.883942\n",
      "0.310406 \t 0.882258\n",
      "0.231054 \t 0.902725 \t 0.356936 \t 4930\n",
      "0.239531 \t 0.903416 \t 0.350140 \t 2382\n"
     ]
    }
   ],
   "source": [
    "print('%f \\t %f' %(train_ev[0], train_ev[1]))\n",
    "print('%f \\t %f' %(test_ev[0], test_ev[1]))\n",
    "print('%f \\t %f \\t %f \\t %d' %(train_ev_reject[0][0], train_ev_reject[0][1], train_ev_reject[1], train_ev_reject[2]))\n",
    "print('%f \\t %f \\t %f \\t %d' %(test_ev_reject[0][0], test_ev_reject[0][1], test_ev_reject[1], test_ev_reject[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_plot(base_history,'RDclf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_plot(combined_model_history,'TTclf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_model.save('./figure/amazon-joint-50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_agreement_LR = np.copy(y_train_agreement)\n",
    "y_train_agreement_LR[y_train_agreement_LR != 0] = 1\n",
    "\n",
    "y_test_agreement_LR = np.copy(y_test_agreement)\n",
    "y_test_agreement_LR[y_test_agreement_LR != 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4421/4421 [==============================] - 0s 101us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ht_lr = LogisticRegression(penalty='l1', random_state=42)\n",
    "\n",
    "\n",
    "# Train LR\n",
    "ht_lr.fit(y_train_agreement_LR, y_train)\n",
    "ht_test_pred = ht_lr.predict(y_test_agreement_LR)\n",
    "\n",
    "human_terms_relu_model = Model(inputs=combined_model.input,\n",
    "                                    outputs=combined_model.get_layer('concatenate').output)\n",
    "predict_relu = human_terms_relu_model.predict([X_test, y_test_agreement])\n",
    "accept_indices = np.where(np.sum(predict_relu, axis=1)!=0)\n",
    "accept_indices = accept_indices[0]\n",
    "total_reject = X.shape[0] - len(accept_indices)\n",
    "rejection_rate = total_reject/X.shape[0]\n",
    "\n",
    "test_eval = combined_model.evaluate([X_test[accept_indices], y_test_agreement[accept_indices]], y_test[accept_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9026899897104219, 0.9174798835815785)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1_accept_indices = np.where(np.sum(y_test_agreement_LR, axis=1)!=0)[0]\n",
    "\n",
    "ht_lr.score(y_test_agreement_LR, y_test), ht_lr.score(y_test_agreement_LR[lr1_accept_indices], y_test[lr1_accept_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962, 1283, 137)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_reject_indices = np.where(np.sum(predict_relu, axis=1)==0)[0]\n",
    "\n",
    "lr1_reject_indices = np.where(np.sum(y_test_agreement_LR, axis=1)==0)[0]\n",
    "lr1_correct = np.where(ht_test_pred == y_test)[0]\n",
    "lr1_correct = np.array(list(set(lr1_correct) - set(lr1_reject_indices)))\n",
    "lr1_incorrect = np.where(ht_test_pred != y_test)[0]\n",
    "lr1_incorrect = np.array(list(set(lr1_incorrect) - set(lr1_reject_indices)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "our_reject_lr_reject = list(set(our_reject_indices) & set(lr1_reject_indices))\n",
    "our_reject_lr_correct = list(set(our_reject_indices) & set(lr1_correct))\n",
    "our_reject_lr_incorrect = list(set(our_reject_indices) & set(lr1_incorrect))\n",
    "\n",
    "len(our_reject_lr_reject), len(our_reject_lr_correct), len(our_reject_lr_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_predict = np.squeeze(combined_model.predict([X_test, y_test_agreement]))\n",
    "\n",
    "our_predict_class = np.zeros(len(our_predict))\n",
    "our_predict_class[our_predict >= 0.5] = 1\n",
    "\n",
    "our_correct = np.where(our_predict_class == y_test)[0]\n",
    "our_correct = np.array(list(set(our_correct) - set(our_reject_indices)))\n",
    "our_incorrect = np.where(our_predict_class != y_test)[0]\n",
    "our_incorrect = np.array(list(set(our_incorrect) - set(our_reject_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3913, 81)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_correct_lr_reject = list(set(our_correct) & set(lr1_reject_indices))\n",
    "our_correct_lr_correct = list(set(our_correct) & set(lr1_correct))\n",
    "our_correct_lr_incorrect = list(set(our_correct) & set(lr1_incorrect))\n",
    "\n",
    "len(our_correct_lr_reject), len(our_correct_lr_correct), len(our_correct_lr_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 163, 264)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_incorrect_lr_reject = list(set(our_incorrect) & set(lr1_reject_indices))\n",
    "our_incorrect_lr_correct = list(set(our_incorrect) & set(lr1_correct))\n",
    "our_incorrect_lr_incorrect = list(set(our_incorrect) & set(lr1_incorrect))\n",
    "\n",
    "len(our_incorrect_lr_reject), len(our_incorrect_lr_correct), len(our_incorrect_lr_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
