{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2)\n",
      "corpus update start\n",
      "corpus update end\n",
      "\n",
      "(75, 2)\n",
      "corpus update start\n",
      "corpus update end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from dataset_load import *\n",
    "\n",
    "path = r\"..\\..\\data\\reviews_Amazon_Instant_Video_5.json.gz\"\n",
    "\n",
    "X, y = extract_review_amazon(path, 'reviewText')\n",
    "y_label = np.asarray(y)\n",
    "\n",
    "neutral_indices = np.where(y_label == 3)[0]\n",
    "y_label[y_label<3] = 0\n",
    "y_label[y_label>3] = 1\n",
    "\n",
    "X_discarded = np.delete(X,neutral_indices)\n",
    "y_discarded = np.delete(y_label, neutral_indices)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "# split\n",
    "X_train_split, X_test_split, y_train, y_test = train_test_split(X_discarded, y_discarded, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "X_train_corpus_update = update_corpus_contraction(X_train_split)\n",
    "X_test_corpus_update = update_corpus_contraction(X_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "\n",
    "# Count vectorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "cv = CountVectorizer(min_df = 100, token_pattern=token, lowercase=True, binary=True)\n",
    "X_train = cv.fit_transform(X_train_corpus_update)\n",
    "X_test = cv.transform(X_test_corpus_update)\n",
    "\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1499"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr1 = LogisticRegression(penalty='l1', random_state=42)\n",
    "lr1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, connotation = load_unigrams('./amazon-video-unigrams-more.txt', X_train_corpus_update, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_agreement, y_test_agreement = generate_appearance(X_train_corpus_update, X_test_corpus_update, \n",
    "                                                          word_list, connotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "htcv = CountVectorizer(min_df = 100, token_pattern=token, lowercase=True, binary=True, vocabulary=word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_train = htcv.transform(X_train_corpus_update)\n",
    "ht_test = htcv.transform(X_test_corpus_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_agreement_pos = np.copy(y_train_agreement)\n",
    "y_train_agreement_neg = np.copy(y_train_agreement)\n",
    "y_test_agreement_pos = np.copy(y_test_agreement)\n",
    "y_test_agreement_neg = np.copy(y_test_agreement)\n",
    "\n",
    "y_train_agreement_pos[y_train_agreement_pos == -1] = 0\n",
    "y_train_agreement_neg[y_train_agreement_neg == 1] = 0\n",
    "y_test_agreement_pos[y_test_agreement_pos == -1] = 0\n",
    "y_test_agreement_neg[y_test_agreement_neg == 1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From actual label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_train = list()\n",
    "for i,y in enumerate(y_train):\n",
    "    if y == 1:\n",
    "        lr2_train.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train = np.asarray(lr2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LogisticRegression(penalty='l1', random_state=42)\n",
    "lr2.fit(lr2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892916283348666\n",
      "0.892916283348666\n"
     ]
    }
   ],
   "source": [
    "# Test with predict {0,1}\n",
    "\n",
    "lr1_predict = lr1.predict(X_test)\n",
    "\n",
    "lr2_test_bin = list()\n",
    "for i,y in enumerate(lr1_predict):\n",
    "    if y==1:\n",
    "        lr2_test_bin.append(y_test_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_test_bin.append(y_test_agreement_neg[i] * y)\n",
    "    \n",
    "lr2_test_bin = np.asarray(lr2_test_bin)\n",
    "\n",
    "print(lr2.score(lr2_test_bin, y_test))\n",
    "\n",
    "# Test with predict [0,1]\n",
    "\n",
    "lr1_predict = lr1.predict_proba(X_test)[:,1]\n",
    "\n",
    "lr2_test_proba = list()\n",
    "for i,y in enumerate(lr1_predict):\n",
    "    if y>=0.5:\n",
    "        lr2_test_proba.append(y_test_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_test_proba.append(y_test_agreement_neg[i] * y)\n",
    "    \n",
    "lr2_test_proba = np.asarray(lr2_test_proba)\n",
    "\n",
    "print(lr2.score(lr2_test_proba, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.28918339, 2.67608546, 2.06030386, 1.23953709, 0.        ,\n",
       "       1.44715692, 3.59021862, 5.44840051, 2.9410274 , 2.34183544,\n",
       "       2.23180046, 0.        , 3.10105059, 2.60747664, 4.16913173,\n",
       "       1.34150674, 2.67811426, 0.        , 4.97959419, 4.0351474 ,\n",
       "       6.85408214, 5.85027575, 4.7721894 , 4.82172967, 3.34839224,\n",
       "       2.23796446, 4.80542253, 3.82654216, 2.13342247, 2.68336358,\n",
       "       6.6060343 , 3.82547233, 2.99316974, 4.06270428, 2.51605173,\n",
       "       0.        , 0.        , 0.27412764, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       2.01044686, 1.94684598, 1.42204315, 0.        , 1.53956788,\n",
       "       1.7602934 , 0.        , 2.81949389, 2.14899092, 3.86829695,\n",
       "       0.        , 1.19486136, 1.86958905, 4.62976364, 1.88177154,\n",
       "       1.6589575 , 2.07634325, 2.61391363, 1.57157637, 2.22516645,\n",
       "       1.43331211, 2.39872507, 1.8250656 , 1.12657921, 2.21986553,\n",
       "       2.00817979, 4.30834626, 2.609186  , 0.        , 2.58729719,\n",
       "       3.32637765, 3.70545236, 3.99869495])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = lr2.coef_.flatten()\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weight(clf1, clf2=None):\n",
    "    w = clf1.coef_.flatten()\n",
    "    indices = np.argsort(w)[::-1]\n",
    "    con = list(connotation.values())\n",
    "\n",
    "    if clf2 is not None:\n",
    "        w2 = clf2.coef_.flatten()\n",
    "        for i in indices:\n",
    "            print('%s \\t %.3f \\t %.3f \\t %d' %(word_list[i], w[i], w2[i], con[i]))\n",
    "    else:  \n",
    "        for i in indices:\n",
    "            print('%s \\t %.3f \\t %d' %(word_list[i], w[i],con[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = lr1.predict(X_train)\n",
    "proba_y = lr1.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_train_bin = list()\n",
    "for i,y in enumerate(predicted_y):\n",
    "    if y == 1:\n",
    "        lr2_train_bin.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train_bin.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train_bin = np.asarray(lr2_train_bin)\n",
    "\n",
    "lr2_train_proba = list()\n",
    "for i,y in enumerate(proba_y):\n",
    "    if y >= 0.5:\n",
    "        lr2_train_proba.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train_proba.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train_proba = np.asarray(lr2_train_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with {0,1} label\n",
    "# Train with [0,1] proba\n",
    "\n",
    "lr2_y_hat_bin = LogisticRegression(penalty='l1', random_state=42)\n",
    "lr2_y_hat_proba = LogisticRegression(penalty='l1', random_state=42)\n",
    "\n",
    "lr2_y_hat_bin.fit(lr2_train_bin, y_train)\n",
    "lr2_y_hat_proba.fit(lr2_train_proba, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_bin = lr2_y_hat_bin.predict(lr2_test_bin)\n",
    "y_test_pred_proba = lr2_y_hat_proba.predict(lr2_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8932842686292548\n",
      "0.8939282428702852\n",
      "\n",
      "0.8893017354660383\n",
      "0.8946939145407585\n"
     ]
    }
   ],
   "source": [
    "print(lr2_y_hat_bin.score(lr2_test_bin,y_test))\n",
    "print(lr2_y_hat_proba.score(lr2_test_proba,y_test))\n",
    "print()\n",
    "print(lr2_y_hat_bin.score(lr2_train_bin,y_train))\n",
    "print(lr2_y_hat_proba.score(lr2_train_proba,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.01963155]\n",
      "[1.05741623]\n"
     ]
    }
   ],
   "source": [
    "print(lr2_y_hat_bin.intercept_)\n",
    "print(lr2_y_hat_proba.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_weight(lr2_y_hat_bin, lr2_y_hat_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_weight(lr2_y_hat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if... we put scale and ReLU manually\n",
    "\n",
    "If we do not scale. Then, the negative weights would be closer to zero. The magnitude would be lesser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = lr1.predict(X_train)\n",
    "proba_y = lr1.predict_proba(X_train)[:,1]\n",
    "\n",
    "# Scale\n",
    "\n",
    "predicted_y = predicted_y * 2 - 1\n",
    "proba_y = proba_y * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_train_bin = list()\n",
    "for i,y in enumerate(predicted_y):\n",
    "    if y == 1:\n",
    "        lr2_train_bin.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train_bin.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train_bin = np.asarray(lr2_train_bin)\n",
    "\n",
    "lr2_train_proba = list()\n",
    "for i,y in enumerate(proba_y):\n",
    "    if y >= 0.5:\n",
    "        lr2_train_proba.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train_proba.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train_proba = np.asarray(lr2_train_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with {0,1} label\n",
    "# Train with [0,1] proba\n",
    "\n",
    "lr2_y_hat_bin = LogisticRegression(penalty='l1', random_state=42)\n",
    "lr2_y_hat_proba = LogisticRegression(penalty='l1', random_state=42)\n",
    "\n",
    "lr2_y_hat_bin.fit(lr2_train_bin, y_train)\n",
    "lr2_y_hat_proba.fit(lr2_train_proba, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with predict {0,1}\n",
    "\n",
    "predicted_y_test = lr1.predict(X_test)\n",
    "predicted_y_test = predicted_y_test * 2 - 1\n",
    "\n",
    "lr2_test_bin = list()\n",
    "for i,y in enumerate(predicted_y_test):\n",
    "    if y==1:\n",
    "        lr2_test_bin.append(y_test_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_test_bin.append(y_test_agreement_neg[i] * y)\n",
    "    \n",
    "lr2_test_bin = np.asarray(lr2_test_bin)\n",
    "\n",
    "\n",
    "# Test with predict [0,1]\n",
    "\n",
    "predicted_y_test_proba = lr1.predict_proba(X_test)[:,1]\n",
    "predicted_y_test_proba = predicted_y_test_proba * 2 - 1\n",
    "\n",
    "lr2_test_proba = list()\n",
    "for i,y in enumerate(predicted_y_test_proba):\n",
    "    if y>=0:\n",
    "        lr2_test_proba.append(y_test_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_test_proba.append(y_test_agreement_neg[i] * y)\n",
    "    \n",
    "lr2_test_proba = np.asarray(lr2_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9164673413063478\n",
      "0.9161913523459062\n",
      "\n",
      "0.9205219991843763\n",
      "0.9190720014499978\n"
     ]
    }
   ],
   "source": [
    "print(lr2_y_hat_bin.score(lr2_test_bin,y_test))\n",
    "print(lr2_y_hat_proba.score(lr2_test_proba,y_test))\n",
    "print()\n",
    "print(lr2_y_hat_bin.score(lr2_train_bin,y_train))\n",
    "print(lr2_y_hat_proba.score(lr2_train_proba,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_indices = np.where(np.sum(lr2_test_proba,axis=1)!=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9490515564202334\n",
      "0.9486867704280155\n"
     ]
    }
   ],
   "source": [
    "print(lr2_y_hat_bin.score(lr2_test_bin[accept_indices], y_test[accept_indices]))\n",
    "print(lr2_y_hat_proba.score(lr2_test_proba[accept_indices], y_test[accept_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19371377731153747"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "p = lr2_y_hat_proba.predict_proba(lr2_test_proba[accept_indices])[:,1]\n",
    "\n",
    "log_loss(y_test[accept_indices], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    3,    12,    13, ..., 10854, 10859, 10866], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.sum(lr2_test_bin,axis=1)==0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24342226310947562"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(lr2_test_proba,axis=1)==0)/lr2_test_proba.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2646"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(lr2_test_proba,axis=1)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.99558703,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.99558703, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2_test_proba[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2_test_bin[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9955870320224969"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y_test_proba[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y_test[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intense \t 2.702 \t 2.497 \t 1\n",
      "hooked \t 2.561 \t 2.826 \t 1\n",
      "enjoyed \t 1.778 \t 2.446 \t 1\n",
      "love \t 1.711 \t 2.500 \t 1\n",
      "pleased \t 1.643 \t 1.573 \t 1\n",
      "favorite \t 1.570 \t 2.051 \t 1\n",
      "unexpected \t 1.561 \t 2.088 \t 1\n",
      "awesome \t 1.529 \t 2.393 \t 1\n",
      "great \t 1.519 \t 2.348 \t 1\n",
      "addicted \t 1.508 \t 1.778 \t 1\n",
      "addictive \t 1.506 \t 2.211 \t 1\n",
      "fantastic \t 1.471 \t 1.759 \t 1\n",
      "excellent \t 1.441 \t 2.192 \t 1\n",
      "fascinating \t 1.414 \t 2.352 \t 1\n",
      "enjoying \t 1.404 \t 2.124 \t 1\n",
      "superb \t 1.389 \t 1.453 \t 1\n",
      "amazing \t 1.330 \t 2.018 \t 1\n",
      "wonderfully \t 1.300 \t 0.653 \t 1\n",
      "entertaining \t 1.293 \t 2.064 \t 1\n",
      "outstanding \t 1.242 \t 1.982 \t 1\n",
      "informative \t 1.227 \t 2.310 \t 1\n",
      "hilarious \t 1.112 \t 1.556 \t 1\n",
      "enjoyable \t 1.061 \t 1.747 \t 1\n",
      "perfect \t 0.947 \t 1.671 \t 1\n",
      "happy \t 0.864 \t 1.202 \t 1\n",
      "fun \t 0.813 \t 1.927 \t 1\n",
      "liked \t 0.740 \t 1.497 \t 1\n",
      "nicely \t 0.668 \t 1.807 \t 1\n",
      "surprise \t 0.639 \t 1.238 \t 1\n",
      "wow \t 0.628 \t 1.312 \t 1\n",
      "satisfying \t 0.598 \t 0.958 \t 1\n",
      "suspenseful \t 0.594 \t 1.058 \t 1\n",
      "avoid \t 0.586 \t 0.191 \t 1\n",
      "rare \t 0.543 \t 1.275 \t 1\n",
      "laughing \t 0.483 \t 0.626 \t 1\n",
      "famous \t 0.481 \t 1.803 \t 1\n",
      "classic \t 0.398 \t 1.292 \t 1\n",
      "weak \t 0.313 \t 0.321 \t 1\n",
      "favorites \t 0.288 \t 0.000 \t 1\n",
      "complicated \t 0.260 \t 0.190 \t 1\n",
      "effective \t 0.207 \t 0.515 \t 1\n",
      "loves \t 0.148 \t 0.000 \t 1\n",
      "disappointed \t 0.116 \t 0.498 \t 1\n",
      "disturbing \t 0.085 \t 0.354 \t 1\n",
      "hardly \t 0.083 \t 0.921 \t 1\n",
      "amusing \t 0.078 \t 0.876 \t 1\n",
      "slow \t 0.007 \t 0.764 \t 1\n",
      "perfectly \t 0.000 \t 0.000 \t 1\n",
      "successful \t 0.000 \t 0.770 \t 1\n",
      "dull \t 0.000 \t 0.624 \t 1\n",
      "weird \t -0.037 \t 1.161 \t 1\n",
      "predictable \t -0.059 \t 0.203 \t 1\n",
      "bad \t -0.108 \t 0.751 \t 1\n",
      "likeable \t -0.154 \t 0.000 \t 1\n",
      "disappoint \t -0.156 \t 0.168 \t 1\n",
      "crap \t -0.169 \t 0.000 \t 1\n",
      "fake \t -0.289 \t 0.443 \t 1\n",
      "annoying \t -0.333 \t 0.389 \t 1\n",
      "bizarre \t -0.349 \t 0.281 \t 1\n",
      "worse \t -0.420 \t 0.000 \t 1\n",
      "loved \t -0.446 \t -0.545 \t 1\n",
      "cheap \t -0.482 \t -0.094 \t 1\n",
      "unbelievable \t -0.589 \t 0.000 \t 1\n",
      "sadly \t -0.618 \t 0.040 \t 1\n",
      "ridiculous \t -0.711 \t 0.000 \t 1\n",
      "poorly \t -0.847 \t 0.000 \t 0\n",
      "bored \t -0.861 \t 0.264 \t 1\n",
      "lame \t -1.307 \t -0.638 \t 1\n",
      "terrible \t -2.399 \t -3.211 \t 0\n",
      "stupid \t -2.521 \t -3.498 \t 0\n",
      "horrible \t -2.524 \t -3.943 \t 0\n",
      "dumb \t -2.620 \t -3.045 \t 0\n",
      "awful \t -2.821 \t -3.613 \t 0\n",
      "boring \t -3.086 \t -4.790 \t 0\n",
      "poor \t -3.104 \t -4.062 \t 0\n",
      "worst \t -3.187 \t -4.279 \t 0\n",
      "waste \t -3.482 \t -4.104 \t 0\n",
      "disappointing \t -3.953 \t -4.025 \t 0\n"
     ]
    }
   ],
   "source": [
    "print_weight(lr2_y_hat_bin, lr2_y_hat_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becasue LR sklearn use a regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
