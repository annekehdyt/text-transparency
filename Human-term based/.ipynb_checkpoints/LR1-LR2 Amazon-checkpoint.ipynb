{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 2)\n",
      "corpus update start\n",
      "corpus update end\n",
      "\n",
      "(75, 2)\n",
      "corpus update start\n",
      "corpus update end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from dataset_load import *\n",
    "\n",
    "path = r\"..\\..\\data\\reviews_Amazon_Instant_Video_5.json.gz\"\n",
    "\n",
    "X, y = extract_review_amazon(path, 'reviewText')\n",
    "y_label = np.asarray(y)\n",
    "\n",
    "neutral_indices = np.where(y_label == 3)[0]\n",
    "y_label[y_label<3] = 0\n",
    "y_label[y_label>3] = 1\n",
    "\n",
    "X_discarded = np.delete(X,neutral_indices)\n",
    "y_discarded = np.delete(y_label, neutral_indices)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "# split\n",
    "X_train_split, X_test_split, y_train, y_test = train_test_split(X_discarded, y_discarded, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "X_train_corpus_update = update_corpus_contraction(X_train_split)\n",
    "X_test_corpus_update = update_corpus_contraction(X_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "\n",
    "# Count vectorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "cv = CountVectorizer(min_df = 100, token_pattern=token, lowercase=True, binary=True)\n",
    "X_train = cv.fit_transform(X_train_corpus_update)\n",
    "X_test = cv.transform(X_test_corpus_update)\n",
    "\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1499"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_original' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-809ffb3982f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlr1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlr1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_original\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train_original' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr1 = LogisticRegression(penalty='l1', random_state=42)\n",
    "lr1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, connotation = load_unigrams('./amazon-video-unigrams-more.txt', X_train_corpus_update, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_agreement, y_test_agreement = generate_appearance(X_train_corpus_update, X_test_corpus_update, \n",
    "                                                          word_list, connotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htcv = CountVectorizer(min_df = 100, token_pattern=token, lowercase=True, binary=True, vocabulary=word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_train = htcv.transform(X_train_corpus_update)\n",
    "ht_test = htcv.transform(X_test_corpus_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_agreement_pos = np.copy(y_train_agreement)\n",
    "y_train_agreement_neg = np.copy(y_train_agreement)\n",
    "y_test_agreement_pos = np.copy(y_test_agreement)\n",
    "y_test_agreement_neg = np.copy(y_test_agreement)\n",
    "\n",
    "y_train_agreement_pos[y_train_agreement_pos == -1] = 0\n",
    "y_train_agreement_neg[y_train_agreement_neg == 1] = 0\n",
    "y_test_agreement_pos[y_test_agreement_pos == -1] = 0\n",
    "y_test_agreement_neg[y_test_agreement_neg == 1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From actual label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_train = list()\n",
    "for i,y in enumerate(y_train):\n",
    "    if y == 1:\n",
    "        lr2_train.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train = np.asarray(lr2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(penalty='l1', random_state=42)\n",
    "lr2.fit(lr2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with predict {0,1}\n",
    "\n",
    "lr1_predict = lr1.predict(X_test)\n",
    "\n",
    "lr2_test_bin = list()\n",
    "for i,y in enumerate(lr1_predict):\n",
    "    if y==1:\n",
    "        lr2_test_bin.append(y_test_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_test_bin.append(y_test_agreement_neg[i] * y)\n",
    "    \n",
    "lr2_test_bin = np.asarray(lr2_test_bin)\n",
    "\n",
    "print(lr2.score(lr2_test_bin, y_test_original))\n",
    "\n",
    "# Test with predict [0,1]\n",
    "\n",
    "lr1_predict = lr1.predict_proba(X_test)[:,1]\n",
    "\n",
    "lr2_test_proba = list()\n",
    "for i,y in enumerate(lr1_predict):\n",
    "    if y>=0.5:\n",
    "        lr2_test_proba.append(y_test_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_test_proba.append(y_test_agreement_neg[i] * y)\n",
    "    \n",
    "lr2_test_proba = np.asarray(lr2_test_proba)\n",
    "\n",
    "print(lr2.score(lr2_test_proba, y_test_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = lr2.coef_.flatten()\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weight(clf1, clf2=None):\n",
    "    w = clf1.coef_.flatten()\n",
    "    indices = np.argsort(w)[::-1]\n",
    "    con = list(connotation.values())\n",
    "\n",
    "    if clf2 is not None:\n",
    "        w2 = clf2.coef_.flatten()\n",
    "        for i in indices:\n",
    "            print('%s \\t %.3f \\t %.3f \\t %d' %(word_list[i], w[i], w2[i], con[i]))\n",
    "    else:  \n",
    "        for i in indices:\n",
    "            print('%s \\t %.3f \\t %d' %(word_list[i], w[i],con[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = lr1.predict(X_train)\n",
    "proba_y = lr1.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_train_bin = list()\n",
    "for i,y in enumerate(predicted_y):\n",
    "    if y == 1:\n",
    "        lr2_train_bin.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train_bin.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train_bin = np.asarray(lr2_train_bin)\n",
    "\n",
    "lr2_train_proba = list()\n",
    "for i,y in enumerate(proba_y):\n",
    "    if y >= 0.5:\n",
    "        lr2_train_proba.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train_proba.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train_proba = np.asarray(lr2_train_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with {0,1} label\n",
    "# Train with [0,1] proba\n",
    "\n",
    "lr2_y_hat_bin = LogisticRegression(penalty='l1', random_state=42)\n",
    "lr2_y_hat_proba = LogisticRegression(penalty='l1', random_state=42)\n",
    "\n",
    "lr2_y_hat_bin.fit(lr2_train_bin, y_train)\n",
    "lr2_y_hat_proba.fit(lr2_train_proba, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_bin = lr2_y_hat_bin.predict(lr2_test_bin)\n",
    "y_test_pred_proba = lr2_y_hat_proba.predict(lr2_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr2_y_hat_bin.score(lr2_test_bin,y_test_original))\n",
    "print(lr2_y_hat_proba.score(lr2_test_proba,y_test_original))\n",
    "print()\n",
    "print(lr2_y_hat_bin.score(lr2_train_bin,y_train_original))\n",
    "print(lr2_y_hat_proba.score(lr2_train_proba,y_train_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr2_y_hat_bin.intercept_)\n",
    "print(lr2_y_hat_proba.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_weight(lr2_y_hat_bin, lr2_y_hat_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_weight(lr2_y_hat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if... we put scale and ReLU manually\n",
    "\n",
    "If we do not scale. Then, the negative weights would be closer to zero. The magnitude would be lesser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = lr1.predict(X_train)\n",
    "proba_y = lr1.predict_proba(X_train)[:,1]\n",
    "\n",
    "# Scale\n",
    "\n",
    "predicted_y = predicted_y * 2 - 1\n",
    "proba_y = proba_y * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_train_bin = list()\n",
    "for i,y in enumerate(predicted_y):\n",
    "    if y == 1:\n",
    "        lr2_train_bin.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train_bin.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train_bin = np.asarray(lr2_train_bin)\n",
    "\n",
    "lr2_train_proba = list()\n",
    "for i,y in enumerate(proba_y):\n",
    "    if y >= 0.5:\n",
    "        lr2_train_proba.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train_proba.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train_proba = np.asarray(lr2_train_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with {0,1} label\n",
    "# Train with [0,1] proba\n",
    "\n",
    "lr2_y_hat_bin = LogisticRegression(penalty='l1', random_state=42)\n",
    "lr2_y_hat_proba = LogisticRegression(penalty='l1', random_state=42)\n",
    "\n",
    "lr2_y_hat_bin.fit(lr2_train_bin, y_train_original)\n",
    "lr2_y_hat_proba.fit(lr2_train_proba, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with predict {0,1}\n",
    "\n",
    "predicted_y_test = lr1.predict(X_test)\n",
    "predicted_y_test = predicted_y_test * 2 - 1\n",
    "\n",
    "lr2_test_bin = list()\n",
    "for i,y in enumerate(predicted_y_test):\n",
    "    if y==1:\n",
    "        lr2_test_bin.append(y_test_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_test_bin.append(y_test_agreement_neg[i] * y)\n",
    "    \n",
    "lr2_test_bin = np.asarray(lr2_test_bin)\n",
    "\n",
    "\n",
    "# Test with predict [0,1]\n",
    "\n",
    "predicted_y_test_proba = lr1.predict_proba(X_test)[:,1]\n",
    "predicted_y_test_proba = predicted_y_test_proba * 2 - 1\n",
    "\n",
    "lr2_test_proba = list()\n",
    "for i,y in enumerate(predicted_y_test_proba):\n",
    "    if y>=0:\n",
    "        lr2_test_proba.append(y_test_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_test_proba.append(y_test_agreement_neg[i] * y)\n",
    "    \n",
    "lr2_test_proba = np.asarray(lr2_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr2_y_hat_bin.score(lr2_test_bin,y_test_original))\n",
    "print(lr2_y_hat_proba.score(lr2_test_proba,y_test_original))\n",
    "print()\n",
    "print(lr2_y_hat_bin.score(lr2_train_bin,y_train_original))\n",
    "print(lr2_y_hat_proba.score(lr2_train_proba,y_train_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_indices = np.where(np.sum(lr2_test_proba,axis=1)!=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr2_y_hat_bin.score(lr2_test_bin[accept_indices], y_test_original[accept_indices]))\n",
    "print(lr2_y_hat_proba.score(lr2_test_proba[accept_indices], y_test_original[accept_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.sum(lr2_test_bin,axis=1)==0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.sum(lr2_test_proba,axis=1)==0)/lr2_test_proba.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.sum(lr2_test_proba,axis=1)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_test_proba[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_test_bin[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test_proba[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_weight(lr2_y_hat_bin, lr2_y_hat_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# becasue LR sklearn use a regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
