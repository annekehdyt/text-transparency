{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from dataset_load import *\n",
    "\n",
    "X_train_original = open_pickle('../../data/imdb/imdb_original_preprocessed_xtrain.pickle')\n",
    "X_test_original = open_pickle('../../data/imdb/imdb_original_preprocessed_xtest.pickle')\n",
    "y_train_original = open_pickle('../../data/imdb/imdb_original_preprocessed_ytrain.pickle')\n",
    "y_test_original = open_pickle('../../data/imdb/imdb_original_preprocessed_ytest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "\n",
    "# Count vectorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "cv = CountVectorizer(min_df = 100, token_pattern=token, lowercase=True, binary=True)\n",
    "X_train = cv.fit_transform(X_train_original)\n",
    "X_test = cv.transform(X_test_original)\n",
    "\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr1 = LogisticRegression(penalty='l1', random_state=42)\n",
    "lr1.fit(X_train, y_train_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, connotation = load_unigrams('./imdb-unigrams.txt', X_train_original, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_agreement, y_test_agreement = generate_appearance(X_train_original, X_test_original, \n",
    "                                                          word_list, connotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "htcv = CountVectorizer(min_df = 100, token_pattern=token, lowercase=True, binary=True, vocabulary=word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_train = htcv.transform(X_train_original)\n",
    "ht_test = htcv.transform(X_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_agreement_pos = np.copy(y_train_agreement)\n",
    "y_train_agreement_neg = np.copy(y_train_agreement)\n",
    "y_test_agreement_pos = np.copy(y_test_agreement)\n",
    "y_test_agreement_neg = np.copy(y_test_agreement)\n",
    "\n",
    "y_train_agreement_pos[y_train_agreement_pos == -1] = 0\n",
    "y_train_agreement_neg[y_train_agreement_neg == 1] = 0\n",
    "y_test_agreement_pos[y_test_agreement_pos == -1] = 0\n",
    "y_test_agreement_neg[y_test_agreement_neg == 1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From actual label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_train = list()\n",
    "for i,y in enumerate(y_train_original):\n",
    "    if y == 1:\n",
    "        lr2_train.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train = np.asarray(lr2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LogisticRegression(penalty='l1', random_state=42)\n",
    "lr2.fit(lr2_train, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8418"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with predict {0,1}\n",
    "\n",
    "lr1_predict = lr1.predict(X_test)\n",
    "\n",
    "lr2_test_bin = list()\n",
    "for i,y in enumerate(lr1_predict):\n",
    "    if y==1:\n",
    "        lr2_test_bin.append(y_test_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_test_bin.append(y_test_agreement_neg[i] * y)\n",
    "    \n",
    "lr2_test_bin = np.asarray(lr2_test_bin)\n",
    "\n",
    "lr2.score(lr2_test_bin, y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8418"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with predict [0,1]\n",
    "\n",
    "lr1_predict = lr1.predict_proba(X_test)[:,1]\n",
    "\n",
    "lr2_test_proba = list()\n",
    "for i,y in enumerate(lr1_predict):\n",
    "    if y>=0.5:\n",
    "        lr2_test_proba.append(y_test_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_test_proba.append(y_test_agreement_neg[i] * y)\n",
    "    \n",
    "lr2_test_proba = np.asarray(lr2_test_proba)\n",
    "\n",
    "lr2.score(lr2_test_proba, y_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 3.60950486,\n",
       "       2.00050248, 5.57702426, 5.42721375, 4.47975806, 5.48895803,\n",
       "       6.49374532, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 7.12266294, 0.        , 7.99754779, 0.        ,\n",
       "       0.        , 4.29804201, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 5.78204372, 6.57889363,\n",
       "       7.16281132, 0.        , 5.52208984, 5.79987759, 6.5694834 ,\n",
       "       0.        , 8.08820867, 0.        , 0.        , 5.73227543,\n",
       "       8.40122709, 0.        , 5.4907169 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 6.49429474, 0.        ,\n",
       "       0.        , 0.        , 5.54924019, 0.        , 0.        ,\n",
       "       6.74646851, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 5.70928471, 5.21552235, 0.        , 4.56295182,\n",
       "       0.        , 0.        , 5.29493477, 0.        , 5.63213107,\n",
       "       5.92644426, 5.25289555, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 6.9408705 ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = lr2.coef_.flatten()\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weight(clf1, clf2=None):\n",
    "    w = clf1.coef_.flatten()\n",
    "    indices = np.argsort(w)[::-1]\n",
    "    con = list(connotation.values())\n",
    "\n",
    "    if clf2 is not None:\n",
    "        w2 = clf2.coef_.flatten()\n",
    "        for i in indices:\n",
    "            print('%s \\t %.3f \\t %.3f \\t %d' %(word_list[i], w[i], w2[i], con[i]))\n",
    "    else:  \n",
    "        for i in indices:\n",
    "            print('%s \\t %.3f \\t %d' %(word_list[i], w[i],con[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = lr1.predict(X_train)\n",
    "proba_y = lr1.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_train_bin = list()\n",
    "for i,y in enumerate(predicted_y):\n",
    "    if y == 1:\n",
    "        lr2_train_bin.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train_bin.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train_bin = np.asarray(lr2_train_bin)\n",
    "\n",
    "lr2_train_proba = list()\n",
    "for i,y in enumerate(proba_y):\n",
    "    if y >= 0.5:\n",
    "        lr2_train_proba.append(y_train_agreement_pos[i] * y)\n",
    "    else:\n",
    "        lr2_train_proba.append(y_train_agreement_neg[i] * y)\n",
    "        \n",
    "lr2_train_proba = np.asarray(lr2_train_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with {0,1} label\n",
    "# Train with [0,1] proba\n",
    "\n",
    "lr2_y_hat_bin = LogisticRegression(penalty='l1', random_state=42)\n",
    "lr2_y_hat_proba = LogisticRegression(penalty='l1', random_state=42)\n",
    "\n",
    "lr2_y_hat_bin.fit(lr2_train_bin, y_train_original)\n",
    "lr2_y_hat_proba.fit(lr2_train_proba, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_bin = lr2_y_hat_bin.predict(lr2_test_bin)\n",
    "y_test_pred_proba = lr2_y_hat_proba.predict(lr2_test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84176\n",
      "0.84176\n",
      "\n",
      "0.89284\n",
      "0.89316\n"
     ]
    }
   ],
   "source": [
    "print(lr2_y_hat_bin.score(lr2_test_bin,y_test_original))\n",
    "print(lr2_y_hat_proba.score(lr2_test_proba,y_test_original))\n",
    "print()\n",
    "print(lr2_y_hat_bin.score(lr2_train_bin,y_train_original))\n",
    "print(lr2_y_hat_proba.score(lr2_train_proba,y_train_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.51901016]\n",
      "[-1.6046603]\n"
     ]
    }
   ],
   "source": [
    "print(lr2_y_hat_bin.intercept_)\n",
    "print(lr2_y_hat_proba.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/10 \t 4.023 \t 4.283 \t 1\n",
      "7/10 \t 3.851 \t 4.087 \t 1\n",
      "noir \t 3.268 \t 3.808 \t 1\n",
      "brilliant \t 3.145 \t 3.782 \t 1\n",
      "superb \t 3.139 \t 3.636 \t 1\n",
      "10/10 \t 2.977 \t 3.299 \t 1\n",
      "9/10 \t 2.778 \t 3.091 \t 1\n",
      "incredible \t 2.743 \t 3.259 \t 1\n",
      "fascinating \t 2.638 \t 3.316 \t 1\n",
      "great \t 2.589 \t 3.280 \t 1\n",
      "refreshing \t 2.585 \t 2.743 \t 1\n",
      "excellent \t 2.563 \t 3.050 \t 1\n",
      "beautiful \t 2.548 \t 3.241 \t 1\n",
      "amazing \t 2.519 \t 3.088 \t 1\n",
      "enjoyed \t 2.484 \t 3.005 \t 1\n",
      "wonderful \t 2.457 \t 3.034 \t 1\n",
      "best \t 2.452 \t 3.126 \t 1\n",
      "gem \t 2.418 \t 3.128 \t 1\n",
      "favorite \t 2.369 \t 2.929 \t 1\n",
      "surprisingly \t 2.351 \t 2.946 \t 1\n",
      "subtle \t 2.319 \t 2.946 \t 1\n",
      "perfect \t 2.299 \t 2.933 \t 1\n",
      "rare \t 2.280 \t 2.898 \t 1\n",
      "fun \t 2.273 \t 3.036 \t 1\n",
      "fantastic \t 2.210 \t 2.649 \t 1\n",
      "solid \t 2.123 \t 2.726 \t 1\n",
      "loved \t 2.018 \t 2.643 \t 1\n",
      "recommended \t 1.994 \t 2.562 \t 1\n",
      "enjoyable \t 1.919 \t 2.602 \t 1\n",
      "5/10 \t 0.924 \t 1.218 \t 1\n",
      "beautifully \t 0.511 \t 0.070 \t 1\n",
      "funniest \t 0.365 \t 0.223 \t 1\n",
      "fails \t 0.000 \t 0.000 \t 0\n",
      "avoid \t 0.000 \t 0.000 \t 0\n",
      "2/10 \t 0.000 \t 0.000 \t 0\n",
      "3/10 \t 0.000 \t 0.000 \t 0\n",
      "4/10 \t 0.000 \t 0.000 \t 0\n",
      "6/10 \t 0.000 \t 0.000 \t 1\n",
      "annoying \t 0.000 \t 0.000 \t 0\n",
      "dreadful \t 0.000 \t 0.576 \t 0\n",
      "dull \t 0.000 \t 0.000 \t 0\n",
      "disappointment \t 0.000 \t 0.000 \t 0\n",
      "disappointing \t 0.000 \t 0.000 \t 0\n",
      "disappointed \t 0.000 \t 0.000 \t 0\n",
      "cheap \t 0.000 \t 0.000 \t 0\n",
      "boring \t 0.000 \t -0.110 \t 0\n",
      "awful \t 0.000 \t 0.000 \t 0\n",
      "bland \t 0.000 \t 0.000 \t 0\n",
      "bad \t 0.000 \t -0.901 \t 0\n",
      "badly \t 0.000 \t 0.000 \t 0\n",
      "worst \t 0.000 \t -0.442 \t 0\n",
      "horrible \t 0.000 \t -1.114 \t 0\n",
      "forgettable \t 0.000 \t 0.000 \t 0\n",
      "poorly \t 0.000 \t 0.000 \t 0\n",
      "wonderfully \t 0.000 \t 0.000 \t 1\n",
      "weak \t 0.000 \t -0.562 \t 0\n",
      "wasted \t 0.000 \t 0.000 \t 0\n",
      "waste \t 0.000 \t 0.000 \t 0\n",
      "unfunny \t 0.000 \t 0.000 \t 0\n",
      "unfortunately \t 0.000 \t -0.832 \t 0\n",
      "terrible \t 0.000 \t 0.000 \t 0\n",
      "tedious \t 0.000 \t 0.000 \t 0\n",
      "stupid \t 0.000 \t 0.000 \t 0\n",
      "sadly \t 0.000 \t 0.000 \t 0\n",
      "ridiculous \t 0.000 \t 0.000 \t 0\n",
      "redeeming \t 0.000 \t 0.000 \t 0\n",
      "predictable \t 0.000 \t 0.000 \t 0\n",
      "poor \t 0.000 \t 0.000 \t 0\n",
      "funny \t 0.000 \t -0.859 \t 0\n",
      "pointless \t 0.000 \t 0.000 \t 0\n",
      "pathetic \t 0.000 \t 0.000 \t 0\n",
      "obnoxious \t 0.000 \t 0.000 \t 0\n",
      "mst3k \t 0.000 \t 0.000 \t 0\n",
      "mess \t 0.000 \t 0.000 \t 0\n",
      "mediocre \t 0.000 \t 0.000 \t 0\n",
      "lousy \t 0.000 \t 0.000 \t 0\n",
      "laughable \t 0.000 \t 0.000 \t 0\n",
      "lame \t 0.000 \t 0.000 \t 0\n",
      "lacks \t 0.000 \t 0.000 \t 0\n",
      "insult \t 0.000 \t 0.000 \t 0\n",
      "worse \t 0.000 \t 0.000 \t 0\n",
      "1/10 \t 0.000 \t 0.000 \t 0\n",
      "perfectly \t -0.002 \t -0.070 \t 1\n"
     ]
    }
   ],
   "source": [
    "print_weight(lr2_y_hat_bin, lr2_y_hat_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/10 \t 4.283 \t 1\n",
      "7/10 \t 4.087 \t 1\n",
      "noir \t 3.808 \t 1\n",
      "brilliant \t 3.782 \t 1\n",
      "superb \t 3.636 \t 1\n",
      "fascinating \t 3.316 \t 1\n",
      "10/10 \t 3.299 \t 1\n",
      "great \t 3.280 \t 1\n",
      "incredible \t 3.259 \t 1\n",
      "beautiful \t 3.241 \t 1\n",
      "gem \t 3.128 \t 1\n",
      "best \t 3.126 \t 1\n",
      "9/10 \t 3.091 \t 1\n",
      "amazing \t 3.088 \t 1\n",
      "excellent \t 3.050 \t 1\n",
      "fun \t 3.036 \t 1\n",
      "wonderful \t 3.034 \t 1\n",
      "enjoyed \t 3.005 \t 1\n",
      "subtle \t 2.946 \t 1\n",
      "surprisingly \t 2.946 \t 1\n",
      "perfect \t 2.933 \t 1\n",
      "favorite \t 2.929 \t 1\n",
      "rare \t 2.898 \t 1\n",
      "refreshing \t 2.743 \t 1\n",
      "solid \t 2.726 \t 1\n",
      "fantastic \t 2.649 \t 1\n",
      "loved \t 2.643 \t 1\n",
      "enjoyable \t 2.602 \t 1\n",
      "recommended \t 2.562 \t 1\n",
      "5/10 \t 1.218 \t 1\n",
      "dreadful \t 0.576 \t 0\n",
      "funniest \t 0.223 \t 1\n",
      "beautifully \t 0.070 \t 1\n",
      "dull \t 0.000 \t 0\n",
      "disappointment \t 0.000 \t 0\n",
      "disappointing \t 0.000 \t 0\n",
      "disappointed \t 0.000 \t 0\n",
      "fails \t 0.000 \t 0\n",
      "cheap \t 0.000 \t 0\n",
      "badly \t 0.000 \t 0\n",
      "awful \t 0.000 \t 0\n",
      "forgettable \t 0.000 \t 0\n",
      "avoid \t 0.000 \t 0\n",
      "annoying \t 0.000 \t 0\n",
      "bland \t 0.000 \t 0\n",
      "1/10 \t 0.000 \t 0\n",
      "4/10 \t 0.000 \t 0\n",
      "worse \t 0.000 \t 0\n",
      "wonderfully \t 0.000 \t 1\n",
      "2/10 \t 0.000 \t 0\n",
      "wasted \t 0.000 \t 0\n",
      "waste \t 0.000 \t 0\n",
      "unfunny \t 0.000 \t 0\n",
      "3/10 \t 0.000 \t 0\n",
      "terrible \t 0.000 \t 0\n",
      "tedious \t 0.000 \t 0\n",
      "stupid \t 0.000 \t 0\n",
      "sadly \t 0.000 \t 0\n",
      "ridiculous \t 0.000 \t 0\n",
      "redeeming \t 0.000 \t 0\n",
      "predictable \t 0.000 \t 0\n",
      "poorly \t 0.000 \t 0\n",
      "poor \t 0.000 \t 0\n",
      "pointless \t 0.000 \t 0\n",
      "pathetic \t 0.000 \t 0\n",
      "obnoxious \t 0.000 \t 0\n",
      "mst3k \t 0.000 \t 0\n",
      "mess \t 0.000 \t 0\n",
      "mediocre \t 0.000 \t 0\n",
      "lousy \t 0.000 \t 0\n",
      "laughable \t 0.000 \t 0\n",
      "lame \t 0.000 \t 0\n",
      "6/10 \t 0.000 \t 1\n",
      "insult \t 0.000 \t 0\n",
      "lacks \t 0.000 \t 0\n",
      "perfectly \t -0.070 \t 1\n",
      "boring \t -0.110 \t 0\n",
      "worst \t -0.442 \t 0\n",
      "weak \t -0.562 \t 0\n",
      "unfortunately \t -0.832 \t 0\n",
      "funny \t -0.859 \t 0\n",
      "bad \t -0.901 \t 0\n",
      "horrible \t -1.114 \t 0\n"
     ]
    }
   ],
   "source": [
    "print_weight(lr2_y_hat_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if... we put scale and ReLU manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
