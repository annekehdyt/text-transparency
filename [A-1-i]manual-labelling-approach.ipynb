{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_pickle\n",
    "\n",
    "def open_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset of [relevant,-relevant]\n",
    "\n",
    "X_train_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_xtrain.pickle')\n",
    "X_test_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_xtest.pickle')\n",
    "y_train_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_ytrain.pickle')\n",
    "y_test_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_ytest.pickle')\n",
    "\n",
    "#Load dataset of [+/-]\n",
    "\n",
    "X_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtrain.pickle')\n",
    "X_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtest.pickle')\n",
    "y_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytrain.pickle')\n",
    "y_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26266\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "cv = CountVectorizer(lowercase=True, min_df=5, binary=True, token_pattern=token)\n",
    "\n",
    "X_tr_baseline = cv.fit_transform(X_train_original)\n",
    "X_te_baseline = cv.transform(X_test_original)\n",
    "\n",
    "print(len(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 26266)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr_baseline.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90968\n",
      "0.8794\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, C=0.01)\n",
    "\n",
    "clf.fit(X_tr_baseline, y_train_original)\n",
    "\n",
    "\n",
    "print(clf.score(X_tr_baseline, y_train_original))\n",
    "print(clf.score(X_te_baseline, y_test_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer on rel,unrel dataset\n",
    "# Question : Why rel/unrel? Because it trained as the first step? \n",
    "# Any advantages on more vocabulary?\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "tf_vectorizer = CountVectorizer(lowercase=True, max_df=1.0, min_df=5, binary=True, token_pattern=token)\n",
    "tf_vectorizer.set_params(ngram_range=(1,1))\n",
    "\n",
    "X_train_sentence_bow = tf_vectorizer.fit_transform(X_train_sentence)\n",
    "X_test_sentence_bow = tf_vectorizer.transform(X_test_sentence)\n",
    "\n",
    "X_train_original_bow = tf_vectorizer.transform(X_train_original)\n",
    "X_test_original_bow = tf_vectorizer.transform(X_test_original)\n",
    "\n",
    "\n",
    "words = tf_vectorizer.get_feature_names()\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8416\n",
      "0.83664\n"
     ]
    }
   ],
   "source": [
    "# Again baseline\n",
    "\n",
    "clf = LogisticRegression(random_state=42, C=0.01)\n",
    "\n",
    "clf.fit(X_train_original_bow, y_train_original)\n",
    "\n",
    "print(clf.score(X_train_original_bow, y_train_original))\n",
    "print(clf.score(X_test_original_bow, y_test_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1333,)\n",
      "(667,)\n",
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_sentence.shape)\n",
    "print(y_test_sentence.shape)\n",
    "print(y_train_original.shape)\n",
    "print(y_test_original.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train to [rel,unrel] classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "C=0.01\n",
      "--------------\n",
      "Accuracy\n",
      "Train:\t0.73743 \n",
      "Test:\t0.69265 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.63      0.69       363\n",
      "        1.0       0.63      0.77      0.69       304\n",
      "\n",
      "avg / total       0.70      0.69      0.69       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Okay... Using the function makes me more overwhelmed. Let's do it manually.\n",
    "\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "C = 0.01\n",
    "\n",
    "clf_A = LogisticRegression(random_state=random_state, C=C)\n",
    "clf_A.fit(X_train_sentence_bow, y_train_sentence)\n",
    "\n",
    "y_predict = clf_A.predict(X_test_sentence_bow)\n",
    "\n",
    "print('--------------')\n",
    "print('C=%.2f' %(C))\n",
    "print('--------------')\n",
    "print('Accuracy')\n",
    "print('Train:\\t%.5f ' %(clf_A.score(X_train_sentence_bow, y_train_sentence)))\n",
    "print('Test:\\t%.5f ' %(clf_A.score(X_test_sentence_bow, y_test_sentence)))\n",
    "    \n",
    "print(classification_report(y_test_sentence,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train [+,-] classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using whole corpus\n",
    "\n",
    "clf_1 = LogisticRegression(random_state=random_state, C=C)\n",
    "clf_1.fit(X_train_original_bow, y_train_original)\n",
    "\n",
    "# using the [+/-] sentence\n",
    "# clf_2 = LogisticRegression(random_state=random_state, C=C)\n",
    "# clf_2.fit(X_train_sentence_bow, y_train_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the idea ia a very short film with a lot of information.',\n",
       " 'interesting, entertaining and leaves the viewer wanting more.',\n",
       " 'the producer has produced a short film of excellent quality that cannot be compared to any other short film that i have seen.',\n",
       " 'i have rated this film at the highest possible rating.',\n",
       " 'i also recommend that it is shown to office manager and business person in any establishment.',\n",
       " 'what comes out of it is the fact that person with idea are never listened to, their voice is never heard.',\n",
       " 'it is a lesson to be learned by any office that wants to go forward.',\n",
       " \"i hope that the produced will produce a second part to this 'idea'.\",\n",
       " 'i look forward to viewing the sequence.',\n",
       " 'once again congrat to halaqah medium in producing a film of excellence and quality with a lesson in mind.']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(X_train_original[1]).raw_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"when i was a kid we always used to be babysat, and we always used to rent a film or see a film at the cinema. this is one of the film we watched. this is one of the stupidest film i have ever seen, i think it might even be a walt disney picture film! a martian is dropped on earth, turns into a human, befriends a human, and is trying everything he can to get back home. but he is distracted by the wonder of the earth. the only good comment i can give is the choice of actor, back to the future's christopher lloyd as the martian, uncle martin, dumb and dumber's jeff daniel as tim o'hara, elizabeth hurley as brace channing and daryl hannah as lizzie. but apart from that it is complete crap. poor!\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_original[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when i was a kid we always used to be babysat, and we always used to rent a film or see a film at the cinema.',\n",
       " 'this is one of the film we watched.',\n",
       " 'this is one of the stupidest film i have ever seen, i think it might even be a walt disney picture film!',\n",
       " 'a martian is dropped on earth, turns into a human, befriends a human, and is trying everything he can to get back home.',\n",
       " 'but he is distracted by the wonder of the earth.',\n",
       " \"the only good comment i can give is the choice of actor, back to the future's christopher lloyd as the martian, uncle martin, dumb and dumber's jeff daniel as tim o'hara, elizabeth hurley as brace channing and daryl hannah as lizzie.\",\n",
       " 'but apart from that it is complete crap.',\n",
       " 'poor!']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(X_train_original[5]).raw_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf_vectorizer.transform(TextBlob(X_train_original[5]).raw_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 this is one of the film we watched. \t0.650\n",
      "2 this is one of the stupidest film i have ever seen, i think it might even be a walt disney picture film! \t0.732\n",
      "5 the only good comment i can give is the choice of actor, back to the future's christopher lloyd as the martian, uncle martin, dumb and dumber's jeff daniel as tim o'hara, elizabeth hurley as brace channing and daryl hannah as lizzie. \t0.512\n",
      "6 but apart from that it is complete crap. \t0.608\n",
      "7 poor! \t0.502\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(clf_A.predict_proba(test_set)[:,1]):\n",
    "    if j>0.5:\n",
    "        print(i,TextBlob(X_train_original[5]).raw_sentences[i],\"\\t{:.3f}\".format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array(x).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 this is one of the film we watched. [0.43243437 0.56756563]\n",
      "1 this is one of the stupidest film i have ever seen, i think it might even be a walt disney picture film! [0.42348131 0.57651869]\n",
      "2 the only good comment i can give is the choice of actor, back to the future's christopher lloyd as the martian, uncle martin, dumb and dumber's jeff daniel as tim o'hara, elizabeth hurley as brace channing and daryl hannah as lizzie. [0.41162858 0.58837142]\n",
      "3 but apart from that it is complete crap. [0.51941371 0.48058629]\n",
      "4 poor! [0.63365011 0.36634989]\n"
     ]
    }
   ],
   "source": [
    "x = np.where(clf_A.predict_proba(test_set)[:,1]>0.5)\n",
    "\n",
    "test = test_set[x]\n",
    "\n",
    "for i,j in enumerate(clf_1.predict_proba(test)):\n",
    "    print(i,TextBlob(X_train_original[5]).raw_sentences[np.array(x).flatten()[i]],j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['the idea ia a very short film with a lot of information.', 'interesting, entertaining and leaves the viewer wanting more.', 'the producer has produced a short film of excellent quality that cannot be compared to any other short film that i have seen.', 'i have rated this film at the highest possible rating.', 'i also recommend that it is shown to office manager and business person in any establishment.', 'what comes out of it is the fact that person with idea are never listened to, their voice is never heard.', 'it is a lesson to be learned by any office that wants to go forward.', \"i hope that the produced will produce a second part to this 'idea'.\", 'i look forward to viewing the sequence.', 'once again congrat to halaqah medium in producing a film of excellence and quality with a lesson in mind.']\n",
      "\n",
      "['for me, this movie just seemed to fall on its face.', 'the main problem for me was the casting of glover as a serial killer.', 'i do not know whether this grows out of type-casting or simply his demeanor, but i doubt glover could ever portray a convincing villain.', 'he is a good guy, and that is always obvious in his performance.', 'other than that the film is your run of the mill serial killer story.', 'nothing very innovative .']\n",
      "\n",
      "['was this based on a comic-book?', 'a video-game?', 'a drawing by a 3 year-old?', 'there is nothing in this movie to be taken seriously at all; not the character, not the dialog, not the plot, not the action.', 'nothing.', \"we have high-tech international terrorists/criminal who bicker like pre-school kid, stallone's man-of-steel-type resilience toward ice-cold weather, dialog so dumb that it is sometimes almost hilarious, and so on.\", 'even the codename that the bad guy use is dumb (\"tango-tango\").', 'a film that entertains through some suspense, good action-sequence, and a nice snowy mountainous setting.', 'oh, yes: and the unintentional humour.the film opens with some truly bad and unconvincing gay banter between our go-lucky and happy character who are obviously having a \"swell\" time.', 'then comes a sweat-inducing failed-rescue part, which should make anyone with fear-of-heights problem want to pull their hair out.', 'and then we have some more bad dialog, and after that some more great action.', 'this is the rhythm of the film in a nutshell.', \"stallone's melodramatic exchange with turner, when they meet after a long time, is so soapy, so clichÃ©d, so fake, and so bad that it should force a chuckle out of any self-respecting viewer.\", 'soon after this display of awful dialog-writing, we are witness to a spectacular and excellently shot hijack of an airplane.', 'the entire action is one big absurdity, but it is mindless fun at its best.', 'although the rest of the action is exciting and fun, the airplane scene are truly the highlight of the film.', 'after the landing, our master-criminal seek for a guide and end up with stallone and rooker.', 'they send stallone to fetch the first case of money, but somehow they do everything to make it as difficult as possible for him to reach it; they take most of his clothe off (so he can freeze) and they will not give him the equipment he needs (so he can fall off).', 'do these gangster want their money fetched or not???', 'very silly.', 'apparently they do not trust stallone, but surely they know that they can always black-mail him by using rooker as a hostage.', \"nevertheless, our gangster make stallone's climb difficult, if for no logical reason then to at least show us how truly evil they are - lest there be any doubt.\", 'and for those who might still doubt how evil the bad guy are, they overact, ag, and snicker in a truly evil manner.', 'everyone convinced?', 'good.', 'you would better be.', 'otherwise the writer will throw in a mass execution of twenty school child, just to make sure that the evilness of the bad guy is crystal-clear to everyone.the old guy who flies the chopper... how the hell did he fall for the trap?', \"firstly, he must have been warned by the mtv airhead about the criminal, and secondly, he must have heard stallone's and rooker's voice on the walkie-talky.\", 'a whole bunch of idiotic verbal exchange take place, with lithgow having the questionable honour of getting most of the silly line.', '\"get off my back!\"', 'lithgow: \"i have not even started climbing on your back.\"', 'or, lithgow to stallone: \"we had a deal, but now we only have each other!\"', \"and as for lithgow's gang of murderer: these guy never seem to want to kill immediately.\", 'they are very creative about it; they philosophize, pretend that they are playing football with your body, and so on.', 'stallone co-wrote this thing.', 'i have no idea what drug he was on when he did it.', 'i would hate to think the script is this bad because of a low i.q.']\n",
      "\n",
      "['caution: may contain spoiler...i have seen this movie 3 time and i have liked it every time.', 'upon seeing it again, i am always reminded of how good it is.', \"an hbo tv movie- very well done like most of their movie are- this would've gotten oscar for it is performance had it been released for general distribution instead of made for tv.as i am sure anyone knows from reading other review here, this is the story of serial murderer, andrei chikatilo.\", 'he murdered 56 person over 8 year in the former soviet union.', '(3 victim were buried and could not be found so he was only convicted of 52 out of 53 of his murder.)', 'the story actually focuses more on the forensic analyst, victor burakov played to perfection by stephen rea.', 'a man that becomes tortured and obsessed with finding this killer despite the additional obstacle placed by party hack, his part is essential to be sure.', 'there is a very touching scene towards the end of the movie that mentions how in america, investigator are routinely taken off serial killer case after 18 month whether they want to or not due to the mental strain and frustration.', 'according to this acct, burakov worked for over 5 year before getting his first eak from it.', 'he followed the case to its conclusion, 3 year later.', \"in this scene, his superior, general fetisov, played by donald sutherland, actually tells him he admires his dedication and apologize for not knowing he should have given him a eak sooner.rea's performance is so well done, he does not overact, chew up the scenery or do anything that distracts from his portrayal of a man who is hell bent on finding his killer.\", 'he is a man with passion, but does not show it in the same manner as is so usually portrayed in detective movie.', 'he only occasionally gives outburst after quietly putting up with more than most could stand under such circumstance.', 'rea does so much with his face, his eye, he does not need to overact.', 'he just *is* - his character, so frustrated after so long, at one point, driven to frustration, he actually says he had rather find 3 at one time than none in a year.', 'of course what he means is not that he wants more person to die, he just wants some clue to catch this man.', 'rea makes us feel for this man.', 'he makes us understand but a glimpse of what it is to live with such horror and futility.a mutant to be sure, chikatilo\\'s childhood was one which produces such \"monster.\"', 'the character of chikatilo is very well done by jeffrey demunn.', 'he somehow (impossible though it may seem) elicits some modicum of sympathy for himself.', 'perhaps he is the worst of us gone terribly wrong?', 'either way, his performance is very well done.donald sutherland as colonel fetisov (later promoted to general) also does a great job.', 'he starts out seeming to be a cynical worldly official that does not seem much more interested in helping the investigation than anyone else blocking burakov.', 'but he eventually becomes more than just an assistant, he actually actively participates in helping burakov.', 'there is also a very nice turn by max von sydow as the psychiatrist ought in to help profile and figure out what kind of deviant they are looking for.although this movie deals with a morbid, grotesque and violent story, it really is more about what it takes to catch a killer than the killer himself.', 'all around a very well done movie with fine performance and a great screenplay.', 'the screenplay manages to do what the best of this type of movie does: give factual event and place them meaningfully inside a dramatic framework that makes you feel like you know the person *behind* the facts.9/10 star']\n"
     ]
    }
   ],
   "source": [
    "# Build an accuracy function excluding those -1\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "threshold=None\n",
    "highest_confidence_related=True\n",
    "\n",
    "for corpus in X_train_original[1:5]:\n",
    "    '''\n",
    "    Breakdown the corpus into sentence and transform into bag-of-words\n",
    "    '''\n",
    "    sentence_set = tf_vectorizer.transform(TextBlob(corpus).raw_sentences)\n",
    "    \n",
    "    '''\n",
    "    Related classifier given threshold. \n",
    "    threshold, if None, it only predict the label. If float number given, assign the threshold to the sentence with\n",
    "    probability over threshold\n",
    "    '''\n",
    "    if threshold==None:\n",
    "        y_ind_proba = clf_A.predict_proba(sentence_set)\n",
    "        y_ind = clf_A.predict(sentence_set)\n",
    "    else:\n",
    "        y_ind_proba = clf_A.predict_proba(sentence_set)\n",
    "        y_ind = y_ind_proba[:,1]>threshold\n",
    "        \n",
    "    '''\n",
    "    +/- classifier given the sentences from the previous classifier\n",
    "    if 0, assign the label as -1 (which means it does not have any related sentence)\n",
    "    else, classify the sentence into +/- label according to the given sentence. \n",
    "    '''\n",
    "    if np.sum(y_ind) == 0:\n",
    "        y_pred.append(-1)\n",
    "        continue\n",
    "    else:\n",
    "        if highest_confidence_related:\n",
    "            indices = np.array(np.argmax(y_ind_proba[:,1])).flatten()\n",
    "            y = clf_1.predict(sentence_set[indices, :])\n",
    "            y_pred.append(y)\n",
    "        else:\n",
    "            indices = np.array(np.where(y_ind[:,1] == 1)).flatten()\n",
    "            y_np_proba = clf_1.predict_proba(sentence_set[indices, :])\n",
    "            y_neg_proba = np.max(y_np_proba[:,0])\n",
    "            y_pos_proba = np.max(y_np_proba[:,1])\n",
    "\n",
    "            if y_pos_proba > y_neg_proba:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "\n",
    "     \n",
    "    \n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_original[1:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
