{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_pickle\n",
    "\n",
    "def open_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset of sentence [relevant,-relevant]\n",
    "\n",
    "X_train_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_xtrain.pickle')\n",
    "X_test_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_xtest.pickle')\n",
    "y_train_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_ytrain.pickle')\n",
    "y_test_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_ytest.pickle')\n",
    "\n",
    "#Load dataset of [whole corpus]\n",
    "\n",
    "X_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtrain.pickle')\n",
    "X_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_xtest.pickle')\n",
    "y_train_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytrain.pickle')\n",
    "y_test_original = open_pickle('../data/imdb/imdb_original_preprocessed_ytest.pickle')\n",
    "\n",
    "#Load dataset of sentence [+/-]\n",
    "\n",
    "X_train_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_xtrain.pickle')\n",
    "X_test_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_xtest.pickle')\n",
    "y_train_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_ytrain.pickle')\n",
    "y_test_np_sentence = open_pickle('../data/imdb-sentence/imdb_sentence_np_ytest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1333"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "667"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26266\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer on rel,unrel dataset\n",
    "# Question : Why rel/unrel? Because it trained as the first step? \n",
    "# Any advantages on more vocabulary?\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "tf_vectorizer = CountVectorizer(lowercase=True, max_df=1.0, min_df=5, binary=True, token_pattern=token)\n",
    "tf_vectorizer.set_params(ngram_range=(1,1))\n",
    "\n",
    "# whole imdb corpus\n",
    "X_train_original_bow = tf_vectorizer.fit_transform(X_train_original)\n",
    "X_test_original_bow = tf_vectorizer.transform(X_test_original)\n",
    "\n",
    "# rel/unrel sentence\n",
    "X_train_sentence_bow = tf_vectorizer.transform(X_train_sentence)\n",
    "X_test_sentence_bow = tf_vectorizer.transform(X_test_sentence)\n",
    "\n",
    "# neg/pos sentence\n",
    "X_train_np_bow = tf_vectorizer.transform(X_train_np_sentence)\n",
    "X_test_np_bow = tf_vectorizer.transform(X_test_np_sentence) \n",
    "\n",
    "words = tf_vectorizer.get_feature_names()\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_vectorizer.fit(X_train_sentence)\n",
    "# print(len(tf_vectorizer.get_feature_names()))\n",
    "# 546 for sentence dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfIdf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26266\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(lowercase=True, max_df=1.0, min_df=5, token_pattern=token)\n",
    "\n",
    "X_train_original_tf = tfidf_vect.fit_transform(X_train_original)\n",
    "X_test_original_tf = tfidf_vect.transform(X_test_original)\n",
    "\n",
    "# rel/unrel sentence\n",
    "X_train_sentence_tf = tfidf_vect.transform(X_train_sentence)\n",
    "X_test_sentence_tf = tfidf_vect.transform(X_test_sentence)\n",
    "\n",
    "\n",
    "\n",
    "# neg/pos sentence\n",
    "X_train_np_tf = tfidf_vect.transform(X_train_np_sentence)\n",
    "X_test_np_tf = tfidf_vect.transform(X_test_np_sentence) \n",
    "\n",
    "words = tfidf_vect.get_feature_names()\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 25572)\t0.16648658547419504\n",
      "  (0, 24629)\t0.44979268693691304\n",
      "  (0, 23418)\t0.15287236514401725\n",
      "  (0, 20922)\t0.19081584193860818\n",
      "  (0, 16602)\t0.27256102198457793\n",
      "  (0, 16323)\t0.0798474583391674\n",
      "  (0, 8846)\t0.46566203926716615\n",
      "  (0, 3805)\t0.517173250795398\n",
      "  (0, 2293)\t0.3124435255035184\n",
      "  (0, 1583)\t0.2181575577087448\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sentence_tf[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train A [rel,unrel] classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "C=1.00\n",
      "--------------\n",
      "Accuracy\n",
      "Train:\t0.98425 \n",
      "Test:\t0.75862 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.73      0.77       363\n",
      "        1.0       0.71      0.79      0.75       304\n",
      "\n",
      "avg / total       0.76      0.76      0.76       667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Okay... Using the function makes me more overwhelmed. Let's do it manually.\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "C = 1\n",
    "\n",
    "clf_A = LogisticRegression(random_state=random_state, C=C)\n",
    "clf_A.fit(X_train_sentence_bow, y_train_sentence)\n",
    "\n",
    "y_predict = clf_A.predict(X_test_sentence_bow)\n",
    "\n",
    "print('--------------')\n",
    "print('C=%.2f' %(C))\n",
    "print('--------------')\n",
    "print('Accuracy')\n",
    "print('Train:\\t%.5f ' %(clf_A.score(X_train_sentence_bow, y_train_sentence)))\n",
    "print('Test:\\t%.5f ' %(clf_A.score(X_test_sentence_bow, y_test_sentence)))\n",
    "    \n",
    "print(classification_report(y_test_sentence,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 1 [+,-] classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using whole corpus\n",
    "clf_1_i = LogisticRegression(random_state=random_state, C=C)\n",
    "clf_1_i.fit(X_train_original_bow, y_train_original)\n",
    "\n",
    "# using the [+/-] sentence\n",
    "\n",
    "clf_1_j = LogisticRegression(random_state=random_state, C=C)\n",
    "clf_1_j.fit(X_train_np_bow, y_train_np_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "C=1.00\n",
      "--------------\n",
      "Accuracy\n",
      "Train:\t0.99672 \n",
      "Test:\t0.87304 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.88      0.87     12500\n",
      "          1       0.88      0.87      0.87     12500\n",
      "\n",
      "avg / total       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test baseline\n",
    "\n",
    "y_predict = clf_1_i.predict(X_test_original_bow)\n",
    "\n",
    "print('--------------')\n",
    "print('C=%.2f' %(C))\n",
    "print('--------------')\n",
    "print('Accuracy')\n",
    "print('Train:\\t%.5f ' %(clf_1_i.score(X_train_original_bow, y_train_original)))\n",
    "print('Test:\\t%.5f ' %(clf_1_i.score(X_test_original_bow, y_test_original)))\n",
    "    \n",
    "print(classification_report(y_test_original,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "C=1.00\n",
      "--------------\n",
      "Accuracy\n",
      "Train:\t0.99099 \n",
      "Test:\t0.76946 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.72      0.75       163\n",
      "        1.0       0.75      0.82      0.78       171\n",
      "\n",
      "avg / total       0.77      0.77      0.77       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test baseline\n",
    "\n",
    "y_predict = clf_1_j.predict(X_test_np_bow)\n",
    "\n",
    "print('--------------')\n",
    "print('C=%.2f' %(C))\n",
    "print('--------------')\n",
    "print('Accuracy')\n",
    "print('Train:\\t%.5f ' %(clf_1_j.score(X_train_np_bow, y_train_np_sentence)))\n",
    "print('Test:\\t%.5f ' %(clf_1_j.score(X_test_np_bow, y_test_np_sentence)))\n",
    "    \n",
    "print(classification_report(y_test_np_sentence,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the real deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an accuracy function excluding those -1\n",
    "\n",
    "def nested_classifier(clf_A, clf_1_i, X_test_original, tf, threshold):\n",
    "    y_pred_i = []\n",
    "#     y_pred_j = []\n",
    "    \n",
    "    for ind, corpus in enumerate(X_test_original):\n",
    "        '''\n",
    "        Breakdown the corpus into sentence and transform into bag-of-words\n",
    "        '''\n",
    "        sentence_set = tf.transform(TextBlob(corpus).raw_sentences)\n",
    "\n",
    "        '''\n",
    "        related sentence classifier\n",
    "        '''\n",
    "        y_A_proba = clf_A.predict_proba(sentence_set)\n",
    "        mu, mr = np.argmax(y_A_proba, axis=0)\n",
    "\n",
    "        '''\n",
    "        +/- classifier\n",
    "        '''\n",
    "        if y_A_proba[mr,1] > threshold:\n",
    "            y_i_proba = clf_1_i.predict_proba(sentence_set[mr])\n",
    "            y_pred_i.append(np.argmax(y_i_proba))\n",
    "\n",
    "#             y_j_proba = clf_1_j.predict_proba(sentence_set[mr])\n",
    "#             y_pred_j.append(np.argmax(y_j_proba))\n",
    "        else:\n",
    "            y_pred_i.append(-1)\n",
    "#             y_pred_j.append(-1)\n",
    "            continue\n",
    "            \n",
    "#     return np.array(y_pred_i), np.array(y_pred_j)\n",
    "    return np.asarray(y_pred_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_rate(y):\n",
    "    return np.sum(y==-1)/len(y)\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    return np.sum(y_pred==y)/(np.sum(y_pred==1) + np.sum(y_pred==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.arange(0.5, 1, 0.05)\n",
    "threshold = np.append(threshold, [0.96, 0.97, 0.98, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50 \t 483 \t 0.01932 \t 0.75911\n",
      "0.55 \t 611 \t 0.02444 \t 0.75956\n",
      "0.60 \t 786 \t 0.03144 \t 0.76014\n",
      "0.65 \t 1037 \t 0.04148 \t 0.76117\n",
      "0.70 \t 1380 \t 0.05520 \t 0.76194\n",
      "0.75 \t 1888 \t 0.07552 \t 0.76315\n",
      "0.80 \t 2621 \t 0.10484 \t 0.76460\n",
      "0.85 \t 3811 \t 0.15244 \t 0.76927\n",
      "0.90 \t 5975 \t 0.23900 \t 0.77593\n",
      "0.95 \t 10408 \t 0.41632 \t 0.78570\n",
      "0.96 \t 11884 \t 0.47536 \t 0.78614\n",
      "0.97 \t 13749 \t 0.54996 \t 0.79042\n",
      "0.98 \t 16057 \t 0.64228 \t 0.79582\n",
      "0.99 \t 19392 \t 0.77568 \t 0.80118\n"
     ]
    }
   ],
   "source": [
    "# cv\n",
    "\n",
    "lr_relevant = LogisticRegression(random_state=random_state)\n",
    "lr_relevant.fit(X_train_sentence_bow, y_train_sentence)\n",
    "\n",
    "lr_sentiment = LogisticRegression(random_state=random_state)\n",
    "lr_sentiment.fit(X_train_original_bow, y_train_original)\n",
    "\n",
    "\n",
    "lr_pred = []\n",
    "for t in threshold :\n",
    "    y_pred = nested_classifier(lr_relevant, lr_sentiment, X_test_original, tf_vectorizer, t)\n",
    "    lr_pred.append(y_pred)\n",
    "    print('%.2f \\t %d \\t %.5f \\t %.5f' %(t, np.sum(y_pred==-1), rejection_rate(y_pred), accuracy(y_test_original, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50 \t 784 \t 0.03136 \t 0.77994\n",
      "0.55 \t 2069 \t 0.08276 \t 0.78204\n",
      "0.60 \t 4553 \t 0.18212 \t 0.78740\n",
      "0.65 \t 7959 \t 0.31836 \t 0.79514\n",
      "0.70 \t 11997 \t 0.47988 \t 0.80328\n",
      "0.75 \t 16051 \t 0.64204 \t 0.81249\n",
      "0.80 \t 19425 \t 0.77700 \t 0.82422\n",
      "0.85 \t 22095 \t 0.88380 \t 0.83236\n",
      "0.90 \t 23859 \t 0.95436 \t 0.82559\n",
      "0.95 \t 24786 \t 0.99144 \t 0.82710\n",
      "0.96 \t 24865 \t 0.99460 \t 0.83704\n",
      "0.97 \t 24934 \t 0.99736 \t 0.83333\n",
      "0.98 \t 24978 \t 0.99912 \t 1.00000\n",
      "0.99 \t 25000 \t 1.00000 \t nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anneke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# tfidf\n",
    "\n",
    "lr_relevant_tfidf = LogisticRegression(random_state=random_state)\n",
    "lr_relevant_tfidf.fit(X_train_sentence_tf, y_train_sentence)\n",
    "\n",
    "lr_sentiment_tfidf = LogisticRegression(random_state=random_state)\n",
    "lr_sentiment_tfidf.fit(X_train_original_tf, y_train_original)\n",
    "\n",
    "\n",
    "lr_pred_tf = []\n",
    "for t in threshold :\n",
    "    y_pred = nested_classifier(lr_relevant_tfidf, lr_sentiment_tfidf, X_test_original, tfidf_vect, t)\n",
    "    lr_pred_tf.append(y_pred)\n",
    "    print('%.2f \\t %d \\t %.5f \\t %.5f' %(t, np.sum(y_pred==-1), rejection_rate(y_pred), accuracy(y_test_original, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50 \t 344 \t 0.01376 \t 0.76071\n",
      "0.55 \t 426 \t 0.01704 \t 0.76137\n",
      "0.60 \t 487 \t 0.01948 \t 0.76168\n",
      "0.65 \t 560 \t 0.02240 \t 0.76211\n",
      "0.70 \t 669 \t 0.02676 \t 0.76253\n",
      "0.75 \t 798 \t 0.03192 \t 0.76312\n",
      "0.80 \t 989 \t 0.03956 \t 0.76361\n",
      "0.85 \t 1337 \t 0.05348 \t 0.76457\n",
      "0.90 \t 1862 \t 0.07448 \t 0.76549\n",
      "0.95 \t 3195 \t 0.12780 \t 0.76803\n",
      "0.96 \t 3697 \t 0.14788 \t 0.76900\n",
      "0.97 \t 4423 \t 0.17692 \t 0.76940\n",
      "0.98 \t 5685 \t 0.22740 \t 0.77080\n",
      "0.99 \t 8148 \t 0.32592 \t 0.77694\n"
     ]
    }
   ],
   "source": [
    "# CV\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb_relevant = MultinomialNB()\n",
    "mnb_relevant.fit(X_train_sentence_bow, y_train_sentence)\n",
    "\n",
    "mnb_sentiment = MultinomialNB()\n",
    "mnb_sentiment.fit(X_train_original_bow, y_train_original)\n",
    "\n",
    "mnb_pred = []\n",
    "for t in threshold :\n",
    "    y_pred = nested_classifier(mnb_relevant, mnb_sentiment, X_test_original, tf_vectorizer, t)\n",
    "    mnb_pred.append(y_pred)\n",
    "    print('%.2f \\t %d \\t %.5f \\t %.5f' %(t, np.sum(y_pred==-1), rejection_rate(y_pred), accuracy(y_test_original, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50 \t 112 \t 0.00448 \t 0.76909\n",
      "0.55 \t 346 \t 0.01384 \t 0.76961\n",
      "0.60 \t 976 \t 0.03904 \t 0.77085\n",
      "0.65 \t 2544 \t 0.10176 \t 0.77467\n",
      "0.70 \t 5624 \t 0.22496 \t 0.78102\n",
      "0.75 \t 10199 \t 0.40796 \t 0.79278\n",
      "0.80 \t 15371 \t 0.61484 \t 0.80870\n",
      "0.85 \t 20190 \t 0.80760 \t 0.84304\n",
      "0.90 \t 23562 \t 0.94248 \t 0.88595\n",
      "0.95 \t 24911 \t 0.99644 \t 0.96629\n",
      "0.96 \t 24988 \t 0.99952 \t 1.00000\n",
      "0.97 \t 24999 \t 0.99996 \t 1.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anneke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98 \t 25000 \t 1.00000 \t nan\n",
      "0.99 \t 25000 \t 1.00000 \t nan\n"
     ]
    }
   ],
   "source": [
    "# tfidf\n",
    "\n",
    "mnb_relevant_tf = MultinomialNB()\n",
    "mnb_relevant_tf.fit(X_train_sentence_tf, y_train_sentence)\n",
    "\n",
    "mnb_sentiment_tf = MultinomialNB()\n",
    "mnb_sentiment_tf.fit(X_train_original_tf, y_train_original)\n",
    "\n",
    "mnb_pred_tf = []\n",
    "for t in threshold :\n",
    "    y_pred = nested_classifier(mnb_relevant_tf, mnb_sentiment_tf, X_test_original, tfidf_vect, t)\n",
    "    mnb_pred_tf.append(y_pred)\n",
    "    print('%.2f \\t %d \\t %.5f \\t %.5f' %(t, np.sum(y_pred==-1), rejection_rate(y_pred), accuracy(y_test_original, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87304\n",
      "0.83476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "base_lr = LogisticRegression(random_state=random_state)\n",
    "base_lr.fit(X_train_original_bow, y_train_original)\n",
    "\n",
    "print(base_lr.score(X_test_original_bow, y_test_original))\n",
    "\n",
    "base_mnb = MultinomialNB()\n",
    "base_mnb.fit(X_train_original_bow, y_train_original)\n",
    "\n",
    "print(base_mnb.score(X_test_original_bow, y_test_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88792\n",
      "0.83408\n"
     ]
    }
   ],
   "source": [
    "base_lr_tf = LogisticRegression(random_state=random_state)\n",
    "base_lr_tf.fit(X_train_original_tf, y_train_original)\n",
    "\n",
    "print(base_lr_tf.score(X_test_original_tf, y_test_original))\n",
    "\n",
    "base_mnb_tf = MultinomialNB()\n",
    "base_mnb_tf.fit(X_train_original_tf, y_train_original)\n",
    "\n",
    "print(base_mnb_tf.score(X_test_original_tf, y_test_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# np.savetxt('cos_sim.csv', np.around(cos_sim,2), delimiter=',')\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have been following Marvel’s movies, until this Black Panther movie came out. [0.41722985 0.58277015]\n",
      "To be honest, it was a good movie. [0.03844995 0.96155005]\n",
      "However, it was boring in the middle. [0.3612379 0.6387621]\n",
      "The scenario contains mainstream storyline. [0.66960472 0.33039528]\n",
      "I feel like I am watching a Disney movie rather than Marvel. [0.2986911 0.7013089]\n",
      "Lack of action, but still very entertaining. [0.04510595 0.95489405]\n",
      "I watched it on my flight during the turbulence. [0.86232269 0.13767731]\n",
      "At least, it did makes me distracted from the motion sickness. [0.7270355 0.2729645]\n",
      "Good movie, recommended to all ages. [0.03508099 0.96491901]\n",
      "\n",
      "Good movie, recommended to all ages. [0.03508099 0.96491901]\n",
      "I watched it on my flight during the turbulence. [0.86232269 0.13767731]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.21747813, 0.78252187]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp = \"I have been following Marvel’s movies, until this Black Panther movie came out. To be honest, it was a good movie. However, it was boring in the middle. The scenario contains mainstream storyline. I feel like I am watching a Disney movie rather than Marvel. Lack of action, but still very entertaining. I watched it on my flight during the turbulence. At least, it did makes me distracted from the motion sickness. Good movie, recommended to all ages.\"\n",
    "\n",
    "sent = tf_vectorizer.transform(TextBlob(corp).raw_sentences)\n",
    "\n",
    "\n",
    "y_A_proba = clf_A.predict_proba(sent)\n",
    "mu, mr = np.argmax(y_A_proba, axis=0)\n",
    "\n",
    "for i in range(y_A_proba.shape[0]):\n",
    "    print(TextBlob(corp).raw_sentences[i], y_A_proba[i])\n",
    "\n",
    "print()\n",
    "print(TextBlob(corp).raw_sentences[mr], y_A_proba[mr])\n",
    "print(TextBlob(corp).raw_sentences[mu], y_A_proba[mu])\n",
    "\n",
    "y_proba = clf_1_i.predict_proba(sent[mr])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19116551 0.80883449]\n",
      " [0.19116551 0.80883449]]\n"
     ]
    }
   ],
   "source": [
    "corps = list([corp, corp])\n",
    "x_corp = tf_vectorizer.transform(corps)\n",
    "# x_corp.shape\n",
    "y = clf_1_i.predict_proba(x_corp)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look on the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_vocab = []\n",
    "filelist = glob.glob(os.path.join(\"../data/human-provided-phrases\", \"*.txt\"))\n",
    "for file in filelist:\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            human_vocab.append(line.split('\\t')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2/10',\n",
       " '3/10',\n",
       " '7/10',\n",
       " '4/10',\n",
       " '8/10',\n",
       " '1/10',\n",
       " 'unwatchable',\n",
       " 'incoherent',\n",
       " 'stinker',\n",
       " 'mst3k',\n",
       " 'unfunny',\n",
       " 'waste',\n",
       " '9/10',\n",
       " 'flawless',\n",
       " 'atrocious',\n",
       " 'pointless',\n",
       " 'horrid',\n",
       " 'superbly',\n",
       " 'redeeming',\n",
       " '10/10',\n",
       " 'laughable',\n",
       " 'drivel',\n",
       " 'worst',\n",
       " 'perfection',\n",
       " 'lousy',\n",
       " 'awful',\n",
       " 'wasting',\n",
       " 'remotely',\n",
       " 'poorly',\n",
       " 'sucks',\n",
       " 'captures',\n",
       " 'wonderfully',\n",
       " 'existent',\n",
       " 'lame',\n",
       " 'boredom',\n",
       " 'uninspired',\n",
       " 'miserably',\n",
       " 'refreshing',\n",
       " 'amateurish',\n",
       " 'unintentional',\n",
       " 'pathetic',\n",
       " 'eathtaking',\n",
       " 'appalling',\n",
       " 'uninteresting',\n",
       " 'unconvincing',\n",
       " 'suck',\n",
       " 'delightful',\n",
       " 'idiotic',\n",
       " 'wasted',\n",
       " 'beautifully',\n",
       " 'underrated',\n",
       " 'crap',\n",
       " 'stupidity',\n",
       " 'dreadful',\n",
       " 'tedious',\n",
       " 'sadness',\n",
       " 'horrible',\n",
       " 'insulting',\n",
       " 'dire',\n",
       " 'mess',\n",
       " 'superb',\n",
       " 'gripping',\n",
       " 'garbage',\n",
       " 'timeless',\n",
       " 'embarrassing',\n",
       " 'badly',\n",
       " 'insult',\n",
       " 'terrible',\n",
       " 'wooden',\n",
       " 'touching',\n",
       " 'worse',\n",
       " 'cardboard',\n",
       " 'unforgettable',\n",
       " 'extraordinary',\n",
       " 'inept',\n",
       " 'stupid',\n",
       " 'pile',\n",
       " 'worthless',\n",
       " 'ashamed',\n",
       " 'junk',\n",
       " 'illiantly',\n",
       " 'forgettable',\n",
       " 'dull',\n",
       " 'marvelous',\n",
       " 'rubbish',\n",
       " 'terrific',\n",
       " 'finest',\n",
       " 'turkey',\n",
       " 'magnificent',\n",
       " 'pleasantly',\n",
       " 'splendid',\n",
       " 'whatsoever',\n",
       " 'avoid',\n",
       " 'ralph',\n",
       " 'moron',\n",
       " 'tremendous',\n",
       " 'ridiculous',\n",
       " 'outstanding',\n",
       " 'delight',\n",
       " 'wonderful',\n",
       " 'this crap',\n",
       " 'worst film',\n",
       " 'save this',\n",
       " 'worst movie',\n",
       " 'this mess',\n",
       " 'waste your',\n",
       " 'awful the',\n",
       " 'well worth',\n",
       " 'highly recommended',\n",
       " 'save your',\n",
       " 'waste of',\n",
       " 'avoid this',\n",
       " 'is awful',\n",
       " 'not waste',\n",
       " 'was awful',\n",
       " 'is worse',\n",
       " 'definitely worth',\n",
       " 'awful i',\n",
       " 'skip this',\n",
       " 'was terrible',\n",
       " 'how bad',\n",
       " 'your money',\n",
       " 'not funny',\n",
       " 'awful and',\n",
       " 'poorly written',\n",
       " 'captures the',\n",
       " 'all cost',\n",
       " 'terrible the',\n",
       " 'a waste',\n",
       " 'first rate',\n",
       " 'is perfect',\n",
       " 'is terrible',\n",
       " 'bad acting',\n",
       " 'only good',\n",
       " 'even worse',\n",
       " 'of crap',\n",
       " 'loved this',\n",
       " 'no plot',\n",
       " 'the worst',\n",
       " 'not worth',\n",
       " 'this piece',\n",
       " 'an insult',\n",
       " 'excellent as',\n",
       " 'redeeming quality',\n",
       " 'insult to',\n",
       " 'is wonderful',\n",
       " 'a must',\n",
       " 'my money',\n",
       " 'money on',\n",
       " 'a 1',\n",
       " 'is horrible',\n",
       " 'so bad',\n",
       " 'walked out',\n",
       " 'bad this',\n",
       " 'worse than',\n",
       " 'bad movie',\n",
       " 'fast forward',\n",
       " 'not scary',\n",
       " 'favorite movie',\n",
       " 'is illiant',\n",
       " 'a 2',\n",
       " 'highly recommend',\n",
       " 'really bad',\n",
       " 'this thing',\n",
       " 'your time',\n",
       " 'non existent',\n",
       " 'minute into',\n",
       " 'a disappointment',\n",
       " 'pile of',\n",
       " 'to waste',\n",
       " 'is superb',\n",
       " 'loved it',\n",
       " 'absolutely no',\n",
       " 'worst of',\n",
       " 'bad film',\n",
       " 'was bad',\n",
       " 'is excellent',\n",
       " 'great job',\n",
       " 'bad i',\n",
       " 'pleasantly surprised',\n",
       " 'is fantastic',\n",
       " 'very bad',\n",
       " 'excellent and',\n",
       " 'ridiculous and',\n",
       " 'must see',\n",
       " 'a superb',\n",
       " 'excuse for',\n",
       " 'bad it',\n",
       " 'is bad',\n",
       " 'stupid and',\n",
       " 'not recommend',\n",
       " 'pretty bad',\n",
       " 'and boring',\n",
       " 'bad the',\n",
       " 'be funny',\n",
       " 'at best',\n",
       " 'no sense',\n",
       " 'my time',\n",
       " 'annoying and',\n",
       " 'sit through',\n",
       " 'worst movie i',\n",
       " 'worst film i',\n",
       " 'the worst film',\n",
       " 'the worst movie',\n",
       " 'excuse for a',\n",
       " 'piece of crap',\n",
       " 'not waste your',\n",
       " 'i love this',\n",
       " 'do not waste',\n",
       " 'of the worst',\n",
       " 'waste your time',\n",
       " 'waste of time',\n",
       " 'worst movie ever',\n",
       " 'i loved this',\n",
       " 'was so bad',\n",
       " 'the only good',\n",
       " 'this piece of',\n",
       " 'a waste of',\n",
       " 'must see for',\n",
       " 'highly recommend this',\n",
       " 'is so bad',\n",
       " 'is the worst',\n",
       " 'at all cost',\n",
       " 'is not worth',\n",
       " 'is not funny',\n",
       " 'would not recommend',\n",
       " 'i loved it',\n",
       " 'so bad that',\n",
       " 'is a must',\n",
       " 'a must see',\n",
       " 'so bad it',\n",
       " 'is not even',\n",
       " 'of my life',\n",
       " 'i highly recommend',\n",
       " 'not the worst',\n",
       " 'not recommend this',\n",
       " 'unless you are',\n",
       " 'the best movie',\n",
       " 'do not bother',\n",
       " 'to sit through',\n",
       " 'bad it is',\n",
       " 'to be funny',\n",
       " 'is an excellent',\n",
       " 'not watch this',\n",
       " 'it is great',\n",
       " 'the worst of',\n",
       " 'of the best',\n",
       " 'a great job',\n",
       " 'do not even',\n",
       " 'is just plain',\n",
       " 'there is absolutely',\n",
       " 'first saw this',\n",
       " 'the best film',\n",
       " 'do not miss',\n",
       " 'not a good',\n",
       " 'with a great',\n",
       " 'not enough to',\n",
       " 'very well done',\n",
       " 'that is it',\n",
       " 'better than this',\n",
       " 'love this movie',\n",
       " 'that is about',\n",
       " 'is very good',\n",
       " 'i am sorry',\n",
       " 'makes no sense',\n",
       " 'are supposed to',\n",
       " 'is a wonderful',\n",
       " 'adds to the',\n",
       " 'does not even',\n",
       " 'going for it',\n",
       " 'can not wait',\n",
       " 'you will love',\n",
       " 'as bad as',\n",
       " 'at all and',\n",
       " 'a bad movie',\n",
       " 'i really enjoyed',\n",
       " 'is a great',\n",
       " 'does not work',\n",
       " 'make a movie',\n",
       " 'is beyond me',\n",
       " 'a good idea',\n",
       " 'this could have',\n",
       " 'i recommend this',\n",
       " 'see it again',\n",
       " 'my all time',\n",
       " 'would love to',\n",
       " 'can not even',\n",
       " 'i first saw',\n",
       " 'is supposed to',\n",
       " 'supposed to be',\n",
       " 'please do not',\n",
       " 'trying to be',\n",
       " 'of my favorite',\n",
       " 'lot of fun',\n",
       " 'a great film',\n",
       " 'what the hell',\n",
       " 'one of my',\n",
       " 'problem with this',\n",
       " 'is not for',\n",
       " 'the only reason',\n",
       " 'worst film i have',\n",
       " 'worst movie i have',\n",
       " 'the worst film i',\n",
       " 'the worst movie i',\n",
       " 'of the worst movie',\n",
       " 'do not waste your',\n",
       " 'one of the worst',\n",
       " 'not waste your time',\n",
       " 'the worst movie ever',\n",
       " 'a waste of time',\n",
       " 'it is not even',\n",
       " 'a must see for',\n",
       " 'this is a great',\n",
       " 'is a must see',\n",
       " 'so bad it is',\n",
       " 'do not watch this',\n",
       " 'one of the best',\n",
       " 'it is a great',\n",
       " 'supposed to be a',\n",
       " 'i first saw this',\n",
       " 'are supposed to be',\n",
       " 'is one of my',\n",
       " 'some of the best',\n",
       " 'is supposed to be',\n",
       " 'one of my favorite',\n",
       " 'one of the greatest',\n",
       " 'is the story of',\n",
       " 'to make a movie',\n",
       " 'want to see a',\n",
       " 'have not seen it',\n",
       " 'the best of the',\n",
       " 'the only reason i',\n",
       " 'a lot of fun',\n",
       " 'hour and a half',\n",
       " 'movie i have ever',\n",
       " 'it is supposed to',\n",
       " 'i can not believe',\n",
       " 'this movie was a',\n",
       " 'was supposed to be',\n",
       " 'for the first time',\n",
       " 'but it is a',\n",
       " 'it is not that',\n",
       " 'nothing to do with',\n",
       " 'film i have ever',\n",
       " 'do not get me',\n",
       " 'all in all a',\n",
       " 'this is a very',\n",
       " 'rest of the movie',\n",
       " 'you want to see',\n",
       " 'could have been a',\n",
       " 'i think it is',\n",
       " 'it is a very',\n",
       " 'in the first place',\n",
       " 'this is a good',\n",
       " 'not get me wrong',\n",
       " 'the only thing that',\n",
       " 'i have seen this',\n",
       " 'if you want to',\n",
       " 'you will not be',\n",
       " 'at the same time',\n",
       " 'if you want a',\n",
       " 'to do with the',\n",
       " 'it is one of',\n",
       " 'have ever seen i',\n",
       " 'the first time i',\n",
       " 'for what it is',\n",
       " 'as well as the',\n",
       " 'have ever seen the',\n",
       " 'i have seen it',\n",
       " 'have ever seen and',\n",
       " 'i do not like',\n",
       " 'is a film that',\n",
       " 'it is a good',\n",
       " 'if you have not',\n",
       " 'would have been a',\n",
       " 'you have not seen',\n",
       " 'the story of the',\n",
       " 'is not one of',\n",
       " 'one of the few',\n",
       " 'you are going to',\n",
       " 'the story of a',\n",
       " 'it would be a',\n",
       " 'when i was a',\n",
       " 'this movie does not',\n",
       " 'is one of the',\n",
       " 'if you are not',\n",
       " 'it could have been',\n",
       " 'as one of the',\n",
       " 'then there is the',\n",
       " 'for the sake of',\n",
       " 'thing about this movie',\n",
       " 'was going to be',\n",
       " 'as good as the',\n",
       " 'with the exception of',\n",
       " 'but i can not',\n",
       " 'and it is a',\n",
       " 'about this movie is',\n",
       " 'i have seen the',\n",
       " 'i have seen a',\n",
       " 'i am a big',\n",
       " 'the worst film i have',\n",
       " 'the worst movie i have',\n",
       " 'worst movie i have ever',\n",
       " 'one of the worst movie',\n",
       " 'is one of the worst',\n",
       " 'do not waste your time',\n",
       " 'is one of the best',\n",
       " 'is supposed to be a',\n",
       " 'movie i have ever seen',\n",
       " 'if you want to see',\n",
       " 'the rest of the movie',\n",
       " 'film i have ever seen',\n",
       " 'i have ever seen the',\n",
       " 'do not get me wrong',\n",
       " 'if you have not seen',\n",
       " 'i have ever seen and',\n",
       " 'it is one of the',\n",
       " 'i do not know what',\n",
       " 'i have ever seen i',\n",
       " 'is one of the most',\n",
       " 'i have ever seen in',\n",
       " 'this is one of the',\n",
       " 'in the middle of the',\n",
       " 'if you are looking for',\n",
       " 'to be one of the',\n",
       " 'the end of the movie',\n",
       " 'the rest of the film',\n",
       " 'i have seen in a',\n",
       " 'i do not want to',\n",
       " 'there is a lot of',\n",
       " 'at the end of the',\n",
       " 'at the beginning of the',\n",
       " 'the end of the film',\n",
       " 'i do not know if',\n",
       " 'the rest of the cast',\n",
       " 'by the end of the',\n",
       " 'and the rest of the',\n",
       " 'if you are a fan',\n",
       " 'is one of those movie',\n",
       " 'you are a fan of',\n",
       " 'this is one of those']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_vectorizer = CountVectorizer(lowercase=True, max_df=1.0, min_df=5, binary=True, token_pattern=token, vocabulary=human_vocab)\n",
    "human_vectorizer.set_params(ngram_range=(1,1))\n",
    "\n",
    "# whole imdb corpus\n",
    "X_tr_org_hum_bow = human_vectorizer.fit_transform(X_train_original)\n",
    "X_te_org_hum_bow = human_vectorizer.transform(X_test_original)\n",
    "\n",
    "# rel/unrel sentence\n",
    "X_tr_sent_hum_bow = human_vectorizer.transform(X_train_sentence)\n",
    "X_te_sent_hum_bow = human_vectorizer.transform(X_test_sentence)\n",
    "\n",
    "\n",
    "# neg/pos sentence\n",
    "X_tr_np_hum_bow = human_vectorizer.transform(X_train_np_sentence)\n",
    "X_te_np_hum_bow = human_vectorizer.transform(X_test_np_sentence) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del clf_A\n",
    "del clf_1_i\n",
    "del clf_1_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "CLF A\n",
      "C=1.00\n",
      "--------------\n",
      "Accuracy\n",
      "Train:\t0.56864 \n",
      "Test:\t0.62069 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.59      0.98      0.74       363\n",
      "        1.0       0.90      0.19      0.31       304\n",
      "\n",
      "avg / total       0.73      0.62      0.54       667\n",
      "\n",
      "--------------\n",
      "CLF A-1-i\n",
      "C=1.00\n",
      "--------------\n",
      "Accuracy\n",
      "Train:\t0.79900 \n",
      "Test:\t0.79280 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.72      0.78     12500\n",
      "          1       0.76      0.86      0.81     12500\n",
      "\n",
      "avg / total       0.80      0.79      0.79     25000\n",
      "\n",
      "--------------\n",
      "CLF A-1-j\n",
      "C=1.00\n",
      "--------------\n",
      "Accuracy\n",
      "Train:\t0.67117 \n",
      "Test:\t0.65269 \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.30      0.46       163\n",
      "        1.0       0.60      0.99      0.74       171\n",
      "\n",
      "avg / total       0.77      0.65      0.60       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Okay... Using the function makes me more overwhelmed. Let's do it manually.\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "C = 1\n",
    "\n",
    "clf_A = LogisticRegression(random_state=random_state, C=C)\n",
    "clf_A.fit(X_tr_sent_hum_bow, y_train_sentence)\n",
    "\n",
    "y_predict = clf_A.predict(X_te_sent_hum_bow)\n",
    "\n",
    "print('--------------')\n",
    "print('CLF A')\n",
    "print('C=%.2f' %(C))\n",
    "print('--------------')\n",
    "print('Accuracy')\n",
    "print('Train:\\t%.5f ' %(clf_A.score(X_tr_sent_hum_bow, y_train_sentence)))\n",
    "print('Test:\\t%.5f ' %(clf_A.score(X_te_sent_hum_bow, y_test_sentence)))\n",
    "    \n",
    "print(classification_report(y_test_sentence,y_predict))\n",
    "\n",
    "# using whole corpus\n",
    "clf_1_i = LogisticRegression(random_state=random_state, C=C)\n",
    "clf_1_i.fit(X_tr_org_hum_bow, y_train_original)\n",
    "\n",
    "y_predict = clf_1_i.predict(X_te_org_hum_bow)\n",
    "\n",
    "print('--------------')\n",
    "print('CLF A-1-i')\n",
    "print('C=%.2f' %(C))\n",
    "print('--------------')\n",
    "print('Accuracy')\n",
    "print('Train:\\t%.5f ' %(clf_1_i.score(X_tr_org_hum_bow, y_train_original)))\n",
    "print('Test:\\t%.5f ' %(clf_1_i.score(X_te_org_hum_bow, y_test_original)))\n",
    "    \n",
    "print(classification_report(y_test_original,y_predict))\n",
    "\n",
    "# using the [+/-] sentence\n",
    "\n",
    "clf_1_j = LogisticRegression(random_state=random_state, C=C)\n",
    "clf_1_j.fit(X_tr_np_hum_bow, y_train_np_sentence)\n",
    "\n",
    "y_predict = clf_1_i.predict(X_te_np_hum_bow)\n",
    "\n",
    "print('--------------')\n",
    "print('CLF A-1-j')\n",
    "print('C=%.2f' %(C))\n",
    "print('--------------')\n",
    "print('Accuracy')\n",
    "print('Train:\\t%.5f ' %(clf_1_i.score(X_tr_np_hum_bow, y_train_np_sentence)))\n",
    "print('Test:\\t%.5f ' %(clf_1_i.score(X_te_np_hum_bow, y_test_np_sentence)))\n",
    "    \n",
    "print(classification_report(y_test_np_sentence,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t \t ~rel \t rr \t acc_i \t acc_j\n",
      "0.50 \t 12535 \t 0.50140 \t 0.83730 \t 0.82631\n",
      "0.55 \t 12642 \t 0.50568 \t 0.83743 \t 0.82643\n",
      "0.60 \t 14326 \t 0.57304 \t 0.84720 \t 0.84289\n",
      "0.65 \t 14877 \t 0.59508 \t 0.85024 \t 0.84807\n",
      "0.70 \t 16277 \t 0.65108 \t 0.86278 \t 0.86094\n",
      "0.75 \t 19218 \t 0.76872 \t 0.89640 \t 0.89502\n",
      "0.80 \t 21225 \t 0.84900 \t 0.90172 \t 0.90146\n",
      "0.85 \t 22962 \t 0.91848 \t 0.90922 \t 0.90726\n",
      "0.90 \t 24441 \t 0.97764 \t 0.93918 \t 0.93918\n",
      "0.95 \t 24849 \t 0.99396 \t 0.98675 \t 0.99338\n",
      "0.96 \t 24893 \t 0.99572 \t 1.00000 \t 1.00000\n",
      "0.97 \t 24947 \t 0.99788 \t 1.00000 \t 1.00000\n",
      "0.98 \t 24974 \t 0.99896 \t 1.00000 \t 1.00000\n",
      "0.99 \t 24992 \t 0.99968 \t 1.00000 \t 1.00000\n"
     ]
    }
   ],
   "source": [
    "threshold = np.arange(0.5, 1, 0.05)\n",
    "threshold = np.append(threshold, [0.96, 0.97, 0.98, 0.99])\n",
    "\n",
    "print('t \\t ~rel \\t rr \\t acc_i \\t acc_j')\n",
    "for t in threshold : \n",
    "    y_pred_i, y_pred_j = nested_classifier(X_test_original, human_vectorizer, t)\n",
    "    print('%.2f \\t %d \\t %.5f \\t %.5f \\t %.5f' %(t,\n",
    "                                                 np.sum(y_pred_i==-1),\n",
    "                                                 rejection_rate(y_pred_i), \n",
    "                                                 accuracy(y_test_original, y_pred_i), \n",
    "                                                 accuracy(y_test_original,y_pred_j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
